{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Embeddings on Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on\n",
    "# https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.2-understanding-recurrent-neural-networks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
    "max_features = 1000  # number of words to consider as features\n",
    "maxlen = 20  # cut texts after this number of words (among top max_features most common words)\n",
    "\n",
    "# each review is encoded as a sequence of word indexes\n",
    "# indexed by overall frequency in the dataset\n",
    "# output is 0 (negative) or 1 (positive) \n",
    "imdb = tf.keras.datasets.imdb.load_data(num_words=max_features)\n",
    "(raw_input_train, y_train), (raw_input_test, y_test) = imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.datasets.imdb.load_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25000 texts\n",
    "len(raw_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first text has 218 words\n",
    "len(raw_input_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 2,\n",
       " 2,\n",
       " 65,\n",
       " 458,\n",
       " 2,\n",
       " 66,\n",
       " 2,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 2,\n",
       " 2,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 2,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 2,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 2,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 2,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 2,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 2,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 2,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 2,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.preprocessing.sequence.pad_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "\n",
    "input_train = tf.keras.preprocessing.sequence.pad_sequences(raw_input_train, maxlen=maxlen)\n",
    "input_test = tf.keras.preprocessing.sequence.pad_sequences(raw_input_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 20), (25000, 20), (25000,), (25000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape, input_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65,  16,  38,   2,  88,  12,  16, 283,   5,  16,   2, 113, 103,\n",
       "        32,  15,  16,   2,  19, 178,  32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left padded with zeros\n",
    "# As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "input_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can use a randomly initialized embedding without any training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 3)             3000      \n",
      "=================================================================\n",
      "Total params: 3,000\n",
      "Trainable params: 3,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 2\n",
    "\n",
    "random_model = tf.keras.Sequential()\n",
    "# Parameters: max_features * embedding_dim \n",
    "random_model.add(tf.keras.layers.Embedding(name='embedding',input_dim=max_features, output_dim=embedding_dim, input_length=maxlen))\n",
    "\n",
    "random_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5936861 , 0.77287316, 0.02072346],\n",
       "        [0.6062163 , 0.07699966, 0.47093225],\n",
       "        [0.9561682 , 0.4152248 , 0.49542224],\n",
       "        [0.30127788, 0.5647658 , 0.26295507],\n",
       "        [0.05658948, 0.9963356 , 0.6097648 ],\n",
       "        [0.65952754, 0.34018636, 0.39102137],\n",
       "        [0.6062163 , 0.07699966, 0.47093225],\n",
       "        [0.9267534 , 0.8859894 , 0.85122645],\n",
       "        [0.4188727 , 0.59827256, 0.46787512],\n",
       "        [0.6062163 , 0.07699966, 0.47093225],\n",
       "        [0.30127788, 0.5647658 , 0.26295507],\n",
       "        [0.5868968 , 0.73676896, 0.7879758 ],\n",
       "        [0.6847576 , 0.721261  , 0.529927  ],\n",
       "        [0.14753532, 0.04975915, 0.31954753],\n",
       "        [0.9042752 , 0.6088532 , 0.4106363 ],\n",
       "        [0.6062163 , 0.07699966, 0.47093225],\n",
       "        [0.30127788, 0.5647658 , 0.26295507],\n",
       "        [0.8785337 , 0.4494549 , 0.9322605 ],\n",
       "        [0.20418513, 0.8619759 , 0.3101083 ],\n",
       "        [0.14753532, 0.04975915, 0.31954753]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.predict(input_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the embedding together with the whole model is more reasonable\n",
    "Alternative: use a pre-trained model, probably trained using skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 2)             2000      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,345\n",
      "Trainable params: 3,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 2\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Parameters: max_features * embedding_dim \n",
    "model.add(tf.keras.layers.Embedding(name='embedding', input_dim=max_features, output_dim=embedding_dim, input_length=maxlen))\n",
    "\n",
    "# Output: maxlen * embedding_dim (8)\n",
    "model.add(tf.keras.layers.Flatten(name='flatten'))\n",
    "\n",
    "# binary classifier\n",
    "model.add(tf.keras.layers.Dense(name='fc', units=32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(name='classifier', units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 2s 82us/step - loss: 0.4736 - acc: 0.7704 - val_loss: 0.5400 - val_acc: 0.7228\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 2s 76us/step - loss: 0.4731 - acc: 0.7695 - val_loss: 0.5384 - val_acc: 0.7246\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.4712 - acc: 0.7715 - val_loss: 0.5399 - val_acc: 0.7228\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 1s 75us/step - loss: 0.4695 - acc: 0.7729 - val_loss: 0.5411 - val_acc: 0.7202\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 2s 87us/step - loss: 0.4689 - acc: 0.7752 - val_loss: 0.5442 - val_acc: 0.7228\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 2s 95us/step - loss: 0.4677 - acc: 0.7733 - val_loss: 0.5438 - val_acc: 0.7228\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.4668 - acc: 0.7736 - val_loss: 0.5424 - val_acc: 0.7222\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 2s 93us/step - loss: 0.4661 - acc: 0.7751 - val_loss: 0.5423 - val_acc: 0.7238\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 2s 88us/step - loss: 0.4651 - acc: 0.7764 - val_loss: 0.5409 - val_acc: 0.7224\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 2s 96us/step - loss: 0.4641 - acc: 0.7765 - val_loss: 0.5407 - val_acc: 0.7236\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 2s 85us/step - loss: 0.4630 - acc: 0.7790 - val_loss: 0.5495 - val_acc: 0.7208\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 2s 82us/step - loss: 0.4618 - acc: 0.7779 - val_loss: 0.5424 - val_acc: 0.7246\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 1s 73us/step - loss: 0.4612 - acc: 0.7766 - val_loss: 0.5424 - val_acc: 0.7258\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.4598 - acc: 0.7788 - val_loss: 0.5433 - val_acc: 0.7248\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.4594 - acc: 0.7802 - val_loss: 0.5432 - val_acc: 0.7248\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.4588 - acc: 0.7782 - val_loss: 0.5435 - val_acc: 0.7242\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.4583 - acc: 0.7793 - val_loss: 0.5449 - val_acc: 0.7244\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.4573 - acc: 0.7800 - val_loss: 0.5460 - val_acc: 0.7240\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.4558 - acc: 0.7808 - val_loss: 0.5463 - val_acc: 0.7244\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.4549 - acc: 0.7828 - val_loss: 0.5477 - val_acc: 0.7240\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.4552 - acc: 0.7819 - val_loss: 0.5481 - val_acc: 0.7222\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.4538 - acc: 0.7826 - val_loss: 0.5522 - val_acc: 0.7190\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.4525 - acc: 0.7815 - val_loss: 0.5491 - val_acc: 0.7214\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.4511 - acc: 0.7832 - val_loss: 0.5528 - val_acc: 0.7200\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 2s 79us/step - loss: 0.4503 - acc: 0.7826 - val_loss: 0.5502 - val_acc: 0.7246\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.4508 - acc: 0.7818 - val_loss: 0.5510 - val_acc: 0.7234\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.4492 - acc: 0.7843 - val_loss: 0.5516 - val_acc: 0.7238\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.4487 - acc: 0.7844 - val_loss: 0.5522 - val_acc: 0.7256\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 1s 69us/step - loss: 0.4478 - acc: 0.7856 - val_loss: 0.5570 - val_acc: 0.7206\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 1s 74us/step - loss: 0.4469 - acc: 0.7859 - val_loss: 0.5578 - val_acc: 0.7218\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.4462 - acc: 0.7854 - val_loss: 0.5553 - val_acc: 0.7228\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.4456 - acc: 0.7852 - val_loss: 0.5564 - val_acc: 0.7240\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 1s 69us/step - loss: 0.4458 - acc: 0.7861 - val_loss: 0.5569 - val_acc: 0.7212\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.4441 - acc: 0.7863 - val_loss: 0.5557 - val_acc: 0.7226\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.4448 - acc: 0.7854 - val_loss: 0.5596 - val_acc: 0.7220\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.4425 - acc: 0.7866 - val_loss: 0.5585 - val_acc: 0.7230\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.4416 - acc: 0.7871 - val_loss: 0.5599 - val_acc: 0.7218\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.4414 - acc: 0.7872 - val_loss: 0.5618 - val_acc: 0.7222\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.4402 - acc: 0.7887 - val_loss: 0.5628 - val_acc: 0.7224\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 1s 74us/step - loss: 0.4400 - acc: 0.7892 - val_loss: 0.5628 - val_acc: 0.7218\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.4391 - acc: 0.7904 - val_loss: 0.5685 - val_acc: 0.7214\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.4374 - acc: 0.7910 - val_loss: 0.5627 - val_acc: 0.7232\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 1s 75us/step - loss: 0.4381 - acc: 0.7908 - val_loss: 0.5669 - val_acc: 0.7222\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.4377 - acc: 0.7878 - val_loss: 0.5765 - val_acc: 0.7218\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.4360 - acc: 0.7903 - val_loss: 0.5643 - val_acc: 0.7234\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.4361 - acc: 0.7907 - val_loss: 0.5705 - val_acc: 0.7204\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 1s 55us/step - loss: 0.4343 - acc: 0.7913 - val_loss: 0.5716 - val_acc: 0.7226\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 1s 73us/step - loss: 0.4336 - acc: 0.7919 - val_loss: 0.5787 - val_acc: 0.7194\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 1s 57us/step - loss: 0.4337 - acc: 0.7928 - val_loss: 0.5707 - val_acc: 0.7194\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 1s 57us/step - loss: 0.4333 - acc: 0.7915 - val_loss: 0.5718 - val_acc: 0.7238\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "%time history = model.fit(input_train, y_train, epochs=50, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def plot_history(history, samples=10, init_phase_samples=None):\n",
    "    epochs = history.params['epochs']\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "\n",
    "    every_sample =  int(epochs / samples)\n",
    "    acc = pd.DataFrame(acc).iloc[::every_sample, :]\n",
    "    val_acc = pd.DataFrame(val_acc).iloc[::every_sample, :]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "    ax.plot(acc, 'bo', label='Training acc')\n",
    "    ax.plot(val_acc, 'b', label='Validation acc')\n",
    "    ax.set_title('Training and validation accuracy')\n",
    "    ax.legend()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 28us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.780119999961853"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(input_train, y_train, batch_size=batch_size)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 21us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7199200000190735"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(input_test, y_test, batch_size=batch_size)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4178122 ],\n",
       "       [0.7546584 ],\n",
       "       [0.08093119],\n",
       "       [0.6011621 ],\n",
       "       [0.99955887]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precition\n",
    "model.predict(input_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ground truth\n",
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the output of the trained embedding look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = model.get_layer('embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stub= tf.keras.Model(inputs=model.input, outputs=embedding_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_prediction = model_stub.predict(input_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 20, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 sample reviews, 500 words per review, 8 dimensions per word\n",
    "embedding_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34398577, 1.2706754 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 embedding dimensions of first word of first sample review\n",
    "embedding_prediction[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing trained to untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65,  16,  38,   2,  88,  12,  16, 283,   5,  16,   2, 113, 103,\n",
       "        32,  15,  16,   2,  19, 178,  32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.46705735, 0.27016178],\n",
       "        [0.2602645 , 0.37189814],\n",
       "        [0.4597462 , 0.4190455 ],\n",
       "        [0.4966503 , 0.4869977 ],\n",
       "        [0.2184457 , 0.47358653],\n",
       "        [0.6243387 , 0.41245297],\n",
       "        [0.2602645 , 0.37189814],\n",
       "        [0.5351182 , 0.04236972],\n",
       "        [0.485593  , 0.19996975],\n",
       "        [0.2602645 , 0.37189814],\n",
       "        [0.4966503 , 0.4869977 ],\n",
       "        [0.6562382 , 0.41497004],\n",
       "        [0.69112915, 0.5127459 ],\n",
       "        [0.70034343, 0.52249765],\n",
       "        [0.67163855, 0.7169122 ],\n",
       "        [0.2602645 , 0.37189814],\n",
       "        [0.4966503 , 0.4869977 ],\n",
       "        [0.6260364 , 0.5533504 ],\n",
       "        [0.57491267, 0.28364214],\n",
       "        [0.70034343, 0.52249765]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stub.predict(input_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5936861 , 0.77287316, 0.02072346],\n",
       "        [0.6062163 , 0.07699966, 0.47093225],\n",
       "        [0.9561682 , 0.4152248 , 0.49542224],\n",
       "        [0.30127788, 0.5647658 , 0.26295507],\n",
       "        [0.05658948, 0.9963356 , 0.6097648 ],\n",
       "        [0.65952754, 0.34018636, 0.39102137],\n",
       "        [0.6062163 , 0.07699966, 0.47093225],\n",
       "        [0.9267534 , 0.8859894 , 0.85122645],\n",
       "        [0.4188727 , 0.59827256, 0.46787512],\n",
       "        [0.6062163 , 0.07699966, 0.47093225],\n",
       "        [0.30127788, 0.5647658 , 0.26295507],\n",
       "        [0.5868968 , 0.73676896, 0.7879758 ],\n",
       "        [0.6847576 , 0.721261  , 0.529927  ],\n",
       "        [0.14753532, 0.04975915, 0.31954753],\n",
       "        [0.9042752 , 0.6088532 , 0.4106363 ],\n",
       "        [0.6062163 , 0.07699966, 0.47093225],\n",
       "        [0.30127788, 0.5647658 , 0.26295507],\n",
       "        [0.8785337 , 0.4494549 , 0.9322605 ],\n",
       "        [0.20418513, 0.8619759 , 0.3101083 ],\n",
       "        [0.14753532, 0.04975915, 0.31954753]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.predict(input_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
