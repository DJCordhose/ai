{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on\n",
    "# https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.2-understanding-recurrent-neural-networks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
    "max_features = 10000  # number of words to consider as features\n",
    "maxlen = 500  # cut texts after this number of words (among top max_features most common words)\n",
    "\n",
    "# each review is encoded as a sequence of word indexes\n",
    "# indexed by overall frequency in the dataset\n",
    "# output is 0 (negative) or 1 (positive) \n",
    "imdb = tf.keras.datasets.imdb.load_data(num_words=max_features)\n",
    "(raw_input_train, y_train), (raw_input_test, y_test) = imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.datasets.imdb.load_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25000 texts\n",
    "len(raw_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first text has 218 words\n",
    "len(raw_input_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.preprocessing.sequence.pad_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "\n",
    "input_train = tf.keras.preprocessing.sequence.pad_sequences(raw_input_train, maxlen=maxlen)\n",
    "input_test = tf.keras.preprocessing.sequence.pad_sequences(raw_input_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 500), (25000, 500), (25000,), (25000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape, input_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    1,   14,   22,   16,\n",
       "         43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,\n",
       "        173,   36,  256,    5,   25,  100,   43,  838,  112,   50,  670,\n",
       "          2,    9,   35,  480,  284,    5,  150,    4,  172,  112,  167,\n",
       "          2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
       "         13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,\n",
       "         22,    4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,\n",
       "         43,  530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,\n",
       "         17,   12,   16,  626,   18,    2,    5,   62,  386,   12,    8,\n",
       "        316,    8,  106,    5,    4, 2223, 5244,   16,  480,   66, 3785,\n",
       "         33,    4,  130,   12,   16,   38,  619,    5,   25,  124,   51,\n",
       "         36,  135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,\n",
       "         77,   52,    5,   14,  407,   16,   82,    2,    8,    4,  107,\n",
       "        117, 5952,   15,  256,    4,    2,    7, 3766,    5,  723,   36,\n",
       "         71,   43,  530,  476,   26,  400,  317,   46,    7,    4,    2,\n",
       "       1029,   13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,\n",
       "         56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,   21,\n",
       "        134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,   36,\n",
       "         28,  224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,\n",
       "         88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
       "         16, 5345,   19,  178,   32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left padded with zeros\n",
    "# As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "input_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers.SimpleRNN?\n",
    "tf.keras.layers.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4001      \n",
      "=================================================================\n",
      "Total params: 84,001\n",
      "Trainable params: 84,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Parameters: max_features (10000) * 8 = 80000 \n",
    "model.add(tf.keras.layers.Embedding(input_dim=max_features, output_dim=8, input_length=maxlen))\n",
    "# model.add(tf.keras.layers.Embedding(max_features, 32, input_length=maxlen))\n",
    "# model.add(tf.keras.layers.SimpleRNN(32, return_sequences=True))\n",
    "# model.add(tf.keras.layers.SimpleRNN(32, return_sequences=True))\n",
    "# model.add(tf.keras.layers.SimpleRNN(32))\n",
    "\n",
    "# Input format: maxlen (500) * dimension of embedding (8)\n",
    "# Output: 4000\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# binary classifier\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s 95us/step - loss: 0.7167 - acc: 0.5030 - val_loss: 0.7019 - val_acc: 0.5174\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.6907 - acc: 0.5440 - val_loss: 0.6909 - val_acc: 0.5414\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.6600 - acc: 0.6037 - val_loss: 0.6546 - val_acc: 0.6174\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.5887 - acc: 0.7130 - val_loss: 0.5916 - val_acc: 0.6744\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 74us/step - loss: 0.5067 - acc: 0.7734 - val_loss: 0.4957 - val_acc: 0.7800\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.4164 - acc: 0.8380 - val_loss: 0.4313 - val_acc: 0.8138\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.3484 - acc: 0.8739 - val_loss: 0.3868 - val_acc: 0.8392\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.3066 - acc: 0.8851 - val_loss: 0.3715 - val_acc: 0.8386\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 74us/step - loss: 0.2678 - acc: 0.9044 - val_loss: 0.3530 - val_acc: 0.8420\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 69us/step - loss: 0.2399 - acc: 0.9142 - val_loss: 0.3262 - val_acc: 0.8654\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "%time history = model.fit(input_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 326,273\n",
      "Trainable params: 326,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(max_features, 32))\n",
    "model.add(tf.keras.layers.SimpleRNN(32, return_sequences=True))\n",
    "model.add(tf.keras.layers.SimpleRNN(32, return_sequences=True))\n",
    "model.add(tf.keras.layers.SimpleRNN(32))\n",
    "\n",
    "# binary classifier\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 79s 4ms/step - loss: 0.6932 - acc: 0.5245 - val_loss: 0.6865 - val_acc: 0.5404\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 75s 4ms/step - loss: 0.6682 - acc: 0.5809 - val_loss: 0.6670 - val_acc: 0.5856\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 74s 4ms/step - loss: 0.5908 - acc: 0.6760 - val_loss: 0.6008 - val_acc: 0.6686\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 75s 4ms/step - loss: 0.4917 - acc: 0.7636 - val_loss: 0.5727 - val_acc: 0.7176\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 75s 4ms/step - loss: 0.3940 - acc: 0.8260 - val_loss: 0.4868 - val_acc: 0.7842\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 74s 4ms/step - loss: 0.3346 - acc: 0.8609 - val_loss: 0.5023 - val_acc: 0.7772\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 74s 4ms/step - loss: 0.3092 - acc: 0.8731 - val_loss: 0.5193 - val_acc: 0.7740\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.2414 - acc: 0.9072 - val_loss: 0.5634 - val_acc: 0.7928\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 78s 4ms/step - loss: 0.2033 - acc: 0.9247 - val_loss: 0.5568 - val_acc: 0.7870\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 80s 4ms/step - loss: 0.1791 - acc: 0.9357 - val_loss: 0.6360 - val_acc: 0.7640\n",
      "Wall time: 12min 43s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "%time history = model.fit(input_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(max_features, 32))\n",
    "model.add(tf.keras.layers.LSTM(32))\n",
    "\n",
    "# binary classifier\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 136s 7ms/step - loss: 0.6782 - acc: 0.5729 - val_loss: 0.6345 - val_acc: 0.6514\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 135s 7ms/step - loss: 0.5924 - acc: 0.6887 - val_loss: 0.5230 - val_acc: 0.7508\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 138s 7ms/step - loss: 0.5083 - acc: 0.7577 - val_loss: 0.5250 - val_acc: 0.7372\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 138s 7ms/step - loss: 0.4384 - acc: 0.8012 - val_loss: 0.4658 - val_acc: 0.7786\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 163s 8ms/step - loss: 0.4032 - acc: 0.8216 - val_loss: 0.3855 - val_acc: 0.8252\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 145s 7ms/step - loss: 0.3626 - acc: 0.8457 - val_loss: 0.3903 - val_acc: 0.8314\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 138s 7ms/step - loss: 0.3298 - acc: 0.8616 - val_loss: 0.3690 - val_acc: 0.8322\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 138s 7ms/step - loss: 0.3124 - acc: 0.8710 - val_loss: 0.7688 - val_acc: 0.7004\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 140s 7ms/step - loss: 0.2906 - acc: 0.8806 - val_loss: 0.3884 - val_acc: 0.8402\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 155s 8ms/step - loss: 0.2779 - acc: 0.8872 - val_loss: 0.4575 - val_acc: 0.7806\n",
      "Wall time: 23min 47s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "%time history = model.fit(input_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 50s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80948"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(input_train, y_train, batch_size=batch_size)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 50s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7776799999809265"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(input_test, y_test, batch_size=batch_size)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1902623 ],\n",
       "       [0.7821825 ],\n",
       "       [0.24731928],\n",
       "       [0.24368538],\n",
       "       [0.96904045]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precition\n",
    "model.predict(input_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ground truth\n",
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-68307870a185>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdrop_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "drop_out = 0.15\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(max_features, 32))\n",
    "model.add(tf.keras.layers.Dropout(drop_out))\n",
    "model.add(tf.keras.layers.GRU(32))\n",
    "model.add(tf.keras.layers.Dropout(drop_out))\n",
    "\n",
    "# binary classifier\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "20000/20000 [==============================] - 15s 729us/step - loss: 0.7017 - acc: 0.5153 - val_loss: 0.6872 - val_acc: 0.5490\n",
      "Epoch 2/25\n",
      "20000/20000 [==============================] - 14s 682us/step - loss: 0.6843 - acc: 0.5529 - val_loss: 0.6840 - val_acc: 0.5476\n",
      "Epoch 3/25\n",
      "20000/20000 [==============================] - 14s 684us/step - loss: 0.6762 - acc: 0.5859 - val_loss: 0.6768 - val_acc: 0.5694\n",
      "Epoch 4/25\n",
      "20000/20000 [==============================] - 14s 696us/step - loss: 0.6653 - acc: 0.6095 - val_loss: 0.6673 - val_acc: 0.5830\n",
      "Epoch 5/25\n",
      "20000/20000 [==============================] - 13s 668us/step - loss: 0.6451 - acc: 0.6385 - val_loss: 0.6485 - val_acc: 0.6100\n",
      "Epoch 6/25\n",
      "20000/20000 [==============================] - 13s 661us/step - loss: 0.5966 - acc: 0.6859 - val_loss: 0.5830 - val_acc: 0.6878\n",
      "Epoch 7/25\n",
      "20000/20000 [==============================] - 13s 659us/step - loss: 0.5074 - acc: 0.7542 - val_loss: 0.5084 - val_acc: 0.7474\n",
      "Epoch 8/25\n",
      "20000/20000 [==============================] - 13s 660us/step - loss: 0.4240 - acc: 0.8061 - val_loss: 0.4551 - val_acc: 0.7940\n",
      "Epoch 9/25\n",
      "20000/20000 [==============================] - 13s 663us/step - loss: 0.3625 - acc: 0.8441 - val_loss: 0.4228 - val_acc: 0.8144\n",
      "Epoch 10/25\n",
      "20000/20000 [==============================] - 13s 666us/step - loss: 0.3149 - acc: 0.8721 - val_loss: 0.3831 - val_acc: 0.8362\n",
      "Epoch 11/25\n",
      "20000/20000 [==============================] - 13s 663us/step - loss: 0.2786 - acc: 0.8887 - val_loss: 0.3671 - val_acc: 0.8494\n",
      "Epoch 12/25\n",
      "20000/20000 [==============================] - 15s 758us/step - loss: 0.2460 - acc: 0.9059 - val_loss: 0.3532 - val_acc: 0.8560\n",
      "Epoch 13/25\n",
      "20000/20000 [==============================] - 14s 719us/step - loss: 0.2231 - acc: 0.9167 - val_loss: 0.3524 - val_acc: 0.8574\n",
      "Epoch 14/25\n",
      "20000/20000 [==============================] - 14s 701us/step - loss: 0.2040 - acc: 0.9264 - val_loss: 0.3602 - val_acc: 0.8552\n",
      "Epoch 15/25\n",
      "20000/20000 [==============================] - 14s 683us/step - loss: 0.1975 - acc: 0.9272 - val_loss: 0.3418 - val_acc: 0.8638\n",
      "Epoch 16/25\n",
      "20000/20000 [==============================] - 14s 680us/step - loss: 0.1741 - acc: 0.9402 - val_loss: 0.3394 - val_acc: 0.8682\n",
      "Epoch 17/25\n",
      "20000/20000 [==============================] - 14s 685us/step - loss: 0.1639 - acc: 0.9434 - val_loss: 0.3538 - val_acc: 0.8632\n",
      "Epoch 18/25\n",
      "20000/20000 [==============================] - 14s 681us/step - loss: 0.1543 - acc: 0.9481 - val_loss: 0.3473 - val_acc: 0.8700\n",
      "Epoch 19/25\n",
      "20000/20000 [==============================] - 14s 679us/step - loss: 0.1426 - acc: 0.9523 - val_loss: 0.3869 - val_acc: 0.8580\n",
      "Epoch 20/25\n",
      "20000/20000 [==============================] - 14s 682us/step - loss: 0.1445 - acc: 0.9505 - val_loss: 0.3532 - val_acc: 0.8716\n",
      "Epoch 21/25\n",
      "20000/20000 [==============================] - 14s 688us/step - loss: 0.1217 - acc: 0.9622 - val_loss: 0.3647 - val_acc: 0.8722\n",
      "Epoch 22/25\n",
      "20000/20000 [==============================] - 14s 684us/step - loss: 0.1363 - acc: 0.9514 - val_loss: 0.3830 - val_acc: 0.8626\n",
      "Epoch 23/25\n",
      "20000/20000 [==============================] - 14s 681us/step - loss: 0.1156 - acc: 0.9628 - val_loss: 0.3709 - val_acc: 0.8714\n",
      "Epoch 24/25\n",
      "20000/20000 [==============================] - 14s 683us/step - loss: 0.0995 - acc: 0.9700 - val_loss: 0.3682 - val_acc: 0.8728\n",
      "Epoch 25/25\n",
      "20000/20000 [==============================] - 14s 687us/step - loss: 0.0958 - acc: 0.9723 - val_loss: 0.3851 - val_acc: 0.8718\n",
      "Wall time: 5min 42s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "%time history = model.fit(input_train, y_train, epochs=25, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
