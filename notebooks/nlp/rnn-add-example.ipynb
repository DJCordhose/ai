{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from\n",
    "# https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate sample equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  479+1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [ True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True],\n",
       "       [False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Training/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input shape: 7 digits, each being 0-9, + or space (12 possibilities)\n",
    "MAXLEN, len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 128)               54144     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 4, 128)            98688     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 154,380\n",
      "Trainable params: 154,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "# Try replacing LSTM, GRU, or SimpleRNN.\n",
    "# RNN = layers.LSTM\n",
    "# RNN = layers.SimpleRNN\n",
    "RNN = layers.GRU\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 170us/step - loss: 1.8599 - acc: 0.3299 - val_loss: 1.7563 - val_acc: 0.3513\n",
      "Q 863+17  T 880  \u001b[91m☒\u001b[0m 100 \n",
      "Q 65+970  T 1035 \u001b[91m☒\u001b[0m 100 \n",
      "Q 656+36  T 692  \u001b[91m☒\u001b[0m 166 \n",
      "Q 904+55  T 959  \u001b[91m☒\u001b[0m 100 \n",
      "Q 82+70   T 152  \u001b[91m☒\u001b[0m 880 \n",
      "Q 408+5   T 413  \u001b[91m☒\u001b[0m 440 \n",
      "Q 82+786  T 868  \u001b[91m☒\u001b[0m 100 \n",
      "Q 17+256  T 273  \u001b[91m☒\u001b[0m 120 \n",
      "Q 858+35  T 893  \u001b[91m☒\u001b[0m 100 \n",
      "Q 4+341   T 345  \u001b[91m☒\u001b[0m 44  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 173us/step - loss: 1.6472 - acc: 0.3877 - val_loss: 1.5187 - val_acc: 0.4355\n",
      "Q 37+616  T 653  \u001b[91m☒\u001b[0m 667 \n",
      "Q 33+814  T 847  \u001b[91m☒\u001b[0m 891 \n",
      "Q 504+94  T 598  \u001b[91m☒\u001b[0m 506 \n",
      "Q 5+68    T 73   \u001b[91m☒\u001b[0m 16  \n",
      "Q 186+83  T 269  \u001b[91m☒\u001b[0m 891 \n",
      "Q 764+67  T 831  \u001b[91m☒\u001b[0m 731 \n",
      "Q 191+690 T 881  \u001b[91m☒\u001b[0m 100 \n",
      "Q 334+555 T 889  \u001b[91m☒\u001b[0m 100 \n",
      "Q 886+78  T 964  \u001b[91m☒\u001b[0m 801 \n",
      "Q 705+755 T 1460 \u001b[91m☒\u001b[0m 1317\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 184us/step - loss: 1.3921 - acc: 0.4781 - val_loss: 1.2842 - val_acc: 0.5181\n",
      "Q 57+697  T 754  \u001b[91m☒\u001b[0m 776 \n",
      "Q 281+696 T 977  \u001b[91m☒\u001b[0m 907 \n",
      "Q 619+70  T 689  \u001b[91m☒\u001b[0m 614 \n",
      "Q 491+26  T 517  \u001b[91m☒\u001b[0m 504 \n",
      "Q 321+79  T 400  \u001b[91m☒\u001b[0m 393 \n",
      "Q 58+59   T 117  \u001b[91m☒\u001b[0m 120 \n",
      "Q 18+48   T 66   \u001b[91m☒\u001b[0m 10  \n",
      "Q 7+424   T 431  \u001b[91m☒\u001b[0m 443 \n",
      "Q 522+835 T 1357 \u001b[91m☒\u001b[0m 1367\n",
      "Q 919+20  T 939  \u001b[91m☒\u001b[0m 941 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 196us/step - loss: 1.2064 - acc: 0.5516 - val_loss: 1.1308 - val_acc: 0.5767\n",
      "Q 52+477  T 529  \u001b[91m☒\u001b[0m 524 \n",
      "Q 743+91  T 834  \u001b[91m☒\u001b[0m 844 \n",
      "Q 671+193 T 864  \u001b[91m☒\u001b[0m 771 \n",
      "Q 621+6   T 627  \u001b[91m☒\u001b[0m 620 \n",
      "Q 45+559  T 604  \u001b[91m☒\u001b[0m 511 \n",
      "Q 925+500 T 1425 \u001b[91m☒\u001b[0m 1441\n",
      "Q 50+569  T 619  \u001b[91m☒\u001b[0m 611 \n",
      "Q 80+81   T 161  \u001b[92m☑\u001b[0m 161 \n",
      "Q 434+99  T 533  \u001b[91m☒\u001b[0m 524 \n",
      "Q 49+402  T 451  \u001b[92m☑\u001b[0m 451 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 186us/step - loss: 1.0566 - acc: 0.6123 - val_loss: 1.0012 - val_acc: 0.6335\n",
      "Q 864+390 T 1254 \u001b[91m☒\u001b[0m 1220\n",
      "Q 649+52  T 701  \u001b[92m☑\u001b[0m 701 \n",
      "Q 796+78  T 874  \u001b[91m☒\u001b[0m 867 \n",
      "Q 489+620 T 1109 \u001b[91m☒\u001b[0m 1120\n",
      "Q 222+323 T 545  \u001b[91m☒\u001b[0m 530 \n",
      "Q 51+915  T 966  \u001b[91m☒\u001b[0m 981 \n",
      "Q 811+630 T 1441 \u001b[91m☒\u001b[0m 1463\n",
      "Q 494+462 T 956  \u001b[91m☒\u001b[0m 900 \n",
      "Q 64+459  T 523  \u001b[91m☒\u001b[0m 521 \n",
      "Q 4+651   T 655  \u001b[91m☒\u001b[0m 652 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 192us/step - loss: 0.9479 - acc: 0.6547 - val_loss: 0.8973 - val_acc: 0.6686\n",
      "Q 422+802 T 1224 \u001b[91m☒\u001b[0m 1344\n",
      "Q 363+5   T 368  \u001b[91m☒\u001b[0m 367 \n",
      "Q 912+18  T 930  \u001b[91m☒\u001b[0m 929 \n",
      "Q 786+86  T 872  \u001b[91m☒\u001b[0m 873 \n",
      "Q 335+16  T 351  \u001b[91m☒\u001b[0m 350 \n",
      "Q 36+655  T 691  \u001b[91m☒\u001b[0m 687 \n",
      "Q 6+971   T 977  \u001b[91m☒\u001b[0m 971 \n",
      "Q 134+30  T 164  \u001b[91m☒\u001b[0m 154 \n",
      "Q 22+274  T 296  \u001b[91m☒\u001b[0m 399 \n",
      "Q 298+275 T 573  \u001b[91m☒\u001b[0m 555 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 197us/step - loss: 0.8480 - acc: 0.6911 - val_loss: 0.8072 - val_acc: 0.7085\n",
      "Q 3+162   T 165  \u001b[91m☒\u001b[0m 164 \n",
      "Q 529+318 T 847  \u001b[91m☒\u001b[0m 850 \n",
      "Q 241+5   T 246  \u001b[91m☒\u001b[0m 247 \n",
      "Q 247+206 T 453  \u001b[91m☒\u001b[0m 465 \n",
      "Q 367+10  T 377  \u001b[91m☒\u001b[0m 374 \n",
      "Q 394+499 T 893  \u001b[91m☒\u001b[0m 875 \n",
      "Q 14+375  T 389  \u001b[91m☒\u001b[0m 381 \n",
      "Q 75+222  T 297  \u001b[91m☒\u001b[0m 299 \n",
      "Q 313+7   T 320  \u001b[91m☒\u001b[0m 319 \n",
      "Q 386+188 T 574  \u001b[91m☒\u001b[0m 565 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 199us/step - loss: 0.7786 - acc: 0.7181 - val_loss: 0.7496 - val_acc: 0.7330\n",
      "Q 8+957   T 965  \u001b[91m☒\u001b[0m 963 \n",
      "Q 334+0   T 334  \u001b[92m☑\u001b[0m 334 \n",
      "Q 624+30  T 654  \u001b[91m☒\u001b[0m 653 \n",
      "Q 478+641 T 1119 \u001b[92m☑\u001b[0m 1119\n",
      "Q 740+82  T 822  \u001b[91m☒\u001b[0m 829 \n",
      "Q 304+4   T 308  \u001b[92m☑\u001b[0m 308 \n",
      "Q 566+19  T 585  \u001b[92m☑\u001b[0m 585 \n",
      "Q 605+38  T 643  \u001b[91m☒\u001b[0m 646 \n",
      "Q 45+38   T 83   \u001b[91m☒\u001b[0m 84  \n",
      "Q 872+222 T 1094 \u001b[91m☒\u001b[0m 1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 195us/step - loss: 0.7261 - acc: 0.7363 - val_loss: 0.7109 - val_acc: 0.7394\n",
      "Q 2+445   T 447  \u001b[92m☑\u001b[0m 447 \n",
      "Q 58+802  T 860  \u001b[91m☒\u001b[0m 856 \n",
      "Q 593+51  T 644  \u001b[91m☒\u001b[0m 645 \n",
      "Q 842+263 T 1105 \u001b[91m☒\u001b[0m 1102\n",
      "Q 48+94   T 142  \u001b[91m☒\u001b[0m 140 \n",
      "Q 536+196 T 732  \u001b[92m☑\u001b[0m 732 \n",
      "Q 557+83  T 640  \u001b[91m☒\u001b[0m 632 \n",
      "Q 47+610  T 657  \u001b[91m☒\u001b[0m 652 \n",
      "Q 990+22  T 1012 \u001b[92m☑\u001b[0m 1012\n",
      "Q 63+287  T 350  \u001b[91m☒\u001b[0m 340 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 186us/step - loss: 0.6812 - acc: 0.7526 - val_loss: 0.6661 - val_acc: 0.7592\n",
      "Q 375+6   T 381  \u001b[92m☑\u001b[0m 381 \n",
      "Q 86+881  T 967  \u001b[91m☒\u001b[0m 965 \n",
      "Q 838+89  T 927  \u001b[91m☒\u001b[0m 925 \n",
      "Q 633+7   T 640  \u001b[92m☑\u001b[0m 640 \n",
      "Q 957+7   T 964  \u001b[91m☒\u001b[0m 963 \n",
      "Q 397+696 T 1093 \u001b[91m☒\u001b[0m 1075\n",
      "Q 708+285 T 993  \u001b[91m☒\u001b[0m 998 \n",
      "Q 606+76  T 682  \u001b[91m☒\u001b[0m 684 \n",
      "Q 572+2   T 574  \u001b[91m☒\u001b[0m 575 \n",
      "Q 768+1   T 769  \u001b[92m☑\u001b[0m 769 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 184us/step - loss: 0.6459 - acc: 0.7652 - val_loss: 0.6271 - val_acc: 0.7736\n",
      "Q 450+323 T 773  \u001b[92m☑\u001b[0m 773 \n",
      "Q 0+819   T 819  \u001b[92m☑\u001b[0m 819 \n",
      "Q 305+4   T 309  \u001b[92m☑\u001b[0m 309 \n",
      "Q 440+340 T 780  \u001b[91m☒\u001b[0m 783 \n",
      "Q 42+399  T 441  \u001b[91m☒\u001b[0m 449 \n",
      "Q 50+498  T 548  \u001b[91m☒\u001b[0m 549 \n",
      "Q 538+55  T 593  \u001b[91m☒\u001b[0m 599 \n",
      "Q 48+704  T 752  \u001b[91m☒\u001b[0m 756 \n",
      "Q 814+90  T 904  \u001b[91m☒\u001b[0m 903 \n",
      "Q 39+254  T 293  \u001b[91m☒\u001b[0m 290 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 181us/step - loss: 0.6113 - acc: 0.7782 - val_loss: 0.6103 - val_acc: 0.7787\n",
      "Q 657+910 T 1567 \u001b[91m☒\u001b[0m 1561\n",
      "Q 98+611  T 709  \u001b[91m☒\u001b[0m 713 \n",
      "Q 400+895 T 1295 \u001b[91m☒\u001b[0m 1296\n",
      "Q 238+67  T 305  \u001b[91m☒\u001b[0m 303 \n",
      "Q 82+403  T 485  \u001b[91m☒\u001b[0m 486 \n",
      "Q 276+72  T 348  \u001b[91m☒\u001b[0m 343 \n",
      "Q 652+813 T 1465 \u001b[91m☒\u001b[0m 1461\n",
      "Q 427+485 T 912  \u001b[91m☒\u001b[0m 911 \n",
      "Q 135+3   T 138  \u001b[92m☑\u001b[0m 138 \n",
      "Q 95+726  T 821  \u001b[91m☒\u001b[0m 824 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 183us/step - loss: 0.5742 - acc: 0.7913 - val_loss: 0.5580 - val_acc: 0.7946\n",
      "Q 191+690 T 881  \u001b[91m☒\u001b[0m 873 \n",
      "Q 33+2    T 35   \u001b[92m☑\u001b[0m 35  \n",
      "Q 874+165 T 1039 \u001b[91m☒\u001b[0m 1033\n",
      "Q 6+606   T 612  \u001b[92m☑\u001b[0m 612 \n",
      "Q 4+70    T 74   \u001b[91m☒\u001b[0m 77  \n",
      "Q 570+3   T 573  \u001b[91m☒\u001b[0m 572 \n",
      "Q 54+123  T 177  \u001b[91m☒\u001b[0m 174 \n",
      "Q 47+680  T 727  \u001b[91m☒\u001b[0m 723 \n",
      "Q 618+182 T 800  \u001b[91m☒\u001b[0m 809 \n",
      "Q 162+33  T 195  \u001b[91m☒\u001b[0m 196 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 168us/step - loss: 0.5215 - acc: 0.8121 - val_loss: 0.5053 - val_acc: 0.8212\n",
      "Q 81+534  T 615  \u001b[91m☒\u001b[0m 623 \n",
      "Q 28+58   T 86   \u001b[92m☑\u001b[0m 86  \n",
      "Q 95+850  T 945  \u001b[91m☒\u001b[0m 946 \n",
      "Q 891+25  T 916  \u001b[91m☒\u001b[0m 918 \n",
      "Q 377+5   T 382  \u001b[92m☑\u001b[0m 382 \n",
      "Q 477+78  T 555  \u001b[92m☑\u001b[0m 555 \n",
      "Q 72+202  T 274  \u001b[91m☒\u001b[0m 276 \n",
      "Q 887+442 T 1329 \u001b[91m☒\u001b[0m 1322\n",
      "Q 600+131 T 731  \u001b[91m☒\u001b[0m 738 \n",
      "Q 84+659  T 743  \u001b[91m☒\u001b[0m 745 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 8s 168us/step - loss: 0.4778 - acc: 0.8300 - val_loss: 0.4618 - val_acc: 0.8350\n",
      "Q 17+969  T 986  \u001b[91m☒\u001b[0m 971 \n",
      "Q 718+80  T 798  \u001b[92m☑\u001b[0m 798 \n",
      "Q 29+635  T 664  \u001b[91m☒\u001b[0m 661 \n",
      "Q 58+240  T 298  \u001b[92m☑\u001b[0m 298 \n",
      "Q 14+391  T 405  \u001b[91m☒\u001b[0m 406 \n",
      "Q 564+149 T 713  \u001b[91m☒\u001b[0m 715 \n",
      "Q 756+7   T 763  \u001b[92m☑\u001b[0m 763 \n",
      "Q 97+527  T 624  \u001b[91m☒\u001b[0m 621 \n",
      "Q 60+699  T 759  \u001b[91m☒\u001b[0m 764 \n",
      "Q 360+9   T 369  \u001b[92m☑\u001b[0m 369 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 170us/step - loss: 0.4202 - acc: 0.8538 - val_loss: 0.4101 - val_acc: 0.8539\n",
      "Q 260+72  T 332  \u001b[92m☑\u001b[0m 332 \n",
      "Q 162+39  T 201  \u001b[92m☑\u001b[0m 201 \n",
      "Q 431+83  T 514  \u001b[91m☒\u001b[0m 513 \n",
      "Q 80+561  T 641  \u001b[91m☒\u001b[0m 642 \n",
      "Q 116+53  T 169  \u001b[92m☑\u001b[0m 169 \n",
      "Q 702+60  T 762  \u001b[91m☒\u001b[0m 761 \n",
      "Q 317+36  T 353  \u001b[92m☑\u001b[0m 353 \n",
      "Q 562+71  T 633  \u001b[92m☑\u001b[0m 633 \n",
      "Q 651+96  T 747  \u001b[92m☑\u001b[0m 747 \n",
      "Q 75+222  T 297  \u001b[92m☑\u001b[0m 297 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 175us/step - loss: 0.3613 - acc: 0.8753 - val_loss: 0.3572 - val_acc: 0.8740\n",
      "Q 912+900 T 1812 \u001b[92m☑\u001b[0m 1812\n",
      "Q 708+858 T 1566 \u001b[91m☒\u001b[0m 1556\n",
      "Q 90+599  T 689  \u001b[91m☒\u001b[0m 688 \n",
      "Q 62+23   T 85   \u001b[91m☒\u001b[0m 86  \n",
      "Q 24+364  T 388  \u001b[92m☑\u001b[0m 388 \n",
      "Q 59+668  T 727  \u001b[91m☒\u001b[0m 726 \n",
      "Q 124+62  T 186  \u001b[92m☑\u001b[0m 186 \n",
      "Q 764+67  T 831  \u001b[91m☒\u001b[0m 832 \n",
      "Q 8+672   T 680  \u001b[92m☑\u001b[0m 680 \n",
      "Q 53+7    T 60   \u001b[92m☑\u001b[0m 60  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 159us/step - loss: 0.3052 - acc: 0.8981 - val_loss: 0.3006 - val_acc: 0.8947\n",
      "Q 156+2   T 158  \u001b[92m☑\u001b[0m 158 \n",
      "Q 478+52  T 530  \u001b[92m☑\u001b[0m 530 \n",
      "Q 11+139  T 150  \u001b[92m☑\u001b[0m 150 \n",
      "Q 33+0    T 33   \u001b[91m☒\u001b[0m 34  \n",
      "Q 7+858   T 865  \u001b[92m☑\u001b[0m 865 \n",
      "Q 96+621  T 717  \u001b[92m☑\u001b[0m 717 \n",
      "Q 567+779 T 1346 \u001b[91m☒\u001b[0m 1343\n",
      "Q 753+51  T 804  \u001b[92m☑\u001b[0m 804 \n",
      "Q 878+67  T 945  \u001b[92m☑\u001b[0m 945 \n",
      "Q 401+42  T 443  \u001b[92m☑\u001b[0m 443 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 164us/step - loss: 0.2456 - acc: 0.9205 - val_loss: 0.2210 - val_acc: 0.9283\n",
      "Q 75+920  T 995  \u001b[91m☒\u001b[0m 996 \n",
      "Q 858+74  T 932  \u001b[92m☑\u001b[0m 932 \n",
      "Q 263+997 T 1260 \u001b[91m☒\u001b[0m 1250\n",
      "Q 661+53  T 714  \u001b[92m☑\u001b[0m 714 \n",
      "Q 671+193 T 864  \u001b[91m☒\u001b[0m 863 \n",
      "Q 566+19  T 585  \u001b[92m☑\u001b[0m 585 \n",
      "Q 33+5    T 38   \u001b[92m☑\u001b[0m 38  \n",
      "Q 634+646 T 1280 \u001b[91m☒\u001b[0m 1279\n",
      "Q 157+685 T 842  \u001b[91m☒\u001b[0m 833 \n",
      "Q 14+543  T 557  \u001b[92m☑\u001b[0m 557 \n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 20):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
