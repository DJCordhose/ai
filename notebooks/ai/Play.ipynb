{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* debugging\n",
    "  * https://medium.com/@anthonypjshaw/python-3-7s-new-builtin-breakpoint-a-quick-tour-4f1aebc444c\n",
    "  * %debug\n",
    "  * https://davidhamann.de/2017/04/22/debugging-jupyter-notebooks/\n",
    "* Noch einfacheres Maze for mini max\n",
    "* minimax\n",
    "    * why none, none as terminal state and depth\n",
    "    * Path to best move wie bei Depth first\n",
    "* alpha beta umsetzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Installation:\n",
    "* https://www.anaconda.com/download/\n",
    "* git clone git@github.com:DJCordhose/haw.git\n",
    "* cd haw/notebooks\n",
    "* jupyter notebook\n",
    "\n",
    "Or clone on Azure Notebooks\n",
    "* https://notebooks.azure.com/djcordhose/libraries/ai-haw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Game\n",
    "In a certain terrain a Robot (R) plays against a Human player (H)\n",
    "* Both Human and Robot try to reach a goal which is at the same distance from both of them\n",
    "* Blocks (B) and both players block each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain = [\n",
    "    [\"_\", \"R\", \"_\", \"_\"],\n",
    "    [\"H\", \"_\", \"B\", \"_\"],\n",
    "    [\"_\", \"_\", \"B\", \"_\"],\n",
    "    [\"B\", \"_\", \"G\", \"_\"]   \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Game Playing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from math import sqrt, pow\n",
    "\n",
    "robot_symbol = 'R'\n",
    "robot_win_symbol = '*'\n",
    "goal_symbol = 'G'\n",
    "human_symbol = 'H'\n",
    "human_win_symbol = '#'\n",
    "blank_symbol = '_'\n",
    "\n",
    "def field_contains(state, symbol):\n",
    "    for row in state:\n",
    "        for field in row:\n",
    "            if field == symbol:\n",
    "                return True\n",
    "    return False   \n",
    "\n",
    "def is_robot_win(state):\n",
    "    return field_contains(state, robot_win_symbol)  \n",
    "\n",
    "def is_human_win(state):\n",
    "    return field_contains(state, human_win_symbol)  \n",
    "\n",
    "def as_string(state):\n",
    "    s = ''\n",
    "    for row in state:\n",
    "        row_string = ''\n",
    "        for field in row:\n",
    "            row_string += field + ' '\n",
    "        s += row_string + '\\n'\n",
    "    return s\n",
    "\n",
    "def locate(state, what):\n",
    "    for row_index, row in enumerate(state):\n",
    "        for column_index, field in enumerate(row):\n",
    "            if field == what:\n",
    "                return (row_index, column_index)\n",
    "\n",
    "def check_position(state, position):\n",
    "    max_row = len(state) - 1\n",
    "    max_column = len(state[0]) - 1\n",
    "    if position[0] < 0 or position[0] > max_row or position[1] < 0 or position[1] > max_column:\n",
    "        return False\n",
    "    symbol = state[position[0]][position[1]]\n",
    "    if symbol != blank_symbol and symbol != goal_symbol:\n",
    "        return False\n",
    "    return True\n",
    "            \n",
    "def player_moves(state, player_symbol):\n",
    "    player = locate(state, player_symbol)\n",
    "    left = (player[0], player[1] - 1)\n",
    "    right = (player[0], player[1] + 1)\n",
    "    up = (player[0] - 1, player[1])\n",
    "    down = (player[0] + 1, player[1])\n",
    "    valid_moves = [move for move in (left, right, down, up) if check_position(state, move)]\n",
    "    return valid_moves\n",
    "            \n",
    "def place_player(state, player, player_symbol, player_win_symbol):\n",
    "    old_player = locate(state, player_symbol)\n",
    "    new_state = deepcopy(state)\n",
    "    new_state[old_player[0]][old_player[1]] = blank_symbol\n",
    "    if new_state[player[0]][player[1]] == goal_symbol:\n",
    "        new_state[player[0]][player[1]] = player_win_symbol\n",
    "    else:\n",
    "        new_state[player[0]][player[1]] = player_symbol\n",
    "    return new_state\n",
    "\n",
    "def expand(state, player_symbol, player_win_symbol):\n",
    "    valid_moves = player_moves(state, player_symbol)\n",
    "    new_states = [(position, place_player(state, position, player_symbol, player_win_symbol)) for position in valid_moves]\n",
    "    return new_states\n",
    "\n",
    "def expand_robot(state):\n",
    "    return expand(state, robot_symbol, robot_win_symbol)\n",
    "\n",
    "def expand_human(state):\n",
    "    return expand(state, human_symbol, human_win_symbol)\n",
    "\n",
    "def distance(pos1, pos2):\n",
    "    if pos1 and pos2:\n",
    "        return sqrt(pow(pos1[0] - pos2[0], 2) + pow(pos1[1] - pos2[1], 2))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def estimate_state(state):\n",
    "    goal_position = locate(state, goal_symbol)\n",
    "\n",
    "    robot_position = locate(state, robot_symbol)\n",
    "    human_position = locate(state, human_symbol)\n",
    "    \n",
    "    robot_distance = distance(robot_position, goal_position)\n",
    "    human_distance = distance(human_position, goal_position)\n",
    "\n",
    "    estimated_value = human_distance - robot_distance \n",
    "    return estimated_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth first search as a recursive solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Depth-first_search\n",
    "# 1  procedure DFS(G,v):\n",
    "# 2      label v as discovered\n",
    "# 3      for all edges from v to w in G.adjacentEdges(v) do\n",
    "# 4          if vertex w is not labeled as discovered then\n",
    "# 5              recursively call DFS(G,w)\n",
    "\n",
    "def depth_first_search(state, max_depth=10, debug=False, closed_list=[], depth = 0, path=[]):\n",
    "    if as_string(state) in closed_list or depth > max_depth:\n",
    "        return None\n",
    "    \n",
    "    if debug:\n",
    "        print('depth', depth)\n",
    "        print('closed_list', closed_list)\n",
    "        print('path', path)\n",
    "        print('state', as_string(state))\n",
    "        \n",
    "    if is_robot_win(state):\n",
    "        return path\n",
    "    \n",
    "    closed_list = closed_list + [as_string(state)]\n",
    "    \n",
    "    for move, next_state in expand_robot(state):\n",
    "        new_path = path + [move]\n",
    "        res = depth_first_search(next_state, max_depth, debug, closed_list, depth + 1, new_path)\n",
    "        if res:\n",
    "            return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This quite obviously is not the shortest path, but who cares, as long as your robot wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 3), (1, 3), (2, 3), (3, 3), (3, 2)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_first_search(terrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is not good enough, because now we have an adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Minimax\n",
    "# robot is maximizer, human is minimizer\n",
    "\n",
    "def mini_max(state, is_robot_move=True, max_depth=10, debug=False, depth = 0):\n",
    "    if debug:\n",
    "        print('-----')\n",
    "        print('inspected state')\n",
    "        print(as_string(state))\n",
    "        print('is_robot_move', is_robot_move)\n",
    "        print('depth', depth)\n",
    "        \n",
    "    if depth > max_depth:\n",
    "        estimated_value = estimate_state(state)\n",
    "        if debug:\n",
    "            print('estimation at edge {}'.format(estimated_value))\n",
    "        return (estimated_value, None, state, depth)\n",
    "    \n",
    "    if is_robot_win(state):\n",
    "        if debug:\n",
    "            print('robot win detected')\n",
    "        return (float('inf'), None, state, depth)\n",
    "    \n",
    "    if is_human_win(state):\n",
    "        if debug:\n",
    "            print('human win detected')\n",
    "        return (float('-inf'), None, state, depth)\n",
    "    \n",
    "    if debug:\n",
    "        print('*** what moves are possible from here?')\n",
    "    if is_robot_move:\n",
    "        best_value = float('-inf')\n",
    "        best_move = None\n",
    "        best_terminal_state = None\n",
    "        best_terminal_depth = None\n",
    "        for move, next_state in expand_robot(state):\n",
    "            value_for_move, _, terminal_state, terminal_depth =\\\n",
    "                mini_max(next_state, is_robot_move=False, max_depth=max_depth, debug=debug, depth = depth + 1)\n",
    "            if value_for_move > best_value:\n",
    "                best_value = value_for_move\n",
    "                best_move = next_state\n",
    "                best_terminal_state = terminal_state\n",
    "                best_terminal_depth = terminal_depth\n",
    "        if debug:\n",
    "            print('*** completed looking at moves on level {}'.format(depth))\n",
    "            print('best robot score', best_value)\n",
    "            print('best robot move', as_string(best_move))\n",
    "        return (best_value, best_move, best_terminal_state, best_terminal_depth)\n",
    "    else:\n",
    "        best_value = float('inf')\n",
    "        best_move = None\n",
    "        best_terminal_state = None\n",
    "        best_terminal_depth = None\n",
    "        for move, next_state in expand_human(state):\n",
    "            value_for_move, _, terminal_state, terminal_depth =\\\n",
    "                mini_max(next_state, is_robot_move=True, max_depth=max_depth, debug=debug, depth = depth + 1)\n",
    "            if value_for_move < best_value:\n",
    "                best_value = value_for_move\n",
    "                best_move = next_state\n",
    "                best_terminal_state = terminal_state\n",
    "                best_terminal_depth = terminal_depth\n",
    "        if debug:\n",
    "            print('*** completed looking at moves on level {}'.format(depth))\n",
    "            print('best human score', best_value)\n",
    "            print('best human move', as_string(best_move))\n",
    "        return (best_value, best_move, best_terminal_state, best_terminal_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_', 'R', '_', '_'],\n",
       " ['H', '_', 'B', '_'],\n",
       " ['_', '_', 'B', '_'],\n",
       " ['B', '_', 'G', '_']]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like who ever starts wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(inf,\n",
       " [['_', '_', '_', '_'],\n",
       "  ['H', 'R', 'B', '_'],\n",
       "  ['_', '_', 'B', '_'],\n",
       "  ['B', '_', 'G', '_']],\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_max(terrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf,\n",
       " [['_', 'R', '_', '_'],\n",
       "  ['_', 'H', 'B', '_'],\n",
       "  ['_', '_', 'B', '_'],\n",
       "  ['B', '_', 'G', '_']],\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_max(terrain, is_robot_move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_', 'R', '_', '_'],\n",
       " ['H', '_', 'B', '_'],\n",
       " ['_', '_', 'B', '_'],\n",
       " ['B', '_', 'G', '_']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "inspected state\n",
      "_ R _ _ \n",
      "H _ B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move True\n",
      "depth 0\n",
      "*** what moves are possible from here?\n",
      "-----\n",
      "inspected state\n",
      "R _ _ _ \n",
      "H _ B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move False\n",
      "depth 1\n",
      "*** what moves are possible from here?\n",
      "-----\n",
      "inspected state\n",
      "R _ _ _ \n",
      "_ H B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move True\n",
      "depth 2\n",
      "estimation at edge -1.3694832979641993\n",
      "-----\n",
      "inspected state\n",
      "R _ _ _ \n",
      "_ _ B _ \n",
      "H _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move True\n",
      "depth 2\n",
      "estimation at edge -1.3694832979641993\n",
      "*** completed looking at moves on level 1\n",
      "best human score -1.3694832979641993\n",
      "best human move R _ _ _ \n",
      "_ H B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "-----\n",
      "inspected state\n",
      "_ _ R _ \n",
      "H _ B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move False\n",
      "depth 1\n",
      "*** what moves are possible from here?\n",
      "-----\n",
      "inspected state\n",
      "_ _ R _ \n",
      "_ H B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move True\n",
      "depth 2\n",
      "estimation at edge -0.7639320225002102\n",
      "-----\n",
      "inspected state\n",
      "_ _ R _ \n",
      "_ _ B _ \n",
      "H _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move True\n",
      "depth 2\n",
      "estimation at edge -0.7639320225002102\n",
      "-----\n",
      "inspected state\n",
      "H _ R _ \n",
      "_ _ B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move True\n",
      "depth 2\n",
      "estimation at edge 0.6055512754639891\n",
      "*** completed looking at moves on level 1\n",
      "best human score -0.7639320225002102\n",
      "best human move _ _ R _ \n",
      "_ H B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "-----\n",
      "inspected state\n",
      "_ _ _ _ \n",
      "H R B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move False\n",
      "depth 1\n",
      "*** what moves are possible from here?\n",
      "-----\n",
      "inspected state\n",
      "_ _ _ _ \n",
      "_ R B _ \n",
      "H _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move True\n",
      "depth 2\n",
      "estimation at edge 0.0\n",
      "-----\n",
      "inspected state\n",
      "H _ _ _ \n",
      "_ R B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n",
      "is_robot_move True\n",
      "depth 2\n",
      "estimation at edge 1.3694832979641993\n",
      "*** completed looking at moves on level 1\n",
      "best human score 0.0\n",
      "best human move _ _ _ _ \n",
      "_ R B _ \n",
      "H _ B _ \n",
      "B _ G _ \n",
      "\n",
      "*** completed looking at moves on level 0\n",
      "best robot score 0.0\n",
      "best robot move _ _ _ _ \n",
      "H R B _ \n",
      "_ _ B _ \n",
      "B _ G _ \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " [['_', '_', '_', '_'],\n",
       "  ['H', 'R', 'B', '_'],\n",
       "  ['_', '_', 'B', '_'],\n",
       "  ['B', '_', 'G', '_']])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_max(terrain, max_depth = 1, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are checking on a lot of obviously stupid moves\n",
    "* if we did not we could look at more promising moves instead\n",
    "* this of course would only pay off in larger mazes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning\n",
    "# function alphabeta(state, depth, phase, alpha = - Number.MAX_VALUE, beta = Number.MAX_VALUE, maxPlayer=true) {"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
