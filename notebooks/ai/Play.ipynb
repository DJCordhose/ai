{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Installation:\n",
    "* https://www.anaconda.com/download/\n",
    "* git clone git@github.com:DJCordhose/haw.git\n",
    "* cd haw/notebooks\n",
    "* jupyter notebook\n",
    "\n",
    "Or clone on Azure Notebooks\n",
    "* https://notebooks.azure.com/djcordhose/libraries/ai-haw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Game\n",
    "In a certain terrain a Robot (R) plays against a Human player (H)\n",
    "* Both Human and Robot try to reach a goal which is at the same distance from both of them\n",
    "* Blocks (B) and both players block each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain = [\n",
    "    [\"_\", \"R\", \"_\", \"_\"],\n",
    "    [\"H\", \"_\", \"B\", \"_\"],\n",
    "    [\"_\", \"_\", \"B\", \"_\"],\n",
    "    [\"B\", \"_\", \"G\", \"_\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Game Playing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from math import sqrt, pow\n",
    "\n",
    "robot_symbol = 'R'\n",
    "robot_win_symbol = '*'\n",
    "goal_symbol = 'G'\n",
    "human_symbol = 'H'\n",
    "human_win_symbol = '#'\n",
    "blank_symbol = '_'\n",
    "\n",
    "def field_contains(state, symbol):\n",
    "    for row in state:\n",
    "        for field in row:\n",
    "            if field == symbol:\n",
    "                return True\n",
    "    return False   \n",
    "\n",
    "def is_robot_win(state):\n",
    "    return field_contains(state, robot_win_symbol)  \n",
    "\n",
    "def is_human_win(state):\n",
    "    return field_contains(state, human_win_symbol)  \n",
    "\n",
    "def as_string(state):\n",
    "    s = ''\n",
    "    for row in state:\n",
    "        row_string = ''\n",
    "        for field in row:\n",
    "            row_string += field + ' '\n",
    "        s += row_string + '\\n'\n",
    "    return s\n",
    "\n",
    "def locate(state, what):\n",
    "    for row_index, row in enumerate(state):\n",
    "        for column_index, field in enumerate(row):\n",
    "            if field == what:\n",
    "                return (row_index, column_index)\n",
    "\n",
    "def check_position(state, position):\n",
    "    max_row = len(state) - 1\n",
    "    max_column = len(state[0]) - 1\n",
    "    if position[0] < 0 or position[0] > max_row or position[1] < 0 or position[1] > max_column:\n",
    "        return False\n",
    "    symbol = state[position[0]][position[1]]\n",
    "    if symbol != blank_symbol and symbol != goal_symbol:\n",
    "        return False\n",
    "    return True\n",
    "            \n",
    "def player_moves(state, player_symbol):\n",
    "    player = locate(state, player_symbol)\n",
    "    left = (player[0], player[1] - 1)\n",
    "    right = (player[0], player[1] + 1)\n",
    "    up = (player[0] - 1, player[1])\n",
    "    down = (player[0] + 1, player[1])\n",
    "    valid_moves = [move for move in (left, right, down, up) if check_position(state, move)]\n",
    "    return valid_moves\n",
    "            \n",
    "def place_player(state, player, player_symbol, player_win_symbol):\n",
    "    old_player = locate(state, player_symbol)\n",
    "    new_state = deepcopy(state)\n",
    "    new_state[old_player[0]][old_player[1]] = blank_symbol\n",
    "    if new_state[player[0]][player[1]] == goal_symbol:\n",
    "        new_state[player[0]][player[1]] = player_win_symbol\n",
    "    else:\n",
    "        new_state[player[0]][player[1]] = player_symbol\n",
    "    return new_state\n",
    "\n",
    "def expand(state, player_symbol, player_win_symbol):\n",
    "    valid_moves = player_moves(state, player_symbol)\n",
    "    new_states = [(position, place_player(state, position, player_symbol, player_win_symbol)) for position in valid_moves]\n",
    "    return new_states\n",
    "\n",
    "def expand_robot(state):\n",
    "    return expand(state, robot_symbol, robot_win_symbol)\n",
    "\n",
    "def expand_human(state):\n",
    "    return expand(state, human_symbol, human_win_symbol)\n",
    "\n",
    "def distance(pos1, pos2):\n",
    "    if pos1 and pos2:\n",
    "        return sqrt(pow(pos1[0] - pos2[0], 2) + pow(pos1[1] - pos2[1], 2))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def estimate_state(state):\n",
    "    goal_position = locate(state, goal_symbol)\n",
    "\n",
    "    robot_position = locate(state, robot_symbol)\n",
    "    human_position = locate(state, human_symbol)\n",
    "    \n",
    "    robot_distance = distance(robot_position, goal_position)\n",
    "    human_distance = distance(human_position, goal_position)\n",
    "\n",
    "    estimated_value = human_distance - robot_distance \n",
    "    return estimated_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth first search as a recursive solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Depth-first_search\n",
    "# 1  procedure DFS(G,v):\n",
    "# 2      label v as discovered\n",
    "# 3      for all edges from v to w in G.adjacentEdges(v) do\n",
    "# 4          if vertex w is not labeled as discovered then\n",
    "# 5              recursively call DFS(G,w)\n",
    "\n",
    "def depth_first_search(state, max_depth=10, debug=False, closed_list=[], depth = 0, path=[]):\n",
    "    if as_string(state) in closed_list or depth > max_depth:\n",
    "        return None\n",
    "    \n",
    "    if debug:\n",
    "        print('depth', depth)\n",
    "        print('closed_list', closed_list)\n",
    "        print('path', path)\n",
    "        print('state', as_string(state))\n",
    "        \n",
    "    if is_robot_win(state):\n",
    "        return path\n",
    "    \n",
    "    closed_list = closed_list + [as_string(state)]\n",
    "    \n",
    "    for move, next_state in expand_robot(state):\n",
    "        new_path = path + [move]\n",
    "        res = depth_first_search(next_state, max_depth, debug, closed_list, depth + 1, new_path)\n",
    "        if res:\n",
    "            return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This quite obviously is not the shortest path, but who cares, as long as your robot wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_', 'R', '_', '_'],\n",
       " ['H', '_', 'B', '_'],\n",
       " ['_', '_', 'B', '_'],\n",
       " ['B', '_', 'G', '_']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 3), (1, 3), (2, 3), (3, 3), (3, 2)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_first_search(terrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax\n",
    "### This is not good enough, because now we have an adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Minimax\n",
    "# robot is maximizer, human is minimizer\n",
    "\n",
    "min = float('-inf')\n",
    "max = float('inf')\n",
    "\n",
    "def mini_max(state, is_robot_move=True, max_depth=10, debug=False, verbose=False, depth = 0):\n",
    "    if debug:\n",
    "        print('-----')\n",
    "        print('is_robot_move', is_robot_move)\n",
    "        print('depth', depth)\n",
    "        print('inspecting state')\n",
    "        print(as_string(state))\n",
    "        \n",
    "    if is_robot_win(state):\n",
    "        if verbose:\n",
    "            print('-----')\n",
    "            print('robot win detected')\n",
    "            print('depth', depth)\n",
    "            print('state', state)\n",
    "            print('-----')\n",
    "        return (max, None)\n",
    "    \n",
    "    if is_human_win(state):\n",
    "        if verbose:\n",
    "            print('-----')\n",
    "            print('human win detected')\n",
    "            print('depth', depth)\n",
    "            print('state', state)\n",
    "            print('-----')\n",
    "        return (min, None)\n",
    "    \n",
    "    if depth == max_depth:\n",
    "        estimated_value = estimate_state(state)\n",
    "        if verbose:\n",
    "            print('max depth reached, estimation at edge {}'.format(estimated_value))\n",
    "        return (estimated_value, None)\n",
    "    \n",
    "    if is_robot_move:\n",
    "        best_value = min\n",
    "        best_move = None\n",
    "        for move, next_state in expand_robot(state):\n",
    "            value_for_move, _ =\\\n",
    "                mini_max(next_state, is_robot_move=False, max_depth=max_depth, debug=debug, verbose=verbose, depth = depth + 1)\n",
    "            if value_for_move > best_value:\n",
    "                best_value = value_for_move\n",
    "                best_move = next_state\n",
    "        return (best_value, best_move)\n",
    "    else:\n",
    "        best_value = max\n",
    "        best_move = None\n",
    "        for move, next_state in expand_human(state):\n",
    "            value_for_move, _, =\\\n",
    "                mini_max(next_state, is_robot_move=True, max_depth=max_depth, debug=debug, verbose=verbose, depth = depth + 1)\n",
    "            if value_for_move < best_value:\n",
    "                best_value = value_for_move\n",
    "                best_move = next_state\n",
    "        return (best_value, best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_', 'R', '_', '_'],\n",
       " ['H', '_', 'B', '_'],\n",
       " ['_', '_', 'B', '_'],\n",
       " ['B', '_', 'G', '_']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like who ever starts wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(inf,\n",
       " [['_', '_', '_', '_'],\n",
       "  ['H', 'R', 'B', '_'],\n",
       "  ['_', '_', 'B', '_'],\n",
       "  ['B', '_', 'G', '_']])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_max(terrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf,\n",
       " [['_', 'R', '_', '_'],\n",
       "  ['_', 'H', 'B', '_'],\n",
       "  ['_', '_', 'B', '_'],\n",
       "  ['B', '_', 'G', '_']])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_max(terrain, is_robot_move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_terrain = [\n",
    "    [\"R\", \"_\" ],\n",
    "    [\"_\", \"G\"],\n",
    "    [\"H\", \"_\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth reached, estimation at edge -0.41421356237309515\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['_', '*'], ['_', 'H']]\n",
      "-----\n",
      "max depth reached, estimation at edge -0.41421356237309515\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['H', '*'], ['_', '_']]\n",
      "-----\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['_', '*'], ['_', 'H']]\n",
      "-----\n",
      "max depth reached, estimation at edge -0.41421356237309515\n",
      "max depth reached, estimation at edge -0.41421356237309515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf, [['_', 'R'], ['_', 'G'], ['H', '_']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after 3 moves in total (2 robot, 1 human) we have a win for robot\n",
    "# mini_max(simple_terrain, max_depth = 1)\n",
    "# mini_max(simple_terrain, max_depth = 2)\n",
    "mini_max(simple_terrain, max_depth = 3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Beta Pruning\n",
    "### We are checking on a lot of obviously stupid moves\n",
    "* we repeatedly check for robot win, even though we could know we already won\n",
    "* if we did not we could look at more promising moves instead\n",
    "* this of course would only pay off in larger mazes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning\n",
    "def alpha_beta(state, alpha = min, beta = max, is_robot_move=True, max_depth=10, depth = 0, verbose=True, debug=False):\n",
    "    if debug:\n",
    "        print('-----')\n",
    "        print('is_robot_move', is_robot_move)\n",
    "        print('depth', depth)\n",
    "        print('inspecting state')\n",
    "        print(as_string(state))\n",
    "\n",
    "    if is_robot_win(state):\n",
    "        if verbose:\n",
    "            print('-----')\n",
    "            print('robot win detected')\n",
    "            print('depth', depth)\n",
    "            print('state', state)\n",
    "            print('-----')\n",
    "        return (max, None)\n",
    "    \n",
    "    if is_human_win(state):\n",
    "        if verbose:\n",
    "            print('-----')\n",
    "            print('human win detected')\n",
    "            print('depth', depth)\n",
    "            print('state', state)\n",
    "            print('-----')\n",
    "        return (min, None)\n",
    "    \n",
    "    if depth == max_depth:\n",
    "        estimated_value = estimate_state(state)\n",
    "        if verbose:\n",
    "            print('max depth reached, estimation at edge {}'.format(estimated_value))\n",
    "\n",
    "        return (estimated_value, None)\n",
    "    \n",
    "    if is_robot_move:\n",
    "        best_value = min\n",
    "        best_move = None\n",
    "        for move, next_state in expand_robot(state):\n",
    "            value_for_move, _ =\\\n",
    "                alpha_beta(next_state, is_robot_move=False, alpha = alpha, beta = beta, max_depth=max_depth, verbose=verbose, debug=debug, depth = depth + 1)\n",
    "            if value_for_move > best_value:\n",
    "                best_value = value_for_move\n",
    "                best_move = next_state\n",
    "            if best_value > alpha:\n",
    "                if debug:\n",
    "                    print('adjusting alpha from {} to {}'.format(alpha, best_value))\n",
    "                alpha = best_value\n",
    "            if beta <= alpha:\n",
    "                if debug:\n",
    "                    print('breaking, beta {} <= alpha {}'.format(beta, alpha))\n",
    "                break\n",
    "        return (best_value, best_move)\n",
    "    else:\n",
    "        best_value = max\n",
    "        best_move = None\n",
    "        for move, next_state in expand_human(state):\n",
    "            value_for_move, _, =\\\n",
    "                alpha_beta(next_state, is_robot_move=True, alpha = alpha, beta = beta, max_depth=max_depth, verbose=verbose, debug=debug, depth = depth + 1)\n",
    "            if value_for_move < best_value:\n",
    "                best_value = value_for_move\n",
    "                best_move = next_state\n",
    "            if best_value < beta:\n",
    "                if debug:\n",
    "                    print('adjusting beta from {} to {}'.format(beta, best_value))\n",
    "                beta = best_value\n",
    "            if beta <= alpha:\n",
    "                if debug:\n",
    "                    print('breaking, beta {} <= alpha {}'.format(beta, alpha))\n",
    "                break\n",
    "        return (best_value, best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth reached, estimation at edge 0.0\n",
      "-----\n",
      "human win detected\n",
      "depth 4\n",
      "state [['R', '_'], ['_', '#'], ['_', '_']]\n",
      "-----\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['_', '*'], ['_', 'H']]\n",
      "-----\n",
      "-----\n",
      "human win detected\n",
      "depth 4\n",
      "state [['R', '_'], ['_', '#'], ['_', '_']]\n",
      "-----\n",
      "max depth reached, estimation at edge 0.0\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['H', '*'], ['_', '_']]\n",
      "-----\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['_', '*'], ['_', 'H']]\n",
      "-----\n",
      "-----\n",
      "human win detected\n",
      "depth 4\n",
      "state [['_', '_'], ['_', '#'], ['R', '_']]\n",
      "-----\n",
      "max depth reached, estimation at edge 0.0\n",
      "-----\n",
      "human win detected\n",
      "depth 4\n",
      "state [['R', '_'], ['_', '#'], ['_', '_']]\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf, [['_', 'R'], ['_', 'G'], ['H', '_']])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_max(simple_terrain, max_depth = 4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth reached, estimation at edge 0.0\n",
      "-----\n",
      "human win detected\n",
      "depth 4\n",
      "state [['R', '_'], ['_', '#'], ['_', '_']]\n",
      "-----\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['_', '*'], ['_', 'H']]\n",
      "-----\n",
      "-----\n",
      "human win detected\n",
      "depth 4\n",
      "state [['R', '_'], ['_', '#'], ['_', '_']]\n",
      "-----\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['H', '*'], ['_', '_']]\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf, [['_', 'R'], ['_', 'G'], ['H', '_']])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_beta(simple_terrain, max_depth = 4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf,\n",
       " [['_', '_', '_', '_'],\n",
       "  ['H', 'R', 'B', '_'],\n",
       "  ['_', '_', 'B', '_'],\n",
       "  ['B', '_', 'G', '_']])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time mini_max(terrain, max_depth = 15, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 187 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf,\n",
       " [['_', '_', '_', '_'],\n",
       "  ['H', 'R', 'B', '_'],\n",
       "  ['_', '_', 'B', '_'],\n",
       "  ['B', '_', 'G', '_']])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time alpha_beta(terrain, max_depth = 15, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['R', '_'], ['_', 'G'], ['H', '_']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "is_robot_move True\n",
      "depth 0\n",
      "inspecting state\n",
      "R _ \n",
      "_ G \n",
      "H _ \n",
      "\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 1\n",
      "inspecting state\n",
      "_ R \n",
      "_ G \n",
      "H _ \n",
      "\n",
      "-----\n",
      "is_robot_move True\n",
      "depth 2\n",
      "inspecting state\n",
      "_ R \n",
      "_ G \n",
      "_ H \n",
      "\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "R _ \n",
      "_ G \n",
      "_ H \n",
      "\n",
      "max depth reached, estimation at edge -0.41421356237309515\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "_ _ \n",
      "_ * \n",
      "_ H \n",
      "\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['_', '*'], ['_', 'H']]\n",
      "-----\n",
      "-----\n",
      "is_robot_move True\n",
      "depth 2\n",
      "inspecting state\n",
      "_ R \n",
      "H G \n",
      "_ _ \n",
      "\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "R _ \n",
      "H G \n",
      "_ _ \n",
      "\n",
      "max depth reached, estimation at edge -0.41421356237309515\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "_ _ \n",
      "H * \n",
      "_ _ \n",
      "\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['H', '*'], ['_', '_']]\n",
      "-----\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 1\n",
      "inspecting state\n",
      "_ _ \n",
      "R G \n",
      "H _ \n",
      "\n",
      "-----\n",
      "is_robot_move True\n",
      "depth 2\n",
      "inspecting state\n",
      "_ _ \n",
      "R G \n",
      "_ H \n",
      "\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "_ _ \n",
      "_ * \n",
      "_ H \n",
      "\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['_', '*'], ['_', 'H']]\n",
      "-----\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "_ _ \n",
      "_ G \n",
      "R H \n",
      "\n",
      "max depth reached, estimation at edge -0.41421356237309515\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "R _ \n",
      "_ G \n",
      "_ H \n",
      "\n",
      "max depth reached, estimation at edge -0.41421356237309515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf, [['_', 'R'], ['_', 'G'], ['H', '_']])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# booth mini max and alpha beta expand the same left side, but alpha beta prunes complete right side (see mini-max-tree.jpg)\n",
    "mini_max(simple_terrain, max_depth = 3, verbose=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "is_robot_move True\n",
      "depth 0\n",
      "inspecting state\n",
      "R _ \n",
      "_ G \n",
      "H _ \n",
      "\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 1\n",
      "inspecting state\n",
      "_ R \n",
      "_ G \n",
      "H _ \n",
      "\n",
      "-----\n",
      "is_robot_move True\n",
      "depth 2\n",
      "inspecting state\n",
      "_ R \n",
      "_ G \n",
      "_ H \n",
      "\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "R _ \n",
      "_ G \n",
      "_ H \n",
      "\n",
      "max depth reached, estimation at edge -0.41421356237309515\n",
      "adjusting alpha from -inf to -0.41421356237309515\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "_ _ \n",
      "_ * \n",
      "_ H \n",
      "\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['_', '*'], ['_', 'H']]\n",
      "-----\n",
      "adjusting alpha from -0.41421356237309515 to inf\n",
      "breaking, beta inf <= alpha inf\n",
      "-----\n",
      "is_robot_move True\n",
      "depth 2\n",
      "inspecting state\n",
      "_ R \n",
      "H G \n",
      "_ _ \n",
      "\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "R _ \n",
      "H G \n",
      "_ _ \n",
      "\n",
      "max depth reached, estimation at edge -0.41421356237309515\n",
      "adjusting alpha from -inf to -0.41421356237309515\n",
      "-----\n",
      "is_robot_move False\n",
      "depth 3\n",
      "inspecting state\n",
      "_ _ \n",
      "H * \n",
      "_ _ \n",
      "\n",
      "-----\n",
      "robot win detected\n",
      "depth 3\n",
      "state [['_', '_'], ['H', '*'], ['_', '_']]\n",
      "-----\n",
      "adjusting alpha from -0.41421356237309515 to inf\n",
      "breaking, beta inf <= alpha inf\n",
      "adjusting alpha from -inf to inf\n",
      "breaking, beta inf <= alpha inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf, [['_', 'R'], ['_', 'G'], ['H', '_']])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_beta(simple_terrain, max_depth = 3, verbose=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
