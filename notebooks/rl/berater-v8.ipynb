{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v8\n",
        "\n",
        "## Changes from v7\n",
        "1. return to complete observation gives better results\n",
        "    * not listing all paths, but\n",
        "    * local paths plus all rest rewards\n",
        "  \n",
        "## next steps\n",
        "1. configure custom network including regularization (https://blog.openai.com/quantifying-generalization-in-reinforcement-learning/)\n",
        "* better rewards\n",
        "  * set discount factor (gamma) to 1\n",
        "    * rewards late in the game are as good as eartly ones\n",
        "    * no need to push game to an end, as every move comes at costs anyway\n",
        " * add reward for returning home once all other locations have been visited \n",
        "* better observation?\n",
        "  * network can learn all costs and all connections as they are static\n",
        "  * rewards are not, but are given in the observation\n",
        "  * all information is there, but\n",
        "  * it is very convoluted, too hard for us as humans\n",
        "  * could we make this more accessible? Would this also help? \n",
        "* create baselines to better understand what is a good result\n",
        "  1. low level: always go in the direction of greatest reward\n",
        "  1. Dijkstra\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        max_paths = 4\n",
        "        self.action_space = spaces.Discrete(max_paths)\n",
        "      \n",
        "        positions = len(self.map)\n",
        "        # observations: position, reward of all 4 local paths, rest reward of all locations\n",
        "        # non existing path is -1000 and no position change\n",
        "        # look at what #getObservation returns if you are confused\n",
        "        low = np.append(np.append([0], np.full(max_paths, -1000)), np.full(positions, 0))\n",
        "        high = np.append(np.append([positions - 1], np.full(max_paths, 1000)), np.full(positions, 1000))\n",
        "        self.observation_space = spaces.Box(low=low,\n",
        "                                             high=high,\n",
        "                                             dtype=np.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = np.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=np.float32)\n",
        "        all_rest_rewards = list(self.customer_reward.values())\n",
        "        result = np.append(result, all_rest_rewards)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/2)\n",
        "#       number_per_consultant = int(number_of_customers/1.5)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "outputId": "fe6edc83-bf41-41f4-ad82-f2eee0106097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.   700.   900.   800. -1000.     0.  1000.  1000.  1000.     0.\n",
            "     0.  1000.     0.     0.     0.  1000.  1000.     0.     0.]\n",
            "{'S': 0, 'A': 1000, 'B': 1000, 'C': 1000, 'D': 0, 'E': 0, 'F': 1000, 'G': 0, 'H': 0, 'K': 0, 'L': 1000, 'M': 1000, 'N': 0, 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "73833683-9080-45f4-bbd1-aaf1e4bafb2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3485
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.   700.  -100.  -200. -1000.     0.  1000.     0.     0.     0.\n",
            "  1000.     0.  1000.     0.  1000.     0.  1000.     0.  1000.]\n",
            "Episode:    0   Step:    1  S --0-> A R= 0.12 totalR= 0.12 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    2  A --3-> D R=-0.02 totalR= 0.10 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    3  D --1-> F R=-0.01 totalR= 0.09 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.08 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.17 totalR=-0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.17 totalR=-0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.17 totalR=-0.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.17 totalR=-0.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.59 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.17 totalR=-0.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  F --1-> E R= 0.15 totalR=-0.61 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R=-0.02 totalR=-0.62 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR=-0.64 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.17 totalR=-0.81 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.02 totalR=-0.82 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.02 totalR=-0.84 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.02 totalR=-0.86 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.05 totalR=-0.91 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  S --2-> C R=-0.03 totalR=-0.94 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   20  C --1-> B R=-0.01 totalR=-0.95 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.96 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  C --3-> L R=-0.03 totalR=-0.99 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.17 totalR=-1.16 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.17 totalR=-1.33 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-1.36 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-1.37 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.02 totalR=-1.38 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.02 totalR=-1.40 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.02 totalR=-1.42 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.05 totalR=-1.47 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.02 totalR=-1.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.02 totalR=-1.50 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.17 totalR=-1.67 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.05 totalR=-1.72 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.02 totalR=-1.73 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-1.74 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   37  F --2-> G R= 0.13 totalR=-1.61 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.17 totalR=-1.78 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.17 totalR=-1.94 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.98 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-2.01 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.17 totalR=-2.18 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-2.21 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.02 totalR=-2.23 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.17 totalR=-2.39 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.02 totalR=-2.41 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.17 totalR=-2.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.17 totalR=-2.74 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-2.77 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.17 totalR=-2.94 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-2.97 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.02 totalR=-2.99 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.02 totalR=-3.01 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.02 totalR=-3.02 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.17 totalR=-3.19 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.02 totalR=-3.21 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.02 totalR=-3.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.17 totalR=-3.39 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.02 totalR=-3.41 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.02 totalR=-3.42 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.17 totalR=-3.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.17 totalR=-3.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.17 totalR=-3.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.17 totalR=-4.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.17 totalR=-4.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.02 totalR=-4.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.02 totalR=-4.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.02 totalR=-4.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.05 totalR=-4.36 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   70  S --0-> A R=-0.05 totalR=-4.41 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   71  A --1-> B R=-0.02 totalR=-4.42 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   72  B --1-> A R=-0.02 totalR=-4.44 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   73  A --2-> E R=-0.02 totalR=-4.46 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   74  E --0-> A R=-0.02 totalR=-4.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   75  A --0-> S R=-0.05 totalR=-4.52 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   76  S --1-> B R=-0.02 totalR=-4.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   77  B --3-> K R= 0.13 totalR=-4.41 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   78  K --0-> B R=-0.03 totalR=-4.44 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   79  B --1-> A R=-0.02 totalR=-4.46 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   80  A --2-> E R=-0.02 totalR=-4.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   81  E --2-> H R=-0.02 totalR=-4.49 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   82  H --3-> H R=-0.17 totalR=-4.66 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   83  H --0-> E R=-0.02 totalR=-4.67 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   84  E --1-> F R=-0.02 totalR=-4.69 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   85  F --1-> E R=-0.02 totalR=-4.71 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   86  E --3-> E R=-0.17 totalR=-4.87 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   87  E --1-> F R=-0.02 totalR=-4.89 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   88  F --1-> E R=-0.02 totalR=-4.91 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   89  E --3-> E R=-0.17 totalR=-5.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   90  E --2-> H R=-0.02 totalR=-5.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   91  H --3-> H R=-0.17 totalR=-5.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   92  H --3-> H R=-0.17 totalR=-5.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   93  H --2-> H R=-0.17 totalR=-5.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   94  H --2-> H R=-0.17 totalR=-5.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   95  H --3-> H R=-0.17 totalR=-5.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   96  H --0-> E R=-0.02 totalR=-5.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   97  E --2-> H R=-0.02 totalR=-5.96 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   98  H --3-> H R=-0.17 totalR=-6.12 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   99  H --1-> K R=-0.05 totalR=-6.17 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  100  K --0-> B R=-0.03 totalR=-6.21 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  101  B --1-> A R=-0.02 totalR=-6.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  102  A --2-> E R=-0.02 totalR=-6.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  103  E --0-> A R=-0.02 totalR=-6.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  104  A --3-> D R=-0.02 totalR=-6.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  105  D --0-> A R=-0.02 totalR=-6.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  106  A --2-> E R=-0.02 totalR=-6.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  107  E --0-> A R=-0.02 totalR=-6.32 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  108  A --3-> D R=-0.02 totalR=-6.34 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  109  D --3-> D R=-0.17 totalR=-6.51 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  110  D --0-> A R=-0.02 totalR=-6.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  111  A --3-> D R=-0.02 totalR=-6.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  112  D --0-> A R=-0.02 totalR=-6.56 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  113  A --0-> S R=-0.05 totalR=-6.61 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  114  S --0-> A R=-0.05 totalR=-6.66 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  115  A --0-> S R=-0.05 totalR=-6.71 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  116  S --2-> C R=-0.03 totalR=-6.74 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  117  C --3-> L R=-0.03 totalR=-6.77 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  118  L --0-> C R=-0.03 totalR=-6.81 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  119  C --3-> L R=-0.03 totalR=-6.84 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  120  L --2-> L R=-0.17 totalR=-7.01 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  121  L --3-> L R=-0.17 totalR=-7.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  122  L --3-> L R=-0.17 totalR=-7.34 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  123  L --1-> M R= 0.16 totalR=-7.18 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:  124  M --1-> L R=-0.01 totalR=-7.19 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  125  L --1-> M R=-0.01 totalR=-7.20 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  126  M --0-> C R=-0.02 totalR=-7.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  127  C --1-> B R=-0.01 totalR=-7.22 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  128  B --1-> A R=-0.02 totalR=-7.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  129  A --1-> B R=-0.02 totalR=-7.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  130  B --3-> K R=-0.03 totalR=-7.29 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  131  K --0-> B R=-0.03 totalR=-7.32 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  132  B --3-> K R=-0.03 totalR=-7.36 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  133  K --1-> H R=-0.05 totalR=-7.41 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  134  H --2-> H R=-0.17 totalR=-7.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  135  H --0-> E R=-0.02 totalR=-7.59 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  136  E --1-> F R=-0.02 totalR=-7.61 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  137  F --2-> G R=-0.03 totalR=-7.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  138  G --0-> F R=-0.03 totalR=-7.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  139  F --2-> G R=-0.03 totalR=-7.71 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  140  G --0-> F R=-0.03 totalR=-7.74 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  141  F --1-> E R=-0.02 totalR=-7.76 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  142  E --3-> E R=-0.17 totalR=-7.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  143  E --2-> H R=-0.02 totalR=-7.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  144  H --2-> H R=-0.17 totalR=-8.11 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  145  H --1-> K R=-0.05 totalR=-8.16 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  146  K --0-> B R=-0.03 totalR=-8.19 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  147  B --3-> K R=-0.03 totalR=-8.22 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  148  K --1-> H R=-0.05 totalR=-8.28 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  149  H --1-> K R=-0.05 totalR=-8.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  150  K --3-> K R=-0.17 totalR=-8.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  151  K --0-> B R=-0.03 totalR=-8.53 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  152  B --2-> C R=-0.01 totalR=-8.53 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  153  C --2-> M R=-0.02 totalR=-8.55 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  154  M --3-> M R=-0.17 totalR=-8.72 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  155  M --2-> N R=-0.02 totalR=-8.73 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  156  N --3-> N R=-0.17 totalR=-8.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  157  N --3-> N R=-0.17 totalR=-9.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  158  N --3-> N R=-0.17 totalR=-9.23 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  159  N --2-> N R=-0.17 totalR=-9.40 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  160  N --1-> O R= 0.15 totalR=-9.25 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:  161  O --2-> O R=-0.17 totalR=-9.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  162  O --2-> O R=-0.17 totalR=-9.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  163  O --3-> O R=-0.17 totalR=-9.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  164  O --2-> O R=-0.17 totalR=-9.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  165  O --3-> O R=-0.17 totalR=-10.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  166  O --3-> O R=-0.17 totalR=-10.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  167  O --2-> O R=-0.17 totalR=-10.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  168  O --2-> O R=-0.17 totalR=-10.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  169  O --3-> O R=-0.17 totalR=-10.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  170  O --0-> N R=-0.02 totalR=-10.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  171  N --1-> O R=-0.02 totalR=-10.78 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  172  O --2-> O R=-0.17 totalR=-10.95 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  173  O --3-> O R=-0.17 totalR=-11.12 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  174  O --2-> O R=-0.17 totalR=-11.28 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  175  O --1-> G R=-0.05 totalR=-11.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  176  G --2-> G R=-0.17 totalR=-11.50 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  177  G --1-> O R=-0.05 totalR=-11.55 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  178  O --0-> N R=-0.02 totalR=-11.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  179  N --2-> N R=-0.17 totalR=-11.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  180  N --2-> N R=-0.17 totalR=-11.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  181  N --3-> N R=-0.17 totalR=-12.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  182  N --0-> M R=-0.02 totalR=-12.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  183  M --3-> M R=-0.17 totalR=-12.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  184  M --2-> N R=-0.02 totalR=-12.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  185  N --3-> N R=-0.17 totalR=-12.43 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  186  N --0-> M R=-0.02 totalR=-12.45 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  187  M --0-> C R=-0.02 totalR=-12.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  188  C --2-> M R=-0.02 totalR=-12.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  189  M --0-> C R=-0.02 totalR=-12.50 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  190  C --2-> M R=-0.02 totalR=-12.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  191  M --3-> M R=-0.17 totalR=-12.68 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  192  M --2-> N R=-0.02 totalR=-12.70 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  193  N --2-> N R=-0.17 totalR=-12.87 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  194  N --3-> N R=-0.17 totalR=-13.03 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  195  N --0-> M R=-0.02 totalR=-13.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  196  M --0-> C R=-0.02 totalR=-13.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  197  C --0-> S R=-0.03 totalR=-13.10 cost= 200 customerR=   0 optimum=6000\n",
            "Done: episodes=     1  avgSteps=197.00  avgTotalReward=-13.10\n",
            "Episode finished after 197 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "* random has lower total reward than version with dense customers \n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* additional pernalty for liiegal moves 1000\n",
        "* all rewards: 6000\n",
        "* perfect score???\n",
        "* estimate: half the travel cost and no illegal moves: (6000 - 1250) / 6000 = .79\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n",
        "* additionally: the agent only sees very little of the whole scenario\n",
        "  * changes with every episode\n",
        "  * was ok when network can learn fixed scenario\n"
      ]
    },
    {
      "metadata": {
        "id": "Qvi-T-YuEO0A",
        "colab_type": "code",
        "outputId": "12246f44-be0f-44f3-f524-db351fd4b820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "b9a58f4e-8fc2-4b8e-9425-85f1ad3ebcf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6443
        }
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "%time model = ppo2.learn(\\\n",
        "    env=monitored_env,\\\n",
        "    network='mlp',\\\n",
        "    num_hidden=5000,\\\n",
        "    num_layers=3,\\\n",
        "    ent_coef=0.01,\\\n",
        "    total_timesteps=500000)\n",
        "\n",
        "# %time model = ppo2.learn(\\\n",
        "#     env=monitored_env,\\\n",
        "#     network='mlp',\\\n",
        "#     num_hidden=2000,\\\n",
        "#     num_layers=3,\\\n",
        "#     ent_coef=0.1,\\\n",
        "#     total_timesteps=500000)\n",
        "\n",
        "# model = ppo2.learn(\n",
        "#     env=monitored_env,\\\n",
        "#     layer_norm=True,\\\n",
        "#     network='mlp',\\\n",
        "#     num_hidden=2000,\\\n",
        "#     activation=tf.nn.relu,\\\n",
        "#     num_layers=3,\\\n",
        "#     ent_coef=0.03,\\\n",
        "#     total_timesteps=1000000)\n",
        "\n",
        "# monitored_env = bench.Monitor(env, log_dir)\n",
        "# https://en.wikipedia.org/wiki/Q-learning#Influence_of_variables\n",
        "# %time model = deepq.learn(\\\n",
        "#         monitored_env,\\\n",
        "#         seed=42,\\\n",
        "#         network='mlp',\\\n",
        "#         lr=1e-3,\\\n",
        "#         gamma=0.99,\\\n",
        "#         total_timesteps=30000,\\\n",
        "#         buffer_size=50000,\\\n",
        "#         exploration_fraction=0.5,\\\n",
        "#         exploration_final_eps=0.02,\\\n",
        "#         print_freq=1000)\n",
        "\n",
        "model.save('berater-ppo-v7.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-01-05-09-49-26-745013\n",
            "-------------------------------------\n",
            "| approxkl           | 0.05127006   |\n",
            "| clipfrac           | 0.4300537    |\n",
            "| eplenmean          | 109          |\n",
            "| eprewmean          | -6.393057    |\n",
            "| explained_variance | -0.374       |\n",
            "| fps                | 169          |\n",
            "| nupdates           | 1            |\n",
            "| policy_entropy     | 1.3456209    |\n",
            "| policy_loss        | -0.017576873 |\n",
            "| serial_timesteps   | 2048         |\n",
            "| time_elapsed       | 12.1         |\n",
            "| total_timesteps    | 2048         |\n",
            "| value_loss         | 5.0013447    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.033649225  |\n",
            "| clipfrac           | 0.31469727   |\n",
            "| eplenmean          | 39.4         |\n",
            "| eprewmean          | -0.12291664  |\n",
            "| explained_variance | 0.191        |\n",
            "| fps                | 193          |\n",
            "| nupdates           | 10           |\n",
            "| policy_entropy     | 0.9306614    |\n",
            "| policy_loss        | -0.025409166 |\n",
            "| serial_timesteps   | 20480        |\n",
            "| time_elapsed       | 107          |\n",
            "| total_timesteps    | 20480        |\n",
            "| value_loss         | 0.17561111   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.05542698  |\n",
            "| clipfrac           | 0.31018066  |\n",
            "| eplenmean          | 31.6        |\n",
            "| eprewmean          | 0.37308335  |\n",
            "| explained_variance | 0.0981      |\n",
            "| fps                | 193         |\n",
            "| nupdates           | 20          |\n",
            "| policy_entropy     | 0.5296578   |\n",
            "| policy_loss        | -0.02961483 |\n",
            "| serial_timesteps   | 40960       |\n",
            "| time_elapsed       | 213         |\n",
            "| total_timesteps    | 40960       |\n",
            "| value_loss         | 0.02592381  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.04365254   |\n",
            "| clipfrac           | 0.22741699   |\n",
            "| eplenmean          | 20.2         |\n",
            "| eprewmean          | 0.5805834    |\n",
            "| explained_variance | 0.572        |\n",
            "| fps                | 193          |\n",
            "| nupdates           | 30           |\n",
            "| policy_entropy     | 0.4309192    |\n",
            "| policy_loss        | -0.018368207 |\n",
            "| serial_timesteps   | 61440        |\n",
            "| time_elapsed       | 319          |\n",
            "| total_timesteps    | 61440        |\n",
            "| value_loss         | 0.013548988  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.038945585  |\n",
            "| clipfrac           | 0.20263672   |\n",
            "| eplenmean          | 19.4         |\n",
            "| eprewmean          | 0.6041667    |\n",
            "| explained_variance | 0.624        |\n",
            "| fps                | 191          |\n",
            "| nupdates           | 40           |\n",
            "| policy_entropy     | 0.43682644   |\n",
            "| policy_loss        | -0.004864812 |\n",
            "| serial_timesteps   | 81920        |\n",
            "| time_elapsed       | 425          |\n",
            "| total_timesteps    | 81920        |\n",
            "| value_loss         | 0.03578509   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.041430943  |\n",
            "| clipfrac           | 0.19946289   |\n",
            "| eplenmean          | 18.9         |\n",
            "| eprewmean          | 0.61275005   |\n",
            "| explained_variance | 0.561        |\n",
            "| fps                | 196          |\n",
            "| nupdates           | 50           |\n",
            "| policy_entropy     | 0.35651794   |\n",
            "| policy_loss        | -0.016227707 |\n",
            "| serial_timesteps   | 102400       |\n",
            "| time_elapsed       | 531          |\n",
            "| total_timesteps    | 102400       |\n",
            "| value_loss         | 0.010343211  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.11565823  |\n",
            "| clipfrac           | 0.24047852  |\n",
            "| eplenmean          | 21.1        |\n",
            "| eprewmean          | 0.5963334   |\n",
            "| explained_variance | 0.372       |\n",
            "| fps                | 194         |\n",
            "| nupdates           | 60          |\n",
            "| policy_entropy     | 0.33400667  |\n",
            "| policy_loss        | 0.013092534 |\n",
            "| serial_timesteps   | 122880      |\n",
            "| time_elapsed       | 636         |\n",
            "| total_timesteps    | 122880      |\n",
            "| value_loss         | 0.009124604 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008532841   |\n",
            "| clipfrac           | 0.029174805   |\n",
            "| eplenmean          | 16.9          |\n",
            "| eprewmean          | 0.65024996    |\n",
            "| explained_variance | 0.82          |\n",
            "| fps                | 194           |\n",
            "| nupdates           | 70            |\n",
            "| policy_entropy     | 0.04408144    |\n",
            "| policy_loss        | -0.0120493835 |\n",
            "| serial_timesteps   | 143360        |\n",
            "| time_elapsed       | 742           |\n",
            "| total_timesteps    | 143360        |\n",
            "| value_loss         | 0.023514796   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.100871064  |\n",
            "| clipfrac           | 0.19384766   |\n",
            "| eplenmean          | 19.5         |\n",
            "| eprewmean          | 0.60025      |\n",
            "| explained_variance | 0.722        |\n",
            "| fps                | 193          |\n",
            "| nupdates           | 80           |\n",
            "| policy_entropy     | 0.2680549    |\n",
            "| policy_loss        | -0.022070099 |\n",
            "| serial_timesteps   | 163840       |\n",
            "| time_elapsed       | 848          |\n",
            "| total_timesteps    | 163840       |\n",
            "| value_loss         | 0.007869679  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.034146316  |\n",
            "| clipfrac           | 0.09362793   |\n",
            "| eplenmean          | 16.3         |\n",
            "| eprewmean          | 0.67475      |\n",
            "| explained_variance | 0.807        |\n",
            "| fps                | 193          |\n",
            "| nupdates           | 90           |\n",
            "| policy_entropy     | 0.15488099   |\n",
            "| policy_loss        | -0.009867809 |\n",
            "| serial_timesteps   | 184320       |\n",
            "| time_elapsed       | 954          |\n",
            "| total_timesteps    | 184320       |\n",
            "| value_loss         | 0.0075420733 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.091742806  |\n",
            "| clipfrac           | 0.15698242   |\n",
            "| eplenmean          | 17           |\n",
            "| eprewmean          | 0.65841657   |\n",
            "| explained_variance | 0.901        |\n",
            "| fps                | 192          |\n",
            "| nupdates           | 100          |\n",
            "| policy_entropy     | 0.21207516   |\n",
            "| policy_loss        | -0.013321315 |\n",
            "| serial_timesteps   | 204800       |\n",
            "| time_elapsed       | 1.06e+03     |\n",
            "| total_timesteps    | 204800       |\n",
            "| value_loss         | 0.0020749767 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.11334531   |\n",
            "| clipfrac           | 0.22814941   |\n",
            "| eplenmean          | 19.6         |\n",
            "| eprewmean          | 0.6185834    |\n",
            "| explained_variance | 0.826        |\n",
            "| fps                | 192          |\n",
            "| nupdates           | 110          |\n",
            "| policy_entropy     | 0.29120943   |\n",
            "| policy_loss        | -0.023046596 |\n",
            "| serial_timesteps   | 225280       |\n",
            "| time_elapsed       | 1.17e+03     |\n",
            "| total_timesteps    | 225280       |\n",
            "| value_loss         | 0.0043909065 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.038772028  |\n",
            "| clipfrac           | 0.107055664  |\n",
            "| eplenmean          | 15.5         |\n",
            "| eprewmean          | 0.68008333   |\n",
            "| explained_variance | 0.894        |\n",
            "| fps                | 192          |\n",
            "| nupdates           | 120          |\n",
            "| policy_entropy     | 0.16804786   |\n",
            "| policy_loss        | -0.009299656 |\n",
            "| serial_timesteps   | 245760       |\n",
            "| time_elapsed       | 1.27e+03     |\n",
            "| total_timesteps    | 245760       |\n",
            "| value_loss         | 0.004024453  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.13149968   |\n",
            "| clipfrac           | 0.15039062   |\n",
            "| eplenmean          | 19.2         |\n",
            "| eprewmean          | 0.6229167    |\n",
            "| explained_variance | 0.76         |\n",
            "| fps                | 189          |\n",
            "| nupdates           | 130          |\n",
            "| policy_entropy     | 0.17033865   |\n",
            "| policy_loss        | -0.008782024 |\n",
            "| serial_timesteps   | 266240       |\n",
            "| time_elapsed       | 1.38e+03     |\n",
            "| total_timesteps    | 266240       |\n",
            "| value_loss         | 0.011089902  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.04462887   |\n",
            "| clipfrac           | 0.10961914   |\n",
            "| eplenmean          | 16.5         |\n",
            "| eprewmean          | 0.6571667    |\n",
            "| explained_variance | 0.545        |\n",
            "| fps                | 193          |\n",
            "| nupdates           | 140          |\n",
            "| policy_entropy     | 0.14125988   |\n",
            "| policy_loss        | -0.033947762 |\n",
            "| serial_timesteps   | 286720       |\n",
            "| time_elapsed       | 1.48e+03     |\n",
            "| total_timesteps    | 286720       |\n",
            "| value_loss         | 0.017571434  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.052347623  |\n",
            "| clipfrac           | 0.091918945  |\n",
            "| eplenmean          | 17.1         |\n",
            "| eprewmean          | 0.6750834    |\n",
            "| explained_variance | 0.802        |\n",
            "| fps                | 192          |\n",
            "| nupdates           | 150          |\n",
            "| policy_entropy     | 0.12886694   |\n",
            "| policy_loss        | 0.012757084  |\n",
            "| serial_timesteps   | 307200       |\n",
            "| time_elapsed       | 1.59e+03     |\n",
            "| total_timesteps    | 307200       |\n",
            "| value_loss         | 0.0059873643 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.24333608   |\n",
            "| clipfrac           | 0.15649414   |\n",
            "| eplenmean          | 18.1         |\n",
            "| eprewmean          | 0.68291664   |\n",
            "| explained_variance | 0.845        |\n",
            "| fps                | 191          |\n",
            "| nupdates           | 160          |\n",
            "| policy_entropy     | 0.13740852   |\n",
            "| policy_loss        | -0.018098805 |\n",
            "| serial_timesteps   | 327680       |\n",
            "| time_elapsed       | 1.7e+03      |\n",
            "| total_timesteps    | 327680       |\n",
            "| value_loss         | 0.0031910392 |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.095002    |\n",
            "| clipfrac           | 0.12390137  |\n",
            "| eplenmean          | 16.8        |\n",
            "| eprewmean          | 0.68441683  |\n",
            "| explained_variance | 0.607       |\n",
            "| fps                | 193         |\n",
            "| nupdates           | 170         |\n",
            "| policy_entropy     | 0.1286461   |\n",
            "| policy_loss        | -0.02305587 |\n",
            "| serial_timesteps   | 348160      |\n",
            "| time_elapsed       | 1.8e+03     |\n",
            "| total_timesteps    | 348160      |\n",
            "| value_loss         | 0.005933811 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010284234  |\n",
            "| clipfrac           | 0.012451172  |\n",
            "| eplenmean          | 28.9         |\n",
            "| eprewmean          | 0.4749159    |\n",
            "| explained_variance | 0.543        |\n",
            "| fps                | 194          |\n",
            "| nupdates           | 180          |\n",
            "| policy_entropy     | 0.044512235  |\n",
            "| policy_loss        | 0.0027946366 |\n",
            "| serial_timesteps   | 368640       |\n",
            "| time_elapsed       | 1.91e+03     |\n",
            "| total_timesteps    | 368640       |\n",
            "| value_loss         | 0.04808835   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.40270528    |\n",
            "| clipfrac           | 0.13793945    |\n",
            "| eplenmean          | 221           |\n",
            "| eprewmean          | -3.2612076    |\n",
            "| explained_variance | 0.863         |\n",
            "| fps                | 193           |\n",
            "| nupdates           | 190           |\n",
            "| policy_entropy     | 0.13223392    |\n",
            "| policy_loss        | -0.0011471274 |\n",
            "| serial_timesteps   | 389120        |\n",
            "| time_elapsed       | 2.02e+03      |\n",
            "| total_timesteps    | 389120        |\n",
            "| value_loss         | 0.02148403    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.12118763   |\n",
            "| clipfrac           | 0.2479248    |\n",
            "| eplenmean          | 23.7         |\n",
            "| eprewmean          | 0.5844167    |\n",
            "| explained_variance | 0.813        |\n",
            "| fps                | 193          |\n",
            "| nupdates           | 200          |\n",
            "| policy_entropy     | 0.25758258   |\n",
            "| policy_loss        | -0.030573342 |\n",
            "| serial_timesteps   | 409600       |\n",
            "| time_elapsed       | 2.12e+03     |\n",
            "| total_timesteps    | 409600       |\n",
            "| value_loss         | 0.0066235336 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.119006425   |\n",
            "| clipfrac           | 0.2220459     |\n",
            "| eplenmean          | 20.3          |\n",
            "| eprewmean          | 0.5409167     |\n",
            "| explained_variance | 0.558         |\n",
            "| fps                | 190           |\n",
            "| nupdates           | 210           |\n",
            "| policy_entropy     | 0.257251      |\n",
            "| policy_loss        | -0.0049227523 |\n",
            "| serial_timesteps   | 430080        |\n",
            "| time_elapsed       | 2.23e+03      |\n",
            "| total_timesteps    | 430080        |\n",
            "| value_loss         | 0.012221637   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.9420598    |\n",
            "| clipfrac           | 0.13916016   |\n",
            "| eplenmean          | 17.3         |\n",
            "| eprewmean          | 0.6630833    |\n",
            "| explained_variance | 0.859        |\n",
            "| fps                | 192          |\n",
            "| nupdates           | 220          |\n",
            "| policy_entropy     | 0.09531072   |\n",
            "| policy_loss        | -0.02849185  |\n",
            "| serial_timesteps   | 450560       |\n",
            "| time_elapsed       | 2.33e+03     |\n",
            "| total_timesteps    | 450560       |\n",
            "| value_loss         | 0.0070347553 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.02957901   |\n",
            "| clipfrac           | 0.12182617   |\n",
            "| eplenmean          | 23.4         |\n",
            "| eprewmean          | 0.58225      |\n",
            "| explained_variance | 0.78         |\n",
            "| fps                | 193          |\n",
            "| nupdates           | 230          |\n",
            "| policy_entropy     | 0.19237123   |\n",
            "| policy_loss        | 0.0049069906 |\n",
            "| serial_timesteps   | 471040       |\n",
            "| time_elapsed       | 2.44e+03     |\n",
            "| total_timesteps    | 471040       |\n",
            "| value_loss         | 0.015563551  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.10990309   |\n",
            "| clipfrac           | 0.26428223   |\n",
            "| eplenmean          | 17.2         |\n",
            "| eprewmean          | 0.6840001    |\n",
            "| explained_variance | -1.19        |\n",
            "| fps                | 193          |\n",
            "| nupdates           | 240          |\n",
            "| policy_entropy     | 0.37644613   |\n",
            "| policy_loss        | -0.023404025 |\n",
            "| serial_timesteps   | 491520       |\n",
            "| time_elapsed       | 2.54e+03     |\n",
            "| total_timesteps    | 491520       |\n",
            "| value_loss         | 0.024558686  |\n",
            "-------------------------------------\n",
            "CPU times: user 47min 34s, sys: 9min 45s, total: 57min 20s\n",
            "Wall time: 47min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "e99b32b5-f7ae-4aca-daa0-f23b5de8e45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2ba4ecec18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2c01238d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "212a6449-6578-42c0-90fe-4cc7073545c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 0, 'B': 0, 'C': 1000, 'D': 1000, 'E': 0, 'F': 0, 'G': 1000, 'H': 0, 'K': 1000, 'L': 1000, 'M': 1000, 'N': 0, 'O': 0}\n",
            "Episode:    0   Step:    1  S --1-> B R=-0.02 totalR=-0.02 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    2  B --2-> C R= 0.16 totalR= 0.14 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    3  C --2-> M R= 0.15 totalR= 0.29 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    4  M --1-> L R= 0.16 totalR= 0.45 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    5  L --1-> M R=-0.01 totalR= 0.44 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  M --1-> L R=-0.01 totalR= 0.43 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  L --1-> M R=-0.01 totalR= 0.42 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  M --2-> N R=-0.02 totalR= 0.41 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  N --1-> O R=-0.02 totalR= 0.39 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  O --1-> G R= 0.12 totalR= 0.51 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   11  G --0-> F R=-0.03 totalR= 0.47 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   12  F --0-> D R= 0.16 totalR= 0.63 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   13  D --0-> A R=-0.02 totalR= 0.62 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  A --1-> B R=-0.02 totalR= 0.60 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  B --3-> K R= 0.13 totalR= 0.73 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   16  K --0-> B R=-0.03 totalR= 0.70 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  B --0-> S R=-0.02 totalR= 0.68 cost= 100 customerR=   0 optimum=6000\n",
            "Episode finished after 17 timesteps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5fY1da_0l15E",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}