{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v11-lower.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v11-lower.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v11 lower\n",
        "\n",
        "## less stops per consultant\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        max_paths = 4\n",
        "        self.action_space = spaces.Discrete(max_paths)\n",
        "      \n",
        "        positions = len(self.map)\n",
        "        # observations: position, reward of all 4 local paths, rest reward of all locations\n",
        "        # non existing path is -1000 and no position change\n",
        "        # look at what #getObservation returns if you are confused\n",
        "        low = np.append(np.append([0], np.full(max_paths, -1000)), np.full(positions, 0))\n",
        "        high = np.append(np.append([positions - 1], np.full(max_paths, 1000)), np.full(positions, 1000))\n",
        "        self.observation_space = spaces.Box(low=low,\n",
        "                                             high=high,\n",
        "                                             dtype=np.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = np.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=np.float32)\n",
        "        all_rest_rewards = list(self.customer_reward.values())\n",
        "        result = np.append(result, all_rest_rewards)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/3)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "outputId": "b44d4c11-2842-4f31-d6ee-fce0ac2d350b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "  1000.     0.  1000.     0.  1000.     0.  1000.     0.     0.]\n",
            "{'S': 0, 'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 1000, 'F': 0, 'G': 1000, 'H': 0, 'K': 1000, 'L': 0, 'M': 1000, 'N': 0, 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "9623730e-4fab-4df0-d664-cfd40b6bff8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3485
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.  -300.   900.  -200. -1000.     0.     0.  1000.     0.  1000.\n",
            "     0.     0.     0.  1000.     0.     0.     0.  1000.     0.]\n",
            "Episode:    0   Step:    1  S --0-> A R=-0.07 totalR=-0.07 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:    2  A --3-> D R= 0.23 totalR= 0.15 cost= 100 customerR=1000 optimum=4000\n",
            "Episode:    0   Step:    3  D --1-> F R=-0.01 totalR= 0.14 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.12 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.25 totalR=-0.12 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.25 totalR=-0.38 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.25 totalR=-0.62 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.25 totalR=-0.88 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.89 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.25 totalR=-1.14 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   11  F --1-> E R=-0.03 totalR=-1.16 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   12  E --2-> H R= 0.23 totalR=-0.94 cost= 100 customerR=1000 optimum=4000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.03 totalR=-0.96 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.25 totalR=-1.21 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.03 totalR=-1.24 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.03 totalR=-1.26 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.03 totalR=-1.29 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.07 totalR=-1.36 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   19  S --2-> C R=-0.05 totalR=-1.41 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   20  C --1-> B R= 0.24 totalR=-1.17 cost=  50 customerR=1000 optimum=4000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-1.19 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   22  C --3-> L R=-0.05 totalR=-1.24 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.25 totalR=-1.49 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.25 totalR=-1.74 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.05 totalR=-1.79 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-1.80 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.03 totalR=-1.82 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.03 totalR=-1.85 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.03 totalR=-1.87 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.07 totalR=-1.95 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.03 totalR=-1.97 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.03 totalR=-2.00 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.25 totalR=-2.25 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.07 totalR=-2.32 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.03 totalR=-2.35 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-2.36 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   37  F --2-> G R=-0.05 totalR=-2.41 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.25 totalR=-2.66 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.25 totalR=-2.91 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.05 totalR=-2.96 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.05 totalR=-3.01 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.25 totalR=-3.26 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.05 totalR=-3.31 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.03 totalR=-3.34 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.25 totalR=-3.59 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.03 totalR=-3.61 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.25 totalR=-3.86 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.25 totalR=-4.11 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.05 totalR=-4.16 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.25 totalR=-4.41 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.05 totalR=-4.46 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.03 totalR=-4.49 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.03 totalR=-4.51 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.03 totalR=-4.54 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.25 totalR=-4.79 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.03 totalR=-4.81 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.03 totalR=-4.84 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.25 totalR=-5.09 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.03 totalR=-5.11 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.03 totalR=-5.14 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.25 totalR=-5.39 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.25 totalR=-5.64 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.25 totalR=-5.89 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.25 totalR=-6.14 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.25 totalR=-6.39 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.03 totalR=-6.41 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.03 totalR=-6.44 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.03 totalR=-6.46 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.07 totalR=-6.54 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   70  S --0-> A R=-0.07 totalR=-6.61 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   71  A --1-> B R=-0.03 totalR=-6.64 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   72  B --1-> A R=-0.03 totalR=-6.66 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   73  A --2-> E R=-0.03 totalR=-6.69 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   74  E --0-> A R=-0.03 totalR=-6.71 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   75  A --0-> S R=-0.07 totalR=-6.79 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   76  S --1-> B R=-0.03 totalR=-6.81 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   77  B --3-> K R=-0.05 totalR=-6.86 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   78  K --0-> B R=-0.05 totalR=-6.91 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   79  B --1-> A R=-0.03 totalR=-6.94 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   80  A --2-> E R=-0.03 totalR=-6.96 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   81  E --2-> H R=-0.03 totalR=-6.99 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   82  H --3-> H R=-0.25 totalR=-7.24 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   83  H --0-> E R=-0.03 totalR=-7.26 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   84  E --1-> F R=-0.03 totalR=-7.29 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   85  F --1-> E R=-0.03 totalR=-7.31 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   86  E --3-> E R=-0.25 totalR=-7.56 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   87  E --1-> F R=-0.03 totalR=-7.59 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   88  F --1-> E R=-0.03 totalR=-7.61 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   89  E --3-> E R=-0.25 totalR=-7.86 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   90  E --2-> H R=-0.03 totalR=-7.89 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   91  H --3-> H R=-0.25 totalR=-8.14 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   92  H --3-> H R=-0.25 totalR=-8.39 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   93  H --2-> H R=-0.25 totalR=-8.64 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   94  H --2-> H R=-0.25 totalR=-8.89 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   95  H --3-> H R=-0.25 totalR=-9.14 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   96  H --0-> E R=-0.03 totalR=-9.16 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   97  E --2-> H R=-0.03 totalR=-9.19 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   98  H --3-> H R=-0.25 totalR=-9.44 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:   99  H --1-> K R=-0.07 totalR=-9.51 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  100  K --0-> B R=-0.05 totalR=-9.56 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  101  B --1-> A R=-0.03 totalR=-9.59 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  102  A --2-> E R=-0.03 totalR=-9.61 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  103  E --0-> A R=-0.03 totalR=-9.64 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  104  A --3-> D R=-0.03 totalR=-9.66 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  105  D --0-> A R=-0.03 totalR=-9.69 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  106  A --2-> E R=-0.03 totalR=-9.71 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  107  E --0-> A R=-0.03 totalR=-9.74 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  108  A --3-> D R=-0.03 totalR=-9.76 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  109  D --3-> D R=-0.25 totalR=-10.01 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  110  D --0-> A R=-0.03 totalR=-10.04 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  111  A --3-> D R=-0.03 totalR=-10.06 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  112  D --0-> A R=-0.03 totalR=-10.09 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  113  A --0-> S R=-0.07 totalR=-10.16 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  114  S --0-> A R=-0.07 totalR=-10.24 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  115  A --0-> S R=-0.07 totalR=-10.31 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  116  S --2-> C R=-0.05 totalR=-10.36 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  117  C --3-> L R=-0.05 totalR=-10.41 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  118  L --0-> C R=-0.05 totalR=-10.46 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  119  C --3-> L R=-0.05 totalR=-10.51 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  120  L --2-> L R=-0.25 totalR=-10.76 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  121  L --3-> L R=-0.25 totalR=-11.01 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  122  L --3-> L R=-0.25 totalR=-11.26 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  123  L --1-> M R=-0.01 totalR=-11.28 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  124  M --1-> L R=-0.01 totalR=-11.29 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  125  L --1-> M R=-0.01 totalR=-11.30 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  126  M --0-> C R=-0.03 totalR=-11.33 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  127  C --1-> B R=-0.01 totalR=-11.34 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  128  B --1-> A R=-0.03 totalR=-11.36 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  129  A --1-> B R=-0.03 totalR=-11.39 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  130  B --3-> K R=-0.05 totalR=-11.44 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  131  K --0-> B R=-0.05 totalR=-11.49 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  132  B --3-> K R=-0.05 totalR=-11.54 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  133  K --1-> H R=-0.07 totalR=-11.61 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  134  H --2-> H R=-0.25 totalR=-11.86 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  135  H --0-> E R=-0.03 totalR=-11.89 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  136  E --1-> F R=-0.03 totalR=-11.91 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  137  F --2-> G R=-0.05 totalR=-11.96 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  138  G --0-> F R=-0.05 totalR=-12.01 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  139  F --2-> G R=-0.05 totalR=-12.06 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  140  G --0-> F R=-0.05 totalR=-12.11 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  141  F --1-> E R=-0.03 totalR=-12.14 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  142  E --3-> E R=-0.25 totalR=-12.39 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  143  E --2-> H R=-0.03 totalR=-12.41 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  144  H --2-> H R=-0.25 totalR=-12.66 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  145  H --1-> K R=-0.07 totalR=-12.74 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  146  K --0-> B R=-0.05 totalR=-12.79 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  147  B --3-> K R=-0.05 totalR=-12.84 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  148  K --1-> H R=-0.07 totalR=-12.91 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  149  H --1-> K R=-0.07 totalR=-12.99 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  150  K --3-> K R=-0.25 totalR=-13.24 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  151  K --0-> B R=-0.05 totalR=-13.29 cost= 200 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  152  B --2-> C R=-0.01 totalR=-13.30 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  153  C --2-> M R=-0.03 totalR=-13.33 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  154  M --3-> M R=-0.25 totalR=-13.58 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  155  M --2-> N R= 0.23 totalR=-13.35 cost= 100 customerR=1000 optimum=4000\n",
            "Episode:    0   Step:  156  N --3-> N R=-0.25 totalR=-13.60 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  157  N --3-> N R=-0.25 totalR=-13.85 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  158  N --3-> N R=-0.25 totalR=-14.10 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  159  N --2-> N R=-0.25 totalR=-14.35 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  160  N --1-> O R=-0.03 totalR=-14.38 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  161  O --2-> O R=-0.25 totalR=-14.63 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  162  O --2-> O R=-0.25 totalR=-14.88 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  163  O --3-> O R=-0.25 totalR=-15.13 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  164  O --2-> O R=-0.25 totalR=-15.38 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  165  O --3-> O R=-0.25 totalR=-15.63 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  166  O --3-> O R=-0.25 totalR=-15.88 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  167  O --2-> O R=-0.25 totalR=-16.13 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  168  O --2-> O R=-0.25 totalR=-16.38 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  169  O --3-> O R=-0.25 totalR=-16.63 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  170  O --0-> N R=-0.03 totalR=-16.65 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  171  N --1-> O R=-0.03 totalR=-16.68 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  172  O --2-> O R=-0.25 totalR=-16.93 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  173  O --3-> O R=-0.25 totalR=-17.18 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  174  O --2-> O R=-0.25 totalR=-17.43 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  175  O --1-> G R=-0.07 totalR=-17.50 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  176  G --2-> G R=-0.25 totalR=-17.75 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  177  G --1-> O R=-0.07 totalR=-17.83 cost= 300 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  178  O --0-> N R=-0.03 totalR=-17.85 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  179  N --2-> N R=-0.25 totalR=-18.10 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  180  N --2-> N R=-0.25 totalR=-18.35 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  181  N --3-> N R=-0.25 totalR=-18.60 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  182  N --0-> M R=-0.03 totalR=-18.63 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  183  M --3-> M R=-0.25 totalR=-18.88 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  184  M --2-> N R=-0.03 totalR=-18.90 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  185  N --3-> N R=-0.25 totalR=-19.15 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  186  N --0-> M R=-0.03 totalR=-19.18 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  187  M --0-> C R=-0.03 totalR=-19.20 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  188  C --2-> M R=-0.03 totalR=-19.23 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  189  M --0-> C R=-0.03 totalR=-19.25 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  190  C --2-> M R=-0.03 totalR=-19.27 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  191  M --3-> M R=-0.25 totalR=-19.52 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  192  M --2-> N R=-0.03 totalR=-19.55 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  193  N --2-> N R=-0.25 totalR=-19.80 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  194  N --3-> N R=-0.25 totalR=-20.05 cost=1000 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  195  N --0-> M R=-0.03 totalR=-20.07 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  196  M --0-> C R=-0.03 totalR=-20.10 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:    0   Step:  197  C --0-> S R=-0.05 totalR=-20.15 cost= 200 customerR=   0 optimum=4000\n",
            "Done: episodes=     1  avgSteps=197.00  avgTotalReward=-20.15\n",
            "Episode finished after 197 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWpCU8xH0ZKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ]
    },
    {
      "metadata": {
        "id": "7NxTojLi0N0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import json\n",
        "\n",
        "class Baseline():\n",
        "\n",
        "  def __init__(self, env, max_reward, verbose=1):\n",
        "    self.env = env\n",
        "    self.max_reward = max_reward\n",
        "    self.verbose = verbose\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.map = self.env.map\n",
        "    self.rewards = self.env.customer_reward.copy()\n",
        "    \n",
        "  def as_string(self, state):\n",
        "    # reward/cost does not hurt, but is useless, path obsucres same state\n",
        "    new_state = {\n",
        "        'rewards': state['rewards'],\n",
        "        'position': state['position']\n",
        "    }\n",
        "    return json.dumps(new_state, sort_keys=True)\n",
        "  \n",
        "  def is_goal(self, state):\n",
        "    if state['position'] != 'S': return False\n",
        "    for reward in state['rewards'].values():\n",
        "      if reward != 0: return False\n",
        "    return True\n",
        "    \n",
        "\n",
        "  def expand(self, state):\n",
        "    states = []\n",
        "    for position, cost in self.map[state['position']]:\n",
        "      new_state = deepcopy(state)\n",
        "      new_state['position'] = position\n",
        "      new_state['rewards'][position] = 0\n",
        "      reward = state['rewards'][position]\n",
        "      new_state['reward'] += reward\n",
        "      new_state['cost'] += cost\n",
        "      new_state['path'].append(position)\n",
        "      states.append(new_state)\n",
        "    return states\n",
        "\n",
        "  def search(self, root, max_depth = 25):\n",
        "      closed = set()\n",
        "      open = [root]\n",
        "\n",
        "      while open:\n",
        "          state = open.pop(0)\n",
        "          if self.as_string(state) in closed: continue  \n",
        "\n",
        "          closed.add(self.as_string(state))\n",
        "\n",
        "          depth = len(state['path'])\n",
        "          if depth > max_depth:\n",
        "            if self.verbose > 0:\n",
        "              print(\"Visited:\", len(closed))\n",
        "              print(\"Reached max depth, without reaching goal\")\n",
        "            return None\n",
        "\n",
        "          if self.is_goal(state):\n",
        "            scaled_reward = (state['reward'] - state['cost']) / self.max_reward\n",
        "            state['scaled_reward'] = scaled_reward\n",
        "            if self.verbose > 0:\n",
        "              print(\"Scaled reward:\", scaled_reward)            \n",
        "              print(\"Perfect path\", state['path'])\n",
        "            return state\n",
        "\n",
        "          expanded = self.expand(state)\n",
        "          open += expanded\n",
        "          # make this best first\n",
        "          open.sort(key=lambda state: state['cost'])\n",
        "        \n",
        "  def find_optimum(self):\n",
        "    initial_state = {\n",
        "        'rewards': self.rewards.copy(),\n",
        "        'position': 'S',\n",
        "        'reward': 0,\n",
        "        'cost': 0,\n",
        "        'path': ['S']\n",
        "    }\n",
        "    return self.search(initial_state)\n",
        "  \n",
        "  def benchmark(self, model, sample_runs=100):\n",
        "    self.verbose = 0\n",
        "    BeraterEnv.showStep = False\n",
        "    BeraterEnv.showDone = False\n",
        "\n",
        "    perfect_rewards = []\n",
        "    model_rewards = []\n",
        "    for run in range(sample_runs):\n",
        "      observation = self.env.reset()\n",
        "      self.reset()\n",
        "      \n",
        "      optimum_state = self.find_optimum()\n",
        "      perfect_rewards.append(optimum_state['scaled_reward'])\n",
        "      \n",
        "      state = np.zeros((1, 2*128))\n",
        "      dones = np.zeros((1))\n",
        "\n",
        "      for t in range(1000):\n",
        "        actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "        observation, reward, done, info = self.env.step(actions[0])\n",
        "        if done:\n",
        "          break\n",
        "      model_rewards.append(env.totalReward)\n",
        "    return perfect_rewards, model_rewards\n",
        "  \n",
        "  def score(self, model, sample_runs=100):\n",
        "    perfect_rewards, model_rewards = self.benchmark(model, sample_runs=100)\n",
        "    \n",
        "    perfect_score_mean, perfect_score_std = np.array(perfect_rewards).mean(), np.array(perfect_rewards).std()\n",
        "    test_score_mean, test_score_std = np.array(model_rewards).mean(), np.array(model_rewards).std()\n",
        "    \n",
        "    return perfect_score_mean, perfect_score_std, test_score_mean, test_score_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "Estimation\n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* all rewards: 6000\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n",
        "* estimate: no illegal moves and between\n",
        "  * half the travel cost: (6000 - 1250) / 6000 = .79\n",
        "  * and full traval cost (6000 - 2500) / 6000 = 0.58\n",
        "* additionally: the agent only sees very little of the whole scenario\n",
        "  * changes with every episode\n",
        "  * was ok when network can learn fixed scenario\n"
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LArM6BsJgUvL",
        "colab_type": "code",
        "outputId": "2d0a6239-b88e-4405-ca6f-e3d1ba459afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GCufDIpnjNms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1: Extract MLP builder from openai sources"
      ]
    },
    {
      "metadata": {
        "id": "WMylk8s_amq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# copied from https://github.com/openai/baselines/blob/master/baselines/a2c/utils.py\n",
        "\n",
        "def ortho_init(scale=1.0):\n",
        "    def _ortho_init(shape, dtype, partition_info=None):\n",
        "        #lasagne ortho init for tf\n",
        "        shape = tuple(shape)\n",
        "        if len(shape) == 2:\n",
        "            flat_shape = shape\n",
        "        elif len(shape) == 4: # assumes NHWC\n",
        "            flat_shape = (np.prod(shape[:-1]), shape[-1])\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        a = np.random.normal(0.0, 1.0, flat_shape)\n",
        "        u, _, v = np.linalg.svd(a, full_matrices=False)\n",
        "        q = u if u.shape == flat_shape else v # pick the one with the correct shape\n",
        "        q = q.reshape(shape)\n",
        "        return (scale * q[:shape[0], :shape[1]]).astype(np.float32)\n",
        "    return _ortho_init      \n",
        "\n",
        "def fc(x, scope, nh, *, init_scale=1.0, init_bias=0.0):\n",
        "    with tf.variable_scope(scope):\n",
        "        nin = x.get_shape()[1].value\n",
        "        w = tf.get_variable(\"w\", [nin, nh], initializer=ortho_init(init_scale))\n",
        "        b = tf.get_variable(\"b\", [nh], initializer=tf.constant_initializer(init_bias))\n",
        "        return tf.matmul(x, w)+b\n",
        "      \n",
        "\n",
        "# copied from https://github.com/openai/baselines/blob/master/baselines/common/models.py#L31\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.tanh, layer_norm=False):\n",
        "    \"\"\"\n",
        "    Stack of fully-connected layers to be used in a policy / q-function approximator\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "\n",
        "    num_layers: int                 number of fully-connected layers (default: 2)\n",
        "\n",
        "    num_hidden: int                 size of fully-connected layers (default: 64)\n",
        "\n",
        "    activation:                     activation function (default: tf.tanh)\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "\n",
        "    function that builds fully connected network with a given input tensor / placeholder\n",
        "    \"\"\"\n",
        "    def network_fn(X):\n",
        "#         print('network_fn called')\n",
        "#         Tensor(\"ppo2_model_4/Ob:0\", shape=(1, 19), dtype=float32)\n",
        "#         Tensor(\"ppo2_model_4/Ob_1:0\", shape=(512, 19), dtype=float32)\n",
        "#         print (X)\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = fc(h, 'mlp_fc{}'.format(i), nh=num_hidden, init_scale=np.sqrt(2))\n",
        "            if layer_norm:\n",
        "                h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "          \n",
        "#         Tensor(\"ppo2_model_4/pi/Tanh_2:0\", shape=(1, 500), dtype=float32)\n",
        "#         Tensor(\"ppo2_model_4/pi_2/Tanh_2:0\", shape=(512, 500), dtype=float32)\n",
        "#         print(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUvTLKKK8L8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2: Replace exotic parts\n",
        "\n",
        "Steps:\n",
        "1. Low level matmul replaced with dense layer (no need for custom code here)\n",
        "    * https://www.tensorflow.org/api_docs/python/tf/layers\n",
        "    * https://www.tensorflow.org/api_docs/python/tf/layers/Dense\n",
        "\n",
        "1. initializer changed to best practice glorot uniform, but does not give reliable results, so use seed\n",
        "1. use relu activations (should train faster)\n",
        "1. standard batch normalization does not train with any configuration (no idea why), so we need to keep layer normalization\n",
        "1.Dropout and L2 would be nice as well, but easy to do within the boundaries of the OpenAI framework:  https://stackoverflow.com/questions/38292760/tensorflow-introducing-both-l2-regularization-and-dropout-into-the-network-do\n",
        "\n",
        "#### Alternative: Using Keras API\n",
        "\n",
        "Not done here, as no big benefit expected and would need to be integrated into surrounding low level tensorflow model. Need to reuse session. If you want to do this, be sure to check at least the first link\n",
        "\n",
        "* using Keras within TensorFlow model: https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html\n",
        "* https://stackoverflow.com/questions/46790506/calling-a-keras-model-on-a-tensorflow-tensor-but-keep-weights\n",
        "* https://www.tensorflow.org/api_docs/python/tf/get_default_session\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_session"
      ]
    },
    {
      "metadata": {
        "id": "9X4G6Y4O8Khh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# first the dense layer\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.tanh, layer_norm=False):\n",
        "    def network_fn(X):\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = tf.layers.dense(h, units=num_hidden, kernel_initializer=ortho_init(np.sqrt(2)))\n",
        "#             h = fc(h, 'mlp_fc{}'.format(i), nh=num_hidden, init_scale=np.sqrt(2))\n",
        "            if layer_norm:\n",
        "                h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIbexm3U_341",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# then initializer, relu activations\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.nn.relu, layer_norm=False):\n",
        "    def network_fn(X):\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = tf.layers.dense(h, units=num_hidden, kernel_initializer=tf.initializers.glorot_uniform(seed=13))\n",
        "            if layer_norm:\n",
        "#               h = tf.layers.batch_normalization(h, center=True, scale=True)\n",
        "              h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "390c2fe8-1427-4d9e-8c90-5fdb97e8cad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12563
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "# https://arxiv.org/abs/1607.06450 for layer_norm\n",
        "\n",
        "# lr linear from lr=1e-2 to lr=1e-4 (default lr=3e-4)\n",
        "def lr_range(frac):\n",
        "  # we get the remaining updates between 1 and 0\n",
        "  start_lr = 1e-2\n",
        "  end_lr = 1e-4\n",
        "  diff_lr = start_lr - end_lr\n",
        "  lr = end_lr + diff_lr * frac\n",
        "  return lr\n",
        "  \n",
        "network = mlp(num_hidden=500, num_layers=3, layer_norm=True)\n",
        "  \n",
        "model = ppo2.learn(\n",
        "    env=monitored_env,\n",
        "    network=network,\n",
        "    lr=lr_range,\n",
        "    gamma=1.0,\n",
        "    ent_coef=0.05,\n",
        "    total_timesteps=1000000)\n",
        "\n",
        "# model = ppo2.learn(\n",
        "#     env=monitored_env,\n",
        "#     network='mlp',\n",
        "#     num_hidden=500,\n",
        "#     num_layers=3,\n",
        "#     layer_norm=True,\n",
        "#     lr=lr_range,\n",
        "#     gamma=1.0,\n",
        "#     ent_coef=0.05,\n",
        "#     total_timesteps=500000)\n",
        "\n",
        "\n",
        "# model.save('berater-ppo-v11.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-02-02-11-53-30-053080\n",
            "-----------------------------------\n",
            "| approxkl           | 2.941825   |\n",
            "| clipfrac           | 0.8652344  |\n",
            "| eplenmean          | 103        |\n",
            "| eprewmean          | -9.56776   |\n",
            "| explained_variance | -0.0733    |\n",
            "| fps                | 229        |\n",
            "| nupdates           | 1          |\n",
            "| policy_entropy     | 0.7919297  |\n",
            "| policy_loss        | 0.22188225 |\n",
            "| serial_timesteps   | 2048       |\n",
            "| time_elapsed       | 8.93       |\n",
            "| total_timesteps    | 2048       |\n",
            "| value_loss         | 5.650091   |\n",
            "-----------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011109623  |\n",
            "| clipfrac           | 0.17163086   |\n",
            "| eplenmean          | 197          |\n",
            "| eprewmean          | -24.284218   |\n",
            "| explained_variance | 0.357        |\n",
            "| fps                | 242          |\n",
            "| nupdates           | 10           |\n",
            "| policy_entropy     | 1.2311755    |\n",
            "| policy_loss        | 0.0035450112 |\n",
            "| serial_timesteps   | 20480        |\n",
            "| time_elapsed       | 86.1         |\n",
            "| total_timesteps    | 20480        |\n",
            "| value_loss         | 0.7877262    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.020323595   |\n",
            "| clipfrac           | 0.23449707    |\n",
            "| eplenmean          | 33.5          |\n",
            "| eprewmean          | -0.5572501    |\n",
            "| explained_variance | 0.268         |\n",
            "| fps                | 235           |\n",
            "| nupdates           | 20            |\n",
            "| policy_entropy     | 1.0036737     |\n",
            "| policy_loss        | -0.0025038125 |\n",
            "| serial_timesteps   | 40960         |\n",
            "| time_elapsed       | 173           |\n",
            "| total_timesteps    | 40960         |\n",
            "| value_loss         | 0.8844344     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.022769066   |\n",
            "| clipfrac           | 0.13952637    |\n",
            "| eplenmean          | 17.8          |\n",
            "| eprewmean          | 0.444875      |\n",
            "| explained_variance | 0.362         |\n",
            "| fps                | 238           |\n",
            "| nupdates           | 30            |\n",
            "| policy_entropy     | 0.48463985    |\n",
            "| policy_loss        | -0.0115797445 |\n",
            "| serial_timesteps   | 61440         |\n",
            "| time_elapsed       | 258           |\n",
            "| total_timesteps    | 61440         |\n",
            "| value_loss         | 0.018630525   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014277967  |\n",
            "| clipfrac           | 0.09863281   |\n",
            "| eplenmean          | 15.7         |\n",
            "| eprewmean          | 0.54287505   |\n",
            "| explained_variance | 0.641        |\n",
            "| fps                | 224          |\n",
            "| nupdates           | 40           |\n",
            "| policy_entropy     | 0.4177548    |\n",
            "| policy_loss        | -0.010330426 |\n",
            "| serial_timesteps   | 81920        |\n",
            "| time_elapsed       | 345          |\n",
            "| total_timesteps    | 81920        |\n",
            "| value_loss         | 0.010846087  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.033244397 |\n",
            "| clipfrac           | 0.19274902  |\n",
            "| eplenmean          | 16.1        |\n",
            "| eprewmean          | 0.53400004  |\n",
            "| explained_variance | 0.615       |\n",
            "| fps                | 245         |\n",
            "| nupdates           | 50          |\n",
            "| policy_entropy     | 0.4156646   |\n",
            "| policy_loss        | -0.0164154  |\n",
            "| serial_timesteps   | 102400      |\n",
            "| time_elapsed       | 432         |\n",
            "| total_timesteps    | 102400      |\n",
            "| value_loss         | 0.011962597 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.3159182    |\n",
            "| clipfrac           | 0.14355469   |\n",
            "| eplenmean          | 16.7         |\n",
            "| eprewmean          | 0.5480001    |\n",
            "| explained_variance | 0.736        |\n",
            "| fps                | 240          |\n",
            "| nupdates           | 60           |\n",
            "| policy_entropy     | 0.2923594    |\n",
            "| policy_loss        | -0.008356356 |\n",
            "| serial_timesteps   | 122880       |\n",
            "| time_elapsed       | 517          |\n",
            "| total_timesteps    | 122880       |\n",
            "| value_loss         | 0.0059518963 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.018375905  |\n",
            "| clipfrac           | 0.0592041    |\n",
            "| eplenmean          | 13.4         |\n",
            "| eprewmean          | 0.6322501    |\n",
            "| explained_variance | 0.919        |\n",
            "| fps                | 243          |\n",
            "| nupdates           | 70           |\n",
            "| policy_entropy     | 0.1634921    |\n",
            "| policy_loss        | -0.006269118 |\n",
            "| serial_timesteps   | 143360       |\n",
            "| time_elapsed       | 603          |\n",
            "| total_timesteps    | 143360       |\n",
            "| value_loss         | 0.0023508794 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0241796     |\n",
            "| clipfrac           | 0.08935547    |\n",
            "| eplenmean          | 14.3          |\n",
            "| eprewmean          | 0.5982501     |\n",
            "| explained_variance | 0.862         |\n",
            "| fps                | 245           |\n",
            "| nupdates           | 80            |\n",
            "| policy_entropy     | 0.18425635    |\n",
            "| policy_loss        | -0.0029391998 |\n",
            "| serial_timesteps   | 163840        |\n",
            "| time_elapsed       | 686           |\n",
            "| total_timesteps    | 163840        |\n",
            "| value_loss         | 0.004549614   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.015241606  |\n",
            "| clipfrac           | 0.064697266  |\n",
            "| eplenmean          | 13.5         |\n",
            "| eprewmean          | 0.61450005   |\n",
            "| explained_variance | 0.867        |\n",
            "| fps                | 237          |\n",
            "| nupdates           | 90           |\n",
            "| policy_entropy     | 0.16506186   |\n",
            "| policy_loss        | -0.009734957 |\n",
            "| serial_timesteps   | 184320       |\n",
            "| time_elapsed       | 772          |\n",
            "| total_timesteps    | 184320       |\n",
            "| value_loss         | 0.004604857  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.030398399  |\n",
            "| clipfrac           | 0.06750488   |\n",
            "| eplenmean          | 13.3         |\n",
            "| eprewmean          | 0.6353751    |\n",
            "| explained_variance | 0.899        |\n",
            "| fps                | 236          |\n",
            "| nupdates           | 100          |\n",
            "| policy_entropy     | 0.14458856   |\n",
            "| policy_loss        | -0.011282699 |\n",
            "| serial_timesteps   | 204800       |\n",
            "| time_elapsed       | 858          |\n",
            "| total_timesteps    | 204800       |\n",
            "| value_loss         | 0.002601428  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 1.0168337    |\n",
            "| clipfrac           | 0.09411621   |\n",
            "| eplenmean          | 14.3         |\n",
            "| eprewmean          | 0.59925      |\n",
            "| explained_variance | 0.718        |\n",
            "| fps                | 238          |\n",
            "| nupdates           | 110          |\n",
            "| policy_entropy     | 0.18029702   |\n",
            "| policy_loss        | -0.013885051 |\n",
            "| serial_timesteps   | 225280       |\n",
            "| time_elapsed       | 944          |\n",
            "| total_timesteps    | 225280       |\n",
            "| value_loss         | 0.00835008   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014737571  |\n",
            "| clipfrac           | 0.057861328  |\n",
            "| eplenmean          | 14           |\n",
            "| eprewmean          | 0.5975       |\n",
            "| explained_variance | 0.873        |\n",
            "| fps                | 234          |\n",
            "| nupdates           | 120          |\n",
            "| policy_entropy     | 0.20613486   |\n",
            "| policy_loss        | -0.006952518 |\n",
            "| serial_timesteps   | 245760       |\n",
            "| time_elapsed       | 1.03e+03     |\n",
            "| total_timesteps    | 245760       |\n",
            "| value_loss         | 0.0035512256 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.018355738  |\n",
            "| clipfrac           | 0.06347656   |\n",
            "| eplenmean          | 13.4         |\n",
            "| eprewmean          | 0.62575006   |\n",
            "| explained_variance | 0.896        |\n",
            "| fps                | 238          |\n",
            "| nupdates           | 130          |\n",
            "| policy_entropy     | 0.14095928   |\n",
            "| policy_loss        | -0.010998954 |\n",
            "| serial_timesteps   | 266240       |\n",
            "| time_elapsed       | 1.12e+03     |\n",
            "| total_timesteps    | 266240       |\n",
            "| value_loss         | 0.003295257  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.19399488   |\n",
            "| clipfrac           | 0.10986328   |\n",
            "| eplenmean          | 14           |\n",
            "| eprewmean          | 0.5835001    |\n",
            "| explained_variance | 0.631        |\n",
            "| fps                | 230          |\n",
            "| nupdates           | 140          |\n",
            "| policy_entropy     | 0.16596594   |\n",
            "| policy_loss        | -0.007981181 |\n",
            "| serial_timesteps   | 286720       |\n",
            "| time_elapsed       | 1.21e+03     |\n",
            "| total_timesteps    | 286720       |\n",
            "| value_loss         | 0.012636683  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.019220036   |\n",
            "| clipfrac           | 0.080200195   |\n",
            "| eplenmean          | 14            |\n",
            "| eprewmean          | 0.60325       |\n",
            "| explained_variance | 0.888         |\n",
            "| fps                | 234           |\n",
            "| nupdates           | 150           |\n",
            "| policy_entropy     | 0.18601565    |\n",
            "| policy_loss        | -0.0049650325 |\n",
            "| serial_timesteps   | 307200        |\n",
            "| time_elapsed       | 1.29e+03      |\n",
            "| total_timesteps    | 307200        |\n",
            "| value_loss         | 0.0030240435  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009970713   |\n",
            "| clipfrac           | 0.057495117   |\n",
            "| eplenmean          | 14.1          |\n",
            "| eprewmean          | 0.60862505    |\n",
            "| explained_variance | 0.869         |\n",
            "| fps                | 238           |\n",
            "| nupdates           | 160           |\n",
            "| policy_entropy     | 0.13423318    |\n",
            "| policy_loss        | -0.0061767497 |\n",
            "| serial_timesteps   | 327680        |\n",
            "| time_elapsed       | 1.38e+03      |\n",
            "| total_timesteps    | 327680        |\n",
            "| value_loss         | 0.003461809   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009839177   |\n",
            "| clipfrac           | 0.048828125   |\n",
            "| eplenmean          | 13.7          |\n",
            "| eprewmean          | 0.62825006    |\n",
            "| explained_variance | 0.891         |\n",
            "| fps                | 302           |\n",
            "| nupdates           | 170           |\n",
            "| policy_entropy     | 0.13447367    |\n",
            "| policy_loss        | -0.0070082555 |\n",
            "| serial_timesteps   | 348160        |\n",
            "| time_elapsed       | 1.46e+03      |\n",
            "| total_timesteps    | 348160        |\n",
            "| value_loss         | 0.0032754636  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.021614809   |\n",
            "| clipfrac           | 0.084228516   |\n",
            "| eplenmean          | 12.9          |\n",
            "| eprewmean          | 0.6433751     |\n",
            "| explained_variance | 0.891         |\n",
            "| fps                | 447           |\n",
            "| nupdates           | 180           |\n",
            "| policy_entropy     | 0.1379534     |\n",
            "| policy_loss        | -0.0092982985 |\n",
            "| serial_timesteps   | 368640        |\n",
            "| time_elapsed       | 1.52e+03      |\n",
            "| total_timesteps    | 368640        |\n",
            "| value_loss         | 0.0028722738  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0052087777  |\n",
            "| clipfrac           | 0.040649414   |\n",
            "| eplenmean          | 12.6          |\n",
            "| eprewmean          | 0.652625      |\n",
            "| explained_variance | 0.919         |\n",
            "| fps                | 455           |\n",
            "| nupdates           | 190           |\n",
            "| policy_entropy     | 0.13391213    |\n",
            "| policy_loss        | -0.0025335078 |\n",
            "| serial_timesteps   | 389120        |\n",
            "| time_elapsed       | 1.56e+03      |\n",
            "| total_timesteps    | 389120        |\n",
            "| value_loss         | 0.0027993554  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012602154  |\n",
            "| clipfrac           | 0.05053711   |\n",
            "| eplenmean          | 13.8         |\n",
            "| eprewmean          | 0.62675005   |\n",
            "| explained_variance | 0.931        |\n",
            "| fps                | 447          |\n",
            "| nupdates           | 200          |\n",
            "| policy_entropy     | 0.14118853   |\n",
            "| policy_loss        | -0.005303227 |\n",
            "| serial_timesteps   | 409600       |\n",
            "| time_elapsed       | 1.61e+03     |\n",
            "| total_timesteps    | 409600       |\n",
            "| value_loss         | 0.0022257585 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0052323123 |\n",
            "| clipfrac           | 0.02709961   |\n",
            "| eplenmean          | 13.4         |\n",
            "| eprewmean          | 0.6413751    |\n",
            "| explained_variance | 0.94         |\n",
            "| fps                | 451          |\n",
            "| nupdates           | 210          |\n",
            "| policy_entropy     | 0.13991146   |\n",
            "| policy_loss        | -0.003223437 |\n",
            "| serial_timesteps   | 430080       |\n",
            "| time_elapsed       | 1.66e+03     |\n",
            "| total_timesteps    | 430080       |\n",
            "| value_loss         | 0.001764402  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.12947075   |\n",
            "| clipfrac           | 0.06225586   |\n",
            "| eplenmean          | 14.4         |\n",
            "| eprewmean          | 0.61112505   |\n",
            "| explained_variance | 0.438        |\n",
            "| fps                | 306          |\n",
            "| nupdates           | 220          |\n",
            "| policy_entropy     | 0.15536869   |\n",
            "| policy_loss        | -0.006629542 |\n",
            "| serial_timesteps   | 450560       |\n",
            "| time_elapsed       | 1.71e+03     |\n",
            "| total_timesteps    | 450560       |\n",
            "| value_loss         | 0.01965701   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00417855    |\n",
            "| clipfrac           | 0.028320312   |\n",
            "| eplenmean          | 13.8          |\n",
            "| eprewmean          | 0.62187505    |\n",
            "| explained_variance | 0.819         |\n",
            "| fps                | 455           |\n",
            "| nupdates           | 230           |\n",
            "| policy_entropy     | 0.14575034    |\n",
            "| policy_loss        | -0.0054530757 |\n",
            "| serial_timesteps   | 471040        |\n",
            "| time_elapsed       | 1.77e+03      |\n",
            "| total_timesteps    | 471040        |\n",
            "| value_loss         | 0.0061102803  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.015792925   |\n",
            "| clipfrac           | 0.061645508   |\n",
            "| eplenmean          | 13.4          |\n",
            "| eprewmean          | 0.63750005    |\n",
            "| explained_variance | 0.929         |\n",
            "| fps                | 454           |\n",
            "| nupdates           | 240           |\n",
            "| policy_entropy     | 0.13534781    |\n",
            "| policy_loss        | -0.0027168347 |\n",
            "| serial_timesteps   | 491520        |\n",
            "| time_elapsed       | 1.81e+03      |\n",
            "| total_timesteps    | 491520        |\n",
            "| value_loss         | 0.0021382559  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 1.0184951    |\n",
            "| clipfrac           | 0.056030273  |\n",
            "| eplenmean          | 14.6         |\n",
            "| eprewmean          | 0.6278751    |\n",
            "| explained_variance | 0.867        |\n",
            "| fps                | 447          |\n",
            "| nupdates           | 250          |\n",
            "| policy_entropy     | 0.08797901   |\n",
            "| policy_loss        | -0.009060582 |\n",
            "| serial_timesteps   | 512000       |\n",
            "| time_elapsed       | 1.86e+03     |\n",
            "| total_timesteps    | 512000       |\n",
            "| value_loss         | 0.0033240865 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0067446     |\n",
            "| clipfrac           | 0.026611328   |\n",
            "| eplenmean          | 13.8          |\n",
            "| eprewmean          | 0.63850003    |\n",
            "| explained_variance | 0.936         |\n",
            "| fps                | 453           |\n",
            "| nupdates           | 260           |\n",
            "| policy_entropy     | 0.091363266   |\n",
            "| policy_loss        | -0.0074315793 |\n",
            "| serial_timesteps   | 532480        |\n",
            "| time_elapsed       | 1.9e+03       |\n",
            "| total_timesteps    | 532480        |\n",
            "| value_loss         | 0.0020089825  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0026345062 |\n",
            "| clipfrac           | 0.01965332   |\n",
            "| eplenmean          | 13.2         |\n",
            "| eprewmean          | 0.652625     |\n",
            "| explained_variance | 0.842        |\n",
            "| fps                | 446          |\n",
            "| nupdates           | 270          |\n",
            "| policy_entropy     | 0.09904944   |\n",
            "| policy_loss        | -0.004740921 |\n",
            "| serial_timesteps   | 552960       |\n",
            "| time_elapsed       | 1.95e+03     |\n",
            "| total_timesteps    | 552960       |\n",
            "| value_loss         | 0.0074977507 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01302915    |\n",
            "| clipfrac           | 0.040405273   |\n",
            "| eplenmean          | 13.7          |\n",
            "| eprewmean          | 0.64512515    |\n",
            "| explained_variance | 0.936         |\n",
            "| fps                | 452           |\n",
            "| nupdates           | 280           |\n",
            "| policy_entropy     | 0.11074939    |\n",
            "| policy_loss        | -0.0050132987 |\n",
            "| serial_timesteps   | 573440        |\n",
            "| time_elapsed       | 1.99e+03      |\n",
            "| total_timesteps    | 573440        |\n",
            "| value_loss         | 0.0021768366  |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 1.9540656   |\n",
            "| clipfrac           | 0.16918945  |\n",
            "| eplenmean          | 16.4        |\n",
            "| eprewmean          | 0.5826249   |\n",
            "| explained_variance | 0.676       |\n",
            "| fps                | 452         |\n",
            "| nupdates           | 290         |\n",
            "| policy_entropy     | 0.104800746 |\n",
            "| policy_loss        | -0.00900771 |\n",
            "| serial_timesteps   | 593920      |\n",
            "| time_elapsed       | 2.04e+03    |\n",
            "| total_timesteps    | 593920      |\n",
            "| value_loss         | 0.010487304 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0056301765 |\n",
            "| clipfrac           | 0.033447266  |\n",
            "| eplenmean          | 13.1         |\n",
            "| eprewmean          | 0.64412504   |\n",
            "| explained_variance | 0.948        |\n",
            "| fps                | 301          |\n",
            "| nupdates           | 300          |\n",
            "| policy_entropy     | 0.10101879   |\n",
            "| policy_loss        | -0.00554824  |\n",
            "| serial_timesteps   | 614400       |\n",
            "| time_elapsed       | 2.1e+03      |\n",
            "| total_timesteps    | 614400       |\n",
            "| value_loss         | 0.001592973  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.21309415   |\n",
            "| clipfrac           | 0.06335449   |\n",
            "| eplenmean          | 14.3         |\n",
            "| eprewmean          | 0.62775004   |\n",
            "| explained_variance | 0.895        |\n",
            "| fps                | 455          |\n",
            "| nupdates           | 310          |\n",
            "| policy_entropy     | 0.079781845  |\n",
            "| policy_loss        | -0.011604965 |\n",
            "| serial_timesteps   | 634880       |\n",
            "| time_elapsed       | 2.14e+03     |\n",
            "| total_timesteps    | 634880       |\n",
            "| value_loss         | 0.002812557  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0043862015  |\n",
            "| clipfrac           | 0.032470703   |\n",
            "| eplenmean          | 13.4          |\n",
            "| eprewmean          | 0.64849997    |\n",
            "| explained_variance | 0.955         |\n",
            "| fps                | 452           |\n",
            "| nupdates           | 320           |\n",
            "| policy_entropy     | 0.08803745    |\n",
            "| policy_loss        | -0.0045434036 |\n",
            "| serial_timesteps   | 655360        |\n",
            "| time_elapsed       | 2.19e+03      |\n",
            "| total_timesteps    | 655360        |\n",
            "| value_loss         | 0.0014379303  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0024406593  |\n",
            "| clipfrac           | 0.020141602   |\n",
            "| eplenmean          | 13.2          |\n",
            "| eprewmean          | 0.65262514    |\n",
            "| explained_variance | 0.968         |\n",
            "| fps                | 458           |\n",
            "| nupdates           | 330           |\n",
            "| policy_entropy     | 0.08018157    |\n",
            "| policy_loss        | -0.0037007118 |\n",
            "| serial_timesteps   | 675840        |\n",
            "| time_elapsed       | 2.23e+03      |\n",
            "| total_timesteps    | 675840        |\n",
            "| value_loss         | 0.0010899325  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009145873  |\n",
            "| clipfrac           | 0.03125      |\n",
            "| eplenmean          | 13.5         |\n",
            "| eprewmean          | 0.65975016   |\n",
            "| explained_variance | 0.959        |\n",
            "| fps                | 426          |\n",
            "| nupdates           | 340          |\n",
            "| policy_entropy     | 0.069653824  |\n",
            "| policy_loss        | -0.004031658 |\n",
            "| serial_timesteps   | 696320       |\n",
            "| time_elapsed       | 2.28e+03     |\n",
            "| total_timesteps    | 696320       |\n",
            "| value_loss         | 0.0013633264 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.007949681   |\n",
            "| clipfrac           | 0.034423828   |\n",
            "| eplenmean          | 13.3          |\n",
            "| eprewmean          | 0.64712507    |\n",
            "| explained_variance | 0.966         |\n",
            "| fps                | 451           |\n",
            "| nupdates           | 350           |\n",
            "| policy_entropy     | 0.056294866   |\n",
            "| policy_loss        | -0.0041342983 |\n",
            "| serial_timesteps   | 716800        |\n",
            "| time_elapsed       | 2.33e+03      |\n",
            "| total_timesteps    | 716800        |\n",
            "| value_loss         | 0.001151719   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.072082736   |\n",
            "| clipfrac           | 0.022705078   |\n",
            "| eplenmean          | 12.9          |\n",
            "| eprewmean          | 0.6565001     |\n",
            "| explained_variance | 0.974         |\n",
            "| fps                | 454           |\n",
            "| nupdates           | 360           |\n",
            "| policy_entropy     | 0.042207815   |\n",
            "| policy_loss        | 0.00043820913 |\n",
            "| serial_timesteps   | 737280        |\n",
            "| time_elapsed       | 2.37e+03      |\n",
            "| total_timesteps    | 737280        |\n",
            "| value_loss         | 0.00088604516 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.48683086   |\n",
            "| clipfrac           | 0.16015625   |\n",
            "| eplenmean          | 13.8         |\n",
            "| eprewmean          | 0.64475006   |\n",
            "| explained_variance | 0.567        |\n",
            "| fps                | 457          |\n",
            "| nupdates           | 370          |\n",
            "| policy_entropy     | 0.10219899   |\n",
            "| policy_loss        | -0.027342254 |\n",
            "| serial_timesteps   | 757760       |\n",
            "| time_elapsed       | 2.42e+03     |\n",
            "| total_timesteps    | 757760       |\n",
            "| value_loss         | 0.0056514023 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0018960744  |\n",
            "| clipfrac           | 0.012817383   |\n",
            "| eplenmean          | 13            |\n",
            "| eprewmean          | 0.6593751     |\n",
            "| explained_variance | 0.975         |\n",
            "| fps                | 456           |\n",
            "| nupdates           | 380           |\n",
            "| policy_entropy     | 0.055053737   |\n",
            "| policy_loss        | -0.0030122474 |\n",
            "| serial_timesteps   | 778240        |\n",
            "| time_elapsed       | 2.46e+03      |\n",
            "| total_timesteps    | 778240        |\n",
            "| value_loss         | 0.0007830829  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0027322252  |\n",
            "| clipfrac           | 0.0146484375  |\n",
            "| eplenmean          | 13.3          |\n",
            "| eprewmean          | 0.66187507    |\n",
            "| explained_variance | 0.966         |\n",
            "| fps                | 456           |\n",
            "| nupdates           | 390           |\n",
            "| policy_entropy     | 0.055765595   |\n",
            "| policy_loss        | -0.0029848365 |\n",
            "| serial_timesteps   | 798720        |\n",
            "| time_elapsed       | 2.51e+03      |\n",
            "| total_timesteps    | 798720        |\n",
            "| value_loss         | 0.001131454   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0041841506  |\n",
            "| clipfrac           | 0.0146484375  |\n",
            "| eplenmean          | 13.7          |\n",
            "| eprewmean          | 0.65162504    |\n",
            "| explained_variance | 0.98          |\n",
            "| fps                | 456           |\n",
            "| nupdates           | 400           |\n",
            "| policy_entropy     | 0.036050744   |\n",
            "| policy_loss        | -0.0029349213 |\n",
            "| serial_timesteps   | 819200        |\n",
            "| time_elapsed       | 2.55e+03      |\n",
            "| total_timesteps    | 819200        |\n",
            "| value_loss         | 0.0006780743  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014107618  |\n",
            "| clipfrac           | 0.04296875   |\n",
            "| eplenmean          | 13.9         |\n",
            "| eprewmean          | 0.65900004   |\n",
            "| explained_variance | 0.963        |\n",
            "| fps                | 455          |\n",
            "| nupdates           | 410          |\n",
            "| policy_entropy     | 0.058429115  |\n",
            "| policy_loss        | -0.008078549 |\n",
            "| serial_timesteps   | 839680       |\n",
            "| time_elapsed       | 2.6e+03      |\n",
            "| total_timesteps    | 839680       |\n",
            "| value_loss         | 0.0010480622 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0034239083  |\n",
            "| clipfrac           | 0.016479492   |\n",
            "| eplenmean          | 13.3          |\n",
            "| eprewmean          | 0.6492501     |\n",
            "| explained_variance | 0.913         |\n",
            "| fps                | 456           |\n",
            "| nupdates           | 420           |\n",
            "| policy_entropy     | 0.04147793    |\n",
            "| policy_loss        | -0.0016530517 |\n",
            "| serial_timesteps   | 860160        |\n",
            "| time_elapsed       | 2.64e+03      |\n",
            "| total_timesteps    | 860160        |\n",
            "| value_loss         | 0.0020454326  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.004970356  |\n",
            "| clipfrac           | 0.017089844  |\n",
            "| eplenmean          | 12.8         |\n",
            "| eprewmean          | 0.67537504   |\n",
            "| explained_variance | 0.979        |\n",
            "| fps                | 457          |\n",
            "| nupdates           | 430          |\n",
            "| policy_entropy     | 0.03331552   |\n",
            "| policy_loss        | -0.002474314 |\n",
            "| serial_timesteps   | 880640       |\n",
            "| time_elapsed       | 2.69e+03     |\n",
            "| total_timesteps    | 880640       |\n",
            "| value_loss         | 0.0007392287 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0010154366  |\n",
            "| clipfrac           | 0.0056152344  |\n",
            "| eplenmean          | 13.1          |\n",
            "| eprewmean          | 0.6690001     |\n",
            "| explained_variance | 0.985         |\n",
            "| fps                | 467           |\n",
            "| nupdates           | 440           |\n",
            "| policy_entropy     | 0.02742693    |\n",
            "| policy_loss        | -0.0014554078 |\n",
            "| serial_timesteps   | 901120        |\n",
            "| time_elapsed       | 2.73e+03      |\n",
            "| total_timesteps    | 901120        |\n",
            "| value_loss         | 0.0005306321  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00077193684 |\n",
            "| clipfrac           | 0.00793457    |\n",
            "| eplenmean          | 12.6          |\n",
            "| eprewmean          | 0.6708751     |\n",
            "| explained_variance | 0.982         |\n",
            "| fps                | 463           |\n",
            "| nupdates           | 450           |\n",
            "| policy_entropy     | 0.034371108   |\n",
            "| policy_loss        | -0.0012055722 |\n",
            "| serial_timesteps   | 921600        |\n",
            "| time_elapsed       | 2.77e+03      |\n",
            "| total_timesteps    | 921600        |\n",
            "| value_loss         | 0.0005658836  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0010368674  |\n",
            "| clipfrac           | 0.0073242188  |\n",
            "| eplenmean          | 13            |\n",
            "| eprewmean          | 0.6665001     |\n",
            "| explained_variance | 0.984         |\n",
            "| fps                | 465           |\n",
            "| nupdates           | 460           |\n",
            "| policy_entropy     | 0.023645813   |\n",
            "| policy_loss        | -0.0014689909 |\n",
            "| serial_timesteps   | 942080        |\n",
            "| time_elapsed       | 2.82e+03      |\n",
            "| total_timesteps    | 942080        |\n",
            "| value_loss         | 0.0005269377  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0007725451  |\n",
            "| clipfrac           | 0.0068359375  |\n",
            "| eplenmean          | 12.8          |\n",
            "| eprewmean          | 0.6626251     |\n",
            "| explained_variance | 0.985         |\n",
            "| fps                | 449           |\n",
            "| nupdates           | 470           |\n",
            "| policy_entropy     | 0.027620003   |\n",
            "| policy_loss        | -0.0022085046 |\n",
            "| serial_timesteps   | 962560        |\n",
            "| time_elapsed       | 2.86e+03      |\n",
            "| total_timesteps    | 962560        |\n",
            "| value_loss         | 0.00051442115 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00043838652 |\n",
            "| clipfrac           | 0.0026855469  |\n",
            "| eplenmean          | 13.3          |\n",
            "| eprewmean          | 0.66050005    |\n",
            "| explained_variance | 0.986         |\n",
            "| fps                | 470           |\n",
            "| nupdates           | 480           |\n",
            "| policy_entropy     | 0.020727549   |\n",
            "| policy_loss        | -0.0014504729 |\n",
            "| serial_timesteps   | 983040        |\n",
            "| time_elapsed       | 2.91e+03      |\n",
            "| total_timesteps    | 983040        |\n",
            "| value_loss         | 0.00049987464 |\n",
            "--------------------------------------\n",
            "CPU times: user 48min 57s, sys: 7min 57s, total: 56min 54s\n",
            "Wall time: 49min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "cb34437f-a2af-439d-e961-195dadef498d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fac4931ff98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "id": "H_QTckfBra7l",
        "colab_type": "code",
        "outputId": "d18c779a-50b5-420d-cb81-be5b8ce46331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "baseline = Baseline(env, max_reward=4000)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 0, 'B': 1000, 'C': 1000, 'D': 0, 'E': 0, 'F': 0, 'G': 0, 'H': 0, 'K': 0, 'L': 0, 'M': 0, 'N': 1000, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "c378d55d-e174-40c8-a11c-fe6b4a199826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, reward={}\".format(t+1, env.totalReward))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:  101   Step:    1  S --1-> B R= 0.23 totalR= 0.23 cost= 100 customerR=1000 optimum=4000\n",
            "Episode:  101   Step:    2  B --2-> C R= 0.24 totalR= 0.46 cost=  50 customerR=1000 optimum=4000\n",
            "Episode:  101   Step:    3  C --2-> M R=-0.03 totalR= 0.44 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:  101   Step:    4  M --2-> N R= 0.23 totalR= 0.66 cost= 100 customerR=1000 optimum=4000\n",
            "Episode:  101   Step:    5  N --1-> O R= 0.23 totalR= 0.89 cost= 100 customerR=1000 optimum=4000\n",
            "Episode:  101   Step:    6  O --0-> N R=-0.03 totalR= 0.86 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:  101   Step:    7  N --0-> M R=-0.03 totalR= 0.84 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:  101   Step:    8  M --0-> C R=-0.03 totalR= 0.81 cost= 100 customerR=   0 optimum=4000\n",
            "Episode:  101   Step:    9  C --1-> B R=-0.01 totalR= 0.80 cost=  50 customerR=   0 optimum=4000\n",
            "Episode:  101   Step:   10  B --0-> S R=-0.03 totalR= 0.77 cost= 100 customerR=   0 optimum=4000\n",
            "Episode finished after 10 timesteps, reward=0.7749999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3z35_dMMt6SW",
        "colab_type": "code",
        "outputId": "ccca2537-aa56-491a-94b6-a9a5ece93e9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "%time baseline.find_optimum()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaled reward: 0.775\n",
            "Perfect path ['S', 'B', 'C', 'M', 'N', 'O', 'N', 'M', 'C', 'B', 'S']\n",
            "CPU times: user 12.7 ms, sys: 2.11 ms, total: 14.8 ms\n",
            "Wall time: 16 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cost': 900,\n",
              " 'path': ['S', 'B', 'C', 'M', 'N', 'O', 'N', 'M', 'C', 'B', 'S'],\n",
              " 'position': 'S',\n",
              " 'reward': 4000,\n",
              " 'rewards': {'A': 0,\n",
              "  'B': 0,\n",
              "  'C': 0,\n",
              "  'D': 0,\n",
              "  'E': 0,\n",
              "  'F': 0,\n",
              "  'G': 0,\n",
              "  'H': 0,\n",
              "  'K': 0,\n",
              "  'L': 0,\n",
              "  'M': 0,\n",
              "  'N': 0,\n",
              "  'O': 0,\n",
              "  'S': 0},\n",
              " 'scaled_reward': 0.775}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "K36GXkzyRGOO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "KMb58O_q067F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "baseline = Baseline(env, max_reward=4000)\n",
        "perfect_score_mean, perfect_score_std, test_score_mean, test_score_std = baseline.score(model, sample_runs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dr9ylHgnRIcc",
        "colab_type": "code",
        "outputId": "0b2e0820-f995-475b-b7cd-e87a7334ddc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# perfect scores\n",
        "perfect_score_mean, perfect_score_std"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.675375, 0.06605998694368626)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "rOSOoO29Rwgm",
        "colab_type": "code",
        "outputId": "c6bd240a-6dff-4349-d34b-4041c940811d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# test scores for our model\n",
        "test_score_mean, test_score_std"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6703749999999998, 0.06795345373857023)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "Ls8IKVV1R5SE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}