{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v9\n",
        "\n",
        "## Changes from v8\n",
        "* Dijkstra basline (delivers optimum, and almost always beats us)\n",
        "* smaller network (less expensive and as good as larger one)\n",
        "* better ways of exploration\n",
        "   * lr range from high to low\n",
        "   * ent_coef to 0 instead \n",
        "* set discount factor (gamma) to 1\n",
        "  * rewards late in the game are as good as eartly ones\n",
        "  * no need to push game to an end, as every move comes at costs anyway\n",
        "  \n",
        "## next steps\n",
        "1. configure custom network including regularization (https://blog.openai.com/quantifying-generalization-in-reinforcement-learning/)\n",
        " * add reward for returning home once all other locations have been visited \n",
        "* better observation?\n",
        "  * network can learn all costs and all connections as they are static\n",
        "  * rewards are not, but are given in the observation\n",
        "  * all information is there, but\n",
        "  * it is very convoluted, too hard for us as humans\n",
        "  * could we make this more accessible? Would this also help?\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        max_paths = 4\n",
        "        self.action_space = spaces.Discrete(max_paths)\n",
        "      \n",
        "        positions = len(self.map)\n",
        "        # observations: position, reward of all 4 local paths, rest reward of all locations\n",
        "        # non existing path is -1000 and no position change\n",
        "        # look at what #getObservation returns if you are confused\n",
        "        low = np.append(np.append([0], np.full(max_paths, -1000)), np.full(positions, 0))\n",
        "        high = np.append(np.append([positions - 1], np.full(max_paths, 1000)), np.full(positions, 1000))\n",
        "        self.observation_space = spaces.Box(low=low,\n",
        "                                             high=high,\n",
        "                                             dtype=np.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = np.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=np.float32)\n",
        "        all_rest_rewards = list(self.customer_reward.values())\n",
        "        result = np.append(result, all_rest_rewards)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/2)\n",
        "#       number_per_consultant = int(number_of_customers/1.5)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "outputId": "4b2a5b7a-8f15-4e53-dcd1-633f58b335d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.  -300.   900.  -200. -1000.     0.     0.  1000.     0.  1000.\n",
            "     0.     0.  1000.  1000.  1000.  1000.     0.     0.     0.]\n",
            "{'S': 0, 'A': 0, 'B': 1000, 'C': 0, 'D': 1000, 'E': 0, 'F': 0, 'G': 1000, 'H': 1000, 'K': 1000, 'L': 1000, 'M': 0, 'N': 0, 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "76731f23-9f1b-4283-e7c0-cc50f41db869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3540
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.   700.  -100.  -200. -1000.     0.  1000.     0.     0.     0.\n",
            "  1000.     0.  1000.     0.  1000.     0.  1000.  1000.     0.]\n",
            "Episode:    0   Step:    1  S --0-> A R= 0.12 totalR= 0.12 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    2  A --3-> D R=-0.02 totalR= 0.10 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    3  D --1-> F R=-0.01 totalR= 0.09 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.08 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.17 totalR=-0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.17 totalR=-0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.17 totalR=-0.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.17 totalR=-0.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.59 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.17 totalR=-0.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  F --1-> E R= 0.15 totalR=-0.61 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R=-0.02 totalR=-0.62 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR=-0.64 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.17 totalR=-0.81 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.02 totalR=-0.82 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.02 totalR=-0.84 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.02 totalR=-0.86 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.05 totalR=-0.91 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  S --2-> C R=-0.03 totalR=-0.94 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   20  C --1-> B R=-0.01 totalR=-0.95 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.96 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  C --3-> L R=-0.03 totalR=-0.99 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.17 totalR=-1.16 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.17 totalR=-1.33 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-1.36 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-1.37 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.02 totalR=-1.38 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.02 totalR=-1.40 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.02 totalR=-1.42 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.05 totalR=-1.47 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.02 totalR=-1.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.02 totalR=-1.50 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.17 totalR=-1.67 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.05 totalR=-1.72 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.02 totalR=-1.73 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-1.74 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   37  F --2-> G R= 0.13 totalR=-1.61 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.17 totalR=-1.78 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.17 totalR=-1.94 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.98 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-2.01 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.17 totalR=-2.18 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-2.21 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.02 totalR=-2.23 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.17 totalR=-2.39 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.02 totalR=-2.41 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.17 totalR=-2.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.17 totalR=-2.74 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-2.77 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.17 totalR=-2.94 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-2.97 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.02 totalR=-2.99 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.02 totalR=-3.01 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.02 totalR=-3.02 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.17 totalR=-3.19 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.02 totalR=-3.21 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.02 totalR=-3.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.17 totalR=-3.39 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.02 totalR=-3.41 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.02 totalR=-3.42 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.17 totalR=-3.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.17 totalR=-3.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.17 totalR=-3.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.17 totalR=-4.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.17 totalR=-4.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.02 totalR=-4.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.02 totalR=-4.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.02 totalR=-4.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.05 totalR=-4.36 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   70  S --0-> A R=-0.05 totalR=-4.41 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   71  A --1-> B R=-0.02 totalR=-4.42 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   72  B --1-> A R=-0.02 totalR=-4.44 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   73  A --2-> E R=-0.02 totalR=-4.46 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   74  E --0-> A R=-0.02 totalR=-4.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   75  A --0-> S R=-0.05 totalR=-4.52 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   76  S --1-> B R=-0.02 totalR=-4.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   77  B --3-> K R= 0.13 totalR=-4.41 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   78  K --0-> B R=-0.03 totalR=-4.44 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   79  B --1-> A R=-0.02 totalR=-4.46 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   80  A --2-> E R=-0.02 totalR=-4.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   81  E --2-> H R=-0.02 totalR=-4.49 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   82  H --3-> H R=-0.17 totalR=-4.66 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   83  H --0-> E R=-0.02 totalR=-4.67 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   84  E --1-> F R=-0.02 totalR=-4.69 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   85  F --1-> E R=-0.02 totalR=-4.71 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   86  E --3-> E R=-0.17 totalR=-4.87 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   87  E --1-> F R=-0.02 totalR=-4.89 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   88  F --1-> E R=-0.02 totalR=-4.91 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   89  E --3-> E R=-0.17 totalR=-5.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   90  E --2-> H R=-0.02 totalR=-5.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   91  H --3-> H R=-0.17 totalR=-5.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   92  H --3-> H R=-0.17 totalR=-5.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   93  H --2-> H R=-0.17 totalR=-5.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   94  H --2-> H R=-0.17 totalR=-5.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   95  H --3-> H R=-0.17 totalR=-5.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   96  H --0-> E R=-0.02 totalR=-5.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   97  E --2-> H R=-0.02 totalR=-5.96 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   98  H --3-> H R=-0.17 totalR=-6.12 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   99  H --1-> K R=-0.05 totalR=-6.17 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  100  K --0-> B R=-0.03 totalR=-6.21 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  101  B --1-> A R=-0.02 totalR=-6.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  102  A --2-> E R=-0.02 totalR=-6.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  103  E --0-> A R=-0.02 totalR=-6.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  104  A --3-> D R=-0.02 totalR=-6.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  105  D --0-> A R=-0.02 totalR=-6.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  106  A --2-> E R=-0.02 totalR=-6.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  107  E --0-> A R=-0.02 totalR=-6.32 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  108  A --3-> D R=-0.02 totalR=-6.34 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  109  D --3-> D R=-0.17 totalR=-6.51 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  110  D --0-> A R=-0.02 totalR=-6.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  111  A --3-> D R=-0.02 totalR=-6.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  112  D --0-> A R=-0.02 totalR=-6.56 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  113  A --0-> S R=-0.05 totalR=-6.61 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  114  S --0-> A R=-0.05 totalR=-6.66 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  115  A --0-> S R=-0.05 totalR=-6.71 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  116  S --2-> C R=-0.03 totalR=-6.74 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  117  C --3-> L R=-0.03 totalR=-6.77 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  118  L --0-> C R=-0.03 totalR=-6.81 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  119  C --3-> L R=-0.03 totalR=-6.84 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  120  L --2-> L R=-0.17 totalR=-7.01 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  121  L --3-> L R=-0.17 totalR=-7.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  122  L --3-> L R=-0.17 totalR=-7.34 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  123  L --1-> M R= 0.16 totalR=-7.18 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:  124  M --1-> L R=-0.01 totalR=-7.19 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  125  L --1-> M R=-0.01 totalR=-7.20 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  126  M --0-> C R=-0.02 totalR=-7.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  127  C --1-> B R=-0.01 totalR=-7.22 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  128  B --1-> A R=-0.02 totalR=-7.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  129  A --1-> B R=-0.02 totalR=-7.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  130  B --3-> K R=-0.03 totalR=-7.29 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  131  K --0-> B R=-0.03 totalR=-7.32 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  132  B --3-> K R=-0.03 totalR=-7.36 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  133  K --1-> H R=-0.05 totalR=-7.41 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  134  H --2-> H R=-0.17 totalR=-7.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  135  H --0-> E R=-0.02 totalR=-7.59 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  136  E --1-> F R=-0.02 totalR=-7.61 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  137  F --2-> G R=-0.03 totalR=-7.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  138  G --0-> F R=-0.03 totalR=-7.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  139  F --2-> G R=-0.03 totalR=-7.71 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  140  G --0-> F R=-0.03 totalR=-7.74 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  141  F --1-> E R=-0.02 totalR=-7.76 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  142  E --3-> E R=-0.17 totalR=-7.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  143  E --2-> H R=-0.02 totalR=-7.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  144  H --2-> H R=-0.17 totalR=-8.11 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  145  H --1-> K R=-0.05 totalR=-8.16 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  146  K --0-> B R=-0.03 totalR=-8.19 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  147  B --3-> K R=-0.03 totalR=-8.22 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  148  K --1-> H R=-0.05 totalR=-8.28 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  149  H --1-> K R=-0.05 totalR=-8.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  150  K --3-> K R=-0.17 totalR=-8.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  151  K --0-> B R=-0.03 totalR=-8.53 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  152  B --2-> C R=-0.01 totalR=-8.53 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  153  C --2-> M R=-0.02 totalR=-8.55 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  154  M --3-> M R=-0.17 totalR=-8.72 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  155  M --2-> N R= 0.15 totalR=-8.57 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:  156  N --3-> N R=-0.17 totalR=-8.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  157  N --3-> N R=-0.17 totalR=-8.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  158  N --3-> N R=-0.17 totalR=-9.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  159  N --2-> N R=-0.17 totalR=-9.23 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  160  N --1-> O R=-0.02 totalR=-9.25 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  161  O --2-> O R=-0.17 totalR=-9.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  162  O --2-> O R=-0.17 totalR=-9.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  163  O --3-> O R=-0.17 totalR=-9.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  164  O --2-> O R=-0.17 totalR=-9.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  165  O --3-> O R=-0.17 totalR=-10.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  166  O --3-> O R=-0.17 totalR=-10.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  167  O --2-> O R=-0.17 totalR=-10.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  168  O --2-> O R=-0.17 totalR=-10.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  169  O --3-> O R=-0.17 totalR=-10.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  170  O --0-> N R=-0.02 totalR=-10.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  171  N --1-> O R=-0.02 totalR=-10.78 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  172  O --2-> O R=-0.17 totalR=-10.95 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  173  O --3-> O R=-0.17 totalR=-11.12 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  174  O --2-> O R=-0.17 totalR=-11.28 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  175  O --1-> G R=-0.05 totalR=-11.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  176  G --2-> G R=-0.17 totalR=-11.50 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  177  G --1-> O R=-0.05 totalR=-11.55 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  178  O --0-> N R=-0.02 totalR=-11.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  179  N --2-> N R=-0.17 totalR=-11.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  180  N --2-> N R=-0.17 totalR=-11.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  181  N --3-> N R=-0.17 totalR=-12.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  182  N --0-> M R=-0.02 totalR=-12.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  183  M --3-> M R=-0.17 totalR=-12.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  184  M --2-> N R=-0.02 totalR=-12.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  185  N --3-> N R=-0.17 totalR=-12.43 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  186  N --0-> M R=-0.02 totalR=-12.45 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  187  M --0-> C R=-0.02 totalR=-12.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  188  C --2-> M R=-0.02 totalR=-12.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  189  M --0-> C R=-0.02 totalR=-12.50 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  190  C --2-> M R=-0.02 totalR=-12.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  191  M --3-> M R=-0.17 totalR=-12.68 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  192  M --2-> N R=-0.02 totalR=-12.70 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  193  N --2-> N R=-0.17 totalR=-12.87 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  194  N --3-> N R=-0.17 totalR=-13.03 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  195  N --0-> M R=-0.02 totalR=-13.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  196  M --0-> C R=-0.02 totalR=-13.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  197  C --0-> S R=-0.03 totalR=-13.10 cost= 200 customerR=   0 optimum=6000\n",
            "Done: episodes=     1  avgSteps=197.00  avgTotalReward=-13.10\n",
            "Episode finished after 197 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWpCU8xH0ZKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ]
    },
    {
      "metadata": {
        "id": "7NxTojLi0N0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import json\n",
        "\n",
        "class Baseline():\n",
        "\n",
        "  def __init__(self, env):\n",
        "    self.map = env.map\n",
        "    self.rewards = env.customer_reward.copy()\n",
        "\n",
        "  def as_string(self, state):\n",
        "    # reward/cost does not hurt, but is useless, path obsucres same state\n",
        "    new_state = {\n",
        "        'rewards': state['rewards'],\n",
        "        'position': state['position']\n",
        "    }\n",
        "    return json.dumps(new_state, sort_keys=True)\n",
        "  \n",
        "  def is_goal(self, state):\n",
        "    if state['position'] != 'S': return False\n",
        "    for reward in state['rewards'].values():\n",
        "      if reward != 0: return False\n",
        "    return True\n",
        "    \n",
        "\n",
        "  def expand(self, state):\n",
        "    states = []\n",
        "    for position, cost in self.map[state['position']]:\n",
        "      new_state = deepcopy(state)\n",
        "      new_state['position'] = position\n",
        "      new_state['rewards'][position] = 0\n",
        "      reward = state['rewards'][position]\n",
        "      new_state['reward'] += reward\n",
        "      new_state['cost'] += cost\n",
        "      new_state['path'].append(position)\n",
        "      states.append(new_state)\n",
        "    return states\n",
        "\n",
        "  def search(self, root, max_depth = 25):\n",
        "      closed = set()\n",
        "      open = [root]\n",
        "\n",
        "      while open:\n",
        "          state = open.pop(0)\n",
        "          if self.as_string(state) in closed: continue  \n",
        "\n",
        "          closed.add(self.as_string(state))\n",
        "\n",
        "          depth = len(state['path'])\n",
        "          if depth > max_depth:\n",
        "            print(\"Visited:\", len(closed))\n",
        "            print(\"Reached max depth, without reaching goal\")\n",
        "            return None\n",
        "\n",
        "          if self.is_goal(state):\n",
        "              print(\"Scaled reward:\", (state['reward'] - state['cost']) / 6000)            \n",
        "              print(\"Perfect path\", state['path'])\n",
        "              return state\n",
        "\n",
        "          expanded = self.expand(state)\n",
        "          open += expanded\n",
        "          # make this best first\n",
        "          open.sort(key=lambda state: state['cost'])\n",
        "        \n",
        "  def find_optimum(self):\n",
        "    initial_state = {\n",
        "        'rewards': self.rewards.copy(),\n",
        "        'position': 'S',\n",
        "        'reward': 0,\n",
        "        'cost': 0,\n",
        "        'path': ['S']\n",
        "    }\n",
        "    return self.search(initial_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "Estimation\n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* all rewards: 6000\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n",
        "* estimate: no illegal moves and between\n",
        "  * half the travel cost: (6000 - 1250) / 6000 = .79\n",
        "  * and full traval cost (6000 - 2500) / 6000 = 0.58\n",
        "* additionally: the agent only sees very little of the whole scenario\n",
        "  * changes with every episode\n",
        "  * was ok when network can learn fixed scenario\n"
      ]
    },
    {
      "metadata": {
        "id": "Qvi-T-YuEO0A",
        "colab_type": "code",
        "outputId": "daa7ee4b-37c9-4df8-839a-3bee6da6845f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "43c201fb-9812-4ef7-f931-6818c51a42e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6546
        }
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "\n",
        "# lr linear from lr=1e-2 to lr=1e-4 (default lr=3e-4)\n",
        "def lr_range(frac):\n",
        "  # we get the remaining updates between 1 and 0\n",
        "  start_lr = 1e-2\n",
        "  end_lr = 1e-4\n",
        "  diff_lr = start_lr - end_lr\n",
        "  lr = end_lr + diff_lr * frac\n",
        "  return lr\n",
        "  \n",
        "  \n",
        "%time model = ppo2.learn(\\\n",
        "    env=monitored_env,\\\n",
        "    network='mlp',\\\n",
        "    num_hidden=100,\\\n",
        "    num_layers=2,\\\n",
        "    lr=lr_range,\\\n",
        "    gamma=1.0,\\\n",
        "    ent_coef=0,\\\n",
        "    total_timesteps=500000)\n",
        "\n",
        "model.save('berater-ppo-v9.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-01-15-11-15-58-954522\n",
            "------------------------------------\n",
            "| approxkl           | 0.023103338 |\n",
            "| clipfrac           | 0.35205078  |\n",
            "| eplenmean          | 127         |\n",
            "| eprewmean          | -8.682294   |\n",
            "| explained_variance | -0.161      |\n",
            "| fps                | 513         |\n",
            "| nupdates           | 1           |\n",
            "| policy_entropy     | 1.3645813   |\n",
            "| policy_loss        | -0.01850223 |\n",
            "| serial_timesteps   | 2048        |\n",
            "| time_elapsed       | 3.99        |\n",
            "| total_timesteps    | 2048        |\n",
            "| value_loss         | 0.827625    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.03243614    |\n",
            "| clipfrac           | 0.27197266    |\n",
            "| eplenmean          | 26.2          |\n",
            "| eprewmean          | 0.24858333    |\n",
            "| explained_variance | 0.0876        |\n",
            "| fps                | 541           |\n",
            "| nupdates           | 10            |\n",
            "| policy_entropy     | 0.8294066     |\n",
            "| policy_loss        | -0.0026689938 |\n",
            "| serial_timesteps   | 20480         |\n",
            "| time_elapsed       | 37.9          |\n",
            "| total_timesteps    | 20480         |\n",
            "| value_loss         | 0.06174012    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.053087167  |\n",
            "| clipfrac           | 0.31835938   |\n",
            "| eplenmean          | 23.7         |\n",
            "| eprewmean          | 0.45025003   |\n",
            "| explained_variance | 0.496        |\n",
            "| fps                | 543          |\n",
            "| nupdates           | 20           |\n",
            "| policy_entropy     | 0.5480789    |\n",
            "| policy_loss        | -0.011946119 |\n",
            "| serial_timesteps   | 40960        |\n",
            "| time_elapsed       | 75.7         |\n",
            "| total_timesteps    | 40960        |\n",
            "| value_loss         | 0.017454876  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.043690257  |\n",
            "| clipfrac           | 0.22668457   |\n",
            "| eplenmean          | 57.1         |\n",
            "| eprewmean          | -0.09424737  |\n",
            "| explained_variance | 0.27         |\n",
            "| fps                | 540          |\n",
            "| nupdates           | 30           |\n",
            "| policy_entropy     | 0.43003696   |\n",
            "| policy_loss        | -0.003352603 |\n",
            "| serial_timesteps   | 61440        |\n",
            "| time_elapsed       | 113          |\n",
            "| total_timesteps    | 61440        |\n",
            "| value_loss         | 0.0399479    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.050043352  |\n",
            "| clipfrac           | 0.2043457    |\n",
            "| eplenmean          | 20.7         |\n",
            "| eprewmean          | 0.57525      |\n",
            "| explained_variance | 0.645        |\n",
            "| fps                | 546          |\n",
            "| nupdates           | 40           |\n",
            "| policy_entropy     | 0.39650154   |\n",
            "| policy_loss        | 0.0038919048 |\n",
            "| serial_timesteps   | 81920        |\n",
            "| time_elapsed       | 151          |\n",
            "| total_timesteps    | 81920        |\n",
            "| value_loss         | 0.010507269  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.033678316  |\n",
            "| clipfrac           | 0.08288574   |\n",
            "| eplenmean          | 29.6         |\n",
            "| eprewmean          | 0.5209166    |\n",
            "| explained_variance | 0.459        |\n",
            "| fps                | 545          |\n",
            "| nupdates           | 50           |\n",
            "| policy_entropy     | 0.170712     |\n",
            "| policy_loss        | 0.0033618086 |\n",
            "| serial_timesteps   | 102400       |\n",
            "| time_elapsed       | 189          |\n",
            "| total_timesteps    | 102400       |\n",
            "| value_loss         | 0.0063539003 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.08344242   |\n",
            "| clipfrac           | 0.22912598   |\n",
            "| eplenmean          | 23.9         |\n",
            "| eprewmean          | 0.50725      |\n",
            "| explained_variance | 0.336        |\n",
            "| fps                | 541          |\n",
            "| nupdates           | 60           |\n",
            "| policy_entropy     | 0.31766897   |\n",
            "| policy_loss        | -0.025597129 |\n",
            "| serial_timesteps   | 122880       |\n",
            "| time_elapsed       | 227          |\n",
            "| total_timesteps    | 122880       |\n",
            "| value_loss         | 0.036688264  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.038880594  |\n",
            "| clipfrac           | 0.16918945   |\n",
            "| eplenmean          | 31.3         |\n",
            "| eprewmean          | 0.4221668    |\n",
            "| explained_variance | 0.324        |\n",
            "| fps                | 544          |\n",
            "| nupdates           | 70           |\n",
            "| policy_entropy     | 0.32694247   |\n",
            "| policy_loss        | -0.003205174 |\n",
            "| serial_timesteps   | 143360       |\n",
            "| time_elapsed       | 264          |\n",
            "| total_timesteps    | 143360       |\n",
            "| value_loss         | 0.024353016  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.065428585 |\n",
            "| clipfrac           | 0.18249512  |\n",
            "| eplenmean          | 24.2        |\n",
            "| eprewmean          | 0.54375005  |\n",
            "| explained_variance | 0.6         |\n",
            "| fps                | 543         |\n",
            "| nupdates           | 80          |\n",
            "| policy_entropy     | 0.35694346  |\n",
            "| policy_loss        | 0.003851099 |\n",
            "| serial_timesteps   | 163840      |\n",
            "| time_elapsed       | 302         |\n",
            "| total_timesteps    | 163840      |\n",
            "| value_loss         | 0.017159795 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.028710444  |\n",
            "| clipfrac           | 0.16003418   |\n",
            "| eplenmean          | 20.1         |\n",
            "| eprewmean          | 0.61225003   |\n",
            "| explained_variance | 0.628        |\n",
            "| fps                | 536          |\n",
            "| nupdates           | 90           |\n",
            "| policy_entropy     | 0.30883375   |\n",
            "| policy_loss        | -0.005053243 |\n",
            "| serial_timesteps   | 184320       |\n",
            "| time_elapsed       | 340          |\n",
            "| total_timesteps    | 184320       |\n",
            "| value_loss         | 0.01049211   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.031093929  |\n",
            "| clipfrac           | 0.140625     |\n",
            "| eplenmean          | 19.9         |\n",
            "| eprewmean          | 0.62850004   |\n",
            "| explained_variance | 0.458        |\n",
            "| fps                | 532          |\n",
            "| nupdates           | 100          |\n",
            "| policy_entropy     | 0.26834214   |\n",
            "| policy_loss        | -0.018454708 |\n",
            "| serial_timesteps   | 204800       |\n",
            "| time_elapsed       | 378          |\n",
            "| total_timesteps    | 204800       |\n",
            "| value_loss         | 0.009735778  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.020139245  |\n",
            "| clipfrac           | 0.12390137   |\n",
            "| eplenmean          | 21           |\n",
            "| eprewmean          | 0.61758333   |\n",
            "| explained_variance | 0.518        |\n",
            "| fps                | 545          |\n",
            "| nupdates           | 110          |\n",
            "| policy_entropy     | 0.2436951    |\n",
            "| policy_loss        | -0.013474366 |\n",
            "| serial_timesteps   | 225280       |\n",
            "| time_elapsed       | 416          |\n",
            "| total_timesteps    | 225280       |\n",
            "| value_loss         | 0.01494521   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.055445053   |\n",
            "| clipfrac           | 0.15039062    |\n",
            "| eplenmean          | 22.1          |\n",
            "| eprewmean          | 0.5891667     |\n",
            "| explained_variance | 0.639         |\n",
            "| fps                | 549           |\n",
            "| nupdates           | 120           |\n",
            "| policy_entropy     | 0.2748748     |\n",
            "| policy_loss        | -0.0066524968 |\n",
            "| serial_timesteps   | 245760        |\n",
            "| time_elapsed       | 454           |\n",
            "| total_timesteps    | 245760        |\n",
            "| value_loss         | 0.008918653   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.047130547  |\n",
            "| clipfrac           | 0.12023926   |\n",
            "| eplenmean          | 18.3         |\n",
            "| eprewmean          | 0.6376667    |\n",
            "| explained_variance | 0.58         |\n",
            "| fps                | 540          |\n",
            "| nupdates           | 130          |\n",
            "| policy_entropy     | 0.2530772    |\n",
            "| policy_loss        | -0.007529446 |\n",
            "| serial_timesteps   | 266240       |\n",
            "| time_elapsed       | 491          |\n",
            "| total_timesteps    | 266240       |\n",
            "| value_loss         | 0.009454256  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.021593357  |\n",
            "| clipfrac           | 0.0904541    |\n",
            "| eplenmean          | 18           |\n",
            "| eprewmean          | 0.6723333    |\n",
            "| explained_variance | 0.669        |\n",
            "| fps                | 543          |\n",
            "| nupdates           | 140          |\n",
            "| policy_entropy     | 0.21641606   |\n",
            "| policy_loss        | -0.004053266 |\n",
            "| serial_timesteps   | 286720       |\n",
            "| time_elapsed       | 529          |\n",
            "| total_timesteps    | 286720       |\n",
            "| value_loss         | 0.008783127  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.018039515   |\n",
            "| clipfrac           | 0.08996582    |\n",
            "| eplenmean          | 18.1          |\n",
            "| eprewmean          | 0.65833336    |\n",
            "| explained_variance | 0.691         |\n",
            "| fps                | 543           |\n",
            "| nupdates           | 150           |\n",
            "| policy_entropy     | 0.20136474    |\n",
            "| policy_loss        | -0.0075898273 |\n",
            "| serial_timesteps   | 307200        |\n",
            "| time_elapsed       | 567           |\n",
            "| total_timesteps    | 307200        |\n",
            "| value_loss         | 0.009680129   |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.024310924 |\n",
            "| clipfrac           | 0.12866211  |\n",
            "| eplenmean          | 24.7        |\n",
            "| eprewmean          | 0.5475831   |\n",
            "| explained_variance | 0.677       |\n",
            "| fps                | 542         |\n",
            "| nupdates           | 160         |\n",
            "| policy_entropy     | 0.22451119  |\n",
            "| policy_loss        | -0.01917535 |\n",
            "| serial_timesteps   | 327680      |\n",
            "| time_elapsed       | 605         |\n",
            "| total_timesteps    | 327680      |\n",
            "| value_loss         | 0.013556061 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.024731418   |\n",
            "| clipfrac           | 0.06298828    |\n",
            "| eplenmean          | 17.8          |\n",
            "| eprewmean          | 0.67100006    |\n",
            "| explained_variance | 0.754         |\n",
            "| fps                | 547           |\n",
            "| nupdates           | 170           |\n",
            "| policy_entropy     | 0.17867948    |\n",
            "| policy_loss        | -0.0052739438 |\n",
            "| serial_timesteps   | 348160        |\n",
            "| time_elapsed       | 642           |\n",
            "| total_timesteps    | 348160        |\n",
            "| value_loss         | 0.0063601714  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.014092685   |\n",
            "| clipfrac           | 0.03857422    |\n",
            "| eplenmean          | 18.4          |\n",
            "| eprewmean          | 0.67000014    |\n",
            "| explained_variance | 0.779         |\n",
            "| fps                | 535           |\n",
            "| nupdates           | 180           |\n",
            "| policy_entropy     | 0.12701762    |\n",
            "| policy_loss        | -0.0054957243 |\n",
            "| serial_timesteps   | 368640        |\n",
            "| time_elapsed       | 680           |\n",
            "| total_timesteps    | 368640        |\n",
            "| value_loss         | 0.0057607386  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.008738049  |\n",
            "| clipfrac           | 0.04309082   |\n",
            "| eplenmean          | 17.1         |\n",
            "| eprewmean          | 0.6821667    |\n",
            "| explained_variance | 0.799        |\n",
            "| fps                | 530          |\n",
            "| nupdates           | 190          |\n",
            "| policy_entropy     | 0.14683524   |\n",
            "| policy_loss        | -0.003529948 |\n",
            "| serial_timesteps   | 389120       |\n",
            "| time_elapsed       | 718          |\n",
            "| total_timesteps    | 389120       |\n",
            "| value_loss         | 0.0055448515 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.008342753  |\n",
            "| clipfrac           | 0.05078125   |\n",
            "| eplenmean          | 17.4         |\n",
            "| eprewmean          | 0.66666675   |\n",
            "| explained_variance | 0.776        |\n",
            "| fps                | 546          |\n",
            "| nupdates           | 200          |\n",
            "| policy_entropy     | 0.1431594    |\n",
            "| policy_loss        | -0.012821721 |\n",
            "| serial_timesteps   | 409600       |\n",
            "| time_elapsed       | 756          |\n",
            "| total_timesteps    | 409600       |\n",
            "| value_loss         | 0.0062723183 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008597881   |\n",
            "| clipfrac           | 0.0637207     |\n",
            "| eplenmean          | 18.3          |\n",
            "| eprewmean          | 0.6664999     |\n",
            "| explained_variance | 0.788         |\n",
            "| fps                | 539           |\n",
            "| nupdates           | 210           |\n",
            "| policy_entropy     | 0.15772173    |\n",
            "| policy_loss        | -0.0057416586 |\n",
            "| serial_timesteps   | 430080        |\n",
            "| time_elapsed       | 794           |\n",
            "| total_timesteps    | 430080        |\n",
            "| value_loss         | 0.0065931845  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013855217   |\n",
            "| clipfrac           | 0.037475586   |\n",
            "| eplenmean          | 17.1          |\n",
            "| eprewmean          | 0.67924994    |\n",
            "| explained_variance | 0.785         |\n",
            "| fps                | 538           |\n",
            "| nupdates           | 220           |\n",
            "| policy_entropy     | 0.11485994    |\n",
            "| policy_loss        | -0.0064097503 |\n",
            "| serial_timesteps   | 450560        |\n",
            "| time_elapsed       | 832           |\n",
            "| total_timesteps    | 450560        |\n",
            "| value_loss         | 0.005999385   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0039483244  |\n",
            "| clipfrac           | 0.03515625    |\n",
            "| eplenmean          | 16.5          |\n",
            "| eprewmean          | 0.69075006    |\n",
            "| explained_variance | 0.836         |\n",
            "| fps                | 540           |\n",
            "| nupdates           | 230           |\n",
            "| policy_entropy     | 0.12011368    |\n",
            "| policy_loss        | -0.0057280767 |\n",
            "| serial_timesteps   | 471040        |\n",
            "| time_elapsed       | 870           |\n",
            "| total_timesteps    | 471040        |\n",
            "| value_loss         | 0.005008027   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00066022726 |\n",
            "| clipfrac           | 0.006713867   |\n",
            "| eplenmean          | 16.8          |\n",
            "| eprewmean          | 0.68700004    |\n",
            "| explained_variance | 0.867         |\n",
            "| fps                | 547           |\n",
            "| nupdates           | 240           |\n",
            "| policy_entropy     | 0.12204394    |\n",
            "| policy_loss        | -0.0027046527 |\n",
            "| serial_timesteps   | 491520        |\n",
            "| time_elapsed       | 908           |\n",
            "| total_timesteps    | 491520        |\n",
            "| value_loss         | 0.004023645   |\n",
            "--------------------------------------\n",
            "CPU times: user 19min 39s, sys: 3min 15s, total: 22min 55s\n",
            "Wall time: 15min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "fa1e358f-cff7-43d5-e998-79240ed8a327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f87b76081d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSiImEgaAiYQBYCJhAJhIGAAmAapozPhV1d/FAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f87b7ef41d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "id": "H_QTckfBra7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da208616-d35d-4e74-d6c2-b4f6edbca4f3"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "baseline = Baseline(env)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 0, 'B': 1000, 'C': 1000, 'D': 1000, 'E': 1000, 'F': 0, 'G': 0, 'H': 0, 'K': 1000, 'L': 1000, 'M': 0, 'N': 0, 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "3cd9cb54-2184-4e78-c1f1-79ac18d62948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "cell_type": "code",
      "source": [
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:   17   Step:    1  S --2-> C R= 0.13 totalR= 0.13 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:   17   Step:    2  C --1-> B R= 0.16 totalR= 0.29 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:   17   Step:    3  B --3-> K R= 0.13 totalR= 0.42 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:   17   Step:    4  K --0-> B R=-0.03 totalR= 0.39 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:    5  B --2-> C R=-0.01 totalR= 0.38 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:    6  C --2-> M R=-0.02 totalR= 0.37 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:    7  M --1-> L R= 0.16 totalR= 0.52 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:   17   Step:    8  L --0-> C R=-0.03 totalR= 0.49 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:    9  C --1-> B R=-0.01 totalR= 0.48 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:   10  B --1-> A R=-0.02 totalR= 0.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:   11  A --2-> E R= 0.15 totalR= 0.62 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:   17   Step:   12  E --1-> F R=-0.02 totalR= 0.60 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:   13  F --0-> D R= 0.16 totalR= 0.76 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:   17   Step:   14  D --0-> A R=-0.02 totalR= 0.74 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:   15  A --1-> B R=-0.02 totalR= 0.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:   17   Step:   16  B --0-> S R=-0.02 totalR= 0.71 cost= 100 customerR=   0 optimum=6000\n",
            "Episode finished after 16 timesteps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3z35_dMMt6SW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7ec95c6b-5b22-4dcd-a023-6ffc1b28a608"
      },
      "cell_type": "code",
      "source": [
        "%time optimum = baseline.find_optimum()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaled reward: 0.7416666666666667\n",
            "Perfect path ['S', 'B', 'C', 'M', 'L', 'M', 'C', 'B', 'A', 'D', 'F', 'E', 'H', 'K', 'B', 'S']\n",
            "CPU times: user 87.3 ms, sys: 1.97 ms, total: 89.3 ms\n",
            "Wall time: 91 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KMb58O_q067F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}