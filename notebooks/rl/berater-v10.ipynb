{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v10\n",
        "\n",
        "## Changes from v9\n",
        "* Fighting Overfitting as proposed in https://arxiv.org/abs/1812.02341\n",
        "  1. Batch Normalization\n",
        "  1. Encourage Exploration (increase entropy bonus again) (https://arxiv.org/pdf/1812.02341.pdf)\n",
        "  1. deeper networks (only shown for convolutions on video games)\n",
        "* added scoring code over a number of samples  \n",
        "\n",
        "## next steps\n",
        "* configure custom network \n",
        "  * including L2 regularization / Dropout\n",
        "  * not possible to just configure these two\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        max_paths = 4\n",
        "        self.action_space = spaces.Discrete(max_paths)\n",
        "      \n",
        "        positions = len(self.map)\n",
        "        # observations: position, reward of all 4 local paths, rest reward of all locations\n",
        "        # non existing path is -1000 and no position change\n",
        "        # look at what #getObservation returns if you are confused\n",
        "        low = np.append(np.append([0], np.full(max_paths, -1000)), np.full(positions, 0))\n",
        "        high = np.append(np.append([positions - 1], np.full(max_paths, 1000)), np.full(positions, 1000))\n",
        "        self.observation_space = spaces.Box(low=low,\n",
        "                                             high=high,\n",
        "                                             dtype=np.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = np.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=np.float32)\n",
        "        all_rest_rewards = list(self.customer_reward.values())\n",
        "        result = np.append(result, all_rest_rewards)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/2)\n",
        "#       number_per_consultant = int(number_of_customers/1.5)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "outputId": "24342fe0-23e6-4e0a-c0bb-22ac706fc24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.  -300.   900.  -200. -1000.     0.     0.  1000.     0.     0.\n",
            "  1000.     0.  1000.     0.  1000.     0.  1000.  1000.     0.]\n",
            "{'S': 0, 'A': 0, 'B': 1000, 'C': 0, 'D': 0, 'E': 1000, 'F': 0, 'G': 1000, 'H': 0, 'K': 1000, 'L': 0, 'M': 1000, 'N': 1000, 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "4d1ee730-bc6c-4d01-eb49-56cf5b7ac803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.   700.  -100.   800. -1000.     0.  1000.     0.  1000.  1000.\n",
            "  1000.  1000.  1000.     0.     0.     0.     0.     0.     0.]\n",
            "Episode:    0   Step:    1  S --0-> A R= 0.12 totalR= 0.12 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    2  A --3-> D R= 0.15 totalR= 0.27 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    3  D --1-> F R= 0.16 totalR= 0.42 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.42 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.17 totalR= 0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.17 totalR= 0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.17 totalR=-0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.17 totalR=-0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.26 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.17 totalR=-0.43 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  F --1-> E R= 0.15 totalR=-0.28 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R=-0.02 totalR=-0.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR=-0.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.17 totalR=-0.47 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.02 totalR=-0.49 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.02 totalR=-0.51 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.02 totalR=-0.53 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.05 totalR=-0.58 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  S --2-> C R= 0.13 totalR=-0.44 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   20  C --1-> B R=-0.01 totalR=-0.45 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.46 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  C --3-> L R=-0.03 totalR=-0.49 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.17 totalR=-0.66 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.17 totalR=-0.83 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-0.86 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-0.87 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.02 totalR=-0.88 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.02 totalR=-0.90 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.02 totalR=-0.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.05 totalR=-0.97 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.02 totalR=-0.98 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.02 totalR=-1.00 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.17 totalR=-1.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.05 totalR=-1.22 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.02 totalR=-1.23 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-1.24 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   37  F --2-> G R= 0.13 totalR=-1.11 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.17 totalR=-1.28 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.17 totalR=-1.44 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.48 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-1.51 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.17 totalR=-1.68 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-1.71 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.02 totalR=-1.73 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.17 totalR=-1.89 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.02 totalR=-1.91 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.17 totalR=-2.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.17 totalR=-2.24 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-2.28 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.17 totalR=-2.44 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-2.48 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.02 totalR=-2.49 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.02 totalR=-2.51 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.02 totalR=-2.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.17 totalR=-2.69 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.02 totalR=-2.71 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.02 totalR=-2.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.17 totalR=-2.89 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.02 totalR=-2.91 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.02 totalR=-2.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.17 totalR=-3.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.17 totalR=-3.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.17 totalR=-3.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.17 totalR=-3.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.17 totalR=-3.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.02 totalR=-3.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.02 totalR=-3.79 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.02 totalR=-3.81 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.05 totalR=-3.86 cost= 300 customerR=   0 optimum=6000\n",
            "Done: episodes=     1  avgSteps= 69.00  avgTotalReward=-3.86\n",
            "Episode finished after 69 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWpCU8xH0ZKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ]
    },
    {
      "metadata": {
        "id": "7NxTojLi0N0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import json\n",
        "\n",
        "class Baseline():\n",
        "\n",
        "  def __init__(self, env, verbose=1):\n",
        "    self.env = env\n",
        "    self.verbose = verbose\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.map = self.env.map\n",
        "    self.rewards = self.env.customer_reward.copy()\n",
        "    \n",
        "  def as_string(self, state):\n",
        "    # reward/cost does not hurt, but is useless, path obsucres same state\n",
        "    new_state = {\n",
        "        'rewards': state['rewards'],\n",
        "        'position': state['position']\n",
        "    }\n",
        "    return json.dumps(new_state, sort_keys=True)\n",
        "  \n",
        "  def is_goal(self, state):\n",
        "    if state['position'] != 'S': return False\n",
        "    for reward in state['rewards'].values():\n",
        "      if reward != 0: return False\n",
        "    return True\n",
        "    \n",
        "\n",
        "  def expand(self, state):\n",
        "    states = []\n",
        "    for position, cost in self.map[state['position']]:\n",
        "      new_state = deepcopy(state)\n",
        "      new_state['position'] = position\n",
        "      new_state['rewards'][position] = 0\n",
        "      reward = state['rewards'][position]\n",
        "      new_state['reward'] += reward\n",
        "      new_state['cost'] += cost\n",
        "      new_state['path'].append(position)\n",
        "      states.append(new_state)\n",
        "    return states\n",
        "\n",
        "  def search(self, root, max_depth = 25):\n",
        "      closed = set()\n",
        "      open = [root]\n",
        "\n",
        "      while open:\n",
        "          state = open.pop(0)\n",
        "          if self.as_string(state) in closed: continue  \n",
        "\n",
        "          closed.add(self.as_string(state))\n",
        "\n",
        "          depth = len(state['path'])\n",
        "          if depth > max_depth:\n",
        "            if self.verbose > 0:\n",
        "              print(\"Visited:\", len(closed))\n",
        "              print(\"Reached max depth, without reaching goal\")\n",
        "            return None\n",
        "\n",
        "          if self.is_goal(state):\n",
        "            scaled_reward = (state['reward'] - state['cost']) / 6000\n",
        "            state['scaled_reward'] = scaled_reward\n",
        "            if self.verbose > 0:\n",
        "              print(\"Scaled reward:\", scaled_reward)            \n",
        "              print(\"Perfect path\", state['path'])\n",
        "            return state\n",
        "\n",
        "          expanded = self.expand(state)\n",
        "          open += expanded\n",
        "          # make this best first\n",
        "          open.sort(key=lambda state: state['cost'])\n",
        "        \n",
        "  def find_optimum(self):\n",
        "    initial_state = {\n",
        "        'rewards': self.rewards.copy(),\n",
        "        'position': 'S',\n",
        "        'reward': 0,\n",
        "        'cost': 0,\n",
        "        'path': ['S']\n",
        "    }\n",
        "    return self.search(initial_state)\n",
        "  \n",
        "  def benchmark(self, model, sample_runs=100):\n",
        "    self.verbose = 0\n",
        "    BeraterEnv.showStep = False\n",
        "    BeraterEnv.showDone = False\n",
        "\n",
        "    perfect_rewards = []\n",
        "    model_rewards = []\n",
        "    for run in range(sample_runs):\n",
        "      observation = self.env.reset()\n",
        "      self.reset()\n",
        "      \n",
        "      optimum_state = self.find_optimum()\n",
        "      perfect_rewards.append(optimum_state['scaled_reward'])\n",
        "      \n",
        "      state = np.zeros((1, 2*128))\n",
        "      dones = np.zeros((1))\n",
        "\n",
        "      for t in range(1000):\n",
        "        actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "        observation, reward, done, info = self.env.step(actions[0])\n",
        "        if done:\n",
        "          break\n",
        "      model_rewards.append(env.totalReward)\n",
        "    return perfect_rewards, model_rewards"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "Estimation\n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* all rewards: 6000\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n",
        "* estimate: no illegal moves and between\n",
        "  * half the travel cost: (6000 - 1250) / 6000 = .79\n",
        "  * and full traval cost (6000 - 2500) / 6000 = 0.58\n",
        "* additionally: the agent only sees very little of the whole scenario\n",
        "  * changes with every episode\n",
        "  * was ok when network can learn fixed scenario\n"
      ]
    },
    {
      "metadata": {
        "id": "Qvi-T-YuEO0A",
        "colab_type": "code",
        "outputId": "661caff0-3ead-4b23-f67f-6d7e2bf0eee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "9139e1b8-ffb9-4391-94a6-b967e15f1f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6443
        }
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "# https://arxiv.org/abs/1607.06450 for layer_norm\n",
        "\n",
        "# lr linear from lr=1e-2 to lr=1e-4 (default lr=3e-4)\n",
        "def lr_range(frac):\n",
        "  # we get the remaining updates between 1 and 0\n",
        "  start_lr = 1e-2\n",
        "  end_lr = 1e-4\n",
        "  diff_lr = start_lr - end_lr\n",
        "  lr = end_lr + diff_lr * frac\n",
        "  return lr\n",
        "  \n",
        "  \n",
        "%time model = ppo2.learn(\\\n",
        "    env=monitored_env,\\\n",
        "    network='mlp',\\\n",
        "    num_hidden=500,\\\n",
        "    num_layers=3,\\\n",
        "    lr=lr_range,\\\n",
        "    gamma=1.0,\\\n",
        "    ent_coef=0.05,\\\n",
        "    layer_norm=True,\\\n",
        "    total_timesteps=500000)\n",
        "\n",
        "# model.save('berater-ppo-v10.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-01-20-12-42-29-316583\n",
            "-----------------------------------\n",
            "| approxkl           | 1.106912   |\n",
            "| clipfrac           | 0.85180664 |\n",
            "| eplenmean          | 112        |\n",
            "| eprewmean          | -7.344446  |\n",
            "| explained_variance | -0.338     |\n",
            "| fps                | 454        |\n",
            "| nupdates           | 1          |\n",
            "| policy_entropy     | 0.95964    |\n",
            "| policy_loss        | 0.19367278 |\n",
            "| serial_timesteps   | 2048       |\n",
            "| time_elapsed       | 4.5        |\n",
            "| total_timesteps    | 2048       |\n",
            "| value_loss         | 6.1471424  |\n",
            "-----------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.04339493  |\n",
            "| clipfrac           | 0.4329834   |\n",
            "| eplenmean          | 416         |\n",
            "| eprewmean          | -20.148624  |\n",
            "| explained_variance | -0.723      |\n",
            "| fps                | 489         |\n",
            "| nupdates           | 10          |\n",
            "| policy_entropy     | 0.65929854  |\n",
            "| policy_loss        | 0.015227782 |\n",
            "| serial_timesteps   | 20480       |\n",
            "| time_elapsed       | 42.2        |\n",
            "| total_timesteps    | 20480       |\n",
            "| value_loss         | 0.12013262  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.034814283 |\n",
            "| clipfrac           | 0.26574707  |\n",
            "| eplenmean          | 393         |\n",
            "| eprewmean          | -15.240261  |\n",
            "| explained_variance | -0.342      |\n",
            "| fps                | 490         |\n",
            "| nupdates           | 20          |\n",
            "| policy_entropy     | 0.90020245  |\n",
            "| policy_loss        | 0.023324102 |\n",
            "| serial_timesteps   | 40960       |\n",
            "| time_elapsed       | 84.1        |\n",
            "| total_timesteps    | 40960       |\n",
            "| value_loss         | 1.227856    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.054020975 |\n",
            "| clipfrac           | 0.36206055  |\n",
            "| eplenmean          | 68.5        |\n",
            "| eprewmean          | -1.2545832  |\n",
            "| explained_variance | 0.563       |\n",
            "| fps                | 487         |\n",
            "| nupdates           | 30          |\n",
            "| policy_entropy     | 1.0407382   |\n",
            "| policy_loss        | 0.020006128 |\n",
            "| serial_timesteps   | 61440       |\n",
            "| time_elapsed       | 126         |\n",
            "| total_timesteps    | 61440       |\n",
            "| value_loss         | 2.0772023   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011550133  |\n",
            "| clipfrac           | 0.14611816   |\n",
            "| eplenmean          | 52.4         |\n",
            "| eprewmean          | -0.6906667   |\n",
            "| explained_variance | 0.54         |\n",
            "| fps                | 486          |\n",
            "| nupdates           | 40           |\n",
            "| policy_entropy     | 1.0082229    |\n",
            "| policy_loss        | -0.003875678 |\n",
            "| serial_timesteps   | 81920        |\n",
            "| time_elapsed       | 168          |\n",
            "| total_timesteps    | 81920        |\n",
            "| value_loss         | 1.0327008    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.019898184   |\n",
            "| clipfrac           | 0.21374512    |\n",
            "| eplenmean          | 28.8          |\n",
            "| eprewmean          | 0.16991667    |\n",
            "| explained_variance | -0.0189       |\n",
            "| fps                | 485           |\n",
            "| nupdates           | 50            |\n",
            "| policy_entropy     | 0.83662224    |\n",
            "| policy_loss        | -0.0059831487 |\n",
            "| serial_timesteps   | 102400        |\n",
            "| time_elapsed       | 210           |\n",
            "| total_timesteps    | 102400        |\n",
            "| value_loss         | 0.089379594   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.04559314   |\n",
            "| clipfrac           | 0.1986084    |\n",
            "| eplenmean          | 23           |\n",
            "| eprewmean          | 0.49091664   |\n",
            "| explained_variance | 0.491        |\n",
            "| fps                | 485          |\n",
            "| nupdates           | 60           |\n",
            "| policy_entropy     | 0.5633248    |\n",
            "| policy_loss        | -0.010887655 |\n",
            "| serial_timesteps   | 122880       |\n",
            "| time_elapsed       | 253          |\n",
            "| total_timesteps    | 122880       |\n",
            "| value_loss         | 0.010913096  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.016467288   |\n",
            "| clipfrac           | 0.119140625   |\n",
            "| eplenmean          | 17.8          |\n",
            "| eprewmean          | 0.6400001     |\n",
            "| explained_variance | 0.784         |\n",
            "| fps                | 486           |\n",
            "| nupdates           | 70            |\n",
            "| policy_entropy     | 0.34218857    |\n",
            "| policy_loss        | -0.0059060347 |\n",
            "| serial_timesteps   | 143360        |\n",
            "| time_elapsed       | 295           |\n",
            "| total_timesteps    | 143360        |\n",
            "| value_loss         | 0.0054553514  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01945089    |\n",
            "| clipfrac           | 0.10852051    |\n",
            "| eplenmean          | 16.4          |\n",
            "| eprewmean          | 0.6736666     |\n",
            "| explained_variance | 0.836         |\n",
            "| fps                | 485           |\n",
            "| nupdates           | 80            |\n",
            "| policy_entropy     | 0.26294127    |\n",
            "| policy_loss        | -0.0045008133 |\n",
            "| serial_timesteps   | 163840        |\n",
            "| time_elapsed       | 338           |\n",
            "| total_timesteps    | 163840        |\n",
            "| value_loss         | 0.004712579   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.032737214  |\n",
            "| clipfrac           | 0.13598633   |\n",
            "| eplenmean          | 19.4         |\n",
            "| eprewmean          | 0.6159167    |\n",
            "| explained_variance | 0.691        |\n",
            "| fps                | 488          |\n",
            "| nupdates           | 90           |\n",
            "| policy_entropy     | 0.3559902    |\n",
            "| policy_loss        | -0.017158197 |\n",
            "| serial_timesteps   | 184320       |\n",
            "| time_elapsed       | 380          |\n",
            "| total_timesteps    | 184320       |\n",
            "| value_loss         | 0.006609668  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.03589167   |\n",
            "| clipfrac           | 0.11401367   |\n",
            "| eplenmean          | 15.6         |\n",
            "| eprewmean          | 0.67225015   |\n",
            "| explained_variance | 0.893        |\n",
            "| fps                | 485          |\n",
            "| nupdates           | 100          |\n",
            "| policy_entropy     | 0.266416     |\n",
            "| policy_loss        | -0.006536624 |\n",
            "| serial_timesteps   | 204800       |\n",
            "| time_elapsed       | 422          |\n",
            "| total_timesteps    | 204800       |\n",
            "| value_loss         | 0.0033179817 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010546623  |\n",
            "| clipfrac           | 0.07910156   |\n",
            "| eplenmean          | 15.2         |\n",
            "| eprewmean          | 0.69358337   |\n",
            "| explained_variance | 0.908        |\n",
            "| fps                | 488          |\n",
            "| nupdates           | 110          |\n",
            "| policy_entropy     | 0.28306586   |\n",
            "| policy_loss        | -0.00791038  |\n",
            "| serial_timesteps   | 225280       |\n",
            "| time_elapsed       | 464          |\n",
            "| total_timesteps    | 225280       |\n",
            "| value_loss         | 0.0024299715 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0128233405 |\n",
            "| clipfrac           | 0.07409668   |\n",
            "| eplenmean          | 16.2         |\n",
            "| eprewmean          | 0.6847499    |\n",
            "| explained_variance | 0.912        |\n",
            "| fps                | 490          |\n",
            "| nupdates           | 120          |\n",
            "| policy_entropy     | 0.18715079   |\n",
            "| policy_loss        | -0.008657055 |\n",
            "| serial_timesteps   | 245760       |\n",
            "| time_elapsed       | 506          |\n",
            "| total_timesteps    | 245760       |\n",
            "| value_loss         | 0.002223344  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011322146  |\n",
            "| clipfrac           | 0.06738281   |\n",
            "| eplenmean          | 15.7         |\n",
            "| eprewmean          | 0.6863335    |\n",
            "| explained_variance | 0.902        |\n",
            "| fps                | 485          |\n",
            "| nupdates           | 130          |\n",
            "| policy_entropy     | 0.2390564    |\n",
            "| policy_loss        | -0.007650907 |\n",
            "| serial_timesteps   | 266240       |\n",
            "| time_elapsed       | 549          |\n",
            "| total_timesteps    | 266240       |\n",
            "| value_loss         | 0.0031219693 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.015042002   |\n",
            "| clipfrac           | 0.08508301    |\n",
            "| eplenmean          | 16.6          |\n",
            "| eprewmean          | 0.6698334     |\n",
            "| explained_variance | 0.905         |\n",
            "| fps                | 488           |\n",
            "| nupdates           | 140           |\n",
            "| policy_entropy     | 0.23085533    |\n",
            "| policy_loss        | -0.0080692535 |\n",
            "| serial_timesteps   | 286720        |\n",
            "| time_elapsed       | 591           |\n",
            "| total_timesteps    | 286720        |\n",
            "| value_loss         | 0.0028567512  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014706541  |\n",
            "| clipfrac           | 0.07287598   |\n",
            "| eplenmean          | 15.9         |\n",
            "| eprewmean          | 0.6889167    |\n",
            "| explained_variance | 0.907        |\n",
            "| fps                | 482          |\n",
            "| nupdates           | 150          |\n",
            "| policy_entropy     | 0.21100071   |\n",
            "| policy_loss        | -0.008012    |\n",
            "| serial_timesteps   | 307200       |\n",
            "| time_elapsed       | 634          |\n",
            "| total_timesteps    | 307200       |\n",
            "| value_loss         | 0.0024616255 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0069028493  |\n",
            "| clipfrac           | 0.057373047   |\n",
            "| eplenmean          | 15            |\n",
            "| eprewmean          | 0.7115834     |\n",
            "| explained_variance | 0.946         |\n",
            "| fps                | 484           |\n",
            "| nupdates           | 160           |\n",
            "| policy_entropy     | 0.16892657    |\n",
            "| policy_loss        | -0.0069142045 |\n",
            "| serial_timesteps   | 327680        |\n",
            "| time_elapsed       | 676           |\n",
            "| total_timesteps    | 327680        |\n",
            "| value_loss         | 0.0016335829  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.039367225  |\n",
            "| clipfrac           | 0.07067871   |\n",
            "| eplenmean          | 15.2         |\n",
            "| eprewmean          | 0.6885834    |\n",
            "| explained_variance | 0.825        |\n",
            "| fps                | 490          |\n",
            "| nupdates           | 170          |\n",
            "| policy_entropy     | 0.15657976   |\n",
            "| policy_loss        | -0.013493077 |\n",
            "| serial_timesteps   | 348160       |\n",
            "| time_elapsed       | 719          |\n",
            "| total_timesteps    | 348160       |\n",
            "| value_loss         | 0.0063659805 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014341769  |\n",
            "| clipfrac           | 0.056640625  |\n",
            "| eplenmean          | 15.1         |\n",
            "| eprewmean          | 0.70958346   |\n",
            "| explained_variance | 0.952        |\n",
            "| fps                | 489          |\n",
            "| nupdates           | 180          |\n",
            "| policy_entropy     | 0.16610754   |\n",
            "| policy_loss        | -0.007942176 |\n",
            "| serial_timesteps   | 368640       |\n",
            "| time_elapsed       | 761          |\n",
            "| total_timesteps    | 368640       |\n",
            "| value_loss         | 0.001545281  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.042431876  |\n",
            "| clipfrac           | 0.032958984  |\n",
            "| eplenmean          | 14.2         |\n",
            "| eprewmean          | 0.72108346   |\n",
            "| explained_variance | 0.953        |\n",
            "| fps                | 481          |\n",
            "| nupdates           | 190          |\n",
            "| policy_entropy     | 0.10738936   |\n",
            "| policy_loss        | -0.008103901 |\n",
            "| serial_timesteps   | 389120       |\n",
            "| time_elapsed       | 803          |\n",
            "| total_timesteps    | 389120       |\n",
            "| value_loss         | 0.0015851058 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0067297537  |\n",
            "| clipfrac           | 0.027954102   |\n",
            "| eplenmean          | 14.3          |\n",
            "| eprewmean          | 0.72550005    |\n",
            "| explained_variance | 0.958         |\n",
            "| fps                | 486           |\n",
            "| nupdates           | 200           |\n",
            "| policy_entropy     | 0.105539836   |\n",
            "| policy_loss        | -0.0072995224 |\n",
            "| serial_timesteps   | 409600        |\n",
            "| time_elapsed       | 846           |\n",
            "| total_timesteps    | 409600        |\n",
            "| value_loss         | 0.0012891506  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0032799218  |\n",
            "| clipfrac           | 0.032470703   |\n",
            "| eplenmean          | 14.2          |\n",
            "| eprewmean          | 0.71125       |\n",
            "| explained_variance | 0.966         |\n",
            "| fps                | 485           |\n",
            "| nupdates           | 210           |\n",
            "| policy_entropy     | 0.14588971    |\n",
            "| policy_loss        | -0.0056610624 |\n",
            "| serial_timesteps   | 430080        |\n",
            "| time_elapsed       | 888           |\n",
            "| total_timesteps    | 430080        |\n",
            "| value_loss         | 0.0010298654  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0039197803 |\n",
            "| clipfrac           | 0.02319336   |\n",
            "| eplenmean          | 14.3         |\n",
            "| eprewmean          | 0.7120001    |\n",
            "| explained_variance | 0.969        |\n",
            "| fps                | 485          |\n",
            "| nupdates           | 220          |\n",
            "| policy_entropy     | 0.10374612   |\n",
            "| policy_loss        | -0.004388118 |\n",
            "| serial_timesteps   | 450560       |\n",
            "| time_elapsed       | 931          |\n",
            "| total_timesteps    | 450560       |\n",
            "| value_loss         | 0.0009157567 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0014609414 |\n",
            "| clipfrac           | 0.014282227  |\n",
            "| eplenmean          | 14.4         |\n",
            "| eprewmean          | 0.7238334    |\n",
            "| explained_variance | 0.97         |\n",
            "| fps                | 482          |\n",
            "| nupdates           | 230          |\n",
            "| policy_entropy     | 0.09417924   |\n",
            "| policy_loss        | -0.003142601 |\n",
            "| serial_timesteps   | 471040       |\n",
            "| time_elapsed       | 973          |\n",
            "| total_timesteps    | 471040       |\n",
            "| value_loss         | 0.0009445905 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0007847682  |\n",
            "| clipfrac           | 0.0072021484  |\n",
            "| eplenmean          | 14.3          |\n",
            "| eprewmean          | 0.72475004    |\n",
            "| explained_variance | 0.963         |\n",
            "| fps                | 487           |\n",
            "| nupdates           | 240           |\n",
            "| policy_entropy     | 0.09368164    |\n",
            "| policy_loss        | -0.0042664674 |\n",
            "| serial_timesteps   | 491520        |\n",
            "| time_elapsed       | 1.02e+03      |\n",
            "| total_timesteps    | 491520        |\n",
            "| value_loss         | 0.0012038256  |\n",
            "--------------------------------------\n",
            "CPU times: user 21min 36s, sys: 3min 20s, total: 24min 56s\n",
            "Wall time: 17min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "a48d58be-74bb-4875-a247-d8f7977beacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbcca1dc400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "id": "H_QTckfBra7l",
        "colab_type": "code",
        "outputId": "082ebf22-db1b-4215-f704-4382a7c28639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "baseline = Baseline(env)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 1000, 'B': 1000, 'C': 0, 'D': 0, 'E': 0, 'F': 0, 'G': 1000, 'H': 1000, 'K': 1000, 'L': 0, 'M': 0, 'N': 0, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "9723cc81-b4f3-4bfb-b4c8-3f709f0a94ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, reward={}\".format(t+1, env.totalReward))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:    0   Step:    1  S --1-> B R= 0.15 totalR= 0.15 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    2  B --2-> C R=-0.01 totalR= 0.14 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    3  C --2-> M R=-0.02 totalR= 0.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    4  M --2-> N R=-0.02 totalR= 0.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  N --1-> O R= 0.15 totalR= 0.26 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    6  O --1-> G R= 0.12 totalR= 0.38 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    7  G --0-> F R=-0.03 totalR= 0.34 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  F --0-> D R=-0.01 totalR= 0.33 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --0-> A R= 0.15 totalR= 0.48 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   10  A --2-> E R=-0.02 totalR= 0.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  E --2-> H R= 0.15 totalR= 0.62 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  H --1-> K R= 0.12 totalR= 0.73 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   13  K --0-> B R=-0.03 totalR= 0.70 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  B --0-> S R=-0.02 totalR= 0.68 cost= 100 customerR=   0 optimum=6000\n",
            "Episode finished after 14 timesteps, reward=0.6833333333333332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3z35_dMMt6SW",
        "colab_type": "code",
        "outputId": "f6cd531f-5e7e-4d8b-c335-6e3bdfc3e4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "cell_type": "code",
      "source": [
        "%time baseline.find_optimum()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaled reward: 0.6833333333333333\n",
            "Perfect path ['S', 'B', 'C', 'M', 'N', 'O', 'G', 'F', 'D', 'A', 'E', 'H', 'K', 'B', 'S']\n",
            "CPU times: user 91.9 ms, sys: 0 ns, total: 91.9 ms\n",
            "Wall time: 95.6 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cost': 1900,\n",
              " 'path': ['S',\n",
              "  'B',\n",
              "  'C',\n",
              "  'M',\n",
              "  'N',\n",
              "  'O',\n",
              "  'G',\n",
              "  'F',\n",
              "  'D',\n",
              "  'A',\n",
              "  'E',\n",
              "  'H',\n",
              "  'K',\n",
              "  'B',\n",
              "  'S'],\n",
              " 'position': 'S',\n",
              " 'reward': 6000,\n",
              " 'rewards': {'A': 0,\n",
              "  'B': 0,\n",
              "  'C': 0,\n",
              "  'D': 0,\n",
              "  'E': 0,\n",
              "  'F': 0,\n",
              "  'G': 0,\n",
              "  'H': 0,\n",
              "  'K': 0,\n",
              "  'L': 0,\n",
              "  'M': 0,\n",
              "  'N': 0,\n",
              "  'O': 0,\n",
              "  'S': 0},\n",
              " 'scaled_reward': 0.6833333333333333}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "K36GXkzyRGOO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "KMb58O_q067F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "d8a41152-5cf2-4519-fff5-06a01b56640c"
      },
      "cell_type": "code",
      "source": [
        "baseline = Baseline(env)\n",
        "optimum_score, model_score = baseline.benchmark(model, sample_runs=100)\n",
        "optimum_score, model_score"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4713eac5c698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b46eb0f6385e>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(self, model, sample_runs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'step'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Dr9ylHgnRIcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dd52682-c1ea-4248-ab98-94eb37dd94a2"
      },
      "cell_type": "code",
      "source": [
        "np.array(optimum_score).mean(), np.array(optimum_score).std()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7541666666666667, 0.043501277120460626)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "rOSOoO29Rwgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc76743d-b12d-4ee0-bdb7-4c66dd9df671"
      },
      "cell_type": "code",
      "source": [
        "np.array(model_score).mean(), np.array(model_score).std()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7416666666666666, 0.04958158260214501)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Ls8IKVV1R5SE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}