{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v11\n",
        "\n",
        "## Changes from v10\n",
        "* configure custom network allowing to train to almost perfection\n",
        "* score method for BaseLine"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        max_paths = 4\n",
        "        self.action_space = spaces.Discrete(max_paths)\n",
        "      \n",
        "        positions = len(self.map)\n",
        "        # observations: position, reward of all 4 local paths, rest reward of all locations\n",
        "        # non existing path is -1000 and no position change\n",
        "        # look at what #getObservation returns if you are confused\n",
        "        low = np.append(np.append([0], np.full(max_paths, -1000)), np.full(positions, 0))\n",
        "        high = np.append(np.append([positions - 1], np.full(max_paths, 1000)), np.full(positions, 1000))\n",
        "        self.observation_space = spaces.Box(low=low,\n",
        "                                             high=high,\n",
        "                                             dtype=np.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = np.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=np.float32)\n",
        "        all_rest_rewards = list(self.customer_reward.values())\n",
        "        result = np.append(result, all_rest_rewards)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/2)\n",
        "#       number_per_consultant = int(number_of_customers/1.5)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "outputId": "489b9bbd-8458-4289-d34b-2fa6423669e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.   700.   900.  -200. -1000.     0.  1000.  1000.     0.  1000.\n",
            "  1000.  1000.     0.     0.     0.  1000.     0.     0.     0.]\n",
            "{'S': 0, 'A': 1000, 'B': 1000, 'C': 0, 'D': 1000, 'E': 1000, 'F': 1000, 'G': 0, 'H': 0, 'K': 0, 'L': 1000, 'M': 0, 'N': 0, 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "4fbf26b1-6304-4d81-8af3-6c0eb2e62cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3540
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.   700.   900.  -200. -1000.     0.  1000.  1000.     0.  1000.\n",
            "     0.     0.     0.  1000.     0.  1000.     0.  1000.     0.]\n",
            "Episode:    0   Step:    1  S --0-> A R= 0.12 totalR= 0.12 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    2  A --3-> D R= 0.15 totalR= 0.27 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    3  D --1-> F R=-0.01 totalR= 0.26 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.25 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.17 totalR= 0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.17 totalR=-0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.17 totalR=-0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.17 totalR=-0.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.42 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.17 totalR=-0.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  F --1-> E R=-0.02 totalR=-0.61 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R= 0.15 totalR=-0.46 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR=-0.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.17 totalR=-0.64 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.02 totalR=-0.66 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.02 totalR=-0.68 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.02 totalR=-0.69 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.05 totalR=-0.74 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  S --2-> C R=-0.03 totalR=-0.78 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   20  C --1-> B R= 0.16 totalR=-0.62 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.63 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  C --3-> L R= 0.13 totalR=-0.49 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.17 totalR=-0.66 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.17 totalR=-0.83 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-0.86 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-0.87 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.02 totalR=-0.88 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.02 totalR=-0.90 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.02 totalR=-0.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.05 totalR=-0.97 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.02 totalR=-0.98 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.02 totalR=-1.00 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.17 totalR=-1.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.05 totalR=-1.22 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.02 totalR=-1.23 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-1.24 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   37  F --2-> G R=-0.03 totalR=-1.28 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.17 totalR=-1.44 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.17 totalR=-1.61 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-1.68 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.17 totalR=-1.84 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-1.88 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.02 totalR=-1.89 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.17 totalR=-2.06 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.02 totalR=-2.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.17 totalR=-2.24 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.17 totalR=-2.41 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-2.44 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.17 totalR=-2.61 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-2.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.02 totalR=-2.66 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.02 totalR=-2.68 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.02 totalR=-2.69 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.17 totalR=-2.86 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.02 totalR=-2.88 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.02 totalR=-2.89 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.17 totalR=-3.06 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.02 totalR=-3.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.02 totalR=-3.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.17 totalR=-3.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.17 totalR=-3.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.17 totalR=-3.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.17 totalR=-3.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.17 totalR=-3.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.02 totalR=-3.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.02 totalR=-3.96 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.02 totalR=-3.97 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.05 totalR=-4.02 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   70  S --0-> A R=-0.05 totalR=-4.07 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   71  A --1-> B R=-0.02 totalR=-4.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   72  B --1-> A R=-0.02 totalR=-4.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   73  A --2-> E R=-0.02 totalR=-4.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   74  E --0-> A R=-0.02 totalR=-4.14 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   75  A --0-> S R=-0.05 totalR=-4.19 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   76  S --1-> B R=-0.02 totalR=-4.21 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   77  B --3-> K R=-0.03 totalR=-4.24 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   78  K --0-> B R=-0.03 totalR=-4.27 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   79  B --1-> A R=-0.02 totalR=-4.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   80  A --2-> E R=-0.02 totalR=-4.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   81  E --2-> H R=-0.02 totalR=-4.32 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   82  H --3-> H R=-0.17 totalR=-4.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   83  H --0-> E R=-0.02 totalR=-4.51 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   84  E --1-> F R=-0.02 totalR=-4.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   85  F --1-> E R=-0.02 totalR=-4.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   86  E --3-> E R=-0.17 totalR=-4.71 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   87  E --1-> F R=-0.02 totalR=-4.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   88  F --1-> E R=-0.02 totalR=-4.74 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   89  E --3-> E R=-0.17 totalR=-4.91 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   90  E --2-> H R=-0.02 totalR=-4.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   91  H --3-> H R=-0.17 totalR=-5.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   92  H --3-> H R=-0.17 totalR=-5.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   93  H --2-> H R=-0.17 totalR=-5.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   94  H --2-> H R=-0.17 totalR=-5.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   95  H --3-> H R=-0.17 totalR=-5.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   96  H --0-> E R=-0.02 totalR=-5.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   97  E --2-> H R=-0.02 totalR=-5.79 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   98  H --3-> H R=-0.17 totalR=-5.96 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   99  H --1-> K R=-0.05 totalR=-6.01 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  100  K --0-> B R=-0.03 totalR=-6.04 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  101  B --1-> A R=-0.02 totalR=-6.06 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  102  A --2-> E R=-0.02 totalR=-6.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  103  E --0-> A R=-0.02 totalR=-6.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  104  A --3-> D R=-0.02 totalR=-6.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  105  D --0-> A R=-0.02 totalR=-6.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  106  A --2-> E R=-0.02 totalR=-6.14 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  107  E --0-> A R=-0.02 totalR=-6.16 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  108  A --3-> D R=-0.02 totalR=-6.17 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  109  D --3-> D R=-0.17 totalR=-6.34 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  110  D --0-> A R=-0.02 totalR=-6.36 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  111  A --3-> D R=-0.02 totalR=-6.37 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  112  D --0-> A R=-0.02 totalR=-6.39 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  113  A --0-> S R=-0.05 totalR=-6.44 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  114  S --0-> A R=-0.05 totalR=-6.49 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  115  A --0-> S R=-0.05 totalR=-6.54 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  116  S --2-> C R=-0.03 totalR=-6.57 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  117  C --3-> L R=-0.03 totalR=-6.61 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  118  L --0-> C R=-0.03 totalR=-6.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  119  C --3-> L R=-0.03 totalR=-6.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  120  L --2-> L R=-0.17 totalR=-6.84 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  121  L --3-> L R=-0.17 totalR=-7.01 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  122  L --3-> L R=-0.17 totalR=-7.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  123  L --1-> M R=-0.01 totalR=-7.18 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  124  M --1-> L R=-0.01 totalR=-7.19 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  125  L --1-> M R=-0.01 totalR=-7.20 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  126  M --0-> C R=-0.02 totalR=-7.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  127  C --1-> B R=-0.01 totalR=-7.23 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  128  B --1-> A R=-0.02 totalR=-7.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  129  A --1-> B R=-0.02 totalR=-7.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  130  B --3-> K R=-0.03 totalR=-7.29 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  131  K --0-> B R=-0.03 totalR=-7.33 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  132  B --3-> K R=-0.03 totalR=-7.36 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  133  K --1-> H R=-0.05 totalR=-7.41 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  134  H --2-> H R=-0.17 totalR=-7.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  135  H --0-> E R=-0.02 totalR=-7.59 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  136  E --1-> F R=-0.02 totalR=-7.61 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  137  F --2-> G R=-0.03 totalR=-7.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  138  G --0-> F R=-0.03 totalR=-7.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  139  F --2-> G R=-0.03 totalR=-7.71 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  140  G --0-> F R=-0.03 totalR=-7.74 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  141  F --1-> E R=-0.02 totalR=-7.76 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  142  E --3-> E R=-0.17 totalR=-7.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  143  E --2-> H R=-0.02 totalR=-7.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  144  H --2-> H R=-0.17 totalR=-8.11 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  145  H --1-> K R=-0.05 totalR=-8.16 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  146  K --0-> B R=-0.03 totalR=-8.19 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  147  B --3-> K R=-0.03 totalR=-8.22 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  148  K --1-> H R=-0.05 totalR=-8.28 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  149  H --1-> K R=-0.05 totalR=-8.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  150  K --3-> K R=-0.17 totalR=-8.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  151  K --0-> B R=-0.03 totalR=-8.53 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  152  B --2-> C R=-0.01 totalR=-8.53 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  153  C --2-> M R=-0.02 totalR=-8.55 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  154  M --3-> M R=-0.17 totalR=-8.72 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  155  M --2-> N R= 0.15 totalR=-8.57 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:  156  N --3-> N R=-0.17 totalR=-8.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  157  N --3-> N R=-0.17 totalR=-8.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  158  N --3-> N R=-0.17 totalR=-9.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  159  N --2-> N R=-0.17 totalR=-9.23 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  160  N --1-> O R=-0.02 totalR=-9.25 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  161  O --2-> O R=-0.17 totalR=-9.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  162  O --2-> O R=-0.17 totalR=-9.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  163  O --3-> O R=-0.17 totalR=-9.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  164  O --2-> O R=-0.17 totalR=-9.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  165  O --3-> O R=-0.17 totalR=-10.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  166  O --3-> O R=-0.17 totalR=-10.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  167  O --2-> O R=-0.17 totalR=-10.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  168  O --2-> O R=-0.17 totalR=-10.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  169  O --3-> O R=-0.17 totalR=-10.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  170  O --0-> N R=-0.02 totalR=-10.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  171  N --1-> O R=-0.02 totalR=-10.78 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  172  O --2-> O R=-0.17 totalR=-10.95 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  173  O --3-> O R=-0.17 totalR=-11.12 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  174  O --2-> O R=-0.17 totalR=-11.28 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  175  O --1-> G R=-0.05 totalR=-11.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  176  G --2-> G R=-0.17 totalR=-11.50 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  177  G --1-> O R=-0.05 totalR=-11.55 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  178  O --0-> N R=-0.02 totalR=-11.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  179  N --2-> N R=-0.17 totalR=-11.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  180  N --2-> N R=-0.17 totalR=-11.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  181  N --3-> N R=-0.17 totalR=-12.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  182  N --0-> M R=-0.02 totalR=-12.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  183  M --3-> M R=-0.17 totalR=-12.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  184  M --2-> N R=-0.02 totalR=-12.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  185  N --3-> N R=-0.17 totalR=-12.43 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  186  N --0-> M R=-0.02 totalR=-12.45 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  187  M --0-> C R=-0.02 totalR=-12.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  188  C --2-> M R=-0.02 totalR=-12.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  189  M --0-> C R=-0.02 totalR=-12.50 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  190  C --2-> M R=-0.02 totalR=-12.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  191  M --3-> M R=-0.17 totalR=-12.68 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  192  M --2-> N R=-0.02 totalR=-12.70 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  193  N --2-> N R=-0.17 totalR=-12.87 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  194  N --3-> N R=-0.17 totalR=-13.03 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  195  N --0-> M R=-0.02 totalR=-13.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  196  M --0-> C R=-0.02 totalR=-13.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  197  C --0-> S R=-0.03 totalR=-13.10 cost= 200 customerR=   0 optimum=6000\n",
            "Done: episodes=     1  avgSteps=197.00  avgTotalReward=-13.10\n",
            "Episode finished after 197 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWpCU8xH0ZKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ]
    },
    {
      "metadata": {
        "id": "7NxTojLi0N0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import json\n",
        "\n",
        "class Baseline():\n",
        "\n",
        "  def __init__(self, env, max_reward, verbose=1):\n",
        "    self.env = env\n",
        "    self.max_reward = max_reward\n",
        "    self.verbose = verbose\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.map = self.env.map\n",
        "    self.rewards = self.env.customer_reward.copy()\n",
        "    \n",
        "  def as_string(self, state):\n",
        "    # reward/cost does not hurt, but is useless, path obsucres same state\n",
        "    new_state = {\n",
        "        'rewards': state['rewards'],\n",
        "        'position': state['position']\n",
        "    }\n",
        "    return json.dumps(new_state, sort_keys=True)\n",
        "  \n",
        "  def is_goal(self, state):\n",
        "    if state['position'] != 'S': return False\n",
        "    for reward in state['rewards'].values():\n",
        "      if reward != 0: return False\n",
        "    return True\n",
        "    \n",
        "\n",
        "  def expand(self, state):\n",
        "    states = []\n",
        "    for position, cost in self.map[state['position']]:\n",
        "      new_state = deepcopy(state)\n",
        "      new_state['position'] = position\n",
        "      new_state['rewards'][position] = 0\n",
        "      reward = state['rewards'][position]\n",
        "      new_state['reward'] += reward\n",
        "      new_state['cost'] += cost\n",
        "      new_state['path'].append(position)\n",
        "      states.append(new_state)\n",
        "    return states\n",
        "\n",
        "  def search(self, root, max_depth = 25):\n",
        "      closed = set()\n",
        "      open = [root]\n",
        "\n",
        "      while open:\n",
        "          state = open.pop(0)\n",
        "          if self.as_string(state) in closed: continue  \n",
        "\n",
        "          closed.add(self.as_string(state))\n",
        "\n",
        "          depth = len(state['path'])\n",
        "          if depth > max_depth:\n",
        "            if self.verbose > 0:\n",
        "              print(\"Visited:\", len(closed))\n",
        "              print(\"Reached max depth, without reaching goal\")\n",
        "            return None\n",
        "\n",
        "          if self.is_goal(state):\n",
        "            scaled_reward = (state['reward'] - state['cost']) / self.max_reward\n",
        "            state['scaled_reward'] = scaled_reward\n",
        "            if self.verbose > 0:\n",
        "              print(\"Scaled reward:\", scaled_reward)            \n",
        "              print(\"Perfect path\", state['path'])\n",
        "            return state\n",
        "\n",
        "          expanded = self.expand(state)\n",
        "          open += expanded\n",
        "          # make this best first\n",
        "          open.sort(key=lambda state: state['cost'])\n",
        "        \n",
        "  def find_optimum(self):\n",
        "    initial_state = {\n",
        "        'rewards': self.rewards.copy(),\n",
        "        'position': 'S',\n",
        "        'reward': 0,\n",
        "        'cost': 0,\n",
        "        'path': ['S']\n",
        "    }\n",
        "    return self.search(initial_state)\n",
        "  \n",
        "  def benchmark(self, model, sample_runs=100):\n",
        "    self.verbose = 0\n",
        "    BeraterEnv.showStep = False\n",
        "    BeraterEnv.showDone = False\n",
        "\n",
        "    perfect_rewards = []\n",
        "    model_rewards = []\n",
        "    for run in range(sample_runs):\n",
        "      observation = self.env.reset()\n",
        "      self.reset()\n",
        "      \n",
        "      optimum_state = self.find_optimum()\n",
        "      perfect_rewards.append(optimum_state['scaled_reward'])\n",
        "      \n",
        "      state = np.zeros((1, 2*128))\n",
        "      dones = np.zeros((1))\n",
        "\n",
        "      for t in range(1000):\n",
        "        actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "        observation, reward, done, info = self.env.step(actions[0])\n",
        "        if done:\n",
        "          break\n",
        "      model_rewards.append(env.totalReward)\n",
        "    return perfect_rewards, model_rewards\n",
        "  \n",
        "  def score(self, model, sample_runs=100):\n",
        "    perfect_rewards, model_rewards = self.benchmark(model, sample_runs=100)\n",
        "    \n",
        "    perfect_score_mean, perfect_score_std = np.array(perfect_rewards).mean(), np.array(perfect_rewards).std()\n",
        "    test_score_mean, test_score_std = np.array(model_rewards).mean(), np.array(model_rewards).std()\n",
        "    \n",
        "    return perfect_score_mean, perfect_score_std, test_score_mean, test_score_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "Estimation\n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* all rewards: 6000\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n",
        "* estimate: no illegal moves and between\n",
        "  * half the travel cost: (6000 - 1250) / 6000 = .79\n",
        "  * and full traval cost (6000 - 2500) / 6000 = 0.58\n",
        "* additionally: the agent only sees very little of the whole scenario\n",
        "  * changes with every episode\n",
        "  * was ok when network can learn fixed scenario\n"
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LArM6BsJgUvL",
        "colab_type": "code",
        "outputId": "2826d1d8-7453-429d-d78a-92cc6a9381d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GCufDIpnjNms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1: Extract MLP builder from openai sources"
      ]
    },
    {
      "metadata": {
        "id": "WMylk8s_amq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# copied from https://github.com/openai/baselines/blob/master/baselines/a2c/utils.py\n",
        "\n",
        "def ortho_init(scale=1.0):\n",
        "    def _ortho_init(shape, dtype, partition_info=None):\n",
        "        #lasagne ortho init for tf\n",
        "        shape = tuple(shape)\n",
        "        if len(shape) == 2:\n",
        "            flat_shape = shape\n",
        "        elif len(shape) == 4: # assumes NHWC\n",
        "            flat_shape = (np.prod(shape[:-1]), shape[-1])\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        a = np.random.normal(0.0, 1.0, flat_shape)\n",
        "        u, _, v = np.linalg.svd(a, full_matrices=False)\n",
        "        q = u if u.shape == flat_shape else v # pick the one with the correct shape\n",
        "        q = q.reshape(shape)\n",
        "        return (scale * q[:shape[0], :shape[1]]).astype(np.float32)\n",
        "    return _ortho_init      \n",
        "\n",
        "def fc(x, scope, nh, *, init_scale=1.0, init_bias=0.0):\n",
        "    with tf.variable_scope(scope):\n",
        "        nin = x.get_shape()[1].value\n",
        "        w = tf.get_variable(\"w\", [nin, nh], initializer=ortho_init(init_scale))\n",
        "        b = tf.get_variable(\"b\", [nh], initializer=tf.constant_initializer(init_bias))\n",
        "        return tf.matmul(x, w)+b\n",
        "      \n",
        "\n",
        "# copied from https://github.com/openai/baselines/blob/master/baselines/common/models.py#L31\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.tanh, layer_norm=False):\n",
        "    \"\"\"\n",
        "    Stack of fully-connected layers to be used in a policy / q-function approximator\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "\n",
        "    num_layers: int                 number of fully-connected layers (default: 2)\n",
        "\n",
        "    num_hidden: int                 size of fully-connected layers (default: 64)\n",
        "\n",
        "    activation:                     activation function (default: tf.tanh)\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "\n",
        "    function that builds fully connected network with a given input tensor / placeholder\n",
        "    \"\"\"\n",
        "    def network_fn(X):\n",
        "#         print('network_fn called')\n",
        "#         Tensor(\"ppo2_model_4/Ob:0\", shape=(1, 19), dtype=float32)\n",
        "#         Tensor(\"ppo2_model_4/Ob_1:0\", shape=(512, 19), dtype=float32)\n",
        "#         print (X)\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = fc(h, 'mlp_fc{}'.format(i), nh=num_hidden, init_scale=np.sqrt(2))\n",
        "            if layer_norm:\n",
        "                h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "          \n",
        "#         Tensor(\"ppo2_model_4/pi/Tanh_2:0\", shape=(1, 500), dtype=float32)\n",
        "#         Tensor(\"ppo2_model_4/pi_2/Tanh_2:0\", shape=(512, 500), dtype=float32)\n",
        "#         print(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUvTLKKK8L8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2: Replace exotic parts\n",
        "\n",
        "Steps:\n",
        "1. Low level matmul replaced with dense layer (no need for custom code here)\n",
        "    * https://www.tensorflow.org/api_docs/python/tf/layers\n",
        "    * https://www.tensorflow.org/api_docs/python/tf/layers/Dense\n",
        "\n",
        "1. initializer changed to best practice glorot uniform, but does not give reliable results, so use seed\n",
        "1. use relu activations (should train faster)\n",
        "1. standard batch normalization does not train with any configuration (no idea why), so we need to keep layer normalization\n",
        "1.Dropout and L2 would be nice as well, but easy to do within the boundaries of the OpenAI framework:  https://stackoverflow.com/questions/38292760/tensorflow-introducing-both-l2-regularization-and-dropout-into-the-network-do\n",
        "\n",
        "#### Alternative: Using Keras API\n",
        "\n",
        "Not done here, as no big benefit expected and would need to be integrated into surrounding low level tensorflow model. Need to reuse session. If you want to do this, be sure to check at least the first link\n",
        "\n",
        "* using Keras within TensorFlow model: https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html\n",
        "* https://stackoverflow.com/questions/46790506/calling-a-keras-model-on-a-tensorflow-tensor-but-keep-weights\n",
        "* https://www.tensorflow.org/api_docs/python/tf/get_default_session\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_session"
      ]
    },
    {
      "metadata": {
        "id": "9X4G6Y4O8Khh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# first the dense layer\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.tanh, layer_norm=False):\n",
        "    def network_fn(X):\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = tf.layers.dense(h, units=num_hidden, kernel_initializer=ortho_init(np.sqrt(2)))\n",
        "#             h = fc(h, 'mlp_fc{}'.format(i), nh=num_hidden, init_scale=np.sqrt(2))\n",
        "            if layer_norm:\n",
        "                h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIbexm3U_341",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# then initializer, relu activations\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.nn.relu, layer_norm=False):\n",
        "    def network_fn(X):\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = tf.layers.dense(h, units=num_hidden, kernel_initializer=tf.initializers.glorot_uniform(seed=17))\n",
        "            if layer_norm:\n",
        "#               h = tf.layers.batch_normalization(h, center=True, scale=True)\n",
        "              h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "fa563d7b-700f-4af0-abfe-8d0e08a43ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12764
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "# https://arxiv.org/abs/1607.06450 for layer_norm\n",
        "\n",
        "# lr linear from lr=1e-2 to lr=1e-4 (default lr=3e-4)\n",
        "def lr_range(frac):\n",
        "  # we get the remaining updates between 1 and 0\n",
        "  start_lr = 1e-2\n",
        "  end_lr = 1e-4\n",
        "  diff_lr = start_lr - end_lr\n",
        "  lr = end_lr + diff_lr * frac\n",
        "  return lr\n",
        "  \n",
        "network = mlp(num_hidden=500, num_layers=3, layer_norm=True)\n",
        "  \n",
        "model = ppo2.learn(\n",
        "    env=monitored_env,\n",
        "    network=network,\n",
        "    lr=lr_range,\n",
        "    gamma=1.0,\n",
        "    ent_coef=0.05,\n",
        "    total_timesteps=1000000)\n",
        "\n",
        "# model = ppo2.learn(\n",
        "#     env=monitored_env,\n",
        "#     network='mlp',\n",
        "#     num_hidden=500,\n",
        "#     num_layers=3,\n",
        "#     layer_norm=True,\n",
        "#     lr=lr_range,\n",
        "#     gamma=1.0,\n",
        "#     ent_coef=0.05,\n",
        "#     total_timesteps=500000)\n",
        "\n",
        "\n",
        "# model.save('berater-ppo-v11.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-01-27-15-27-47-240107\n",
            "-----------------------------------\n",
            "| approxkl           | 1.4420375  |\n",
            "| clipfrac           | 0.8397217  |\n",
            "| eplenmean          | 104        |\n",
            "| eprewmean          | -6.1689844 |\n",
            "| explained_variance | -0.248     |\n",
            "| fps                | 386        |\n",
            "| nupdates           | 1          |\n",
            "| policy_entropy     | 0.8404105  |\n",
            "| policy_loss        | 0.19051582 |\n",
            "| serial_timesteps   | 2048       |\n",
            "| time_elapsed       | 5.3        |\n",
            "| total_timesteps    | 2048       |\n",
            "| value_loss         | 5.3930745  |\n",
            "-----------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.026781807    |\n",
            "| clipfrac           | 0.1953125      |\n",
            "| eplenmean          | 338            |\n",
            "| eprewmean          | -9.549868      |\n",
            "| explained_variance | 0.327          |\n",
            "| fps                | 409            |\n",
            "| nupdates           | 10             |\n",
            "| policy_entropy     | 0.93414086     |\n",
            "| policy_loss        | -0.00030102135 |\n",
            "| serial_timesteps   | 20480          |\n",
            "| time_elapsed       | 50.4           |\n",
            "| total_timesteps    | 20480          |\n",
            "| value_loss         | 0.088846214    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.016508345  |\n",
            "| clipfrac           | 0.20739746   |\n",
            "| eplenmean          | 33.8         |\n",
            "| eprewmean          | 0.14341663   |\n",
            "| explained_variance | 0.0657       |\n",
            "| fps                | 403          |\n",
            "| nupdates           | 20           |\n",
            "| policy_entropy     | 0.90960133   |\n",
            "| policy_loss        | -0.014445528 |\n",
            "| serial_timesteps   | 40960        |\n",
            "| time_elapsed       | 101          |\n",
            "| total_timesteps    | 40960        |\n",
            "| value_loss         | 0.053486325  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.023043975  |\n",
            "| clipfrac           | 0.20336914   |\n",
            "| eplenmean          | 23.3         |\n",
            "| eprewmean          | 0.54283327   |\n",
            "| explained_variance | 0.701        |\n",
            "| fps                | 403          |\n",
            "| nupdates           | 30           |\n",
            "| policy_entropy     | 0.5709828    |\n",
            "| policy_loss        | -0.008646036 |\n",
            "| serial_timesteps   | 61440        |\n",
            "| time_elapsed       | 151          |\n",
            "| total_timesteps    | 61440        |\n",
            "| value_loss         | 0.0075427843 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.036137722   |\n",
            "| clipfrac           | 0.15966797    |\n",
            "| eplenmean          | 18            |\n",
            "| eprewmean          | 0.6485833     |\n",
            "| explained_variance | 0.905         |\n",
            "| fps                | 420           |\n",
            "| nupdates           | 40            |\n",
            "| policy_entropy     | 0.34395832    |\n",
            "| policy_loss        | -0.0138049545 |\n",
            "| serial_timesteps   | 81920         |\n",
            "| time_elapsed       | 202           |\n",
            "| total_timesteps    | 81920         |\n",
            "| value_loss         | 0.0025978752  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.016258882  |\n",
            "| clipfrac           | 0.08215332   |\n",
            "| eplenmean          | 17.1         |\n",
            "| eprewmean          | 0.6855001    |\n",
            "| explained_variance | 0.892        |\n",
            "| fps                | 409          |\n",
            "| nupdates           | 50           |\n",
            "| policy_entropy     | 0.22930014   |\n",
            "| policy_loss        | -0.009889038 |\n",
            "| serial_timesteps   | 102400       |\n",
            "| time_elapsed       | 252          |\n",
            "| total_timesteps    | 102400       |\n",
            "| value_loss         | 0.0029221126 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.040627833  |\n",
            "| clipfrac           | 0.0793457    |\n",
            "| eplenmean          | 16.2         |\n",
            "| eprewmean          | 0.69150007   |\n",
            "| explained_variance | 0.937        |\n",
            "| fps                | 409          |\n",
            "| nupdates           | 60           |\n",
            "| policy_entropy     | 0.14939314   |\n",
            "| policy_loss        | -0.008367878 |\n",
            "| serial_timesteps   | 122880       |\n",
            "| time_elapsed       | 301          |\n",
            "| total_timesteps    | 122880       |\n",
            "| value_loss         | 0.0018437295 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.047517613  |\n",
            "| clipfrac           | 0.23278809   |\n",
            "| eplenmean          | 19.5         |\n",
            "| eprewmean          | 0.51625      |\n",
            "| explained_variance | 0.62         |\n",
            "| fps                | 413          |\n",
            "| nupdates           | 70           |\n",
            "| policy_entropy     | 0.42431322   |\n",
            "| policy_loss        | -0.023480183 |\n",
            "| serial_timesteps   | 143360       |\n",
            "| time_elapsed       | 351          |\n",
            "| total_timesteps    | 143360       |\n",
            "| value_loss         | 0.008940705  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.022558138 |\n",
            "| clipfrac           | 0.07788086  |\n",
            "| eplenmean          | 16.4        |\n",
            "| eprewmean          | 0.69066656  |\n",
            "| explained_variance | 0.788       |\n",
            "| fps                | 410         |\n",
            "| nupdates           | 80          |\n",
            "| policy_entropy     | 0.24044533  |\n",
            "| policy_loss        | -0.01237258 |\n",
            "| serial_timesteps   | 163840      |\n",
            "| time_elapsed       | 400         |\n",
            "| total_timesteps    | 163840      |\n",
            "| value_loss         | 0.006068559 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.008366971  |\n",
            "| clipfrac           | 0.03491211   |\n",
            "| eplenmean          | 15.1         |\n",
            "| eprewmean          | 0.7080833    |\n",
            "| explained_variance | 0.931        |\n",
            "| fps                | 411          |\n",
            "| nupdates           | 90           |\n",
            "| policy_entropy     | 0.09522042   |\n",
            "| policy_loss        | -0.004614097 |\n",
            "| serial_timesteps   | 184320       |\n",
            "| time_elapsed       | 450          |\n",
            "| total_timesteps    | 184320       |\n",
            "| value_loss         | 0.0021189214 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.10888699   |\n",
            "| clipfrac           | 0.075805664  |\n",
            "| eplenmean          | 15.4         |\n",
            "| eprewmean          | 0.7098333    |\n",
            "| explained_variance | 0.932        |\n",
            "| fps                | 405          |\n",
            "| nupdates           | 100          |\n",
            "| policy_entropy     | 0.14791274   |\n",
            "| policy_loss        | 0.004112877  |\n",
            "| serial_timesteps   | 204800       |\n",
            "| time_elapsed       | 501          |\n",
            "| total_timesteps    | 204800       |\n",
            "| value_loss         | 0.0018511078 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.00982387   |\n",
            "| clipfrac           | 0.06713867   |\n",
            "| eplenmean          | 16.2         |\n",
            "| eprewmean          | 0.6831667    |\n",
            "| explained_variance | 0.896        |\n",
            "| fps                | 406          |\n",
            "| nupdates           | 110          |\n",
            "| policy_entropy     | 0.24413782   |\n",
            "| policy_loss        | -0.007331957 |\n",
            "| serial_timesteps   | 225280       |\n",
            "| time_elapsed       | 552          |\n",
            "| total_timesteps    | 225280       |\n",
            "| value_loss         | 0.00279108   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.014135233   |\n",
            "| clipfrac           | 0.056152344   |\n",
            "| eplenmean          | 16.2          |\n",
            "| eprewmean          | 0.69716674    |\n",
            "| explained_variance | 0.932         |\n",
            "| fps                | 403           |\n",
            "| nupdates           | 120           |\n",
            "| policy_entropy     | 0.17605259    |\n",
            "| policy_loss        | -0.0014135699 |\n",
            "| serial_timesteps   | 245760        |\n",
            "| time_elapsed       | 602           |\n",
            "| total_timesteps    | 245760        |\n",
            "| value_loss         | 0.002320418   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.020926617  |\n",
            "| clipfrac           | 0.06652832   |\n",
            "| eplenmean          | 16.2         |\n",
            "| eprewmean          | 0.6959168    |\n",
            "| explained_variance | 0.777        |\n",
            "| fps                | 426          |\n",
            "| nupdates           | 130          |\n",
            "| policy_entropy     | 0.18375051   |\n",
            "| policy_loss        | 0.0067167035 |\n",
            "| serial_timesteps   | 266240       |\n",
            "| time_elapsed       | 652          |\n",
            "| total_timesteps    | 266240       |\n",
            "| value_loss         | 0.0066590556 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010054722   |\n",
            "| clipfrac           | 0.03149414    |\n",
            "| eplenmean          | 15.6          |\n",
            "| eprewmean          | 0.709         |\n",
            "| explained_variance | 0.939         |\n",
            "| fps                | 427           |\n",
            "| nupdates           | 140           |\n",
            "| policy_entropy     | 0.103629835   |\n",
            "| policy_loss        | -0.0017408483 |\n",
            "| serial_timesteps   | 286720        |\n",
            "| time_elapsed       | 700           |\n",
            "| total_timesteps    | 286720        |\n",
            "| value_loss         | 0.0016504797  |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.4747235   |\n",
            "| clipfrac           | 0.1262207   |\n",
            "| eplenmean          | 19.8        |\n",
            "| eprewmean          | 0.50933325  |\n",
            "| explained_variance | 0.302       |\n",
            "| fps                | 402         |\n",
            "| nupdates           | 150         |\n",
            "| policy_entropy     | 0.15966588  |\n",
            "| policy_loss        | 0.000542385 |\n",
            "| serial_timesteps   | 307200      |\n",
            "| time_elapsed       | 751         |\n",
            "| total_timesteps    | 307200      |\n",
            "| value_loss         | 0.055644292 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0585206     |\n",
            "| clipfrac           | 0.04699707    |\n",
            "| eplenmean          | 14.9          |\n",
            "| eprewmean          | 0.7075        |\n",
            "| explained_variance | 0.948         |\n",
            "| fps                | 401           |\n",
            "| nupdates           | 160           |\n",
            "| policy_entropy     | 0.099518925   |\n",
            "| policy_loss        | -0.0028842394 |\n",
            "| serial_timesteps   | 327680        |\n",
            "| time_elapsed       | 802           |\n",
            "| total_timesteps    | 327680        |\n",
            "| value_loss         | 0.0017029579  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.016357124   |\n",
            "| clipfrac           | 0.032958984   |\n",
            "| eplenmean          | 15.1          |\n",
            "| eprewmean          | 0.7125        |\n",
            "| explained_variance | 0.958         |\n",
            "| fps                | 406           |\n",
            "| nupdates           | 170           |\n",
            "| policy_entropy     | 0.054430917   |\n",
            "| policy_loss        | -0.0020781658 |\n",
            "| serial_timesteps   | 348160        |\n",
            "| time_elapsed       | 853           |\n",
            "| total_timesteps    | 348160        |\n",
            "| value_loss         | 0.0014069453  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.13181257   |\n",
            "| clipfrac           | 0.041870117  |\n",
            "| eplenmean          | 15.4         |\n",
            "| eprewmean          | 0.6958334    |\n",
            "| explained_variance | 0.858        |\n",
            "| fps                | 440          |\n",
            "| nupdates           | 180          |\n",
            "| policy_entropy     | 0.066288464  |\n",
            "| policy_loss        | -0.011668324 |\n",
            "| serial_timesteps   | 368640       |\n",
            "| time_elapsed       | 899          |\n",
            "| total_timesteps    | 368640       |\n",
            "| value_loss         | 0.0045863683 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.007379102   |\n",
            "| clipfrac           | 0.027832031   |\n",
            "| eplenmean          | 14.3          |\n",
            "| eprewmean          | 0.72275       |\n",
            "| explained_variance | 0.971         |\n",
            "| fps                | 445           |\n",
            "| nupdates           | 190           |\n",
            "| policy_entropy     | 0.096365094   |\n",
            "| policy_loss        | -0.003078008  |\n",
            "| serial_timesteps   | 389120        |\n",
            "| time_elapsed       | 945           |\n",
            "| total_timesteps    | 389120        |\n",
            "| value_loss         | 0.00093441986 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011448664  |\n",
            "| clipfrac           | 0.029174805  |\n",
            "| eplenmean          | 15.3         |\n",
            "| eprewmean          | 0.7102501    |\n",
            "| explained_variance | 0.946        |\n",
            "| fps                | 449          |\n",
            "| nupdates           | 200          |\n",
            "| policy_entropy     | 0.0614279    |\n",
            "| policy_loss        | -0.008784407 |\n",
            "| serial_timesteps   | 409600       |\n",
            "| time_elapsed       | 991          |\n",
            "| total_timesteps    | 409600       |\n",
            "| value_loss         | 0.0018629392 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01342484    |\n",
            "| clipfrac           | 0.04626465    |\n",
            "| eplenmean          | 15.2          |\n",
            "| eprewmean          | 0.7158335     |\n",
            "| explained_variance | 0.974         |\n",
            "| fps                | 449           |\n",
            "| nupdates           | 210           |\n",
            "| policy_entropy     | 0.09103564    |\n",
            "| policy_loss        | -0.0051630316 |\n",
            "| serial_timesteps   | 430080        |\n",
            "| time_elapsed       | 1.04e+03      |\n",
            "| total_timesteps    | 430080        |\n",
            "| value_loss         | 0.0008239947  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.007953094  |\n",
            "| clipfrac           | 0.028930664  |\n",
            "| eplenmean          | 15.2         |\n",
            "| eprewmean          | 0.7163334    |\n",
            "| explained_variance | 0.969        |\n",
            "| fps                | 454          |\n",
            "| nupdates           | 220          |\n",
            "| policy_entropy     | 0.06973121   |\n",
            "| policy_loss        | -0.006585888 |\n",
            "| serial_timesteps   | 450560       |\n",
            "| time_elapsed       | 1.08e+03     |\n",
            "| total_timesteps    | 450560       |\n",
            "| value_loss         | 0.0009260485 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.03702754    |\n",
            "| clipfrac           | 0.05444336    |\n",
            "| eplenmean          | 15.5          |\n",
            "| eprewmean          | 0.70675004    |\n",
            "| explained_variance | 0.951         |\n",
            "| fps                | 455           |\n",
            "| nupdates           | 230           |\n",
            "| policy_entropy     | 0.09789952    |\n",
            "| policy_loss        | -0.0019488911 |\n",
            "| serial_timesteps   | 471040        |\n",
            "| time_elapsed       | 1.13e+03      |\n",
            "| total_timesteps    | 471040        |\n",
            "| value_loss         | 0.0014300046  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.051745325   |\n",
            "| clipfrac           | 0.03125       |\n",
            "| eplenmean          | 15.1          |\n",
            "| eprewmean          | 0.7195833     |\n",
            "| explained_variance | 0.975         |\n",
            "| fps                | 449           |\n",
            "| nupdates           | 240           |\n",
            "| policy_entropy     | 0.065127894   |\n",
            "| policy_loss        | -0.00515756   |\n",
            "| serial_timesteps   | 491520        |\n",
            "| time_elapsed       | 1.17e+03      |\n",
            "| total_timesteps    | 491520        |\n",
            "| value_loss         | 0.00075985683 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.007276212  |\n",
            "| clipfrac           | 0.044311523  |\n",
            "| eplenmean          | 15.8         |\n",
            "| eprewmean          | 0.7081669    |\n",
            "| explained_variance | 0.956        |\n",
            "| fps                | 445          |\n",
            "| nupdates           | 250          |\n",
            "| policy_entropy     | 0.12242043   |\n",
            "| policy_loss        | -0.004001532 |\n",
            "| serial_timesteps   | 512000       |\n",
            "| time_elapsed       | 1.22e+03     |\n",
            "| total_timesteps    | 512000       |\n",
            "| value_loss         | 0.0012700066 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.007015673   |\n",
            "| clipfrac           | 0.024291992   |\n",
            "| eplenmean          | 14.4          |\n",
            "| eprewmean          | 0.72583336    |\n",
            "| explained_variance | 0.983         |\n",
            "| fps                | 424           |\n",
            "| nupdates           | 260           |\n",
            "| policy_entropy     | 0.057486854   |\n",
            "| policy_loss        | -0.0027593905 |\n",
            "| serial_timesteps   | 532480        |\n",
            "| time_elapsed       | 1.27e+03      |\n",
            "| total_timesteps    | 532480        |\n",
            "| value_loss         | 0.0005704223  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.006855382  |\n",
            "| clipfrac           | 0.028564453  |\n",
            "| eplenmean          | 14.6         |\n",
            "| eprewmean          | 0.72208345   |\n",
            "| explained_variance | 0.977        |\n",
            "| fps                | 435          |\n",
            "| nupdates           | 270          |\n",
            "| policy_entropy     | 0.06387735   |\n",
            "| policy_loss        | -0.005685599 |\n",
            "| serial_timesteps   | 552960       |\n",
            "| time_elapsed       | 1.32e+03     |\n",
            "| total_timesteps    | 552960       |\n",
            "| value_loss         | 0.0007501704 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.002857305  |\n",
            "| clipfrac           | 0.015625     |\n",
            "| eplenmean          | 15           |\n",
            "| eprewmean          | 0.7223334    |\n",
            "| explained_variance | 0.983        |\n",
            "| fps                | 429          |\n",
            "| nupdates           | 280          |\n",
            "| policy_entropy     | 0.05390006   |\n",
            "| policy_loss        | -0.002011288 |\n",
            "| serial_timesteps   | 573440       |\n",
            "| time_elapsed       | 1.36e+03     |\n",
            "| total_timesteps    | 573440       |\n",
            "| value_loss         | 0.0005740882 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.12518914    |\n",
            "| clipfrac           | 0.041137695   |\n",
            "| eplenmean          | 16            |\n",
            "| eprewmean          | 0.7076667     |\n",
            "| explained_variance | 0.908         |\n",
            "| fps                | 428           |\n",
            "| nupdates           | 290           |\n",
            "| policy_entropy     | 0.053669304   |\n",
            "| policy_loss        | 0.00048783532 |\n",
            "| serial_timesteps   | 593920        |\n",
            "| time_elapsed       | 1.41e+03      |\n",
            "| total_timesteps    | 593920        |\n",
            "| value_loss         | 0.0021670922  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009636785  |\n",
            "| clipfrac           | 0.064697266  |\n",
            "| eplenmean          | 16.4         |\n",
            "| eprewmean          | 0.66958344   |\n",
            "| explained_variance | 0.905        |\n",
            "| fps                | 432          |\n",
            "| nupdates           | 300          |\n",
            "| policy_entropy     | 0.23065643   |\n",
            "| policy_loss        | -0.010738534 |\n",
            "| serial_timesteps   | 614400       |\n",
            "| time_elapsed       | 1.46e+03     |\n",
            "| total_timesteps    | 614400       |\n",
            "| value_loss         | 0.0027685342 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0031783069  |\n",
            "| clipfrac           | 0.027709961   |\n",
            "| eplenmean          | 15.2          |\n",
            "| eprewmean          | 0.71508336    |\n",
            "| explained_variance | 0.965         |\n",
            "| fps                | 417           |\n",
            "| nupdates           | 310           |\n",
            "| policy_entropy     | 0.11050528    |\n",
            "| policy_loss        | -0.0055362736 |\n",
            "| serial_timesteps   | 634880        |\n",
            "| time_elapsed       | 1.51e+03      |\n",
            "| total_timesteps    | 634880        |\n",
            "| value_loss         | 0.0011054395  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0029553147  |\n",
            "| clipfrac           | 0.026977539   |\n",
            "| eplenmean          | 15.6          |\n",
            "| eprewmean          | 0.7099167     |\n",
            "| explained_variance | 0.962         |\n",
            "| fps                | 431           |\n",
            "| nupdates           | 320           |\n",
            "| policy_entropy     | 0.13246873    |\n",
            "| policy_loss        | -0.0050656684 |\n",
            "| serial_timesteps   | 655360        |\n",
            "| time_elapsed       | 1.55e+03      |\n",
            "| total_timesteps    | 655360        |\n",
            "| value_loss         | 0.0012099134  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0068599028  |\n",
            "| clipfrac           | 0.033691406   |\n",
            "| eplenmean          | 15.1          |\n",
            "| eprewmean          | 0.71875       |\n",
            "| explained_variance | 0.947         |\n",
            "| fps                | 433           |\n",
            "| nupdates           | 330           |\n",
            "| policy_entropy     | 0.071830705   |\n",
            "| policy_loss        | -0.0007105068 |\n",
            "| serial_timesteps   | 675840        |\n",
            "| time_elapsed       | 1.6e+03       |\n",
            "| total_timesteps    | 675840        |\n",
            "| value_loss         | 0.0016185608  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0043550213  |\n",
            "| clipfrac           | 0.024291992   |\n",
            "| eplenmean          | 14.9          |\n",
            "| eprewmean          | 0.72900003    |\n",
            "| explained_variance | 0.982         |\n",
            "| fps                | 427           |\n",
            "| nupdates           | 340           |\n",
            "| policy_entropy     | 0.07719641    |\n",
            "| policy_loss        | -0.0024399122 |\n",
            "| serial_timesteps   | 696320        |\n",
            "| time_elapsed       | 1.65e+03      |\n",
            "| total_timesteps    | 696320        |\n",
            "| value_loss         | 0.0005805964  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.13895583   |\n",
            "| clipfrac           | 0.09851074   |\n",
            "| eplenmean          | 16.9         |\n",
            "| eprewmean          | 0.7007501    |\n",
            "| explained_variance | 0.936        |\n",
            "| fps                | 429          |\n",
            "| nupdates           | 350          |\n",
            "| policy_entropy     | 0.10242043   |\n",
            "| policy_loss        | -0.026852302 |\n",
            "| serial_timesteps   | 716800       |\n",
            "| time_elapsed       | 1.7e+03      |\n",
            "| total_timesteps    | 716800       |\n",
            "| value_loss         | 0.0016744145 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.002885365   |\n",
            "| clipfrac           | 0.011230469   |\n",
            "| eplenmean          | 15            |\n",
            "| eprewmean          | 0.7263334     |\n",
            "| explained_variance | 0.983         |\n",
            "| fps                | 434           |\n",
            "| nupdates           | 360           |\n",
            "| policy_entropy     | 0.06623655    |\n",
            "| policy_loss        | -0.0028897545 |\n",
            "| serial_timesteps   | 737280        |\n",
            "| time_elapsed       | 1.75e+03      |\n",
            "| total_timesteps    | 737280        |\n",
            "| value_loss         | 0.0006023402  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0031549255  |\n",
            "| clipfrac           | 0.020507812   |\n",
            "| eplenmean          | 14.9          |\n",
            "| eprewmean          | 0.7280834     |\n",
            "| explained_variance | 0.983         |\n",
            "| fps                | 427           |\n",
            "| nupdates           | 370           |\n",
            "| policy_entropy     | 0.066166855   |\n",
            "| policy_loss        | -0.0030142223 |\n",
            "| serial_timesteps   | 757760        |\n",
            "| time_elapsed       | 1.79e+03      |\n",
            "| total_timesteps    | 757760        |\n",
            "| value_loss         | 0.0005591386  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0041663903  |\n",
            "| clipfrac           | 0.033081055   |\n",
            "| eplenmean          | 14.5          |\n",
            "| eprewmean          | 0.73100007    |\n",
            "| explained_variance | 0.979         |\n",
            "| fps                | 447           |\n",
            "| nupdates           | 380           |\n",
            "| policy_entropy     | 0.08447483    |\n",
            "| policy_loss        | -0.0053323675 |\n",
            "| serial_timesteps   | 778240        |\n",
            "| time_elapsed       | 1.84e+03      |\n",
            "| total_timesteps    | 778240        |\n",
            "| value_loss         | 0.00063511264 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0029821154  |\n",
            "| clipfrac           | 0.014282227   |\n",
            "| eplenmean          | 15            |\n",
            "| eprewmean          | 0.7252502     |\n",
            "| explained_variance | 0.978         |\n",
            "| fps                | 445           |\n",
            "| nupdates           | 390           |\n",
            "| policy_entropy     | 0.06973519    |\n",
            "| policy_loss        | -0.0038597833 |\n",
            "| serial_timesteps   | 798720        |\n",
            "| time_elapsed       | 1.89e+03      |\n",
            "| total_timesteps    | 798720        |\n",
            "| value_loss         | 0.00070443004 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0025000875 |\n",
            "| clipfrac           | 0.017211914  |\n",
            "| eplenmean          | 15.2         |\n",
            "| eprewmean          | 0.7215833    |\n",
            "| explained_variance | 0.977        |\n",
            "| fps                | 442          |\n",
            "| nupdates           | 400          |\n",
            "| policy_entropy     | 0.062204212  |\n",
            "| policy_loss        | -0.004480864 |\n",
            "| serial_timesteps   | 819200       |\n",
            "| time_elapsed       | 1.93e+03     |\n",
            "| total_timesteps    | 819200       |\n",
            "| value_loss         | 0.0007088655 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.006064726   |\n",
            "| clipfrac           | 0.018310547   |\n",
            "| eplenmean          | 15.5          |\n",
            "| eprewmean          | 0.72141653    |\n",
            "| explained_variance | 0.981         |\n",
            "| fps                | 440           |\n",
            "| nupdates           | 410           |\n",
            "| policy_entropy     | 0.053719625   |\n",
            "| policy_loss        | -0.0041853436 |\n",
            "| serial_timesteps   | 839680        |\n",
            "| time_elapsed       | 1.98e+03      |\n",
            "| total_timesteps    | 839680        |\n",
            "| value_loss         | 0.0005962068  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0018461812  |\n",
            "| clipfrac           | 0.010620117   |\n",
            "| eplenmean          | 14.8          |\n",
            "| eprewmean          | 0.72924995    |\n",
            "| explained_variance | 0.985         |\n",
            "| fps                | 430           |\n",
            "| nupdates           | 420           |\n",
            "| policy_entropy     | 0.03774019    |\n",
            "| policy_loss        | -0.002248707  |\n",
            "| serial_timesteps   | 860160        |\n",
            "| time_elapsed       | 2.03e+03      |\n",
            "| total_timesteps    | 860160        |\n",
            "| value_loss         | 0.00048187908 |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.05437982  |\n",
            "| clipfrac           | 0.036621094 |\n",
            "| eplenmean          | 14.5        |\n",
            "| eprewmean          | 0.7378333   |\n",
            "| explained_variance | 0.902       |\n",
            "| fps                | 430         |\n",
            "| nupdates           | 430         |\n",
            "| policy_entropy     | 0.054468013 |\n",
            "| policy_loss        | -0.01444613 |\n",
            "| serial_timesteps   | 880640      |\n",
            "| time_elapsed       | 2.08e+03    |\n",
            "| total_timesteps    | 880640      |\n",
            "| value_loss         | 0.002808094 |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.001031183    |\n",
            "| clipfrac           | 0.010131836    |\n",
            "| eplenmean          | 15.1           |\n",
            "| eprewmean          | 0.7238334      |\n",
            "| explained_variance | 0.932          |\n",
            "| fps                | 436            |\n",
            "| nupdates           | 440            |\n",
            "| policy_entropy     | 0.042608798    |\n",
            "| policy_loss        | -0.00094039476 |\n",
            "| serial_timesteps   | 901120         |\n",
            "| time_elapsed       | 2.12e+03       |\n",
            "| total_timesteps    | 901120         |\n",
            "| value_loss         | 0.0014700713   |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0018764732 |\n",
            "| clipfrac           | 0.011962891  |\n",
            "| eplenmean          | 14.3         |\n",
            "| eprewmean          | 0.7239167    |\n",
            "| explained_variance | 0.972        |\n",
            "| fps                | 400          |\n",
            "| nupdates           | 450          |\n",
            "| policy_entropy     | 0.044268757  |\n",
            "| policy_loss        | -0.003393606 |\n",
            "| serial_timesteps   | 921600       |\n",
            "| time_elapsed       | 2.17e+03     |\n",
            "| total_timesteps    | 921600       |\n",
            "| value_loss         | 0.0009643771 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0017598544  |\n",
            "| clipfrac           | 0.012451172   |\n",
            "| eplenmean          | 14.3          |\n",
            "| eprewmean          | 0.7313333     |\n",
            "| explained_variance | 0.987         |\n",
            "| fps                | 435           |\n",
            "| nupdates           | 460           |\n",
            "| policy_entropy     | 0.042088002   |\n",
            "| policy_loss        | -0.0031104754 |\n",
            "| serial_timesteps   | 942080        |\n",
            "| time_elapsed       | 2.22e+03      |\n",
            "| total_timesteps    | 942080        |\n",
            "| value_loss         | 0.00043203327 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0005749549  |\n",
            "| clipfrac           | 0.0078125     |\n",
            "| eplenmean          | 14.4          |\n",
            "| eprewmean          | 0.7337499     |\n",
            "| explained_variance | 0.986         |\n",
            "| fps                | 427           |\n",
            "| nupdates           | 470           |\n",
            "| policy_entropy     | 0.04269629    |\n",
            "| policy_loss        | -0.002129221  |\n",
            "| serial_timesteps   | 962560        |\n",
            "| time_elapsed       | 2.27e+03      |\n",
            "| total_timesteps    | 962560        |\n",
            "| value_loss         | 0.00048825034 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00039610395 |\n",
            "| clipfrac           | 0.0034179688  |\n",
            "| eplenmean          | 14.5          |\n",
            "| eprewmean          | 0.73708344    |\n",
            "| explained_variance | 0.984         |\n",
            "| fps                | 401           |\n",
            "| nupdates           | 480           |\n",
            "| policy_entropy     | 0.040699374   |\n",
            "| policy_loss        | -0.001574069  |\n",
            "| serial_timesteps   | 983040        |\n",
            "| time_elapsed       | 2.31e+03      |\n",
            "| total_timesteps    | 983040        |\n",
            "| value_loss         | 0.00053364615 |\n",
            "--------------------------------------\n",
            "CPU times: user 47min 46s, sys: 8min 56s, total: 56min 43s\n",
            "Wall time: 39min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "1e386a52-f722-497f-dde2-5c2fd6233b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f16b5403240>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nExERqYRBmIiISCUMwkRERCr5/xJffIfLNHBEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "id": "H_QTckfBra7l",
        "colab_type": "code",
        "outputId": "49cf8fa2-5356-48bd-fa1a-14c77888da88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "baseline = Baseline(env, max_reward=6000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 0, 'B': 0, 'C': 0, 'D': 1000, 'E': 1000, 'F': 0, 'G': 1000, 'H': 1000, 'K': 0, 'L': 1000, 'M': 0, 'N': 0, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "dda9701d-5bfd-4e93-ba56-1fa7ce341829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "cell_type": "code",
      "source": [
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, reward={}\".format(t+1, env.totalReward))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:    0   Step:    1  S --2-> C R=-0.03 totalR=-0.03 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    2  C --2-> M R=-0.02 totalR=-0.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    3  M --1-> L R= 0.16 totalR= 0.11 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    4  L --1-> M R=-0.01 totalR= 0.10 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  M --2-> N R=-0.02 totalR= 0.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  N --1-> O R= 0.15 totalR= 0.23 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    7  O --1-> G R= 0.12 totalR= 0.35 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    8  G --0-> F R=-0.03 totalR= 0.32 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  F --0-> D R= 0.16 totalR= 0.47 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   10  D --0-> A R=-0.02 totalR= 0.46 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  A --2-> E R= 0.15 totalR= 0.61 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R= 0.15 totalR= 0.76 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR= 0.74 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --0-> A R=-0.02 totalR= 0.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  A --1-> B R=-0.02 totalR= 0.71 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  B --0-> S R=-0.02 totalR= 0.69 cost= 100 customerR=   0 optimum=6000\n",
            "Episode finished after 16 timesteps, reward=0.6916666666666664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3z35_dMMt6SW",
        "colab_type": "code",
        "outputId": "b5fb4d47-b45f-459d-b519-16a04c886c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "cell_type": "code",
      "source": [
        "%time baseline.find_optimum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaled reward: 0.7083333333333334\n",
            "Perfect path ['S', 'B', 'C', 'M', 'L', 'M', 'N', 'O', 'G', 'F', 'D', 'F', 'E', 'H', 'E', 'A', 'B', 'S']\n",
            "CPU times: user 138 ms, sys: 1.57 ms, total: 139 ms\n",
            "Wall time: 143 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cost': 1750,\n",
              " 'path': ['S',\n",
              "  'B',\n",
              "  'C',\n",
              "  'M',\n",
              "  'L',\n",
              "  'M',\n",
              "  'N',\n",
              "  'O',\n",
              "  'G',\n",
              "  'F',\n",
              "  'D',\n",
              "  'F',\n",
              "  'E',\n",
              "  'H',\n",
              "  'E',\n",
              "  'A',\n",
              "  'B',\n",
              "  'S'],\n",
              " 'position': 'S',\n",
              " 'reward': 6000,\n",
              " 'rewards': {'A': 0,\n",
              "  'B': 0,\n",
              "  'C': 0,\n",
              "  'D': 0,\n",
              "  'E': 0,\n",
              "  'F': 0,\n",
              "  'G': 0,\n",
              "  'H': 0,\n",
              "  'K': 0,\n",
              "  'L': 0,\n",
              "  'M': 0,\n",
              "  'N': 0,\n",
              "  'O': 0,\n",
              "  'S': 0},\n",
              " 'scaled_reward': 0.7083333333333334}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "K36GXkzyRGOO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "KMb58O_q067F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "baseline = Baseline(env, max_reward=6000)\n",
        "perfect_score_mean, perfect_score_std, test_score_mean, test_score_std = baseline.score(model, sample_runs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dr9ylHgnRIcc",
        "colab_type": "code",
        "outputId": "b1684d33-86c4-4de0-c7f8-3c4816247691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# perfect scores\n",
        "perfect_score_mean, perfect_score_std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7383333333333334, 0.03227486121839515)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "rOSOoO29Rwgm",
        "colab_type": "code",
        "outputId": "09a856f2-18c6-4779-da15-0b21e5bf3e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# test scores for our model\n",
        "test_score_mean, test_score_std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7308333333333333, 0.03404449702635918)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "Ls8IKVV1R5SE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}