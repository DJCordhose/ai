{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v7\n",
        "\n",
        "## Changes from v6\n",
        "1. per episode set certain rewards to 0 to simulate different customers per consultant\n",
        "  \n",
        "## next steps\n",
        "1. consider returning to complete observation (should give better results) like in previous notebooks\n",
        "1. configure custom network including regularization (https://blog.openai.com/quantifying-generalization-in-reinforcement-learning/)\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        # position, and up to 4 paths from that position, non existing path is -1000 and no position change\n",
        "        self.observation_space = spaces.Box(low=numpy.array([0,-1000,-1000,-1000,-1000]),\n",
        "                                             high=numpy.array([13,1000,1000,1000,1000]),\n",
        "                                             dtype=numpy.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = numpy.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=numpy.float32)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/2)\n",
        "#       number_per_consultant = int(number_of_customers/1.5)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b26277e0-96ee-43f5-9b0f-9513901742fd"
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.  -300.   900.  -200. -1000.]\n",
            "{'S': 0, 'A': 0, 'B': 1000, 'C': 0, 'D': 1000, 'E': 0, 'F': 1000, 'G': 1000, 'H': 1000, 'K': 0, 'L': 0, 'M': 0, 'N': 0, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "a4b876e3-b4e8-4dc2-83e0-0b7855f2de60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.  -300.  -100.   800. -1000.]\n",
            "Episode:    0   Step:    1  S --0-> A R=-0.05 totalR=-0.05 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    2  A --3-> D R=-0.02 totalR=-0.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    3  D --1-> F R= 0.16 totalR= 0.09 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.08 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.17 totalR=-0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.17 totalR=-0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.17 totalR=-0.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.17 totalR=-0.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.59 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.17 totalR=-0.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  F --1-> E R= 0.15 totalR=-0.61 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R=-0.02 totalR=-0.62 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR=-0.64 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.17 totalR=-0.81 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.02 totalR=-0.82 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.02 totalR=-0.84 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.02 totalR=-0.86 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.05 totalR=-0.91 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  S --2-> C R= 0.13 totalR=-0.78 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   20  C --1-> B R=-0.01 totalR=-0.78 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.79 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  C --3-> L R=-0.03 totalR=-0.83 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.17 totalR=-0.99 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.17 totalR=-1.16 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-1.19 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-1.20 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.02 totalR=-1.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.02 totalR=-1.23 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.02 totalR=-1.25 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.05 totalR=-1.30 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.02 totalR=-1.32 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.02 totalR=-1.33 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.17 totalR=-1.50 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.05 totalR=-1.55 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.02 totalR=-1.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-1.57 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   37  F --2-> G R= 0.13 totalR=-1.44 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.17 totalR=-1.61 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.17 totalR=-1.78 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.81 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-1.84 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.17 totalR=-2.01 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-2.04 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.02 totalR=-2.06 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.17 totalR=-2.23 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.02 totalR=-2.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.17 totalR=-2.41 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.17 totalR=-2.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-2.61 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.17 totalR=-2.77 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-2.81 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.02 totalR=-2.82 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.02 totalR=-2.84 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.02 totalR=-2.86 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.17 totalR=-3.02 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.02 totalR=-3.04 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.02 totalR=-3.06 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.17 totalR=-3.22 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.02 totalR=-3.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.02 totalR=-3.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.17 totalR=-3.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.17 totalR=-3.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.17 totalR=-3.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.17 totalR=-3.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.17 totalR=-4.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.02 totalR=-4.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.02 totalR=-4.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.02 totalR=-4.14 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.05 totalR=-4.19 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   70  S --0-> A R=-0.05 totalR=-4.24 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   71  A --1-> B R=-0.02 totalR=-4.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   72  B --1-> A R=-0.02 totalR=-4.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   73  A --2-> E R=-0.02 totalR=-4.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   74  E --0-> A R=-0.02 totalR=-4.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   75  A --0-> S R=-0.05 totalR=-4.36 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   76  S --1-> B R=-0.02 totalR=-4.37 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   77  B --3-> K R= 0.13 totalR=-4.24 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   78  K --0-> B R=-0.03 totalR=-4.27 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   79  B --1-> A R=-0.02 totalR=-4.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   80  A --2-> E R=-0.02 totalR=-4.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   81  E --2-> H R=-0.02 totalR=-4.32 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   82  H --3-> H R=-0.17 totalR=-4.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   83  H --0-> E R=-0.02 totalR=-4.51 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   84  E --1-> F R=-0.02 totalR=-4.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   85  F --1-> E R=-0.02 totalR=-4.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   86  E --3-> E R=-0.17 totalR=-4.71 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   87  E --1-> F R=-0.02 totalR=-4.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   88  F --1-> E R=-0.02 totalR=-4.74 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   89  E --3-> E R=-0.17 totalR=-4.91 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   90  E --2-> H R=-0.02 totalR=-4.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   91  H --3-> H R=-0.17 totalR=-5.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   92  H --3-> H R=-0.17 totalR=-5.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   93  H --2-> H R=-0.17 totalR=-5.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   94  H --2-> H R=-0.17 totalR=-5.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   95  H --3-> H R=-0.17 totalR=-5.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   96  H --0-> E R=-0.02 totalR=-5.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   97  E --2-> H R=-0.02 totalR=-5.79 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   98  H --3-> H R=-0.17 totalR=-5.96 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   99  H --1-> K R=-0.05 totalR=-6.01 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  100  K --0-> B R=-0.03 totalR=-6.04 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  101  B --1-> A R=-0.02 totalR=-6.06 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  102  A --2-> E R=-0.02 totalR=-6.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  103  E --0-> A R=-0.02 totalR=-6.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  104  A --3-> D R=-0.02 totalR=-6.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  105  D --0-> A R=-0.02 totalR=-6.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  106  A --2-> E R=-0.02 totalR=-6.14 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  107  E --0-> A R=-0.02 totalR=-6.16 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  108  A --3-> D R=-0.02 totalR=-6.17 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  109  D --3-> D R=-0.17 totalR=-6.34 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  110  D --0-> A R=-0.02 totalR=-6.36 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  111  A --3-> D R=-0.02 totalR=-6.37 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  112  D --0-> A R=-0.02 totalR=-6.39 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  113  A --0-> S R=-0.05 totalR=-6.44 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  114  S --0-> A R=-0.05 totalR=-6.49 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  115  A --0-> S R=-0.05 totalR=-6.54 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  116  S --2-> C R=-0.03 totalR=-6.57 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  117  C --3-> L R=-0.03 totalR=-6.61 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  118  L --0-> C R=-0.03 totalR=-6.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  119  C --3-> L R=-0.03 totalR=-6.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  120  L --2-> L R=-0.17 totalR=-6.84 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  121  L --3-> L R=-0.17 totalR=-7.01 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  122  L --3-> L R=-0.17 totalR=-7.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  123  L --1-> M R=-0.01 totalR=-7.18 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  124  M --1-> L R=-0.01 totalR=-7.19 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  125  L --1-> M R=-0.01 totalR=-7.20 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  126  M --0-> C R=-0.02 totalR=-7.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  127  C --1-> B R=-0.01 totalR=-7.22 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  128  B --1-> A R=-0.02 totalR=-7.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  129  A --1-> B R=-0.02 totalR=-7.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  130  B --3-> K R=-0.03 totalR=-7.29 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  131  K --0-> B R=-0.03 totalR=-7.32 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  132  B --3-> K R=-0.03 totalR=-7.36 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  133  K --1-> H R=-0.05 totalR=-7.41 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  134  H --2-> H R=-0.17 totalR=-7.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  135  H --0-> E R=-0.02 totalR=-7.59 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  136  E --1-> F R=-0.02 totalR=-7.61 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  137  F --2-> G R=-0.03 totalR=-7.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  138  G --0-> F R=-0.03 totalR=-7.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  139  F --2-> G R=-0.03 totalR=-7.71 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  140  G --0-> F R=-0.03 totalR=-7.74 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  141  F --1-> E R=-0.02 totalR=-7.76 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  142  E --3-> E R=-0.17 totalR=-7.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  143  E --2-> H R=-0.02 totalR=-7.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  144  H --2-> H R=-0.17 totalR=-8.11 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  145  H --1-> K R=-0.05 totalR=-8.16 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  146  K --0-> B R=-0.03 totalR=-8.19 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  147  B --3-> K R=-0.03 totalR=-8.22 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  148  K --1-> H R=-0.05 totalR=-8.28 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  149  H --1-> K R=-0.05 totalR=-8.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  150  K --3-> K R=-0.17 totalR=-8.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  151  K --0-> B R=-0.03 totalR=-8.53 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  152  B --2-> C R=-0.01 totalR=-8.53 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  153  C --2-> M R=-0.02 totalR=-8.55 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  154  M --3-> M R=-0.17 totalR=-8.72 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  155  M --2-> N R=-0.02 totalR=-8.73 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  156  N --3-> N R=-0.17 totalR=-8.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  157  N --3-> N R=-0.17 totalR=-9.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  158  N --3-> N R=-0.17 totalR=-9.23 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  159  N --2-> N R=-0.17 totalR=-9.40 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  160  N --1-> O R= 0.15 totalR=-9.25 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:  161  O --2-> O R=-0.17 totalR=-9.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  162  O --2-> O R=-0.17 totalR=-9.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  163  O --3-> O R=-0.17 totalR=-9.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  164  O --2-> O R=-0.17 totalR=-9.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  165  O --3-> O R=-0.17 totalR=-10.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  166  O --3-> O R=-0.17 totalR=-10.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  167  O --2-> O R=-0.17 totalR=-10.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  168  O --2-> O R=-0.17 totalR=-10.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  169  O --3-> O R=-0.17 totalR=-10.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  170  O --0-> N R=-0.02 totalR=-10.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  171  N --1-> O R=-0.02 totalR=-10.78 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  172  O --2-> O R=-0.17 totalR=-10.95 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  173  O --3-> O R=-0.17 totalR=-11.12 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  174  O --2-> O R=-0.17 totalR=-11.28 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  175  O --1-> G R=-0.05 totalR=-11.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  176  G --2-> G R=-0.17 totalR=-11.50 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  177  G --1-> O R=-0.05 totalR=-11.55 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  178  O --0-> N R=-0.02 totalR=-11.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  179  N --2-> N R=-0.17 totalR=-11.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  180  N --2-> N R=-0.17 totalR=-11.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  181  N --3-> N R=-0.17 totalR=-12.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  182  N --0-> M R=-0.02 totalR=-12.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  183  M --3-> M R=-0.17 totalR=-12.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  184  M --2-> N R=-0.02 totalR=-12.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  185  N --3-> N R=-0.17 totalR=-12.43 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  186  N --0-> M R=-0.02 totalR=-12.45 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  187  M --0-> C R=-0.02 totalR=-12.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  188  C --2-> M R=-0.02 totalR=-12.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  189  M --0-> C R=-0.02 totalR=-12.50 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  190  C --2-> M R=-0.02 totalR=-12.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  191  M --3-> M R=-0.17 totalR=-12.68 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  192  M --2-> N R=-0.02 totalR=-12.70 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  193  N --2-> N R=-0.17 totalR=-12.87 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  194  N --3-> N R=-0.17 totalR=-13.03 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  195  N --0-> M R=-0.02 totalR=-13.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  196  M --0-> C R=-0.02 totalR=-13.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  197  C --0-> S R=-0.03 totalR=-13.10 cost= 200 customerR=   0 optimum=6000\n",
            "Done: episodes=     1  avgSteps=197.00  avgTotalReward=-13.10\n",
            "Episode finished after 197 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "* random has lower total reward than version with dense customers \n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* additional pernalty for liiegal moves 1000\n",
        "* all rewards: 6000\n",
        "* perfect score???\n",
        "* estimate: half the travel cost and no illegal moves: (6000 - 1250) / 6000 = .79\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n",
        "* additionally: the agent only sees very little of the whole scenario\n",
        "  * changes with every episode\n",
        "  * was ok when network can learn fixed scenario\n"
      ]
    },
    {
      "metadata": {
        "id": "Qvi-T-YuEO0A",
        "colab_type": "code",
        "outputId": "a2bb8553-4a83-4e1e-c7d6-8c2157293918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "b063bb8c-3895-4afa-e491-bf0352727d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6443
        }
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "%time model = ppo2.learn(\\\n",
        "    env=monitored_env,\\\n",
        "    network='mlp',\\\n",
        "    num_hidden=2000,\\\n",
        "    num_layers=3,\\\n",
        "    ent_coef=0.03,\\\n",
        "    total_timesteps=1000000)\n",
        "\n",
        "# %time model = ppo2.learn(\\\n",
        "#     env=monitored_env,\\\n",
        "#     network='mlp',\\\n",
        "#     num_hidden=2000,\\\n",
        "#     num_layers=3,\\\n",
        "#     ent_coef=0.1,\\\n",
        "#     total_timesteps=500000)\n",
        "\n",
        "# model = ppo2.learn(\n",
        "#     env=monitored_env,\\\n",
        "#     layer_norm=True,\\\n",
        "#     network='mlp',\\\n",
        "#     num_hidden=2000,\\\n",
        "#     activation=tf.nn.relu,\\\n",
        "#     num_layers=3,\\\n",
        "#     ent_coef=0.03,\\\n",
        "#     total_timesteps=1000000)\n",
        "\n",
        "# monitored_env = bench.Monitor(env, log_dir)\n",
        "# https://en.wikipedia.org/wiki/Q-learning#Influence_of_variables\n",
        "# %time model = deepq.learn(\\\n",
        "#         monitored_env,\\\n",
        "#         seed=42,\\\n",
        "#         network='mlp',\\\n",
        "#         lr=1e-3,\\\n",
        "#         gamma=0.99,\\\n",
        "#         total_timesteps=30000,\\\n",
        "#         buffer_size=50000,\\\n",
        "#         exploration_fraction=0.5,\\\n",
        "#         exploration_final_eps=0.02,\\\n",
        "#         print_freq=1000)\n",
        "\n",
        "model.save('berater-ppo-v7.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-01-03-18-48-01-372539\n",
            "-------------------------------------\n",
            "| approxkl           | 0.019593637  |\n",
            "| clipfrac           | 0.3166504    |\n",
            "| eplenmean          | 151          |\n",
            "| eprewmean          | -9.909617    |\n",
            "| explained_variance | -0.285       |\n",
            "| fps                | 385          |\n",
            "| nupdates           | 1            |\n",
            "| policy_entropy     | 1.3666965    |\n",
            "| policy_loss        | -0.024349716 |\n",
            "| serial_timesteps   | 2048         |\n",
            "| time_elapsed       | 5.31         |\n",
            "| total_timesteps    | 2048         |\n",
            "| value_loss         | 2.1245756    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.007577969   |\n",
            "| clipfrac           | 0.099121094   |\n",
            "| eplenmean          | 43            |\n",
            "| eprewmean          | -0.16400005   |\n",
            "| explained_variance | -0.0476       |\n",
            "| fps                | 442           |\n",
            "| nupdates           | 10            |\n",
            "| policy_entropy     | 1.0529546     |\n",
            "| policy_loss        | -0.0045482353 |\n",
            "| serial_timesteps   | 20480         |\n",
            "| time_elapsed       | 46.9          |\n",
            "| total_timesteps    | 20480         |\n",
            "| value_loss         | 0.1092316     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.014131604   |\n",
            "| clipfrac           | 0.1619873     |\n",
            "| eplenmean          | 37.7          |\n",
            "| eprewmean          | 0.17383336    |\n",
            "| explained_variance | 0.14          |\n",
            "| fps                | 437           |\n",
            "| nupdates           | 20            |\n",
            "| policy_entropy     | 0.8798149     |\n",
            "| policy_loss        | -0.0012780649 |\n",
            "| serial_timesteps   | 40960         |\n",
            "| time_elapsed       | 93.3          |\n",
            "| total_timesteps    | 40960         |\n",
            "| value_loss         | 0.025928076   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.01006335   |\n",
            "| clipfrac           | 0.14685059   |\n",
            "| eplenmean          | 40.9         |\n",
            "| eprewmean          | 0.1085       |\n",
            "| explained_variance | 0.17         |\n",
            "| fps                | 446          |\n",
            "| nupdates           | 30           |\n",
            "| policy_entropy     | 0.9289736    |\n",
            "| policy_loss        | 0.0007974657 |\n",
            "| serial_timesteps   | 61440        |\n",
            "| time_elapsed       | 140          |\n",
            "| total_timesteps    | 61440        |\n",
            "| value_loss         | 0.02261215   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010071272   |\n",
            "| clipfrac           | 0.11987305    |\n",
            "| eplenmean          | 30.2          |\n",
            "| eprewmean          | 0.29674998    |\n",
            "| explained_variance | 0.173         |\n",
            "| fps                | 446           |\n",
            "| nupdates           | 40            |\n",
            "| policy_entropy     | 0.74906313    |\n",
            "| policy_loss        | -0.0055703856 |\n",
            "| serial_timesteps   | 81920         |\n",
            "| time_elapsed       | 186           |\n",
            "| total_timesteps    | 81920         |\n",
            "| value_loss         | 0.020835266   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014220675  |\n",
            "| clipfrac           | 0.114868164  |\n",
            "| eplenmean          | 25.1         |\n",
            "| eprewmean          | 0.40708336   |\n",
            "| explained_variance | 0.302        |\n",
            "| fps                | 444          |\n",
            "| nupdates           | 50           |\n",
            "| policy_entropy     | 0.6445336    |\n",
            "| policy_loss        | -0.008773514 |\n",
            "| serial_timesteps   | 102400       |\n",
            "| time_elapsed       | 233          |\n",
            "| total_timesteps    | 102400       |\n",
            "| value_loss         | 0.0149234375 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009891702   |\n",
            "| clipfrac           | 0.09655762    |\n",
            "| eplenmean          | 21.2          |\n",
            "| eprewmean          | 0.48675       |\n",
            "| explained_variance | 0.342         |\n",
            "| fps                | 449           |\n",
            "| nupdates           | 60            |\n",
            "| policy_entropy     | 0.55703175    |\n",
            "| policy_loss        | -0.0037293616 |\n",
            "| serial_timesteps   | 122880        |\n",
            "| time_elapsed       | 278           |\n",
            "| total_timesteps    | 122880        |\n",
            "| value_loss         | 0.016623318   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.007388264   |\n",
            "| clipfrac           | 0.11425781    |\n",
            "| eplenmean          | 23.4          |\n",
            "| eprewmean          | 0.47516668    |\n",
            "| explained_variance | 0.362         |\n",
            "| fps                | 451           |\n",
            "| nupdates           | 70            |\n",
            "| policy_entropy     | 0.6015584     |\n",
            "| policy_loss        | -0.0039213863 |\n",
            "| serial_timesteps   | 143360        |\n",
            "| time_elapsed       | 325           |\n",
            "| total_timesteps    | 143360        |\n",
            "| value_loss         | 0.013776244   |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.021204086 |\n",
            "| clipfrac           | 0.14904785  |\n",
            "| eplenmean          | 20.4        |\n",
            "| eprewmean          | 0.5139166   |\n",
            "| explained_variance | 0.432       |\n",
            "| fps                | 442         |\n",
            "| nupdates           | 80          |\n",
            "| policy_entropy     | 0.5630118   |\n",
            "| policy_loss        | 0.007254677 |\n",
            "| serial_timesteps   | 163840      |\n",
            "| time_elapsed       | 371         |\n",
            "| total_timesteps    | 163840      |\n",
            "| value_loss         | 0.014949808 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.005994698   |\n",
            "| clipfrac           | 0.072631836   |\n",
            "| eplenmean          | 20.9          |\n",
            "| eprewmean          | 0.5075834     |\n",
            "| explained_variance | 0.371         |\n",
            "| fps                | 450           |\n",
            "| nupdates           | 90            |\n",
            "| policy_entropy     | 0.535086      |\n",
            "| policy_loss        | -0.0045562023 |\n",
            "| serial_timesteps   | 184320        |\n",
            "| time_elapsed       | 417           |\n",
            "| total_timesteps    | 184320        |\n",
            "| value_loss         | 0.0148131875  |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.017413573 |\n",
            "| clipfrac           | 0.16247559  |\n",
            "| eplenmean          | 23.9        |\n",
            "| eprewmean          | 0.4732501   |\n",
            "| explained_variance | 0.436       |\n",
            "| fps                | 457         |\n",
            "| nupdates           | 100         |\n",
            "| policy_entropy     | 0.57642573  |\n",
            "| policy_loss        | 0.010225539 |\n",
            "| serial_timesteps   | 204800      |\n",
            "| time_elapsed       | 463         |\n",
            "| total_timesteps    | 204800      |\n",
            "| value_loss         | 0.014204118 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.017630205   |\n",
            "| clipfrac           | 0.13671875    |\n",
            "| eplenmean          | 20.5          |\n",
            "| eprewmean          | 0.49975005    |\n",
            "| explained_variance | 0.402         |\n",
            "| fps                | 445           |\n",
            "| nupdates           | 110           |\n",
            "| policy_entropy     | 0.5470696     |\n",
            "| policy_loss        | -0.0019779103 |\n",
            "| serial_timesteps   | 225280        |\n",
            "| time_elapsed       | 509           |\n",
            "| total_timesteps    | 225280        |\n",
            "| value_loss         | 0.014785086   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.006835807  |\n",
            "| clipfrac           | 0.08239746   |\n",
            "| eplenmean          | 21.7         |\n",
            "| eprewmean          | 0.5004167    |\n",
            "| explained_variance | 0.437        |\n",
            "| fps                | 449          |\n",
            "| nupdates           | 120          |\n",
            "| policy_entropy     | 0.5435441    |\n",
            "| policy_loss        | -0.002747289 |\n",
            "| serial_timesteps   | 245760       |\n",
            "| time_elapsed       | 555          |\n",
            "| total_timesteps    | 245760       |\n",
            "| value_loss         | 0.0132071525 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.022876767  |\n",
            "| clipfrac           | 0.12609863   |\n",
            "| eplenmean          | 22.4         |\n",
            "| eprewmean          | 0.48058334   |\n",
            "| explained_variance | 0.427        |\n",
            "| fps                | 461          |\n",
            "| nupdates           | 130          |\n",
            "| policy_entropy     | 0.5264168    |\n",
            "| policy_loss        | -0.009492428 |\n",
            "| serial_timesteps   | 266240       |\n",
            "| time_elapsed       | 600          |\n",
            "| total_timesteps    | 266240       |\n",
            "| value_loss         | 0.012696637  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008718463   |\n",
            "| clipfrac           | 0.09326172    |\n",
            "| eplenmean          | 20.4          |\n",
            "| eprewmean          | 0.50858337    |\n",
            "| explained_variance | 0.406         |\n",
            "| fps                | 459           |\n",
            "| nupdates           | 140           |\n",
            "| policy_entropy     | 0.5484952     |\n",
            "| policy_loss        | -0.0065971324 |\n",
            "| serial_timesteps   | 286720        |\n",
            "| time_elapsed       | 647           |\n",
            "| total_timesteps    | 286720        |\n",
            "| value_loss         | 0.012461164   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0053289165  |\n",
            "| clipfrac           | 0.06237793    |\n",
            "| eplenmean          | 19.2          |\n",
            "| eprewmean          | 0.5545        |\n",
            "| explained_variance | 0.444         |\n",
            "| fps                | 446           |\n",
            "| nupdates           | 150           |\n",
            "| policy_entropy     | 0.47149378    |\n",
            "| policy_loss        | -0.0009572138 |\n",
            "| serial_timesteps   | 307200        |\n",
            "| time_elapsed       | 692           |\n",
            "| total_timesteps    | 307200        |\n",
            "| value_loss         | 0.013025255   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.008539572  |\n",
            "| clipfrac           | 0.083984375  |\n",
            "| eplenmean          | 20           |\n",
            "| eprewmean          | 0.5241667    |\n",
            "| explained_variance | 0.381        |\n",
            "| fps                | 461          |\n",
            "| nupdates           | 160          |\n",
            "| policy_entropy     | 0.5156527    |\n",
            "| policy_loss        | -0.006648442 |\n",
            "| serial_timesteps   | 327680       |\n",
            "| time_elapsed       | 737          |\n",
            "| total_timesteps    | 327680       |\n",
            "| value_loss         | 0.012629914  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0062726056 |\n",
            "| clipfrac           | 0.088134766  |\n",
            "| eplenmean          | 20.4         |\n",
            "| eprewmean          | 0.54025006   |\n",
            "| explained_variance | 0.449        |\n",
            "| fps                | 459          |\n",
            "| nupdates           | 170          |\n",
            "| policy_entropy     | 0.49528784   |\n",
            "| policy_loss        | 0.0007002303 |\n",
            "| serial_timesteps   | 348160       |\n",
            "| time_elapsed       | 782          |\n",
            "| total_timesteps    | 348160       |\n",
            "| value_loss         | 0.013654434  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009324665   |\n",
            "| clipfrac           | 0.095947266   |\n",
            "| eplenmean          | 22.4          |\n",
            "| eprewmean          | 0.488         |\n",
            "| explained_variance | 0.417         |\n",
            "| fps                | 452           |\n",
            "| nupdates           | 180           |\n",
            "| policy_entropy     | 0.56534773    |\n",
            "| policy_loss        | -0.0029521256 |\n",
            "| serial_timesteps   | 368640        |\n",
            "| time_elapsed       | 828           |\n",
            "| total_timesteps    | 368640        |\n",
            "| value_loss         | 0.012802036   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009771489   |\n",
            "| clipfrac           | 0.10656738    |\n",
            "| eplenmean          | 22.3          |\n",
            "| eprewmean          | 0.5189167     |\n",
            "| explained_variance | 0.375         |\n",
            "| fps                | 463           |\n",
            "| nupdates           | 190           |\n",
            "| policy_entropy     | 0.59984696    |\n",
            "| policy_loss        | -0.0051241177 |\n",
            "| serial_timesteps   | 389120        |\n",
            "| time_elapsed       | 873           |\n",
            "| total_timesteps    | 389120        |\n",
            "| value_loss         | 0.012006206   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.006131854  |\n",
            "| clipfrac           | 0.076416016  |\n",
            "| eplenmean          | 19.2         |\n",
            "| eprewmean          | 0.5595833    |\n",
            "| explained_variance | 0.415        |\n",
            "| fps                | 458          |\n",
            "| nupdates           | 200          |\n",
            "| policy_entropy     | 0.4860985    |\n",
            "| policy_loss        | -0.005064509 |\n",
            "| serial_timesteps   | 409600       |\n",
            "| time_elapsed       | 917          |\n",
            "| total_timesteps    | 409600       |\n",
            "| value_loss         | 0.013654921  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.007408309  |\n",
            "| clipfrac           | 0.08679199   |\n",
            "| eplenmean          | 22.8         |\n",
            "| eprewmean          | 0.49958336   |\n",
            "| explained_variance | 0.43         |\n",
            "| fps                | 467          |\n",
            "| nupdates           | 210          |\n",
            "| policy_entropy     | 0.56970495   |\n",
            "| policy_loss        | -0.002875534 |\n",
            "| serial_timesteps   | 430080       |\n",
            "| time_elapsed       | 963          |\n",
            "| total_timesteps    | 430080       |\n",
            "| value_loss         | 0.013359591  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008439079   |\n",
            "| clipfrac           | 0.0892334     |\n",
            "| eplenmean          | 22            |\n",
            "| eprewmean          | 0.48216668    |\n",
            "| explained_variance | 0.438         |\n",
            "| fps                | 458           |\n",
            "| nupdates           | 220           |\n",
            "| policy_entropy     | 0.54835963    |\n",
            "| policy_loss        | -0.0035187965 |\n",
            "| serial_timesteps   | 450560        |\n",
            "| time_elapsed       | 1.01e+03      |\n",
            "| total_timesteps    | 450560        |\n",
            "| value_loss         | 0.01059682    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01032425    |\n",
            "| clipfrac           | 0.10681152    |\n",
            "| eplenmean          | 20.3          |\n",
            "| eprewmean          | 0.527         |\n",
            "| explained_variance | 0.408         |\n",
            "| fps                | 460           |\n",
            "| nupdates           | 230           |\n",
            "| policy_entropy     | 0.5360224     |\n",
            "| policy_loss        | -0.0051227687 |\n",
            "| serial_timesteps   | 471040        |\n",
            "| time_elapsed       | 1.05e+03      |\n",
            "| total_timesteps    | 471040        |\n",
            "| value_loss         | 0.012118952   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.007683249   |\n",
            "| clipfrac           | 0.08557129    |\n",
            "| eplenmean          | 21.6          |\n",
            "| eprewmean          | 0.51          |\n",
            "| explained_variance | 0.438         |\n",
            "| fps                | 450           |\n",
            "| nupdates           | 240           |\n",
            "| policy_entropy     | 0.5593899     |\n",
            "| policy_loss        | -0.0035762433 |\n",
            "| serial_timesteps   | 491520        |\n",
            "| time_elapsed       | 1.1e+03       |\n",
            "| total_timesteps    | 491520        |\n",
            "| value_loss         | 0.011544634   |\n",
            "--------------------------------------\n",
            "CPU times: user 21min 46s, sys: 4min 14s, total: 26min\n",
            "Wall time: 18min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "4256605e-992d-4d98-e5c9-b7eaffa76b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4d35619d30>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4d3604db00>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "095749df-4b9f-47d9-efc9-d4bf61c9bcf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 1000, 'B': 1000, 'C': 0, 'D': 1000, 'E': 0, 'F': 1000, 'G': 0, 'H': 0, 'K': 0, 'L': 0, 'M': 1000, 'N': 0, 'O': 1000}\n",
            "Episode:    0   Step:    1  S --1-> B R= 0.15 totalR= 0.15 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    2  B --1-> A R= 0.15 totalR= 0.30 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    3  A --3-> D R= 0.15 totalR= 0.45 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    4  D --1-> F R= 0.16 totalR= 0.61 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    5  F --1-> E R=-0.02 totalR= 0.59 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  E --0-> A R=-0.02 totalR= 0.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  A --1-> B R=-0.02 totalR= 0.56 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  B --0-> S R=-0.02 totalR= 0.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  S --2-> C R=-0.03 totalR= 0.51 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  C --2-> M R= 0.15 totalR= 0.66 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   11  M --2-> N R=-0.02 totalR= 0.64 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   12  N --1-> O R= 0.15 totalR= 0.79 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   13  O --1-> G R=-0.05 totalR= 0.74 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  G --1-> O R=-0.05 totalR= 0.69 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  O --1-> G R=-0.05 totalR= 0.64 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  G --0-> F R=-0.03 totalR= 0.61 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  F --0-> D R=-0.01 totalR= 0.60 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  D --1-> F R=-0.01 totalR= 0.59 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  F --1-> E R=-0.02 totalR= 0.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   20  E --0-> A R=-0.02 totalR= 0.56 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   21  A --1-> B R=-0.02 totalR= 0.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  B --0-> S R=-0.02 totalR= 0.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode finished after 22 timesteps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5fY1da_0l15E",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}