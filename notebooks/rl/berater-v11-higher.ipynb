{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v11-higher.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v11-higher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v11 higher\n",
        "\n",
        "## more stops per consultant\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        max_paths = 4\n",
        "        self.action_space = spaces.Discrete(max_paths)\n",
        "      \n",
        "        positions = len(self.map)\n",
        "        # observations: position, reward of all 4 local paths, rest reward of all locations\n",
        "        # non existing path is -1000 and no position change\n",
        "        # look at what #getObservation returns if you are confused\n",
        "        low = np.append(np.append([0], np.full(max_paths, -1000)), np.full(positions, 0))\n",
        "        high = np.append(np.append([positions - 1], np.full(max_paths, 1000)), np.full(positions, 1000))\n",
        "        self.observation_space = spaces.Box(low=low,\n",
        "                                             high=high,\n",
        "                                             dtype=np.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = np.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=np.float32)\n",
        "        all_rest_rewards = list(self.customer_reward.values())\n",
        "        result = np.append(result, all_rest_rewards)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/2)\n",
        "      number_per_consultant = int(number_of_customers/1.5)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "outputId": "e5b265f7-acff-45c5-b3e1-37395e41f2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "  1000.  1000.  1000.  1000.  1000.     0.  1000.  1000.  1000.]\n",
            "{'S': 0, 'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 1000, 'F': 1000, 'G': 1000, 'H': 1000, 'K': 1000, 'L': 0, 'M': 1000, 'N': 1000, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "528a52ef-d5b9-463d-b34f-a0270d738a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3485
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.  -300.   900.   800. -1000.     0.     0.  1000.  1000.  1000.\n",
            "     0.  1000.     0.     0.  1000.  1000.     0.  1000.  1000.]\n",
            "Episode:    0   Step:    1  S --0-> A R=-0.04 totalR=-0.04 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:    2  A --3-> D R= 0.11 totalR= 0.08 cost= 100 customerR=1000 optimum=8000\n",
            "Episode:    0   Step:    3  D --1-> F R= 0.12 totalR= 0.19 cost=  50 customerR=1000 optimum=8000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.19 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.12 totalR= 0.06 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.12 totalR=-0.06 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.12 totalR=-0.19 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.12 totalR=-0.31 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.32 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.12 totalR=-0.44 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   11  F --1-> E R=-0.01 totalR=-0.46 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   12  E --2-> H R=-0.01 totalR=-0.47 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.01 totalR=-0.48 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.12 totalR=-0.61 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.01 totalR=-0.62 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.01 totalR=-0.63 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.01 totalR=-0.64 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.04 totalR=-0.68 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   19  S --2-> C R= 0.10 totalR=-0.58 cost= 200 customerR=1000 optimum=8000\n",
            "Episode:    0   Step:   20  C --1-> B R= 0.12 totalR=-0.46 cost=  50 customerR=1000 optimum=8000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.47 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   22  C --3-> L R= 0.10 totalR=-0.37 cost= 200 customerR=1000 optimum=8000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.12 totalR=-0.49 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.12 totalR=-0.62 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-0.64 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-0.65 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.01 totalR=-0.66 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.01 totalR=-0.67 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.01 totalR=-0.69 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.04 totalR=-0.72 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.01 totalR=-0.74 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.01 totalR=-0.75 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.12 totalR=-0.87 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.04 totalR=-0.91 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.01 totalR=-0.92 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-0.93 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   37  F --2-> G R=-0.03 totalR=-0.96 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.12 totalR=-1.08 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.12 totalR=-1.21 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.23 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-1.26 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.12 totalR=-1.38 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-1.41 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.01 totalR=-1.42 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.12 totalR=-1.54 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.01 totalR=-1.56 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.12 totalR=-1.68 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.12 totalR=-1.81 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-1.83 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.12 totalR=-1.96 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-1.98 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.01 totalR=-1.99 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.01 totalR=-2.01 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.01 totalR=-2.02 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.12 totalR=-2.14 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.01 totalR=-2.16 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.01 totalR=-2.17 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.12 totalR=-2.29 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.01 totalR=-2.31 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.01 totalR=-2.32 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.12 totalR=-2.44 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.12 totalR=-2.57 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.12 totalR=-2.69 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.12 totalR=-2.82 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.12 totalR=-2.94 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.01 totalR=-2.96 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.01 totalR=-2.97 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.01 totalR=-2.98 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.04 totalR=-3.02 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   70  S --0-> A R=-0.04 totalR=-3.06 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   71  A --1-> B R=-0.01 totalR=-3.07 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   72  B --1-> A R=-0.01 totalR=-3.08 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   73  A --2-> E R=-0.01 totalR=-3.09 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   74  E --0-> A R=-0.01 totalR=-3.11 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   75  A --0-> S R=-0.04 totalR=-3.14 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   76  S --1-> B R=-0.01 totalR=-3.16 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   77  B --3-> K R= 0.10 totalR=-3.06 cost= 200 customerR=1000 optimum=8000\n",
            "Episode:    0   Step:   78  K --0-> B R=-0.03 totalR=-3.08 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   79  B --1-> A R=-0.01 totalR=-3.09 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   80  A --2-> E R=-0.01 totalR=-3.11 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   81  E --2-> H R=-0.01 totalR=-3.12 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   82  H --3-> H R=-0.12 totalR=-3.24 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   83  H --0-> E R=-0.01 totalR=-3.26 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   84  E --1-> F R=-0.01 totalR=-3.27 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   85  F --1-> E R=-0.01 totalR=-3.28 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   86  E --3-> E R=-0.12 totalR=-3.41 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   87  E --1-> F R=-0.01 totalR=-3.42 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   88  F --1-> E R=-0.01 totalR=-3.43 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   89  E --3-> E R=-0.12 totalR=-3.56 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   90  E --2-> H R=-0.01 totalR=-3.57 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   91  H --3-> H R=-0.12 totalR=-3.69 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   92  H --3-> H R=-0.12 totalR=-3.82 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   93  H --2-> H R=-0.12 totalR=-3.94 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   94  H --2-> H R=-0.12 totalR=-4.07 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   95  H --3-> H R=-0.12 totalR=-4.19 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   96  H --0-> E R=-0.01 totalR=-4.21 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   97  E --2-> H R=-0.01 totalR=-4.22 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   98  H --3-> H R=-0.12 totalR=-4.34 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:   99  H --1-> K R=-0.04 totalR=-4.38 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  100  K --0-> B R=-0.03 totalR=-4.41 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  101  B --1-> A R=-0.01 totalR=-4.42 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  102  A --2-> E R=-0.01 totalR=-4.43 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  103  E --0-> A R=-0.01 totalR=-4.44 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  104  A --3-> D R=-0.01 totalR=-4.46 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  105  D --0-> A R=-0.01 totalR=-4.47 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  106  A --2-> E R=-0.01 totalR=-4.48 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  107  E --0-> A R=-0.01 totalR=-4.49 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  108  A --3-> D R=-0.01 totalR=-4.51 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  109  D --3-> D R=-0.12 totalR=-4.63 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  110  D --0-> A R=-0.01 totalR=-4.64 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  111  A --3-> D R=-0.01 totalR=-4.66 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  112  D --0-> A R=-0.01 totalR=-4.67 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  113  A --0-> S R=-0.04 totalR=-4.71 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  114  S --0-> A R=-0.04 totalR=-4.74 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  115  A --0-> S R=-0.04 totalR=-4.78 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  116  S --2-> C R=-0.03 totalR=-4.81 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  117  C --3-> L R=-0.03 totalR=-4.83 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  118  L --0-> C R=-0.03 totalR=-4.86 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  119  C --3-> L R=-0.03 totalR=-4.88 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  120  L --2-> L R=-0.12 totalR=-5.01 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  121  L --3-> L R=-0.12 totalR=-5.13 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  122  L --3-> L R=-0.12 totalR=-5.26 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  123  L --1-> M R=-0.01 totalR=-5.26 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  124  M --1-> L R=-0.01 totalR=-5.27 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  125  L --1-> M R=-0.01 totalR=-5.28 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  126  M --0-> C R=-0.01 totalR=-5.29 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  127  C --1-> B R=-0.01 totalR=-5.29 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  128  B --1-> A R=-0.01 totalR=-5.31 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  129  A --1-> B R=-0.01 totalR=-5.32 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  130  B --3-> K R=-0.03 totalR=-5.34 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  131  K --0-> B R=-0.03 totalR=-5.37 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  132  B --3-> K R=-0.03 totalR=-5.39 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  133  K --1-> H R=-0.04 totalR=-5.43 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  134  H --2-> H R=-0.12 totalR=-5.56 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  135  H --0-> E R=-0.01 totalR=-5.57 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  136  E --1-> F R=-0.01 totalR=-5.58 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  137  F --2-> G R=-0.03 totalR=-5.61 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  138  G --0-> F R=-0.03 totalR=-5.63 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  139  F --2-> G R=-0.03 totalR=-5.66 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  140  G --0-> F R=-0.03 totalR=-5.68 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  141  F --1-> E R=-0.01 totalR=-5.69 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  142  E --3-> E R=-0.12 totalR=-5.82 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  143  E --2-> H R=-0.01 totalR=-5.83 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  144  H --2-> H R=-0.12 totalR=-5.96 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  145  H --1-> K R=-0.04 totalR=-5.99 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  146  K --0-> B R=-0.03 totalR=-6.02 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  147  B --3-> K R=-0.03 totalR=-6.04 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  148  K --1-> H R=-0.04 totalR=-6.08 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  149  H --1-> K R=-0.04 totalR=-6.12 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  150  K --3-> K R=-0.12 totalR=-6.24 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  151  K --0-> B R=-0.03 totalR=-6.27 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  152  B --2-> C R=-0.01 totalR=-6.28 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  153  C --2-> M R=-0.01 totalR=-6.29 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  154  M --3-> M R=-0.12 totalR=-6.41 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  155  M --2-> N R= 0.11 totalR=-6.30 cost= 100 customerR=1000 optimum=8000\n",
            "Episode:    0   Step:  156  N --3-> N R=-0.12 totalR=-6.43 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  157  N --3-> N R=-0.12 totalR=-6.55 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  158  N --3-> N R=-0.12 totalR=-6.68 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  159  N --2-> N R=-0.12 totalR=-6.80 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  160  N --1-> O R= 0.11 totalR=-6.69 cost= 100 customerR=1000 optimum=8000\n",
            "Episode:    0   Step:  161  O --2-> O R=-0.12 totalR=-6.81 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  162  O --2-> O R=-0.12 totalR=-6.94 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  163  O --3-> O R=-0.12 totalR=-7.06 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  164  O --2-> O R=-0.12 totalR=-7.19 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  165  O --3-> O R=-0.12 totalR=-7.31 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  166  O --3-> O R=-0.12 totalR=-7.44 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  167  O --2-> O R=-0.12 totalR=-7.56 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  168  O --2-> O R=-0.12 totalR=-7.69 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  169  O --3-> O R=-0.12 totalR=-7.81 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  170  O --0-> N R=-0.01 totalR=-7.83 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  171  N --1-> O R=-0.01 totalR=-7.84 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  172  O --2-> O R=-0.12 totalR=-7.96 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  173  O --3-> O R=-0.12 totalR=-8.09 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  174  O --2-> O R=-0.12 totalR=-8.21 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  175  O --1-> G R=-0.04 totalR=-8.25 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  176  G --2-> G R=-0.12 totalR=-8.38 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  177  G --1-> O R=-0.04 totalR=-8.41 cost= 300 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  178  O --0-> N R=-0.01 totalR=-8.43 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  179  N --2-> N R=-0.12 totalR=-8.55 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  180  N --2-> N R=-0.12 totalR=-8.68 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  181  N --3-> N R=-0.12 totalR=-8.80 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  182  N --0-> M R=-0.01 totalR=-8.81 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  183  M --3-> M R=-0.12 totalR=-8.94 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  184  M --2-> N R=-0.01 totalR=-8.95 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  185  N --3-> N R=-0.12 totalR=-9.08 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  186  N --0-> M R=-0.01 totalR=-9.09 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  187  M --0-> C R=-0.01 totalR=-9.10 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  188  C --2-> M R=-0.01 totalR=-9.11 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  189  M --0-> C R=-0.01 totalR=-9.13 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  190  C --2-> M R=-0.01 totalR=-9.14 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  191  M --3-> M R=-0.12 totalR=-9.26 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  192  M --2-> N R=-0.01 totalR=-9.28 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  193  N --2-> N R=-0.12 totalR=-9.40 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  194  N --3-> N R=-0.12 totalR=-9.53 cost=1000 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  195  N --0-> M R=-0.01 totalR=-9.54 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  196  M --0-> C R=-0.01 totalR=-9.55 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:    0   Step:  197  C --0-> S R=-0.03 totalR=-9.58 cost= 200 customerR=   0 optimum=8000\n",
            "Done: episodes=     1  avgSteps=197.00  avgTotalReward=-9.58\n",
            "Episode finished after 197 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWpCU8xH0ZKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ]
    },
    {
      "metadata": {
        "id": "7NxTojLi0N0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import json\n",
        "\n",
        "class Baseline():\n",
        "\n",
        "  def __init__(self, env, max_reward, verbose=1):\n",
        "    self.env = env\n",
        "    self.max_reward = max_reward\n",
        "    self.verbose = verbose\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.map = self.env.map\n",
        "    self.rewards = self.env.customer_reward.copy()\n",
        "    \n",
        "  def as_string(self, state):\n",
        "    # reward/cost does not hurt, but is useless, path obsucres same state\n",
        "    new_state = {\n",
        "        'rewards': state['rewards'],\n",
        "        'position': state['position']\n",
        "    }\n",
        "    return json.dumps(new_state, sort_keys=True)\n",
        "  \n",
        "  def is_goal(self, state):\n",
        "    if state['position'] != 'S': return False\n",
        "    for reward in state['rewards'].values():\n",
        "      if reward != 0: return False\n",
        "    return True\n",
        "    \n",
        "\n",
        "  def expand(self, state):\n",
        "    states = []\n",
        "    for position, cost in self.map[state['position']]:\n",
        "      new_state = deepcopy(state)\n",
        "      new_state['position'] = position\n",
        "      new_state['rewards'][position] = 0\n",
        "      reward = state['rewards'][position]\n",
        "      new_state['reward'] += reward\n",
        "      new_state['cost'] += cost\n",
        "      new_state['path'].append(position)\n",
        "      states.append(new_state)\n",
        "    return states\n",
        "\n",
        "  def search(self, root, max_depth = 25):\n",
        "      closed = set()\n",
        "      open = [root]\n",
        "\n",
        "      while open:\n",
        "          state = open.pop(0)\n",
        "          if self.as_string(state) in closed: continue  \n",
        "\n",
        "          closed.add(self.as_string(state))\n",
        "\n",
        "          depth = len(state['path'])\n",
        "          if depth > max_depth:\n",
        "            if self.verbose > 0:\n",
        "              print(\"Visited:\", len(closed))\n",
        "              print(\"Reached max depth, without reaching goal\")\n",
        "            return None\n",
        "\n",
        "          if self.is_goal(state):\n",
        "            scaled_reward = (state['reward'] - state['cost']) / self.max_reward\n",
        "            state['scaled_reward'] = scaled_reward\n",
        "            if self.verbose > 0:\n",
        "              print(\"Scaled reward:\", scaled_reward)            \n",
        "              print(\"Perfect path\", state['path'])\n",
        "            return state\n",
        "\n",
        "          expanded = self.expand(state)\n",
        "          open += expanded\n",
        "          # make this best first\n",
        "          open.sort(key=lambda state: state['cost'])\n",
        "        \n",
        "  def find_optimum(self):\n",
        "    initial_state = {\n",
        "        'rewards': self.rewards.copy(),\n",
        "        'position': 'S',\n",
        "        'reward': 0,\n",
        "        'cost': 0,\n",
        "        'path': ['S']\n",
        "    }\n",
        "    return self.search(initial_state)\n",
        "  \n",
        "  def benchmark(self, model, sample_runs=100):\n",
        "    self.verbose = 0\n",
        "    BeraterEnv.showStep = False\n",
        "    BeraterEnv.showDone = False\n",
        "\n",
        "    perfect_rewards = []\n",
        "    model_rewards = []\n",
        "    for run in range(sample_runs):\n",
        "      observation = self.env.reset()\n",
        "      self.reset()\n",
        "      \n",
        "      optimum_state = self.find_optimum()\n",
        "      perfect_rewards.append(optimum_state['scaled_reward'])\n",
        "      \n",
        "      state = np.zeros((1, 2*128))\n",
        "      dones = np.zeros((1))\n",
        "\n",
        "      for t in range(1000):\n",
        "        actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "        observation, reward, done, info = self.env.step(actions[0])\n",
        "        if done:\n",
        "          break\n",
        "      model_rewards.append(env.totalReward)\n",
        "    return perfect_rewards, model_rewards\n",
        "  \n",
        "  def score(self, model, sample_runs=100):\n",
        "    perfect_rewards, model_rewards = self.benchmark(model, sample_runs=100)\n",
        "    \n",
        "    perfect_score_mean, perfect_score_std = np.array(perfect_rewards).mean(), np.array(perfect_rewards).std()\n",
        "    test_score_mean, test_score_std = np.array(model_rewards).mean(), np.array(model_rewards).std()\n",
        "    \n",
        "    return perfect_score_mean, perfect_score_std, test_score_mean, test_score_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "Estimation\n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* all rewards: 6000\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n",
        "* estimate: no illegal moves and between\n",
        "  * half the travel cost: (6000 - 1250) / 6000 = .79\n",
        "  * and full traval cost (6000 - 2500) / 6000 = 0.58\n",
        "* additionally: the agent only sees very little of the whole scenario\n",
        "  * changes with every episode\n",
        "  * was ok when network can learn fixed scenario\n"
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acd4a3b4-18b2-474f-bd34-71456bd1844e"
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'logs': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LArM6BsJgUvL",
        "colab_type": "code",
        "outputId": "ac3e13dc-e883-4872-d1d7-55e6c1a07d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GCufDIpnjNms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1: Extract MLP builder from openai sources"
      ]
    },
    {
      "metadata": {
        "id": "WMylk8s_amq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# copied from https://github.com/openai/baselines/blob/master/baselines/a2c/utils.py\n",
        "\n",
        "def ortho_init(scale=1.0):\n",
        "    def _ortho_init(shape, dtype, partition_info=None):\n",
        "        #lasagne ortho init for tf\n",
        "        shape = tuple(shape)\n",
        "        if len(shape) == 2:\n",
        "            flat_shape = shape\n",
        "        elif len(shape) == 4: # assumes NHWC\n",
        "            flat_shape = (np.prod(shape[:-1]), shape[-1])\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        a = np.random.normal(0.0, 1.0, flat_shape)\n",
        "        u, _, v = np.linalg.svd(a, full_matrices=False)\n",
        "        q = u if u.shape == flat_shape else v # pick the one with the correct shape\n",
        "        q = q.reshape(shape)\n",
        "        return (scale * q[:shape[0], :shape[1]]).astype(np.float32)\n",
        "    return _ortho_init      \n",
        "\n",
        "def fc(x, scope, nh, *, init_scale=1.0, init_bias=0.0):\n",
        "    with tf.variable_scope(scope):\n",
        "        nin = x.get_shape()[1].value\n",
        "        w = tf.get_variable(\"w\", [nin, nh], initializer=ortho_init(init_scale))\n",
        "        b = tf.get_variable(\"b\", [nh], initializer=tf.constant_initializer(init_bias))\n",
        "        return tf.matmul(x, w)+b\n",
        "      \n",
        "\n",
        "# copied from https://github.com/openai/baselines/blob/master/baselines/common/models.py#L31\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.tanh, layer_norm=False):\n",
        "    \"\"\"\n",
        "    Stack of fully-connected layers to be used in a policy / q-function approximator\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "\n",
        "    num_layers: int                 number of fully-connected layers (default: 2)\n",
        "\n",
        "    num_hidden: int                 size of fully-connected layers (default: 64)\n",
        "\n",
        "    activation:                     activation function (default: tf.tanh)\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "\n",
        "    function that builds fully connected network with a given input tensor / placeholder\n",
        "    \"\"\"\n",
        "    def network_fn(X):\n",
        "#         print('network_fn called')\n",
        "#         Tensor(\"ppo2_model_4/Ob:0\", shape=(1, 19), dtype=float32)\n",
        "#         Tensor(\"ppo2_model_4/Ob_1:0\", shape=(512, 19), dtype=float32)\n",
        "#         print (X)\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = fc(h, 'mlp_fc{}'.format(i), nh=num_hidden, init_scale=np.sqrt(2))\n",
        "            if layer_norm:\n",
        "                h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "          \n",
        "#         Tensor(\"ppo2_model_4/pi/Tanh_2:0\", shape=(1, 500), dtype=float32)\n",
        "#         Tensor(\"ppo2_model_4/pi_2/Tanh_2:0\", shape=(512, 500), dtype=float32)\n",
        "#         print(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUvTLKKK8L8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2: Replace exotic parts\n",
        "\n",
        "Steps:\n",
        "1. Low level matmul replaced with dense layer (no need for custom code here)\n",
        "    * https://www.tensorflow.org/api_docs/python/tf/layers\n",
        "    * https://www.tensorflow.org/api_docs/python/tf/layers/Dense\n",
        "\n",
        "1. initializer changed to best practice glorot uniform, but does not give reliable results, so use seed\n",
        "1. use relu activations (should train faster)\n",
        "1. standard batch normalization does not train with any configuration (no idea why), so we need to keep layer normalization\n",
        "1.Dropout and L2 would be nice as well, but easy to do within the boundaries of the OpenAI framework:  https://stackoverflow.com/questions/38292760/tensorflow-introducing-both-l2-regularization-and-dropout-into-the-network-do\n",
        "\n",
        "#### Alternative: Using Keras API\n",
        "\n",
        "Not done here, as no big benefit expected and would need to be integrated into surrounding low level tensorflow model. Need to reuse session. If you want to do this, be sure to check at least the first link\n",
        "\n",
        "* using Keras within TensorFlow model: https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html\n",
        "* https://stackoverflow.com/questions/46790506/calling-a-keras-model-on-a-tensorflow-tensor-but-keep-weights\n",
        "* https://www.tensorflow.org/api_docs/python/tf/get_default_session\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_session"
      ]
    },
    {
      "metadata": {
        "id": "9X4G6Y4O8Khh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# first the dense layer\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.tanh, layer_norm=False):\n",
        "    def network_fn(X):\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = tf.layers.dense(h, units=num_hidden, kernel_initializer=ortho_init(np.sqrt(2)))\n",
        "#             h = fc(h, 'mlp_fc{}'.format(i), nh=num_hidden, init_scale=np.sqrt(2))\n",
        "            if layer_norm:\n",
        "                h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIbexm3U_341",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# then initializer, relu activations\n",
        "def mlp(num_layers=2, num_hidden=64, activation=tf.nn.relu, layer_norm=False):\n",
        "    def network_fn(X):\n",
        "        h = tf.layers.flatten(X)\n",
        "        for i in range(num_layers):\n",
        "            h = tf.layers.dense(h, units=num_hidden, kernel_initializer=tf.initializers.glorot_uniform(seed=17))\n",
        "            if layer_norm:\n",
        "#               h = tf.layers.batch_normalization(h, center=True, scale=True)\n",
        "              h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\n",
        "            h = activation(h)\n",
        "        return h\n",
        "\n",
        "    return network_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "b6e8e158-1d81-4b28-8f0a-afc67c34a881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12563
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "# https://arxiv.org/abs/1607.06450 for layer_norm\n",
        "\n",
        "# lr linear from lr=1e-2 to lr=1e-4 (default lr=3e-4)\n",
        "def lr_range(frac):\n",
        "  # we get the remaining updates between 1 and 0\n",
        "  start_lr = 1e-2\n",
        "  end_lr = 1e-4\n",
        "  diff_lr = start_lr - end_lr\n",
        "  lr = end_lr + diff_lr * frac\n",
        "  return lr\n",
        "  \n",
        "network = mlp(num_hidden=500, num_layers=3, layer_norm=True)\n",
        "  \n",
        "model = ppo2.learn(\n",
        "    env=monitored_env,\n",
        "    network=network,\n",
        "    lr=lr_range,\n",
        "    gamma=1.0,\n",
        "    ent_coef=0.05,\n",
        "    total_timesteps=1000000)\n",
        "\n",
        "# model = ppo2.learn(\n",
        "#     env=monitored_env,\n",
        "#     network='mlp',\n",
        "#     num_hidden=500,\n",
        "#     num_layers=3,\n",
        "#     layer_norm=True,\n",
        "#     lr=lr_range,\n",
        "#     gamma=1.0,\n",
        "#     ent_coef=0.05,\n",
        "#     total_timesteps=500000)\n",
        "\n",
        "\n",
        "# model.save('berater-ppo-v11.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-02-02-11-20-50-062882\n",
            "-----------------------------------\n",
            "| approxkl           | 2.7361171  |\n",
            "| clipfrac           | 0.82702637 |\n",
            "| eplenmean          | 179        |\n",
            "| eprewmean          | -8.704996  |\n",
            "| explained_variance | -0.134     |\n",
            "| fps                | 392        |\n",
            "| nupdates           | 1          |\n",
            "| policy_entropy     | 0.8260351  |\n",
            "| policy_loss        | 0.22023635 |\n",
            "| serial_timesteps   | 2048       |\n",
            "| time_elapsed       | 5.22       |\n",
            "| total_timesteps    | 2048       |\n",
            "| value_loss         | 4.789582   |\n",
            "-----------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.017313965  |\n",
            "| clipfrac           | 0.10949707   |\n",
            "| eplenmean          | 613          |\n",
            "| eprewmean          | -20.459549   |\n",
            "| explained_variance | -0.00828     |\n",
            "| fps                | 459          |\n",
            "| nupdates           | 10           |\n",
            "| policy_entropy     | 0.51270914   |\n",
            "| policy_loss        | -0.005671847 |\n",
            "| serial_timesteps   | 20480        |\n",
            "| time_elapsed       | 45.1         |\n",
            "| total_timesteps    | 20480        |\n",
            "| value_loss         | 0.0130367    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013541337   |\n",
            "| clipfrac           | 0.20336914    |\n",
            "| eplenmean          | 422           |\n",
            "| eprewmean          | -8.644655     |\n",
            "| explained_variance | 0.423         |\n",
            "| fps                | 462           |\n",
            "| nupdates           | 20            |\n",
            "| policy_entropy     | 0.99957204    |\n",
            "| policy_loss        | -0.0057684667 |\n",
            "| serial_timesteps   | 40960         |\n",
            "| time_elapsed       | 89.7          |\n",
            "| total_timesteps    | 40960         |\n",
            "| value_loss         | 0.59593487    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014980243  |\n",
            "| clipfrac           | 0.17749023   |\n",
            "| eplenmean          | 42.2         |\n",
            "| eprewmean          | 0.0144375125 |\n",
            "| explained_variance | -0.252       |\n",
            "| fps                | 461          |\n",
            "| nupdates           | 30           |\n",
            "| policy_entropy     | 0.817166     |\n",
            "| policy_loss        | -0.009299457 |\n",
            "| serial_timesteps   | 61440        |\n",
            "| time_elapsed       | 134          |\n",
            "| total_timesteps    | 61440        |\n",
            "| value_loss         | 0.24379903   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.018185178   |\n",
            "| clipfrac           | 0.14367676    |\n",
            "| eplenmean          | 27.4          |\n",
            "| eprewmean          | 0.56881255    |\n",
            "| explained_variance | 0.69          |\n",
            "| fps                | 462           |\n",
            "| nupdates           | 40            |\n",
            "| policy_entropy     | 0.5709661     |\n",
            "| policy_loss        | -0.0071893325 |\n",
            "| serial_timesteps   | 81920         |\n",
            "| time_elapsed       | 179           |\n",
            "| total_timesteps    | 81920         |\n",
            "| value_loss         | 0.008446399   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.018044101  |\n",
            "| clipfrac           | 0.12731934   |\n",
            "| eplenmean          | 20.5         |\n",
            "| eprewmean          | 0.67225003   |\n",
            "| explained_variance | 0.822        |\n",
            "| fps                | 459          |\n",
            "| nupdates           | 50           |\n",
            "| policy_entropy     | 0.40748847   |\n",
            "| policy_loss        | -0.010642301 |\n",
            "| serial_timesteps   | 102400       |\n",
            "| time_elapsed       | 224          |\n",
            "| total_timesteps    | 102400       |\n",
            "| value_loss         | 0.005316984  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.016766712  |\n",
            "| clipfrac           | 0.13342285   |\n",
            "| eplenmean          | 18.5         |\n",
            "| eprewmean          | 0.71356255   |\n",
            "| explained_variance | 0.874        |\n",
            "| fps                | 458          |\n",
            "| nupdates           | 60           |\n",
            "| policy_entropy     | 0.3949888    |\n",
            "| policy_loss        | -0.01023488  |\n",
            "| serial_timesteps   | 122880       |\n",
            "| time_elapsed       | 269          |\n",
            "| total_timesteps    | 122880       |\n",
            "| value_loss         | 0.0033444313 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.035753325  |\n",
            "| clipfrac           | 0.1673584    |\n",
            "| eplenmean          | 20.2         |\n",
            "| eprewmean          | 0.6880001    |\n",
            "| explained_variance | 0.899        |\n",
            "| fps                | 465          |\n",
            "| nupdates           | 70           |\n",
            "| policy_entropy     | 0.46918318   |\n",
            "| policy_loss        | -0.015646527 |\n",
            "| serial_timesteps   | 143360       |\n",
            "| time_elapsed       | 313          |\n",
            "| total_timesteps    | 143360       |\n",
            "| value_loss         | 0.002632971  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.021913994  |\n",
            "| clipfrac           | 0.140625     |\n",
            "| eplenmean          | 19.1         |\n",
            "| eprewmean          | 0.70425004   |\n",
            "| explained_variance | 0.885        |\n",
            "| fps                | 461          |\n",
            "| nupdates           | 80           |\n",
            "| policy_entropy     | 0.36162165   |\n",
            "| policy_loss        | -0.014739201 |\n",
            "| serial_timesteps   | 163840       |\n",
            "| time_elapsed       | 358          |\n",
            "| total_timesteps    | 163840       |\n",
            "| value_loss         | 0.0027498538 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0127968835 |\n",
            "| clipfrac           | 0.10266113   |\n",
            "| eplenmean          | 17.1         |\n",
            "| eprewmean          | 0.7380001    |\n",
            "| explained_variance | 0.947        |\n",
            "| fps                | 457          |\n",
            "| nupdates           | 90           |\n",
            "| policy_entropy     | 0.27007896   |\n",
            "| policy_loss        | -0.013740809 |\n",
            "| serial_timesteps   | 184320       |\n",
            "| time_elapsed       | 402          |\n",
            "| total_timesteps    | 184320       |\n",
            "| value_loss         | 0.0014851949 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.48239207   |\n",
            "| clipfrac           | 0.17578125   |\n",
            "| eplenmean          | 20.2         |\n",
            "| eprewmean          | 0.70500016   |\n",
            "| explained_variance | 0.812        |\n",
            "| fps                | 461          |\n",
            "| nupdates           | 100          |\n",
            "| policy_entropy     | 0.22976401   |\n",
            "| policy_loss        | -0.048143074 |\n",
            "| serial_timesteps   | 204800       |\n",
            "| time_elapsed       | 447          |\n",
            "| total_timesteps    | 204800       |\n",
            "| value_loss         | 0.0034509196 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.03258504   |\n",
            "| clipfrac           | 0.20776367   |\n",
            "| eplenmean          | 19           |\n",
            "| eprewmean          | 0.6890626    |\n",
            "| explained_variance | 0.903        |\n",
            "| fps                | 460          |\n",
            "| nupdates           | 110          |\n",
            "| policy_entropy     | 0.41582274   |\n",
            "| policy_loss        | -0.013586381 |\n",
            "| serial_timesteps   | 225280       |\n",
            "| time_elapsed       | 492          |\n",
            "| total_timesteps    | 225280       |\n",
            "| value_loss         | 0.0036422417 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0147229    |\n",
            "| clipfrac           | 0.05102539   |\n",
            "| eplenmean          | 15.6         |\n",
            "| eprewmean          | 0.75793755   |\n",
            "| explained_variance | 0.967        |\n",
            "| fps                | 458          |\n",
            "| nupdates           | 120          |\n",
            "| policy_entropy     | 0.1373909    |\n",
            "| policy_loss        | -0.008769412 |\n",
            "| serial_timesteps   | 245760       |\n",
            "| time_elapsed       | 537          |\n",
            "| total_timesteps    | 245760       |\n",
            "| value_loss         | 0.0010770226 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013273776   |\n",
            "| clipfrac           | 0.05114746    |\n",
            "| eplenmean          | 16            |\n",
            "| eprewmean          | 0.75568765    |\n",
            "| explained_variance | 0.973         |\n",
            "| fps                | 460           |\n",
            "| nupdates           | 130           |\n",
            "| policy_entropy     | 0.14792468    |\n",
            "| policy_loss        | -0.0029979227 |\n",
            "| serial_timesteps   | 266240        |\n",
            "| time_elapsed       | 581           |\n",
            "| total_timesteps    | 266240        |\n",
            "| value_loss         | 0.0011254636  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010896272   |\n",
            "| clipfrac           | 0.044555664   |\n",
            "| eplenmean          | 15.8          |\n",
            "| eprewmean          | 0.75725013    |\n",
            "| explained_variance | 0.968         |\n",
            "| fps                | 459           |\n",
            "| nupdates           | 140           |\n",
            "| policy_entropy     | 0.1168851     |\n",
            "| policy_loss        | -0.0062902533 |\n",
            "| serial_timesteps   | 286720        |\n",
            "| time_elapsed       | 626           |\n",
            "| total_timesteps    | 286720        |\n",
            "| value_loss         | 0.0011135685  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01110676    |\n",
            "| clipfrac           | 0.044311523   |\n",
            "| eplenmean          | 15            |\n",
            "| eprewmean          | 0.77337515    |\n",
            "| explained_variance | 0.969         |\n",
            "| fps                | 457           |\n",
            "| nupdates           | 150           |\n",
            "| policy_entropy     | 0.13378513    |\n",
            "| policy_loss        | -0.0046934066 |\n",
            "| serial_timesteps   | 307200        |\n",
            "| time_elapsed       | 671           |\n",
            "| total_timesteps    | 307200        |\n",
            "| value_loss         | 0.0010066018  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013517318   |\n",
            "| clipfrac           | 0.03527832    |\n",
            "| eplenmean          | 15.6          |\n",
            "| eprewmean          | 0.76512504    |\n",
            "| explained_variance | 0.961         |\n",
            "| fps                | 461           |\n",
            "| nupdates           | 160           |\n",
            "| policy_entropy     | 0.09979431    |\n",
            "| policy_loss        | -0.0027038024 |\n",
            "| serial_timesteps   | 327680        |\n",
            "| time_elapsed       | 715           |\n",
            "| total_timesteps    | 327680        |\n",
            "| value_loss         | 0.0012069466  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011034441   |\n",
            "| clipfrac           | 0.044189453   |\n",
            "| eplenmean          | 15.6          |\n",
            "| eprewmean          | 0.7666876     |\n",
            "| explained_variance | 0.976         |\n",
            "| fps                | 457           |\n",
            "| nupdates           | 170           |\n",
            "| policy_entropy     | 0.11359048    |\n",
            "| policy_loss        | -0.0004797544 |\n",
            "| serial_timesteps   | 348160        |\n",
            "| time_elapsed       | 766           |\n",
            "| total_timesteps    | 348160        |\n",
            "| value_loss         | 0.0007918157  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0139339045  |\n",
            "| clipfrac           | 0.052124023   |\n",
            "| eplenmean          | 16.3          |\n",
            "| eprewmean          | 0.7612501     |\n",
            "| explained_variance | 0.98          |\n",
            "| fps                | 447           |\n",
            "| nupdates           | 180           |\n",
            "| policy_entropy     | 0.12656498    |\n",
            "| policy_loss        | -0.00290019   |\n",
            "| serial_timesteps   | 368640        |\n",
            "| time_elapsed       | 811           |\n",
            "| total_timesteps    | 368640        |\n",
            "| value_loss         | 0.00072889647 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.007519936  |\n",
            "| clipfrac           | 0.037719727  |\n",
            "| eplenmean          | 15.8         |\n",
            "| eprewmean          | 0.77250016   |\n",
            "| explained_variance | 0.968        |\n",
            "| fps                | 439          |\n",
            "| nupdates           | 190          |\n",
            "| policy_entropy     | 0.14990126   |\n",
            "| policy_loss        | 0.0009019253 |\n",
            "| serial_timesteps   | 389120       |\n",
            "| time_elapsed       | 857          |\n",
            "| total_timesteps    | 389120       |\n",
            "| value_loss         | 0.0010368212 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0240735     |\n",
            "| clipfrac           | 0.056640625   |\n",
            "| eplenmean          | 16.3          |\n",
            "| eprewmean          | 0.76193756    |\n",
            "| explained_variance | 0.968         |\n",
            "| fps                | 231           |\n",
            "| nupdates           | 200           |\n",
            "| policy_entropy     | 0.11018643    |\n",
            "| policy_loss        | -0.0011273483 |\n",
            "| serial_timesteps   | 409600        |\n",
            "| time_elapsed       | 928           |\n",
            "| total_timesteps    | 409600        |\n",
            "| value_loss         | 0.0011891121  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0070591792  |\n",
            "| clipfrac           | 0.037353516   |\n",
            "| eplenmean          | 16.3          |\n",
            "| eprewmean          | 0.76531255    |\n",
            "| explained_variance | 0.965         |\n",
            "| fps                | 234           |\n",
            "| nupdates           | 210           |\n",
            "| policy_entropy     | 0.17168991    |\n",
            "| policy_loss        | -0.0074015604 |\n",
            "| serial_timesteps   | 430080        |\n",
            "| time_elapsed       | 1.02e+03      |\n",
            "| total_timesteps    | 430080        |\n",
            "| value_loss         | 0.0012474902  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008749406   |\n",
            "| clipfrac           | 0.049682617   |\n",
            "| eplenmean          | 15.9          |\n",
            "| eprewmean          | 0.76675004    |\n",
            "| explained_variance | 0.972         |\n",
            "| fps                | 236           |\n",
            "| nupdates           | 220           |\n",
            "| policy_entropy     | 0.15160541    |\n",
            "| policy_loss        | -0.0063113347 |\n",
            "| serial_timesteps   | 450560        |\n",
            "| time_elapsed       | 1.1e+03       |\n",
            "| total_timesteps    | 450560        |\n",
            "| value_loss         | 0.0009522619  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010248611  |\n",
            "| clipfrac           | 0.043945312  |\n",
            "| eplenmean          | 16.4         |\n",
            "| eprewmean          | 0.75512505   |\n",
            "| explained_variance | 0.952        |\n",
            "| fps                | 238          |\n",
            "| nupdates           | 230          |\n",
            "| policy_entropy     | 0.14241487   |\n",
            "| policy_loss        | -0.002897937 |\n",
            "| serial_timesteps   | 471040       |\n",
            "| time_elapsed       | 1.19e+03     |\n",
            "| total_timesteps    | 471040       |\n",
            "| value_loss         | 0.0018861683 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.007913977  |\n",
            "| clipfrac           | 0.05847168   |\n",
            "| eplenmean          | 17.9         |\n",
            "| eprewmean          | 0.7420626    |\n",
            "| explained_variance | 0.921        |\n",
            "| fps                | 238          |\n",
            "| nupdates           | 240          |\n",
            "| policy_entropy     | 0.20349191   |\n",
            "| policy_loss        | -0.006303663 |\n",
            "| serial_timesteps   | 491520       |\n",
            "| time_elapsed       | 1.28e+03     |\n",
            "| total_timesteps    | 491520       |\n",
            "| value_loss         | 0.0019487242 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0103598675 |\n",
            "| clipfrac           | 0.038085938  |\n",
            "| eplenmean          | 16.4         |\n",
            "| eprewmean          | 0.76012504   |\n",
            "| explained_variance | 0.958        |\n",
            "| fps                | 238          |\n",
            "| nupdates           | 250          |\n",
            "| policy_entropy     | 0.11783317   |\n",
            "| policy_loss        | -0.007973398 |\n",
            "| serial_timesteps   | 512000       |\n",
            "| time_elapsed       | 1.36e+03     |\n",
            "| total_timesteps    | 512000       |\n",
            "| value_loss         | 0.0015763411 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013673163   |\n",
            "| clipfrac           | 0.044067383   |\n",
            "| eplenmean          | 15.9          |\n",
            "| eprewmean          | 0.76343757    |\n",
            "| explained_variance | 0.974         |\n",
            "| fps                | 236           |\n",
            "| nupdates           | 260           |\n",
            "| policy_entropy     | 0.095494      |\n",
            "| policy_loss        | -0.0069748964 |\n",
            "| serial_timesteps   | 532480        |\n",
            "| time_elapsed       | 1.45e+03      |\n",
            "| total_timesteps    | 532480        |\n",
            "| value_loss         | 0.000828537   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010557143  |\n",
            "| clipfrac           | 0.045776367  |\n",
            "| eplenmean          | 16.2         |\n",
            "| eprewmean          | 0.7600626    |\n",
            "| explained_variance | 0.978        |\n",
            "| fps                | 234          |\n",
            "| nupdates           | 270          |\n",
            "| policy_entropy     | 0.15807539   |\n",
            "| policy_loss        | -0.008362109 |\n",
            "| serial_timesteps   | 552960       |\n",
            "| time_elapsed       | 1.54e+03     |\n",
            "| total_timesteps    | 552960       |\n",
            "| value_loss         | 0.000718708  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011672539  |\n",
            "| clipfrac           | 0.024291992  |\n",
            "| eplenmean          | 16.6         |\n",
            "| eprewmean          | 0.7685626    |\n",
            "| explained_variance | 0.978        |\n",
            "| fps                | 236          |\n",
            "| nupdates           | 280          |\n",
            "| policy_entropy     | 0.12835433   |\n",
            "| policy_loss        | -0.005586968 |\n",
            "| serial_timesteps   | 573440       |\n",
            "| time_elapsed       | 1.62e+03     |\n",
            "| total_timesteps    | 573440       |\n",
            "| value_loss         | 0.0006896088 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0030006978  |\n",
            "| clipfrac           | 0.028930664   |\n",
            "| eplenmean          | 16            |\n",
            "| eprewmean          | 0.7736876     |\n",
            "| explained_variance | 0.979         |\n",
            "| fps                | 235           |\n",
            "| nupdates           | 290           |\n",
            "| policy_entropy     | 0.12570404    |\n",
            "| policy_loss        | -0.0042324797 |\n",
            "| serial_timesteps   | 593920        |\n",
            "| time_elapsed       | 1.71e+03      |\n",
            "| total_timesteps    | 593920        |\n",
            "| value_loss         | 0.0007150443  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0035840645  |\n",
            "| clipfrac           | 0.028564453   |\n",
            "| eplenmean          | 15.8          |\n",
            "| eprewmean          | 0.7724999     |\n",
            "| explained_variance | 0.982         |\n",
            "| fps                | 241           |\n",
            "| nupdates           | 300           |\n",
            "| policy_entropy     | 0.1198026     |\n",
            "| policy_loss        | -0.0060690576 |\n",
            "| serial_timesteps   | 614400        |\n",
            "| time_elapsed       | 1.8e+03       |\n",
            "| total_timesteps    | 614400        |\n",
            "| value_loss         | 0.00062887993 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0035667233  |\n",
            "| clipfrac           | 0.018798828   |\n",
            "| eplenmean          | 15.5          |\n",
            "| eprewmean          | 0.7743125     |\n",
            "| explained_variance | 0.985         |\n",
            "| fps                | 242           |\n",
            "| nupdates           | 310           |\n",
            "| policy_entropy     | 0.102347694   |\n",
            "| policy_loss        | -0.0044761216 |\n",
            "| serial_timesteps   | 634880        |\n",
            "| time_elapsed       | 1.88e+03      |\n",
            "| total_timesteps    | 634880        |\n",
            "| value_loss         | 0.0005069398  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0031647994  |\n",
            "| clipfrac           | 0.020263672   |\n",
            "| eplenmean          | 16            |\n",
            "| eprewmean          | 0.7739376     |\n",
            "| explained_variance | 0.985         |\n",
            "| fps                | 310           |\n",
            "| nupdates           | 320           |\n",
            "| policy_entropy     | 0.09601809    |\n",
            "| policy_loss        | -0.0039683534 |\n",
            "| serial_timesteps   | 655360        |\n",
            "| time_elapsed       | 1.96e+03      |\n",
            "| total_timesteps    | 655360        |\n",
            "| value_loss         | 0.00059688016 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0036201635  |\n",
            "| clipfrac           | 0.024414062   |\n",
            "| eplenmean          | 15.8          |\n",
            "| eprewmean          | 0.77381253    |\n",
            "| explained_variance | 0.942         |\n",
            "| fps                | 240           |\n",
            "| nupdates           | 330           |\n",
            "| policy_entropy     | 0.11247458    |\n",
            "| policy_loss        | -0.0047203335 |\n",
            "| serial_timesteps   | 675840        |\n",
            "| time_elapsed       | 2.04e+03      |\n",
            "| total_timesteps    | 675840        |\n",
            "| value_loss         | 0.0017959595  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0061672605  |\n",
            "| clipfrac           | 0.028442383   |\n",
            "| eplenmean          | 16.1          |\n",
            "| eprewmean          | 0.769625      |\n",
            "| explained_variance | 0.983         |\n",
            "| fps                | 230           |\n",
            "| nupdates           | 340           |\n",
            "| policy_entropy     | 0.087106876   |\n",
            "| policy_loss        | -0.0032513079 |\n",
            "| serial_timesteps   | 696320        |\n",
            "| time_elapsed       | 2.13e+03      |\n",
            "| total_timesteps    | 696320        |\n",
            "| value_loss         | 0.0005659822  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010637563   |\n",
            "| clipfrac           | 0.021728516   |\n",
            "| eplenmean          | 15.7          |\n",
            "| eprewmean          | 0.77418756    |\n",
            "| explained_variance | 0.984         |\n",
            "| fps                | 238           |\n",
            "| nupdates           | 350           |\n",
            "| policy_entropy     | 0.061089084   |\n",
            "| policy_loss        | -0.0032627324 |\n",
            "| serial_timesteps   | 716800        |\n",
            "| time_elapsed       | 2.21e+03      |\n",
            "| total_timesteps    | 716800        |\n",
            "| value_loss         | 0.0005816722  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0026734022   |\n",
            "| clipfrac           | 0.009399414    |\n",
            "| eplenmean          | 15.4           |\n",
            "| eprewmean          | 0.77675        |\n",
            "| explained_variance | 0.99           |\n",
            "| fps                | 245            |\n",
            "| nupdates           | 360            |\n",
            "| policy_entropy     | 0.044956934    |\n",
            "| policy_loss        | -0.00073154113 |\n",
            "| serial_timesteps   | 737280         |\n",
            "| time_elapsed       | 2.3e+03        |\n",
            "| total_timesteps    | 737280         |\n",
            "| value_loss         | 0.00032216712  |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.004057871  |\n",
            "| clipfrac           | 0.018676758  |\n",
            "| eplenmean          | 15.6         |\n",
            "| eprewmean          | 0.77312505   |\n",
            "| explained_variance | 0.985        |\n",
            "| fps                | 246          |\n",
            "| nupdates           | 370          |\n",
            "| policy_entropy     | 0.076074414  |\n",
            "| policy_loss        | -0.002958653 |\n",
            "| serial_timesteps   | 757760       |\n",
            "| time_elapsed       | 2.39e+03     |\n",
            "| total_timesteps    | 757760       |\n",
            "| value_loss         | 0.000528821  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009109436   |\n",
            "| clipfrac           | 0.03857422    |\n",
            "| eplenmean          | 15.8          |\n",
            "| eprewmean          | 0.7796876     |\n",
            "| explained_variance | 0.978         |\n",
            "| fps                | 239           |\n",
            "| nupdates           | 380           |\n",
            "| policy_entropy     | 0.083717115   |\n",
            "| policy_loss        | -0.010305653  |\n",
            "| serial_timesteps   | 778240        |\n",
            "| time_elapsed       | 2.47e+03      |\n",
            "| total_timesteps    | 778240        |\n",
            "| value_loss         | 0.00076633063 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0022491394  |\n",
            "| clipfrac           | 0.014770508   |\n",
            "| eplenmean          | 15.9          |\n",
            "| eprewmean          | 0.77668756    |\n",
            "| explained_variance | 0.987         |\n",
            "| fps                | 248           |\n",
            "| nupdates           | 390           |\n",
            "| policy_entropy     | 0.060779527   |\n",
            "| policy_loss        | -0.0028635152 |\n",
            "| serial_timesteps   | 798720        |\n",
            "| time_elapsed       | 2.56e+03      |\n",
            "| total_timesteps    | 798720        |\n",
            "| value_loss         | 0.00043610806 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008410277   |\n",
            "| clipfrac           | 0.02734375    |\n",
            "| eplenmean          | 15.8          |\n",
            "| eprewmean          | 0.7782501     |\n",
            "| explained_variance | 0.986         |\n",
            "| fps                | 244           |\n",
            "| nupdates           | 400           |\n",
            "| policy_entropy     | 0.058846876   |\n",
            "| policy_loss        | -0.0062343697 |\n",
            "| serial_timesteps   | 819200        |\n",
            "| time_elapsed       | 2.64e+03      |\n",
            "| total_timesteps    | 819200        |\n",
            "| value_loss         | 0.00050279073 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0018363555  |\n",
            "| clipfrac           | 0.008300781   |\n",
            "| eplenmean          | 15.1          |\n",
            "| eprewmean          | 0.78062516    |\n",
            "| explained_variance | 0.991         |\n",
            "| fps                | 236           |\n",
            "| nupdates           | 410           |\n",
            "| policy_entropy     | 0.038991936   |\n",
            "| policy_loss        | -0.0022476085 |\n",
            "| serial_timesteps   | 839680        |\n",
            "| time_elapsed       | 2.73e+03      |\n",
            "| total_timesteps    | 839680        |\n",
            "| value_loss         | 0.0003373317  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0041729556 |\n",
            "| clipfrac           | 0.012451172  |\n",
            "| eplenmean          | 15.2         |\n",
            "| eprewmean          | 0.77762496   |\n",
            "| explained_variance | 0.988        |\n",
            "| fps                | 236          |\n",
            "| nupdates           | 420          |\n",
            "| policy_entropy     | 0.041879598  |\n",
            "| policy_loss        | -0.002006059 |\n",
            "| serial_timesteps   | 860160       |\n",
            "| time_elapsed       | 2.81e+03     |\n",
            "| total_timesteps    | 860160       |\n",
            "| value_loss         | 0.0004382481 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00056480384 |\n",
            "| clipfrac           | 0.007080078   |\n",
            "| eplenmean          | 15.2          |\n",
            "| eprewmean          | 0.7806876     |\n",
            "| explained_variance | 0.992         |\n",
            "| fps                | 235           |\n",
            "| nupdates           | 430           |\n",
            "| policy_entropy     | 0.048072506   |\n",
            "| policy_loss        | -0.0013807977 |\n",
            "| serial_timesteps   | 880640        |\n",
            "| time_elapsed       | 2.9e+03       |\n",
            "| total_timesteps    | 880640        |\n",
            "| value_loss         | 0.00027106228 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00020450853 |\n",
            "| clipfrac           | 0.0025634766  |\n",
            "| eplenmean          | 15.3          |\n",
            "| eprewmean          | 0.77981263    |\n",
            "| explained_variance | 0.992         |\n",
            "| fps                | 231           |\n",
            "| nupdates           | 440           |\n",
            "| policy_entropy     | 0.03609548    |\n",
            "| policy_loss        | -0.0008525177 |\n",
            "| serial_timesteps   | 901120        |\n",
            "| time_elapsed       | 2.99e+03      |\n",
            "| total_timesteps    | 901120        |\n",
            "| value_loss         | 0.00028681871 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0006255049  |\n",
            "| clipfrac           | 0.0052490234  |\n",
            "| eplenmean          | 15.4          |\n",
            "| eprewmean          | 0.776125      |\n",
            "| explained_variance | 0.992         |\n",
            "| fps                | 232           |\n",
            "| nupdates           | 450           |\n",
            "| policy_entropy     | 0.034848      |\n",
            "| policy_loss        | -0.0013789921 |\n",
            "| serial_timesteps   | 921600        |\n",
            "| time_elapsed       | 3.08e+03      |\n",
            "| total_timesteps    | 921600        |\n",
            "| value_loss         | 0.00028704625 |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00022213555  |\n",
            "| clipfrac           | 0.0032958984   |\n",
            "| eplenmean          | 14.9           |\n",
            "| eprewmean          | 0.78581256     |\n",
            "| explained_variance | 0.992          |\n",
            "| fps                | 237            |\n",
            "| nupdates           | 460            |\n",
            "| policy_entropy     | 0.025857367    |\n",
            "| policy_loss        | -0.00058756245 |\n",
            "| serial_timesteps   | 942080         |\n",
            "| time_elapsed       | 3.16e+03       |\n",
            "| total_timesteps    | 942080         |\n",
            "| value_loss         | 0.0002718687   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0013061306  |\n",
            "| clipfrac           | 0.009277344   |\n",
            "| eplenmean          | 15.3          |\n",
            "| eprewmean          | 0.7804375     |\n",
            "| explained_variance | 0.992         |\n",
            "| fps                | 232           |\n",
            "| nupdates           | 470           |\n",
            "| policy_entropy     | 0.031833522   |\n",
            "| policy_loss        | -0.0031035594 |\n",
            "| serial_timesteps   | 962560        |\n",
            "| time_elapsed       | 3.25e+03      |\n",
            "| total_timesteps    | 962560        |\n",
            "| value_loss         | 0.0003024561  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0005865953  |\n",
            "| clipfrac           | 0.0043945312  |\n",
            "| eplenmean          | 15.3          |\n",
            "| eprewmean          | 0.77743745    |\n",
            "| explained_variance | 0.991         |\n",
            "| fps                | 235           |\n",
            "| nupdates           | 480           |\n",
            "| policy_entropy     | 0.034800112   |\n",
            "| policy_loss        | -0.0028271498 |\n",
            "| serial_timesteps   | 983040        |\n",
            "| time_elapsed       | 3.34e+03      |\n",
            "| total_timesteps    | 983040        |\n",
            "| value_loss         | 0.0003087244  |\n",
            "--------------------------------------\n",
            "CPU times: user 51min 29s, sys: 8min 31s, total: 1h\n",
            "Wall time: 57min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "cfde00d3-9d15-4641-9aef-a1b6097150a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f42ad70c630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFKCAYAAADITfxaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "id": "H_QTckfBra7l",
        "colab_type": "code",
        "outputId": "a0571594-9e53-41d5-d3ea-ff426f764b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "baseline = Baseline(env, max_reward=8000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 1000, 'B': 1000, 'C': 0, 'D': 1000, 'E': 0, 'F': 0, 'G': 1000, 'H': 1000, 'K': 1000, 'L': 1000, 'M': 0, 'N': 0, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "1355a767-5ddb-4f19-ed3d-c54fc603b18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, reward={}\".format(t+1, env.totalReward))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:  201   Step:    1  S --1-> B R= 0.11 totalR= 0.11 cost= 100 customerR=1000 optimum=8000\n",
            "Episode:  201   Step:    2  B --2-> C R=-0.01 totalR= 0.11 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:  201   Step:    3  C --2-> M R=-0.01 totalR= 0.09 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:  201   Step:    4  M --1-> L R= 0.12 totalR= 0.21 cost=  50 customerR=1000 optimum=8000\n",
            "Episode:  201   Step:    5  L --1-> M R=-0.01 totalR= 0.21 cost=  50 customerR=   0 optimum=8000\n",
            "Episode:  201   Step:    6  M --2-> N R=-0.01 totalR= 0.19 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:  201   Step:    7  N --1-> O R= 0.11 totalR= 0.31 cost= 100 customerR=1000 optimum=8000\n",
            "Episode:  201   Step:    8  O --1-> G R= 0.09 totalR= 0.39 cost= 300 customerR=1000 optimum=8000\n",
            "Episode:  201   Step:    9  G --0-> F R=-0.03 totalR= 0.37 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:  201   Step:   10  F --0-> D R= 0.12 totalR= 0.49 cost=  50 customerR=1000 optimum=8000\n",
            "Episode:  201   Step:   11  D --0-> A R= 0.11 totalR= 0.60 cost= 100 customerR=1000 optimum=8000\n",
            "Episode:  201   Step:   12  A --2-> E R=-0.01 totalR= 0.59 cost= 100 customerR=   0 optimum=8000\n",
            "Episode:  201   Step:   13  E --2-> H R= 0.11 totalR= 0.70 cost= 100 customerR=1000 optimum=8000\n",
            "Episode:  201   Step:   14  H --1-> K R= 0.09 totalR= 0.79 cost= 300 customerR=1000 optimum=8000\n",
            "Episode:  201   Step:   15  K --0-> B R=-0.03 totalR= 0.76 cost= 200 customerR=   0 optimum=8000\n",
            "Episode:  201   Step:   16  B --0-> S R=-0.01 totalR= 0.75 cost= 100 customerR=   0 optimum=8000\n",
            "Episode finished after 16 timesteps, reward=0.7500000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3z35_dMMt6SW",
        "colab_type": "code",
        "outputId": "da096eb7-afcf-4248-9e46-1b8b685b1bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "%time baseline.find_optimum()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaled reward: 0.75\n",
            "Perfect path ['S', 'B', 'C', 'M', 'L', 'M', 'N', 'O', 'G', 'F', 'D', 'A', 'E', 'H', 'K', 'B', 'S']\n",
            "CPU times: user 656 ms, sys: 15.8 ms, total: 671 ms\n",
            "Wall time: 940 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cost': 2000,\n",
              " 'path': ['S',\n",
              "  'B',\n",
              "  'C',\n",
              "  'M',\n",
              "  'L',\n",
              "  'M',\n",
              "  'N',\n",
              "  'O',\n",
              "  'G',\n",
              "  'F',\n",
              "  'D',\n",
              "  'A',\n",
              "  'E',\n",
              "  'H',\n",
              "  'K',\n",
              "  'B',\n",
              "  'S'],\n",
              " 'position': 'S',\n",
              " 'reward': 8000,\n",
              " 'rewards': {'A': 0,\n",
              "  'B': 0,\n",
              "  'C': 0,\n",
              "  'D': 0,\n",
              "  'E': 0,\n",
              "  'F': 0,\n",
              "  'G': 0,\n",
              "  'H': 0,\n",
              "  'K': 0,\n",
              "  'L': 0,\n",
              "  'M': 0,\n",
              "  'N': 0,\n",
              "  'O': 0,\n",
              "  'S': 0},\n",
              " 'scaled_reward': 0.75}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "K36GXkzyRGOO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "KMb58O_q067F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "baseline = Baseline(env, max_reward=8000)\n",
        "perfect_score_mean, perfect_score_std, test_score_mean, test_score_std = baseline.score(model, sample_runs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dr9ylHgnRIcc",
        "colab_type": "code",
        "outputId": "c281b74b-5731-40e4-a412-6659d81b8425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# perfect scores\n",
        "perfect_score_mean, perfect_score_std"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7833124999999999, 0.02326906140672631)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "rOSOoO29Rwgm",
        "colab_type": "code",
        "outputId": "0553780f-814b-4dd1-a721-919511e6ba16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# test scores for our model\n",
        "test_score_mean, test_score_std"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7802500000000001, 0.024362496793227117)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "Ls8IKVV1R5SE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}