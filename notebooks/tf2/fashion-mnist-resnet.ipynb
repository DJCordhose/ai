{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion MNIST using Resnet",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tf2/fashion-mnist-resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ot79jiI7GiHR"
      },
      "source": [
        "# Fashion MNIST with Keras and Resnet\n",
        "\n",
        "Adapted from \n",
        "* https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb\n",
        "* https://github.com/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgKgnUbT0Hl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvkoOXPCaK6l",
        "colab_type": "code",
        "outputId": "6aedc5ef-4f41-4019-ce94-9c714ecdd3c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zo-Yk6LFGfSf",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA86lMsm0Hl8",
        "colab_type": "code",
        "outputId": "601e20bc-e6d0-403b-951c-8b9209715aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho696hjZ0HmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leTQvij40HmF",
        "colab_type": "code",
        "outputId": "0e51fe52-17fa-425d-83bd-85b6fe5c2a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJY957q80HmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recude memory and compute time\n",
        "NUMBER_OF_SAMPLES = 50000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbAOWanA0HmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_samples = x_train[:NUMBER_OF_SAMPLES]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eirhmhRd0HmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_samples = y_train[:NUMBER_OF_SAMPLES]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJZVXUtD0HmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage.data\n",
        "import skimage.transform\n",
        "\n",
        "x_train_224 = np.array([skimage.transform.resize(image, (32, 32)) for image in x_train_samples])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUdq27Bd0Hmb",
        "colab_type": "code",
        "outputId": "fba73123-1e46-409f-9940-974d06db6ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_224.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hgc2FZKVMx15"
      },
      "source": [
        "## Alternative: ResNet\n",
        "* basic ideas\n",
        "  * depth does matter\n",
        "  * 8x deeper than VGG\n",
        "  * possible by using shortcuts and skipping final fc layer\n",
        "  * prevents vanishing gradient problem\n",
        "* https://keras.io/applications/#resnet50\n",
        "* https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba\n",
        "\n",
        "http://arxiv.org/abs/1512.03385\n",
        "![Deep Learning](https://raw.githubusercontent.com/DJCordhose/ai/master/docs/img/residual.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7gMbs70GxA7",
        "outputId": "f8834467-4a37-48f4-d937-77e77ae64cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "# https://keras.io/applications/#mobilenet\n",
        "# https://arxiv.org/pdf/1704.04861.pdf\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "\n",
        "# model = ResNet50(classes=10, weights=None, input_shape=(32, 32, 1))\n",
        "model = MobileNet(classes=10, weights=None, input_shape=(32, 32, 1))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mobilenet_1.00_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 33, 33, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 16, 16, 32)        288       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)         2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 2, 2, 512)         131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 2, 2, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 2, 2, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 2, 2, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 2, 2, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 2, 2, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_preds (Conv2D)          (None, 1, 1, 10)          10250     \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "act_softmax (Activation)     (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 3,238,538\n",
            "Trainable params: 3,216,650\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlCmC3jk0Hml",
        "colab_type": "code",
        "outputId": "b35e1d30-b28e-434b-bdd8-570d9274383f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "BATCH_SIZE=10\n",
        "EPOCHS = 10\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_224, y_train_samples, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/40000 [=====================================] - 58s 1ms/sample - loss: 0.8670 - accuracy: 0.7041 - val_loss: 0.6607 - val_accuracy: 0.7319\n",
            "Epoch 2/10\n",
            "50000/40000 [=====================================] - 52s 1ms/sample - loss: 0.5105 - accuracy: 0.8125 - val_loss: 0.4264 - val_accuracy: 0.8509\n",
            "Epoch 3/10\n",
            "50000/40000 [=====================================] - 52s 1ms/sample - loss: 0.4074 - accuracy: 0.8528 - val_loss: 0.3954 - val_accuracy: 0.8757\n",
            "Epoch 4/10\n",
            "50000/40000 [=====================================] - 52s 1ms/sample - loss: 0.3718 - accuracy: 0.8736 - val_loss: 0.3468 - val_accuracy: 0.8754\n",
            "Epoch 5/10\n",
            "50000/40000 [=====================================] - 52s 1ms/sample - loss: 0.2917 - accuracy: 0.8883 - val_loss: 0.3616 - val_accuracy: 0.8866\n",
            "Epoch 6/10\n",
            "50000/40000 [=====================================] - 52s 1ms/sample - loss: 0.2873 - accuracy: 0.8964 - val_loss: 0.3145 - val_accuracy: 0.8890\n",
            "Epoch 7/10\n",
            "50000/40000 [=====================================] - 52s 1ms/sample - loss: 0.2755 - accuracy: 0.9036 - val_loss: 0.3005 - val_accuracy: 0.8980\n",
            "Epoch 8/10\n",
            "50000/40000 [=====================================] - 52s 1ms/sample - loss: 0.2390 - accuracy: 0.9130 - val_loss: 0.2683 - val_accuracy: 0.9056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0819 14:20:06.290217 140445368510336 training_v2.py:146] Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50000 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/10\n",
            "\r    0/40000 [..............................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b1f3f8e4d39e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nBATCH_SIZE=10\\nEPOCHS = 10\\n\\nmodel.compile(loss='sparse_categorical_crossentropy',\\n             optimizer='adam',\\n             metrics=['accuracy'])\\n\\nhistory = model.fit(x_train_224, y_train_samples, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, verbose=1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0;31m# End of an epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m   \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Empty training data.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Empty training data."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BTaeQittcgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "a4f9da89-2b96-45a7-820d-79ac7a35dde0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['Loss', 'Validation Loss'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f0885def40f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBZBXu8vIX0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['Accuracy', 'Validation Accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ESL6ltQTMm05"
      },
      "source": [
        "# Checking our results (inference)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKGkFxCE4CfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_224 = np.array([skimage.transform.resize(image, (32, 32)) for image in x_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SaYPv_aKId2d",
        "colab": {}
      },
      "source": [
        "LABEL_NAMES = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n",
        "\n",
        "\n",
        "def plot_predictions(images, predictions):\n",
        "  n = images.shape[0]\n",
        "  nc = int(np.ceil(n / 4))\n",
        "  f, axes = plt.subplots(nc, 4)\n",
        "  for i in range(nc * 4):\n",
        "    y = i // 4\n",
        "    x = i % 4\n",
        "    axes[x, y].axis('off')\n",
        "    \n",
        "    label = LABEL_NAMES[np.argmax(predictions[i])]\n",
        "    confidence = np.max(predictions[i])\n",
        "    if i > n:\n",
        "      continue\n",
        "    axes[x, y].imshow(images[i])\n",
        "    axes[x, y].text(0.5, 0.5, label + '\\n%.3f' % confidence, fontsize=14)\n",
        "\n",
        "  plt.gcf().set_size_inches(8, 8)  \n",
        "\n",
        "plot_predictions(np.squeeze(x_test_224[:16]), \n",
        "                 model.predict(x_test_224[:16]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJlzeWxJ8TQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss, train_accuracy = model.evaluate(x_train_224, y_train_samples, batch_size=BATCH_SIZE)\n",
        "train_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOUNObau8YKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test_224, y_test, batch_size=BATCH_SIZE)\n",
        "test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyrOTv3aLhwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}