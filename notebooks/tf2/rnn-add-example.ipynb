{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn-add-example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tf2/rnn-add-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "28hWKJQtK1oJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Addition as a Sequence to Sequence Translation\n",
        "Adapted from https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py"
      ]
    },
    {
      "metadata": {
        "id": "Zqi1xb086Gl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8a55645a-fc1d-46e2-d84c-4026be8bf7db"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 346.4MB 59kB/s \n",
            "\u001b[K     |████████████████████████████████| 430kB 51.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 29.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 44.4MB/s \n",
            "\u001b[?25h  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wabs7qeWK7la",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fffc4193-fcb6-423a-a653-0d3924870411"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SEvTJtaL6GmR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1: Generate sample equations"
      ]
    },
    {
      "metadata": {
        "id": "IAz9Tnpu6GmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one hot integer representation\n",
        "    + Decode the one hot integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One hot encode given string C.\n",
        "\n",
        "        # Arguments\n",
        "            num_rows: Number of rows in the returned one hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DqdzUFGZ6GmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class colors:\n",
        "    ok = '\\033[92m'\n",
        "    fail = '\\033[91m'\n",
        "    close = '\\033[0m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kf7L7DwB6GmY",
        "colab_type": "code",
        "outputId": "80854972-9aa5-4cbd-fa39-8f6cf60aa19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "# REVERSE = True\n",
        "REVERSE = False\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = '0123456789+ '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}+{}'.format(a, b)\n",
        "    query = q + ' ' * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print('Total addition questions:', len(questions))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gTLONdDN6Gmc",
        "colab_type": "code",
        "outputId": "2e360795-846c-4099-ab62-3561fec54033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "questions[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'506+0  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "YwcSV3ieNBI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9ade81e-754d-4c5e-ec06-bb31bb68b57d"
      },
      "cell_type": "code",
      "source": [
        "expected[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'506 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "L6n6X_w26Gmg",
        "colab_type": "code",
        "outputId": "a99fb837-06ae-4866-c83d-cca0a536f8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L1rqJg9v6Gmk",
        "colab_type": "code",
        "outputId": "cab39d40-56f9-4e16-b9a9-deb956b1cefe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(x[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "0lgZ9xs-6Gmo",
        "colab_type": "code",
        "outputId": "02d4879d-de1d-4218-c977-efe33906b722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(questions[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "NLtol2BUW1tk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input is encoded as one-hot, 7 digits times 12 possibilities"
      ]
    },
    {
      "metadata": {
        "id": "wZ_g5cHf6Gmw",
        "colab_type": "code",
        "outputId": "ab303c9d-865e-4c53-ab5b-f21490167a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False, False,  True, False,\n",
              "        False, False, False],\n",
              "       [False, False,  True, False, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False, False, False, False,  True,\n",
              "        False, False, False],\n",
              "       [False,  True, False, False, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False,  True, False, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [ True, False, False, False, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [ True, False, False, False, False, False, False, False, False,\n",
              "        False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "mbX2RzJVW-dN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Same for output, but at most 4 digits"
      ]
    },
    {
      "metadata": {
        "id": "hWldgEEJ6Gmz",
        "colab_type": "code",
        "outputId": "8af2264b-6c00-41e3-bdda-d4592585271a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False, False,  True, False,\n",
              "        False, False, False],\n",
              "       [False, False,  True, False, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False, False, False, False,  True,\n",
              "        False, False, False],\n",
              "       [ True, False, False, False, False, False, False, False, False,\n",
              "        False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "XPO5c5xe6GnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "envfa2ZT6GnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2: Training/Validation Split"
      ]
    },
    {
      "metadata": {
        "id": "bDSoeziy6GnE",
        "colab_type": "code",
        "outputId": "459c9e3f-30a1-4c82-d575-9c1cdf854746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print('Training Data:')\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('Validation Data:')\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bPUg9slY6GnK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3: Create Model"
      ]
    },
    {
      "metadata": {
        "id": "wK_ll_ew6GnL",
        "colab_type": "code",
        "outputId": "e18d9a77-35a1-4860-885c-44192bb20886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# input shape: 7 digits, each being 0-9, + or space (12 possibilities)\n",
        "MAXLEN, len(chars)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "dksl6o766GnO",
        "colab_type": "code",
        "outputId": "01e4f859-1458-47e6-89e6-adbcf6a25ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  LSTM, GRU, SimpleRNN, Dense, RepeatVector\n",
        "\n",
        "# Try replacing LSTM, GRU, or SimpleRNN.\n",
        "# RNN = LSTM\n",
        "RNN = SimpleRNN # should be enough since we do not have long sequences and only local dependencies\n",
        "# RNN = GRU\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "model = Sequential()\n",
        "# encoder \n",
        "model.add(RNN(units=HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "\n",
        "# latent space\n",
        "encoding_dim = 32\n",
        "model.add(Dense(units=encoding_dim, activation='relu', name=\"encoder\"))\n",
        "\n",
        "# decoder: have 4 temporal outputs one for each of the digits of the results\n",
        "model.add(RepeatVector(DIGITS + 1))\n",
        "\n",
        "# return_sequences=True tells it to keep all 4 temporal outputs, not only the final one (we need all four digits for the results)\n",
        "model.add(RNN(units=HIDDEN_SIZE, return_sequences=True))\n",
        "\n",
        "model.add(Dense(name='classifier', units=len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_4 (SimpleRNN)     (None, 128)               18048     \n",
            "_________________________________________________________________\n",
            "encoder (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, 4, 128)            20608     \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 44,332\n",
            "Trainable params: 44,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cdW2FJVl6GnZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4: Train"
      ]
    },
    {
      "metadata": {
        "id": "izY-B-UF6Gna",
        "colab_type": "code",
        "outputId": "c13cccaf-c06f-497f-c6b9-0fc929f70bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12546
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "\n",
        "merged_losses = {\n",
        "    \"loss\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"accuracy\": [],\n",
        "    \"val_accuracy\": [],\n",
        "    \n",
        "}\n",
        "\n",
        "for iteration in range(1, 50):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    iteration_history = model.fit(x_train, y_train,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "    \n",
        "    merged_losses[\"loss\"].append(iteration_history.history[\"loss\"])\n",
        "    merged_losses[\"val_loss\"].append(iteration_history.history[\"val_loss\"])\n",
        "    merged_losses[\"accuracy\"].append(iteration_history.history[\"accuracy\"])\n",
        "    merged_losses[\"val_accuracy\"].append(iteration_history.history[\"val_accuracy\"])\n",
        "\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = model.predict_classes(rowx, verbose=0)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct == guess:\n",
        "            print(colors.ok + '☑' + colors.close, end=' ')\n",
        "        else:\n",
        "            print(colors.fail + '☒' + colors.close, end=' ')\n",
        "        print(guess)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 6s 123us/sample - loss: 1.6689 - accuracy: 0.3896 - val_loss: 1.5134 - val_accuracy: 0.4410\n",
            "Q 658+775 T 1433 \u001b[91m☒\u001b[0m 1407\n",
            "Q 557+41  T 598  \u001b[91m☒\u001b[0m 666 \n",
            "Q 660+44  T 704  \u001b[91m☒\u001b[0m 666 \n",
            "Q 79+411  T 490  \u001b[91m☒\u001b[0m 444 \n",
            "Q 684+760 T 1444 \u001b[91m☒\u001b[0m 1406\n",
            "Q 4+844   T 848  \u001b[91m☒\u001b[0m 548 \n",
            "Q 816+42  T 858  \u001b[91m☒\u001b[0m 891 \n",
            "Q 644+68  T 712  \u001b[91m☒\u001b[0m 623 \n",
            "Q 500+83  T 583  \u001b[91m☒\u001b[0m 603 \n",
            "Q 9+667   T 676  \u001b[91m☒\u001b[0m 666 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 102us/sample - loss: 1.3752 - accuracy: 0.4873 - val_loss: 1.2841 - val_accuracy: 0.5138\n",
            "Q 97+760  T 857  \u001b[91m☒\u001b[0m 882 \n",
            "Q 914+5   T 919  \u001b[91m☒\u001b[0m 912 \n",
            "Q 72+60   T 132  \u001b[91m☒\u001b[0m 146 \n",
            "Q 915+21  T 936  \u001b[91m☒\u001b[0m 991 \n",
            "Q 734+101 T 835  \u001b[91m☒\u001b[0m 851 \n",
            "Q 3+39    T 42   \u001b[91m☒\u001b[0m 39  \n",
            "Q 175+17  T 192  \u001b[91m☒\u001b[0m 261 \n",
            "Q 411+66  T 477  \u001b[91m☒\u001b[0m 591 \n",
            "Q 82+50   T 132  \u001b[91m☒\u001b[0m 146 \n",
            "Q 663+7   T 670  \u001b[91m☒\u001b[0m 664 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 1.2055 - accuracy: 0.5461 - val_loss: 1.1436 - val_accuracy: 0.5627\n",
            "Q 862+89  T 951  \u001b[91m☒\u001b[0m 958 \n",
            "Q 41+764  T 805  \u001b[91m☒\u001b[0m 819 \n",
            "Q 985+908 T 1893 \u001b[91m☒\u001b[0m 1864\n",
            "Q 126+6   T 132  \u001b[91m☒\u001b[0m 102 \n",
            "Q 82+308  T 390  \u001b[91m☒\u001b[0m 399 \n",
            "Q 714+225 T 939  \u001b[91m☒\u001b[0m 902 \n",
            "Q 363+84  T 447  \u001b[91m☒\u001b[0m 441 \n",
            "Q 29+428  T 457  \u001b[91m☒\u001b[0m 458 \n",
            "Q 690+7   T 697  \u001b[91m☒\u001b[0m 795 \n",
            "Q 630+603 T 1233 \u001b[91m☒\u001b[0m 1237\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 102us/sample - loss: 1.0847 - accuracy: 0.5892 - val_loss: 1.0366 - val_accuracy: 0.6080\n",
            "Q 22+69   T 91   \u001b[91m☒\u001b[0m 70  \n",
            "Q 374+22  T 396  \u001b[91m☒\u001b[0m 390 \n",
            "Q 7+944   T 951  \u001b[91m☒\u001b[0m 941 \n",
            "Q 5+194   T 199  \u001b[91m☒\u001b[0m 190 \n",
            "Q 16+907  T 923  \u001b[91m☒\u001b[0m 901 \n",
            "Q 46+312  T 358  \u001b[91m☒\u001b[0m 360 \n",
            "Q 48+179  T 227  \u001b[91m☒\u001b[0m 223 \n",
            "Q 443+53  T 496  \u001b[91m☒\u001b[0m 490 \n",
            "Q 482+3   T 485  \u001b[91m☒\u001b[0m 490 \n",
            "Q 566+921 T 1487 \u001b[91m☒\u001b[0m 1467\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.9985 - accuracy: 0.6217 - val_loss: 0.9810 - val_accuracy: 0.6253\n",
            "Q 508+94  T 602  \u001b[91m☒\u001b[0m 591 \n",
            "Q 5+518   T 523  \u001b[92m☑\u001b[0m 523 \n",
            "Q 251+280 T 531  \u001b[91m☒\u001b[0m 541 \n",
            "Q 31+962  T 993  \u001b[91m☒\u001b[0m 986 \n",
            "Q 503+318 T 821  \u001b[91m☒\u001b[0m 832 \n",
            "Q 908+27  T 935  \u001b[91m☒\u001b[0m 939 \n",
            "Q 55+507  T 562  \u001b[91m☒\u001b[0m 564 \n",
            "Q 98+592  T 690  \u001b[91m☒\u001b[0m 689 \n",
            "Q 738+893 T 1631 \u001b[91m☒\u001b[0m 1661\n",
            "Q 21+939  T 960  \u001b[91m☒\u001b[0m 963 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.9376 - accuracy: 0.6464 - val_loss: 0.9181 - val_accuracy: 0.6517\n",
            "Q 420+0   T 420  \u001b[91m☒\u001b[0m 424 \n",
            "Q 708+54  T 762  \u001b[91m☒\u001b[0m 765 \n",
            "Q 85+205  T 290  \u001b[91m☒\u001b[0m 380 \n",
            "Q 38+654  T 692  \u001b[91m☒\u001b[0m 694 \n",
            "Q 569+825 T 1394 \u001b[91m☒\u001b[0m 1385\n",
            "Q 540+11  T 551  \u001b[91m☒\u001b[0m 540 \n",
            "Q 32+146  T 178  \u001b[91m☒\u001b[0m 171 \n",
            "Q 29+214  T 243  \u001b[91m☒\u001b[0m 239 \n",
            "Q 72+550  T 622  \u001b[91m☒\u001b[0m 628 \n",
            "Q 446+71  T 517  \u001b[91m☒\u001b[0m 525 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 7\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 102us/sample - loss: 0.8887 - accuracy: 0.6643 - val_loss: 0.8859 - val_accuracy: 0.6597\n",
            "Q 20+71   T 91   \u001b[91m☒\u001b[0m 82  \n",
            "Q 940+45  T 985  \u001b[91m☒\u001b[0m 986 \n",
            "Q 363+84  T 447  \u001b[91m☒\u001b[0m 440 \n",
            "Q 499+8   T 507  \u001b[91m☒\u001b[0m 500 \n",
            "Q 48+788  T 836  \u001b[91m☒\u001b[0m 831 \n",
            "Q 507+724 T 1231 \u001b[91m☒\u001b[0m 1237\n",
            "Q 996+315 T 1311 \u001b[91m☒\u001b[0m 1364\n",
            "Q 2+108   T 110  \u001b[91m☒\u001b[0m 111 \n",
            "Q 781+8   T 789  \u001b[91m☒\u001b[0m 788 \n",
            "Q 27+836  T 863  \u001b[91m☒\u001b[0m 861 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 8\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.8458 - accuracy: 0.6792 - val_loss: 0.8466 - val_accuracy: 0.6753\n",
            "Q 769+78  T 847  \u001b[91m☒\u001b[0m 845 \n",
            "Q 537+34  T 571  \u001b[92m☑\u001b[0m 571 \n",
            "Q 761+799 T 1560 \u001b[91m☒\u001b[0m 1566\n",
            "Q 296+11  T 307  \u001b[91m☒\u001b[0m 303 \n",
            "Q 55+595  T 650  \u001b[91m☒\u001b[0m 643 \n",
            "Q 77+54   T 131  \u001b[91m☒\u001b[0m 130 \n",
            "Q 199+751 T 950  \u001b[91m☒\u001b[0m 943 \n",
            "Q 368+51  T 419  \u001b[91m☒\u001b[0m 415 \n",
            "Q 977+997 T 1974 \u001b[91m☒\u001b[0m 1953\n",
            "Q 947+42  T 989  \u001b[91m☒\u001b[0m 997 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 9\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.7997 - accuracy: 0.6957 - val_loss: 0.7910 - val_accuracy: 0.6970\n",
            "Q 595+67  T 662  \u001b[91m☒\u001b[0m 666 \n",
            "Q 632+69  T 701  \u001b[91m☒\u001b[0m 704 \n",
            "Q 756+70  T 826  \u001b[91m☒\u001b[0m 824 \n",
            "Q 97+564  T 661  \u001b[91m☒\u001b[0m 657 \n",
            "Q 29+144  T 173  \u001b[91m☒\u001b[0m 176 \n",
            "Q 78+306  T 384  \u001b[91m☒\u001b[0m 387 \n",
            "Q 696+181 T 877  \u001b[91m☒\u001b[0m 870 \n",
            "Q 161+851 T 1012 \u001b[91m☒\u001b[0m 1001\n",
            "Q 770+69  T 839  \u001b[91m☒\u001b[0m 847 \n",
            "Q 96+723  T 819  \u001b[91m☒\u001b[0m 817 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 10\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 113us/sample - loss: 0.7469 - accuracy: 0.7143 - val_loss: 0.7541 - val_accuracy: 0.7044\n",
            "Q 437+4   T 441  \u001b[91m☒\u001b[0m 449 \n",
            "Q 54+849  T 903  \u001b[92m☑\u001b[0m 903 \n",
            "Q 776+644 T 1420 \u001b[91m☒\u001b[0m 1424\n",
            "Q 42+812  T 854  \u001b[91m☒\u001b[0m 864 \n",
            "Q 929+34  T 963  \u001b[91m☒\u001b[0m 969 \n",
            "Q 444+664 T 1108 \u001b[91m☒\u001b[0m 1117\n",
            "Q 646+257 T 903  \u001b[91m☒\u001b[0m 990 \n",
            "Q 837+677 T 1514 \u001b[91m☒\u001b[0m 1532\n",
            "Q 142+111 T 253  \u001b[91m☒\u001b[0m 276 \n",
            "Q 28+95   T 123  \u001b[91m☒\u001b[0m 125 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 11\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 119us/sample - loss: 0.6938 - accuracy: 0.7321 - val_loss: 0.6920 - val_accuracy: 0.7304\n",
            "Q 66+877  T 943  \u001b[92m☑\u001b[0m 943 \n",
            "Q 891+349 T 1240 \u001b[91m☒\u001b[0m 1244\n",
            "Q 883+86  T 969  \u001b[91m☒\u001b[0m 979 \n",
            "Q 74+416  T 490  \u001b[92m☑\u001b[0m 490 \n",
            "Q 84+554  T 638  \u001b[91m☒\u001b[0m 639 \n",
            "Q 726+849 T 1575 \u001b[91m☒\u001b[0m 1577\n",
            "Q 20+103  T 123  \u001b[91m☒\u001b[0m 122 \n",
            "Q 33+16   T 49   \u001b[92m☑\u001b[0m 49  \n",
            "Q 226+58  T 284  \u001b[91m☒\u001b[0m 279 \n",
            "Q 19+836  T 855  \u001b[91m☒\u001b[0m 852 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 12\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 111us/sample - loss: 0.6440 - accuracy: 0.7518 - val_loss: 0.6505 - val_accuracy: 0.7487\n",
            "Q 843+644 T 1487 \u001b[91m☒\u001b[0m 1480\n",
            "Q 903+656 T 1559 \u001b[91m☒\u001b[0m 1565\n",
            "Q 58+501  T 559  \u001b[91m☒\u001b[0m 569 \n",
            "Q 229+99  T 328  \u001b[91m☒\u001b[0m 314 \n",
            "Q 290+951 T 1241 \u001b[91m☒\u001b[0m 1235\n",
            "Q 642+645 T 1287 \u001b[91m☒\u001b[0m 1280\n",
            "Q 613+446 T 1059 \u001b[91m☒\u001b[0m 1054\n",
            "Q 49+159  T 208  \u001b[92m☑\u001b[0m 208 \n",
            "Q 106+8   T 114  \u001b[91m☒\u001b[0m 118 \n",
            "Q 57+788  T 845  \u001b[92m☑\u001b[0m 845 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 13\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 102us/sample - loss: 0.6014 - accuracy: 0.7696 - val_loss: 0.6059 - val_accuracy: 0.7653\n",
            "Q 0+686   T 686  \u001b[91m☒\u001b[0m 676 \n",
            "Q 9+655   T 664  \u001b[92m☑\u001b[0m 664 \n",
            "Q 838+3   T 841  \u001b[91m☒\u001b[0m 847 \n",
            "Q 368+54  T 422  \u001b[91m☒\u001b[0m 420 \n",
            "Q 78+849  T 927  \u001b[92m☑\u001b[0m 927 \n",
            "Q 855+90  T 945  \u001b[92m☑\u001b[0m 945 \n",
            "Q 83+987  T 1070 \u001b[92m☑\u001b[0m 1070\n",
            "Q 8+650   T 658  \u001b[92m☑\u001b[0m 658 \n",
            "Q 732+9   T 741  \u001b[91m☒\u001b[0m 730 \n",
            "Q 49+72   T 121  \u001b[91m☒\u001b[0m 122 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 14\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.5643 - accuracy: 0.7828 - val_loss: 0.5742 - val_accuracy: 0.7739\n",
            "Q 632+69  T 701  \u001b[91m☒\u001b[0m 791 \n",
            "Q 92+462  T 554  \u001b[91m☒\u001b[0m 564 \n",
            "Q 81+64   T 145  \u001b[91m☒\u001b[0m 146 \n",
            "Q 568+53  T 621  \u001b[91m☒\u001b[0m 620 \n",
            "Q 134+175 T 309  \u001b[91m☒\u001b[0m 211 \n",
            "Q 126+6   T 132  \u001b[91m☒\u001b[0m 138 \n",
            "Q 731+936 T 1667 \u001b[91m☒\u001b[0m 1670\n",
            "Q 854+47  T 901  \u001b[91m☒\u001b[0m 891 \n",
            "Q 47+152  T 199  \u001b[92m☑\u001b[0m 199 \n",
            "Q 243+504 T 747  \u001b[91m☒\u001b[0m 746 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 15\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 102us/sample - loss: 0.5265 - accuracy: 0.7962 - val_loss: 0.5248 - val_accuracy: 0.7945\n",
            "Q 866+0   T 866  \u001b[92m☑\u001b[0m 866 \n",
            "Q 930+314 T 1244 \u001b[92m☑\u001b[0m 1244\n",
            "Q 448+5   T 453  \u001b[92m☑\u001b[0m 453 \n",
            "Q 809+357 T 1166 \u001b[91m☒\u001b[0m 1153\n",
            "Q 971+901 T 1872 \u001b[91m☒\u001b[0m 1857\n",
            "Q 71+510  T 581  \u001b[92m☑\u001b[0m 581 \n",
            "Q 165+3   T 168  \u001b[91m☒\u001b[0m 161 \n",
            "Q 621+423 T 1044 \u001b[91m☒\u001b[0m 1049\n",
            "Q 926+632 T 1558 \u001b[92m☑\u001b[0m 1558\n",
            "Q 229+35  T 264  \u001b[91m☒\u001b[0m 269 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 16\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.4846 - accuracy: 0.8140 - val_loss: 0.4778 - val_accuracy: 0.8141\n",
            "Q 776+834 T 1610 \u001b[91m☒\u001b[0m 1516\n",
            "Q 455+77  T 532  \u001b[92m☑\u001b[0m 532 \n",
            "Q 33+856  T 889  \u001b[92m☑\u001b[0m 889 \n",
            "Q 200+59  T 259  \u001b[92m☑\u001b[0m 259 \n",
            "Q 331+221 T 552  \u001b[91m☒\u001b[0m 544 \n",
            "Q 79+426  T 505  \u001b[92m☑\u001b[0m 505 \n",
            "Q 444+61  T 505  \u001b[91m☒\u001b[0m 504 \n",
            "Q 454+9   T 463  \u001b[91m☒\u001b[0m 462 \n",
            "Q 767+28  T 795  \u001b[92m☑\u001b[0m 795 \n",
            "Q 400+976 T 1376 \u001b[91m☒\u001b[0m 1367\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 17\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.4558 - accuracy: 0.8247 - val_loss: 0.4723 - val_accuracy: 0.8170\n",
            "Q 28+220  T 248  \u001b[92m☑\u001b[0m 248 \n",
            "Q 346+46  T 392  \u001b[92m☑\u001b[0m 392 \n",
            "Q 831+681 T 1512 \u001b[91m☒\u001b[0m 1510\n",
            "Q 24+817  T 841  \u001b[92m☑\u001b[0m 841 \n",
            "Q 11+924  T 935  \u001b[92m☑\u001b[0m 935 \n",
            "Q 7+311   T 318  \u001b[91m☒\u001b[0m 327 \n",
            "Q 0+699   T 699  \u001b[92m☑\u001b[0m 699 \n",
            "Q 421+46  T 467  \u001b[92m☑\u001b[0m 467 \n",
            "Q 996+382 T 1378 \u001b[91m☒\u001b[0m 1364\n",
            "Q 29+327  T 356  \u001b[92m☑\u001b[0m 356 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 18\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.4177 - accuracy: 0.8411 - val_loss: 0.4305 - val_accuracy: 0.8309\n",
            "Q 2+228   T 230  \u001b[92m☑\u001b[0m 230 \n",
            "Q 22+186  T 208  \u001b[92m☑\u001b[0m 208 \n",
            "Q 632+77  T 709  \u001b[92m☑\u001b[0m 709 \n",
            "Q 11+268  T 279  \u001b[92m☑\u001b[0m 279 \n",
            "Q 51+148  T 199  \u001b[92m☑\u001b[0m 199 \n",
            "Q 96+573  T 669  \u001b[91m☒\u001b[0m 679 \n",
            "Q 97+349  T 446  \u001b[91m☒\u001b[0m 447 \n",
            "Q 17+656  T 673  \u001b[92m☑\u001b[0m 673 \n",
            "Q 25+755  T 780  \u001b[92m☑\u001b[0m 780 \n",
            "Q 1+758   T 759  \u001b[92m☑\u001b[0m 759 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 19\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 100us/sample - loss: 0.3974 - accuracy: 0.8490 - val_loss: 0.4203 - val_accuracy: 0.8382\n",
            "Q 974+6   T 980  \u001b[92m☑\u001b[0m 980 \n",
            "Q 977+1   T 978  \u001b[92m☑\u001b[0m 978 \n",
            "Q 94+953  T 1047 \u001b[91m☒\u001b[0m 1046\n",
            "Q 22+467  T 489  \u001b[92m☑\u001b[0m 489 \n",
            "Q 698+905 T 1603 \u001b[91m☒\u001b[0m 1697\n",
            "Q 6+390   T 396  \u001b[92m☑\u001b[0m 396 \n",
            "Q 959+0   T 959  \u001b[91m☒\u001b[0m 969 \n",
            "Q 41+836  T 877  \u001b[92m☑\u001b[0m 877 \n",
            "Q 282+33  T 315  \u001b[92m☑\u001b[0m 315 \n",
            "Q 88+766  T 854  \u001b[92m☑\u001b[0m 854 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 20\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.3690 - accuracy: 0.8605 - val_loss: 0.4144 - val_accuracy: 0.8386\n",
            "Q 964+942 T 1906 \u001b[91m☒\u001b[0m 1805\n",
            "Q 31+329  T 360  \u001b[91m☒\u001b[0m 350 \n",
            "Q 736+98  T 834  \u001b[91m☒\u001b[0m 935 \n",
            "Q 4+923   T 927  \u001b[92m☑\u001b[0m 927 \n",
            "Q 242+18  T 260  \u001b[91m☒\u001b[0m 250 \n",
            "Q 77+31   T 108  \u001b[92m☑\u001b[0m 108 \n",
            "Q 85+802  T 887  \u001b[91m☒\u001b[0m 888 \n",
            "Q 550+84  T 634  \u001b[91m☒\u001b[0m 635 \n",
            "Q 26+517  T 543  \u001b[92m☑\u001b[0m 543 \n",
            "Q 46+420  T 466  \u001b[92m☑\u001b[0m 466 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 21\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.3525 - accuracy: 0.8654 - val_loss: 0.3803 - val_accuracy: 0.8492\n",
            "Q 12+953  T 965  \u001b[92m☑\u001b[0m 965 \n",
            "Q 3+514   T 517  \u001b[92m☑\u001b[0m 517 \n",
            "Q 3+389   T 392  \u001b[92m☑\u001b[0m 392 \n",
            "Q 54+223  T 277  \u001b[92m☑\u001b[0m 277 \n",
            "Q 57+322  T 379  \u001b[91m☒\u001b[0m 389 \n",
            "Q 274+74  T 348  \u001b[92m☑\u001b[0m 348 \n",
            "Q 716+931 T 1647 \u001b[91m☒\u001b[0m 1657\n",
            "Q 580+3   T 583  \u001b[91m☒\u001b[0m 582 \n",
            "Q 791+0   T 791  \u001b[92m☑\u001b[0m 791 \n",
            "Q 665+735 T 1400 \u001b[91m☒\u001b[0m 1490\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 22\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 99us/sample - loss: 0.3335 - accuracy: 0.8710 - val_loss: 0.3734 - val_accuracy: 0.8537\n",
            "Q 181+935 T 1116 \u001b[91m☒\u001b[0m 1218\n",
            "Q 6+835   T 841  \u001b[92m☑\u001b[0m 841 \n",
            "Q 218+2   T 220  \u001b[92m☑\u001b[0m 220 \n",
            "Q 756+24  T 780  \u001b[92m☑\u001b[0m 780 \n",
            "Q 121+958 T 1079 \u001b[91m☒\u001b[0m 1089\n",
            "Q 45+160  T 205  \u001b[91m☒\u001b[0m 204 \n",
            "Q 646+70  T 716  \u001b[92m☑\u001b[0m 716 \n",
            "Q 25+591  T 616  \u001b[92m☑\u001b[0m 616 \n",
            "Q 31+653  T 684  \u001b[92m☑\u001b[0m 684 \n",
            "Q 598+35  T 633  \u001b[91m☒\u001b[0m 632 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 23\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 100us/sample - loss: 0.3027 - accuracy: 0.8842 - val_loss: 0.3326 - val_accuracy: 0.8688\n",
            "Q 537+34  T 571  \u001b[92m☑\u001b[0m 571 \n",
            "Q 9+627   T 636  \u001b[92m☑\u001b[0m 636 \n",
            "Q 31+922  T 953  \u001b[91m☒\u001b[0m 954 \n",
            "Q 29+144  T 173  \u001b[91m☒\u001b[0m 183 \n",
            "Q 220+77  T 297  \u001b[92m☑\u001b[0m 297 \n",
            "Q 461+77  T 538  \u001b[92m☑\u001b[0m 538 \n",
            "Q 18+16   T 34   \u001b[91m☒\u001b[0m 35  \n",
            "Q 32+146  T 178  \u001b[92m☑\u001b[0m 178 \n",
            "Q 342+82  T 424  \u001b[92m☑\u001b[0m 424 \n",
            "Q 16+904  T 920  \u001b[92m☑\u001b[0m 920 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 24\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 100us/sample - loss: 0.2873 - accuracy: 0.8889 - val_loss: 0.3101 - val_accuracy: 0.8758\n",
            "Q 6+534   T 540  \u001b[92m☑\u001b[0m 540 \n",
            "Q 186+389 T 575  \u001b[92m☑\u001b[0m 575 \n",
            "Q 22+571  T 593  \u001b[91m☒\u001b[0m 693 \n",
            "Q 54+671  T 725  \u001b[92m☑\u001b[0m 725 \n",
            "Q 302+372 T 674  \u001b[91m☒\u001b[0m 679 \n",
            "Q 507+62  T 569  \u001b[91m☒\u001b[0m 579 \n",
            "Q 956+828 T 1784 \u001b[91m☒\u001b[0m 1785\n",
            "Q 538+19  T 557  \u001b[92m☑\u001b[0m 557 \n",
            "Q 81+490  T 571  \u001b[92m☑\u001b[0m 571 \n",
            "Q 995+93  T 1088 \u001b[91m☒\u001b[0m 1089\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 25\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.2698 - accuracy: 0.8966 - val_loss: 0.2871 - val_accuracy: 0.8850\n",
            "Q 110+949 T 1059 \u001b[91m☒\u001b[0m 1070\n",
            "Q 530+861 T 1391 \u001b[91m☒\u001b[0m 1390\n",
            "Q 539+938 T 1477 \u001b[92m☑\u001b[0m 1477\n",
            "Q 512+487 T 999  \u001b[91m☒\u001b[0m 904 \n",
            "Q 3+39    T 42   \u001b[92m☑\u001b[0m 42  \n",
            "Q 951+583 T 1534 \u001b[91m☒\u001b[0m 1539\n",
            "Q 732+0   T 732  \u001b[92m☑\u001b[0m 732 \n",
            "Q 183+6   T 189  \u001b[91m☒\u001b[0m 188 \n",
            "Q 272+68  T 340  \u001b[91m☒\u001b[0m 330 \n",
            "Q 63+790  T 853  \u001b[92m☑\u001b[0m 853 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 26\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 100us/sample - loss: 0.2541 - accuracy: 0.9022 - val_loss: 0.2847 - val_accuracy: 0.8892\n",
            "Q 0+461   T 461  \u001b[92m☑\u001b[0m 461 \n",
            "Q 834+87  T 921  \u001b[92m☑\u001b[0m 921 \n",
            "Q 936+3   T 939  \u001b[92m☑\u001b[0m 939 \n",
            "Q 579+423 T 1002 \u001b[91m☒\u001b[0m 901 \n",
            "Q 38+987  T 1025 \u001b[92m☑\u001b[0m 1025\n",
            "Q 118+88  T 206  \u001b[91m☒\u001b[0m 205 \n",
            "Q 98+228  T 326  \u001b[92m☑\u001b[0m 326 \n",
            "Q 680+54  T 734  \u001b[92m☑\u001b[0m 734 \n",
            "Q 97+206  T 303  \u001b[92m☑\u001b[0m 303 \n",
            "Q 696+69  T 765  \u001b[92m☑\u001b[0m 765 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 27\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 104us/sample - loss: 0.2359 - accuracy: 0.9098 - val_loss: 0.2687 - val_accuracy: 0.8934\n",
            "Q 593+91  T 684  \u001b[92m☑\u001b[0m 684 \n",
            "Q 36+36   T 72   \u001b[92m☑\u001b[0m 72  \n",
            "Q 960+395 T 1355 \u001b[91m☒\u001b[0m 1365\n",
            "Q 98+922  T 1020 \u001b[91m☒\u001b[0m 1010\n",
            "Q 622+98  T 720  \u001b[91m☒\u001b[0m 710 \n",
            "Q 685+19  T 704  \u001b[91m☒\u001b[0m 604 \n",
            "Q 454+346 T 800  \u001b[91m☒\u001b[0m 890 \n",
            "Q 188+95  T 283  \u001b[92m☑\u001b[0m 283 \n",
            "Q 824+248 T 1072 \u001b[91m☒\u001b[0m 1071\n",
            "Q 591+869 T 1460 \u001b[92m☑\u001b[0m 1460\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 28\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 118us/sample - loss: 0.2206 - accuracy: 0.9170 - val_loss: 0.2558 - val_accuracy: 0.9000\n",
            "Q 13+12   T 25   \u001b[92m☑\u001b[0m 25  \n",
            "Q 73+41   T 114  \u001b[91m☒\u001b[0m 124 \n",
            "Q 3+624   T 627  \u001b[92m☑\u001b[0m 627 \n",
            "Q 542+8   T 550  \u001b[92m☑\u001b[0m 550 \n",
            "Q 22+72   T 94   \u001b[92m☑\u001b[0m 94  \n",
            "Q 74+790  T 864  \u001b[92m☑\u001b[0m 864 \n",
            "Q 0+525   T 525  \u001b[92m☑\u001b[0m 525 \n",
            "Q 33+778  T 811  \u001b[92m☑\u001b[0m 811 \n",
            "Q 663+541 T 1204 \u001b[92m☑\u001b[0m 1204\n",
            "Q 85+642  T 727  \u001b[92m☑\u001b[0m 727 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 29\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 112us/sample - loss: 0.2189 - accuracy: 0.9174 - val_loss: 0.2123 - val_accuracy: 0.9194\n",
            "Q 5+689   T 694  \u001b[92m☑\u001b[0m 694 \n",
            "Q 74+219  T 293  \u001b[92m☑\u001b[0m 293 \n",
            "Q 88+355  T 443  \u001b[92m☑\u001b[0m 443 \n",
            "Q 998+7   T 1005 \u001b[92m☑\u001b[0m 1005\n",
            "Q 78+8    T 86   \u001b[91m☒\u001b[0m 85  \n",
            "Q 86+875  T 961  \u001b[91m☒\u001b[0m 971 \n",
            "Q 426+41  T 467  \u001b[92m☑\u001b[0m 467 \n",
            "Q 701+7   T 708  \u001b[92m☑\u001b[0m 708 \n",
            "Q 5+232   T 237  \u001b[92m☑\u001b[0m 237 \n",
            "Q 907+569 T 1476 \u001b[91m☒\u001b[0m 1475\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 30\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 122us/sample - loss: 0.1883 - accuracy: 0.9302 - val_loss: 0.2169 - val_accuracy: 0.9171\n",
            "Q 77+32   T 109  \u001b[91m☒\u001b[0m 119 \n",
            "Q 59+5    T 64   \u001b[91m☒\u001b[0m 55  \n",
            "Q 3+544   T 547  \u001b[92m☑\u001b[0m 547 \n",
            "Q 0+181   T 181  \u001b[92m☑\u001b[0m 181 \n",
            "Q 97+526  T 623  \u001b[92m☑\u001b[0m 623 \n",
            "Q 612+2   T 614  \u001b[91m☒\u001b[0m 615 \n",
            "Q 22+69   T 91   \u001b[91m☒\u001b[0m 90  \n",
            "Q 464+62  T 526  \u001b[92m☑\u001b[0m 526 \n",
            "Q 2+606   T 608  \u001b[92m☑\u001b[0m 608 \n",
            "Q 92+31   T 123  \u001b[92m☑\u001b[0m 123 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 31\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 118us/sample - loss: 0.1889 - accuracy: 0.9294 - val_loss: 0.2154 - val_accuracy: 0.9152\n",
            "Q 45+109  T 154  \u001b[92m☑\u001b[0m 154 \n",
            "Q 8+160   T 168  \u001b[92m☑\u001b[0m 168 \n",
            "Q 198+258 T 456  \u001b[91m☒\u001b[0m 455 \n",
            "Q 369+362 T 731  \u001b[91m☒\u001b[0m 730 \n",
            "Q 880+87  T 967  \u001b[91m☒\u001b[0m 977 \n",
            "Q 164+110 T 274  \u001b[91m☒\u001b[0m 375 \n",
            "Q 230+561 T 791  \u001b[92m☑\u001b[0m 791 \n",
            "Q 704+32  T 736  \u001b[92m☑\u001b[0m 736 \n",
            "Q 100+384 T 484  \u001b[91m☒\u001b[0m 584 \n",
            "Q 5+855   T 860  \u001b[91m☒\u001b[0m 869 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 32\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 99us/sample - loss: 0.1755 - accuracy: 0.9346 - val_loss: 0.1961 - val_accuracy: 0.9248\n",
            "Q 30+94   T 124  \u001b[92m☑\u001b[0m 124 \n",
            "Q 96+581  T 677  \u001b[92m☑\u001b[0m 677 \n",
            "Q 6+729   T 735  \u001b[92m☑\u001b[0m 735 \n",
            "Q 29+327  T 356  \u001b[92m☑\u001b[0m 356 \n",
            "Q 510+602 T 1112 \u001b[91m☒\u001b[0m 1113\n",
            "Q 881+16  T 897  \u001b[92m☑\u001b[0m 897 \n",
            "Q 358+6   T 364  \u001b[92m☑\u001b[0m 364 \n",
            "Q 251+93  T 344  \u001b[92m☑\u001b[0m 344 \n",
            "Q 98+473  T 571  \u001b[92m☑\u001b[0m 571 \n",
            "Q 837+34  T 871  \u001b[92m☑\u001b[0m 871 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 33\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 100us/sample - loss: 0.1597 - accuracy: 0.9411 - val_loss: 0.2021 - val_accuracy: 0.9237\n",
            "Q 3+186   T 189  \u001b[92m☑\u001b[0m 189 \n",
            "Q 842+234 T 1076 \u001b[91m☒\u001b[0m 986 \n",
            "Q 169+32  T 201  \u001b[92m☑\u001b[0m 201 \n",
            "Q 199+751 T 950  \u001b[91m☒\u001b[0m 940 \n",
            "Q 4+820   T 824  \u001b[92m☑\u001b[0m 824 \n",
            "Q 173+78  T 251  \u001b[91m☒\u001b[0m 252 \n",
            "Q 992+95  T 1087 \u001b[92m☑\u001b[0m 1087\n",
            "Q 38+20   T 58   \u001b[92m☑\u001b[0m 58  \n",
            "Q 117+102 T 219  \u001b[91m☒\u001b[0m 229 \n",
            "Q 23+44   T 67   \u001b[92m☑\u001b[0m 67  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 34\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 100us/sample - loss: 0.1622 - accuracy: 0.9409 - val_loss: 0.1928 - val_accuracy: 0.9276\n",
            "Q 627+1   T 628  \u001b[92m☑\u001b[0m 628 \n",
            "Q 36+22   T 58   \u001b[92m☑\u001b[0m 58  \n",
            "Q 307+2   T 309  \u001b[92m☑\u001b[0m 309 \n",
            "Q 566+93  T 659  \u001b[92m☑\u001b[0m 659 \n",
            "Q 53+208  T 261  \u001b[92m☑\u001b[0m 261 \n",
            "Q 1+69    T 70   \u001b[91m☒\u001b[0m 60  \n",
            "Q 1+485   T 486  \u001b[92m☑\u001b[0m 486 \n",
            "Q 425+200 T 625  \u001b[91m☒\u001b[0m 626 \n",
            "Q 5+212   T 217  \u001b[92m☑\u001b[0m 217 \n",
            "Q 785+254 T 1039 \u001b[92m☑\u001b[0m 1039\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 35\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.1604 - accuracy: 0.9407 - val_loss: 0.1869 - val_accuracy: 0.9306\n",
            "Q 31+358  T 389  \u001b[92m☑\u001b[0m 389 \n",
            "Q 423+57  T 480  \u001b[91m☒\u001b[0m 470 \n",
            "Q 417+31  T 448  \u001b[92m☑\u001b[0m 448 \n",
            "Q 946+28  T 974  \u001b[92m☑\u001b[0m 974 \n",
            "Q 22+261  T 283  \u001b[92m☑\u001b[0m 283 \n",
            "Q 787+254 T 1041 \u001b[91m☒\u001b[0m 1042\n",
            "Q 233+57  T 290  \u001b[92m☑\u001b[0m 290 \n",
            "Q 93+20   T 113  \u001b[92m☑\u001b[0m 113 \n",
            "Q 75+406  T 481  \u001b[92m☑\u001b[0m 481 \n",
            "Q 88+54   T 142  \u001b[92m☑\u001b[0m 142 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 36\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 100us/sample - loss: 0.1406 - accuracy: 0.9494 - val_loss: 0.1691 - val_accuracy: 0.9341\n",
            "Q 695+900 T 1595 \u001b[92m☑\u001b[0m 1595\n",
            "Q 202+144 T 346  \u001b[91m☒\u001b[0m 345 \n",
            "Q 140+69  T 209  \u001b[92m☑\u001b[0m 209 \n",
            "Q 673+57  T 730  \u001b[92m☑\u001b[0m 730 \n",
            "Q 503+32  T 535  \u001b[92m☑\u001b[0m 535 \n",
            "Q 48+943  T 991  \u001b[92m☑\u001b[0m 991 \n",
            "Q 78+43   T 121  \u001b[91m☒\u001b[0m 122 \n",
            "Q 479+58  T 537  \u001b[92m☑\u001b[0m 537 \n",
            "Q 860+406 T 1266 \u001b[92m☑\u001b[0m 1266\n",
            "Q 857+673 T 1530 \u001b[92m☑\u001b[0m 1530\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 37\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 100us/sample - loss: 0.1454 - accuracy: 0.9466 - val_loss: 0.1708 - val_accuracy: 0.9360\n",
            "Q 62+585  T 647  \u001b[92m☑\u001b[0m 647 \n",
            "Q 17+118  T 135  \u001b[92m☑\u001b[0m 135 \n",
            "Q 178+71  T 249  \u001b[92m☑\u001b[0m 249 \n",
            "Q 88+615  T 703  \u001b[92m☑\u001b[0m 703 \n",
            "Q 380+2   T 382  \u001b[92m☑\u001b[0m 382 \n",
            "Q 1+586   T 587  \u001b[92m☑\u001b[0m 587 \n",
            "Q 8+897   T 905  \u001b[92m☑\u001b[0m 905 \n",
            "Q 775+68  T 843  \u001b[92m☑\u001b[0m 843 \n",
            "Q 4+923   T 927  \u001b[92m☑\u001b[0m 927 \n",
            "Q 421+502 T 923  \u001b[92m☑\u001b[0m 923 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 38\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.1379 - accuracy: 0.9497 - val_loss: 0.1815 - val_accuracy: 0.9316\n",
            "Q 964+301 T 1265 \u001b[91m☒\u001b[0m 1264\n",
            "Q 9+465   T 474  \u001b[92m☑\u001b[0m 474 \n",
            "Q 843+43  T 886  \u001b[91m☒\u001b[0m 887 \n",
            "Q 375+55  T 430  \u001b[92m☑\u001b[0m 430 \n",
            "Q 92+828  T 920  \u001b[92m☑\u001b[0m 920 \n",
            "Q 13+0    T 13   \u001b[91m☒\u001b[0m 12  \n",
            "Q 99+181  T 280  \u001b[92m☑\u001b[0m 280 \n",
            "Q 341+449 T 790  \u001b[92m☑\u001b[0m 790 \n",
            "Q 812+35  T 847  \u001b[92m☑\u001b[0m 847 \n",
            "Q 501+20  T 521  \u001b[91m☒\u001b[0m 511 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 39\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 101us/sample - loss: 0.1360 - accuracy: 0.9506 - val_loss: 0.1662 - val_accuracy: 0.9395\n",
            "Q 58+78   T 136  \u001b[92m☑\u001b[0m 136 \n",
            "Q 78+707  T 785  \u001b[92m☑\u001b[0m 785 \n",
            "Q 369+4   T 373  \u001b[92m☑\u001b[0m 373 \n",
            "Q 317+3   T 320  \u001b[92m☑\u001b[0m 320 \n",
            "Q 398+18  T 416  \u001b[92m☑\u001b[0m 416 \n",
            "Q 369+362 T 731  \u001b[92m☑\u001b[0m 731 \n",
            "Q 687+226 T 913  \u001b[92m☑\u001b[0m 913 \n",
            "Q 747+784 T 1531 \u001b[92m☑\u001b[0m 1531\n",
            "Q 819+60  T 879  \u001b[92m☑\u001b[0m 879 \n",
            "Q 25+572  T 597  \u001b[91m☒\u001b[0m 697 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 40\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 100us/sample - loss: 0.1312 - accuracy: 0.9534 - val_loss: 0.1454 - val_accuracy: 0.9470\n",
            "Q 118+53  T 171  \u001b[92m☑\u001b[0m 171 \n",
            "Q 73+71   T 144  \u001b[91m☒\u001b[0m 154 \n",
            "Q 624+339 T 963  \u001b[92m☑\u001b[0m 963 \n",
            "Q 109+33  T 142  \u001b[92m☑\u001b[0m 142 \n",
            "Q 15+955  T 970  \u001b[92m☑\u001b[0m 970 \n",
            "Q 31+665  T 696  \u001b[92m☑\u001b[0m 696 \n",
            "Q 985+43  T 1028 \u001b[92m☑\u001b[0m 1028\n",
            "Q 708+991 T 1699 \u001b[91m☒\u001b[0m 1799\n",
            "Q 90+187  T 277  \u001b[92m☑\u001b[0m 277 \n",
            "Q 955+9   T 964  \u001b[91m☒\u001b[0m 974 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 41\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 100us/sample - loss: 0.1244 - accuracy: 0.9556 - val_loss: 0.1295 - val_accuracy: 0.9516\n",
            "Q 72+550  T 622  \u001b[92m☑\u001b[0m 622 \n",
            "Q 977+997 T 1974 \u001b[91m☒\u001b[0m 1874\n",
            "Q 372+3   T 375  \u001b[92m☑\u001b[0m 375 \n",
            "Q 701+415 T 1116 \u001b[92m☑\u001b[0m 1116\n",
            "Q 837+677 T 1514 \u001b[92m☑\u001b[0m 1514\n",
            "Q 916+68  T 984  \u001b[92m☑\u001b[0m 984 \n",
            "Q 288+778 T 1066 \u001b[91m☒\u001b[0m 1065\n",
            "Q 274+73  T 347  \u001b[92m☑\u001b[0m 347 \n",
            "Q 869+9   T 878  \u001b[92m☑\u001b[0m 878 \n",
            "Q 21+888  T 909  \u001b[92m☑\u001b[0m 909 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 42\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 100us/sample - loss: 0.1161 - accuracy: 0.9588 - val_loss: 0.1546 - val_accuracy: 0.9433\n",
            "Q 96+564  T 660  \u001b[92m☑\u001b[0m 660 \n",
            "Q 701+7   T 708  \u001b[91m☒\u001b[0m 707 \n",
            "Q 68+570  T 638  \u001b[92m☑\u001b[0m 638 \n",
            "Q 835+953 T 1788 \u001b[92m☑\u001b[0m 1788\n",
            "Q 3+389   T 392  \u001b[92m☑\u001b[0m 392 \n",
            "Q 90+111  T 201  \u001b[92m☑\u001b[0m 201 \n",
            "Q 957+728 T 1685 \u001b[92m☑\u001b[0m 1685\n",
            "Q 428+41  T 469  \u001b[92m☑\u001b[0m 469 \n",
            "Q 670+539 T 1209 \u001b[92m☑\u001b[0m 1209\n",
            "Q 15+101  T 116  \u001b[92m☑\u001b[0m 116 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 43\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 100us/sample - loss: 0.1304 - accuracy: 0.9525 - val_loss: 0.1577 - val_accuracy: 0.9416\n",
            "Q 168+744 T 912  \u001b[92m☑\u001b[0m 912 \n",
            "Q 93+31   T 124  \u001b[92m☑\u001b[0m 124 \n",
            "Q 893+46  T 939  \u001b[92m☑\u001b[0m 939 \n",
            "Q 416+51  T 467  \u001b[92m☑\u001b[0m 467 \n",
            "Q 3+944   T 947  \u001b[92m☑\u001b[0m 947 \n",
            "Q 696+24  T 720  \u001b[92m☑\u001b[0m 720 \n",
            "Q 250+24  T 274  \u001b[92m☑\u001b[0m 274 \n",
            "Q 532+610 T 1142 \u001b[92m☑\u001b[0m 1142\n",
            "Q 38+329  T 367  \u001b[92m☑\u001b[0m 367 \n",
            "Q 18+502  T 520  \u001b[92m☑\u001b[0m 520 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 44\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 107us/sample - loss: 0.1017 - accuracy: 0.9647 - val_loss: 0.1239 - val_accuracy: 0.9543\n",
            "Q 184+89  T 273  \u001b[92m☑\u001b[0m 273 \n",
            "Q 415+850 T 1265 \u001b[91m☒\u001b[0m 1255\n",
            "Q 258+920 T 1178 \u001b[92m☑\u001b[0m 1178\n",
            "Q 352+52  T 404  \u001b[92m☑\u001b[0m 404 \n",
            "Q 912+2   T 914  \u001b[92m☑\u001b[0m 914 \n",
            "Q 684+760 T 1444 \u001b[92m☑\u001b[0m 1444\n",
            "Q 108+487 T 595  \u001b[91m☒\u001b[0m 695 \n",
            "Q 12+652  T 664  \u001b[92m☑\u001b[0m 664 \n",
            "Q 387+88  T 475  \u001b[92m☑\u001b[0m 475 \n",
            "Q 910+57  T 967  \u001b[92m☑\u001b[0m 967 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 45\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 118us/sample - loss: 0.1101 - accuracy: 0.9606 - val_loss: 0.1779 - val_accuracy: 0.9352\n",
            "Q 80+871  T 951  \u001b[92m☑\u001b[0m 951 \n",
            "Q 25+44   T 69   \u001b[92m☑\u001b[0m 69  \n",
            "Q 1+535   T 536  \u001b[92m☑\u001b[0m 536 \n",
            "Q 22+69   T 91   \u001b[92m☑\u001b[0m 91  \n",
            "Q 205+93  T 298  \u001b[92m☑\u001b[0m 298 \n",
            "Q 16+35   T 51   \u001b[91m☒\u001b[0m 52  \n",
            "Q 8+756   T 764  \u001b[92m☑\u001b[0m 764 \n",
            "Q 19+469  T 488  \u001b[92m☑\u001b[0m 488 \n",
            "Q 482+318 T 800  \u001b[92m☑\u001b[0m 800 \n",
            "Q 316+24  T 340  \u001b[92m☑\u001b[0m 340 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 46\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 5s 110us/sample - loss: 0.1004 - accuracy: 0.9646 - val_loss: 0.1983 - val_accuracy: 0.9311\n",
            "Q 559+82  T 641  \u001b[91m☒\u001b[0m 651 \n",
            "Q 776+80  T 856  \u001b[92m☑\u001b[0m 856 \n",
            "Q 341+52  T 393  \u001b[92m☑\u001b[0m 393 \n",
            "Q 273+57  T 330  \u001b[92m☑\u001b[0m 330 \n",
            "Q 2+366   T 368  \u001b[92m☑\u001b[0m 368 \n",
            "Q 960+395 T 1355 \u001b[92m☑\u001b[0m 1355\n",
            "Q 365+13  T 378  \u001b[92m☑\u001b[0m 378 \n",
            "Q 2+734   T 736  \u001b[91m☒\u001b[0m 746 \n",
            "Q 9+932   T 941  \u001b[92m☑\u001b[0m 941 \n",
            "Q 951+583 T 1534 \u001b[92m☑\u001b[0m 1534\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 47\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 99us/sample - loss: 0.1153 - accuracy: 0.9586 - val_loss: 0.1560 - val_accuracy: 0.9417\n",
            "Q 9+119   T 128  \u001b[92m☑\u001b[0m 128 \n",
            "Q 91+201  T 292  \u001b[92m☑\u001b[0m 292 \n",
            "Q 402+88  T 490  \u001b[91m☒\u001b[0m 491 \n",
            "Q 603+88  T 691  \u001b[92m☑\u001b[0m 691 \n",
            "Q 24+78   T 102  \u001b[92m☑\u001b[0m 102 \n",
            "Q 980+59  T 1039 \u001b[92m☑\u001b[0m 1039\n",
            "Q 67+476  T 543  \u001b[92m☑\u001b[0m 543 \n",
            "Q 297+402 T 699  \u001b[92m☑\u001b[0m 699 \n",
            "Q 22+748  T 770  \u001b[92m☑\u001b[0m 770 \n",
            "Q 698+0   T 698  \u001b[92m☑\u001b[0m 698 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 48\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 99us/sample - loss: 0.0984 - accuracy: 0.9653 - val_loss: 0.1244 - val_accuracy: 0.9545\n",
            "Q 501+589 T 1090 \u001b[91m☒\u001b[0m 1080\n",
            "Q 10+638  T 648  \u001b[92m☑\u001b[0m 648 \n",
            "Q 435+154 T 589  \u001b[91m☒\u001b[0m 599 \n",
            "Q 75+66   T 141  \u001b[92m☑\u001b[0m 141 \n",
            "Q 109+84  T 193  \u001b[92m☑\u001b[0m 193 \n",
            "Q 90+111  T 201  \u001b[92m☑\u001b[0m 201 \n",
            "Q 2+108   T 110  \u001b[92m☑\u001b[0m 110 \n",
            "Q 774+76  T 850  \u001b[92m☑\u001b[0m 850 \n",
            "Q 498+884 T 1382 \u001b[91m☒\u001b[0m 1283\n",
            "Q 641+986 T 1627 \u001b[92m☑\u001b[0m 1627\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 49\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "45000/45000 [==============================] - 4s 99us/sample - loss: 0.1059 - accuracy: 0.9632 - val_loss: 0.1153 - val_accuracy: 0.9582\n",
            "Q 7+61    T 68   \u001b[92m☑\u001b[0m 68  \n",
            "Q 1+134   T 135  \u001b[92m☑\u001b[0m 135 \n",
            "Q 92+584  T 676  \u001b[92m☑\u001b[0m 676 \n",
            "Q 57+58   T 115  \u001b[92m☑\u001b[0m 115 \n",
            "Q 2+658   T 660  \u001b[92m☑\u001b[0m 660 \n",
            "Q 268+830 T 1098 \u001b[92m☑\u001b[0m 1098\n",
            "Q 840+94  T 934  \u001b[92m☑\u001b[0m 934 \n",
            "Q 69+160  T 229  \u001b[92m☑\u001b[0m 229 \n",
            "Q 62+6    T 68   \u001b[92m☑\u001b[0m 68  \n",
            "Q 618+8   T 626  \u001b[91m☒\u001b[0m 625 \n",
            "CPU times: user 5min 37s, sys: 30.6 s, total: 6min 8s\n",
            "Wall time: 3min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7apd-uAFjVHY",
        "colab_type": "code",
        "outputId": "598d5c59-f42b-4a8f-8461-57ab3743924b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.plot(merged_losses['loss'])\n",
        "plt.plot(merged_losses['val_loss'])\n",
        "\n",
        "plt.legend(['loss', 'validation loss'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2c5d49d780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bxojIpIhngkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "93b4bbe4-a286-45fe-ade3-e08d54fa1fbe"
      },
      "cell_type": "code",
      "source": [
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "# plt.yscale('log')\n",
        "\n",
        "plt.plot(merged_losses['accuracy'])\n",
        "plt.plot(merged_losses['val_accuracy'])\n",
        "\n",
        "plt.legend(['accuracy', 'validation accuracy'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2c5d2759e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noJRSqpQmBaWUUqU0KSillCr1/6P0k5q5BFE7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "b2_zvW8OTX9h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}