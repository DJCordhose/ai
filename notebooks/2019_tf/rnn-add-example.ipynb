{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn-add-example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/2019_tf/rnn-add-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Zqi1xb086Gl_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapted from\n",
        "# https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3ey4zBb6GmE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8uDkaTi6GmH",
        "colab_type": "code",
        "outputId": "effade27-3793-4880-d672-458e52271e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8ZQZTEee6GmM",
        "colab_type": "code",
        "outputId": "3026dfa7-f6d0-4851-e904-87a1ffaee079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7kBle7aI9O7O",
        "colab_type": "code",
        "outputId": "60268cdb-5a3e-4623-c387-9d6a7fbfff1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# let's see what compute devices we have available, hopefully a GPU \n",
        "sess = tf.Session()\n",
        "devices = sess.list_devices()\n",
        "for d in devices:\n",
        "    print(d.name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/job:localhost/replica:0/task:0/device:CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0\n",
            "/job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k7rxZQym9PcT",
        "colab_type": "code",
        "outputId": "ad628e26-36db-4f4f-cfee-b54c7380a381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# a small sanity check, does tf seem to work ok?\n",
        "hello = tf.constant('Hello TF!')\n",
        "print(sess.run(hello))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello TF!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2gCgM1JJ9T2v",
        "colab_type": "code",
        "outputId": "3ec5caaa-91b8-4682-8442-2cde24ac3f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.6-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SEvTJtaL6GmR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1: Generate sample equations"
      ]
    },
    {
      "metadata": {
        "id": "IAz9Tnpu6GmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one hot integer representation\n",
        "    + Decode the one hot integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One hot encode given string C.\n",
        "\n",
        "        # Arguments\n",
        "            num_rows: Number of rows in the returned one hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DqdzUFGZ6GmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class colors:\n",
        "    ok = '\\033[92m'\n",
        "    fail = '\\033[91m'\n",
        "    close = '\\033[0m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kf7L7DwB6GmY",
        "colab_type": "code",
        "outputId": "ba77105b-5de7-4486-cf5b-8fd4de8add9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "# REVERSE = True\n",
        "REVERSE = False\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = '0123456789+ '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}+{}'.format(a, b)\n",
        "    query = q + ' ' * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print('Total addition questions:', len(questions))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gTLONdDN6Gmc",
        "colab_type": "code",
        "outputId": "9e15f956-8b73-4db8-e6d5-a91297f837ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "questions[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'83+335 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "L6n6X_w26Gmg",
        "colab_type": "code",
        "outputId": "377ee977-4bfb-42db-bcf9-13c972e3e2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L1rqJg9v6Gmk",
        "colab_type": "code",
        "outputId": "56af22f2-171d-4211-938a-6e20f737e530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(x[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "0lgZ9xs-6Gmo",
        "colab_type": "code",
        "outputId": "47bd1e79-9a84-42fb-f5b0-54aaba106a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(questions[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "5MU2q5Jp6Gmr",
        "colab_type": "code",
        "outputId": "f0f18692-17a2-48c3-b257-2f89cc80b273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "questions[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'83+335 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "NLtol2BUW1tk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input is encoded as one-hot, 7 digits times 12 possibilities"
      ]
    },
    {
      "metadata": {
        "id": "wZ_g5cHf6Gmw",
        "colab_type": "code",
        "outputId": "8f5a8b74-be00-4a50-8a28-2448a0138580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False, False, False, False,\n",
              "        False,  True, False],\n",
              "       [False, False, False, False, False,  True, False, False, False,\n",
              "        False, False, False],\n",
              "       [False,  True, False, False, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False,  True, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False,  True, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False, False, False,  True, False,\n",
              "        False, False, False],\n",
              "       [ True, False, False, False, False, False, False, False, False,\n",
              "        False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "mbX2RzJVW-dN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Same for output, but at most 4 digits"
      ]
    },
    {
      "metadata": {
        "id": "hWldgEEJ6Gmz",
        "colab_type": "code",
        "outputId": "a97a1d8c-a5f3-4100-f5ad-19fa1b998feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False,  True, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False,  True, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False,  True, False],\n",
              "       [ True, False, False, False, False, False, False, False, False,\n",
              "        False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "o-r8EDwQ6Gm5",
        "colab_type": "code",
        "outputId": "828f849a-d663-4e49-b9ed-388e80e984ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "expected[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'418 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "XPO5c5xe6GnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "envfa2ZT6GnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2: Training/Validation Split"
      ]
    },
    {
      "metadata": {
        "id": "bDSoeziy6GnE",
        "colab_type": "code",
        "outputId": "5a1b55be-0a76-4fe9-dac0-69ba7207ff23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "cell_type": "code",
      "source": [
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print('Training Data:')\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('Validation Data:')\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bPUg9slY6GnK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3: Create Model"
      ]
    },
    {
      "metadata": {
        "id": "wK_ll_ew6GnL",
        "colab_type": "code",
        "outputId": "f52de4af-560d-4099-e18e-4cee79eb7b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# input shape: 7 digits, each being 0-9, + or space (12 possibilities)\n",
        "MAXLEN, len(chars)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "dksl6o766GnO",
        "colab_type": "code",
        "outputId": "0a7fc55c-f441-4094-ed77-ae69763b9792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  LSTM, GRU, SimpleRNN, Dense, RepeatVector\n",
        "\n",
        "# Try replacing LSTM, GRU, or SimpleRNN.\n",
        "# RNN = LSTM\n",
        "RNN = SimpleRNN # should be enough since we do not have long sequences and only local dependencies\n",
        "# RNN = GRU\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "model = Sequential()\n",
        "# encoder \n",
        "model.add(RNN(units=HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "\n",
        "# latent space\n",
        "encoding_dim = 32\n",
        "model.add(Dense(units=encoding_dim, activation='relu', name=\"encoder\"))\n",
        "\n",
        "# decoder: have 4 temporal outputs one for each of the digits of the results\n",
        "model.add(RepeatVector(DIGITS + 1))\n",
        "\n",
        "# return_sequences=True tells it to keep all 4 temporal outputs, not only the final one (we need all four digits for the results)\n",
        "model.add(RNN(units=HIDDEN_SIZE, return_sequences=True))\n",
        "\n",
        "model.add(Dense(name='classifier', units=len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 128)               18048     \n",
            "_________________________________________________________________\n",
            "encoder (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 4, 128)            20608     \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 44,332\n",
            "Trainable params: 44,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FBCYGAqBXWlY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Before training lets look at sample input and output"
      ]
    },
    {
      "metadata": {
        "id": "tTb9qwNcXfBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "d0563eb5-d068-4b2a-fbc4-6efb34ff1efe"
      },
      "cell_type": "code",
      "source": [
        "# input one-hot\n",
        "x_val[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False, False, False, False,\n",
              "        False,  True, False],\n",
              "       [False, False,  True, False, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False,  True, False],\n",
              "       [False,  True, False, False, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False,  True, False],\n",
              "       [False, False, False,  True, False, False, False, False, False,\n",
              "        False, False, False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "c8pEzhmT6GnS",
        "colab_type": "code",
        "outputId": "5298f3cb-e35d-4b88-9dd4-2dcbdac52413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "# output \"one-hot\" scores\n",
        "model.predict(np.array([x_val[0]]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.11194286, 0.08703223, 0.04466162, 0.09614258, 0.07991789,\n",
              "         0.10015881, 0.08792052, 0.0613222 , 0.07658774, 0.07327285,\n",
              "         0.09509439, 0.08594634],\n",
              "        [0.0828578 , 0.09545451, 0.04661759, 0.08456481, 0.06100081,\n",
              "         0.12409856, 0.10386992, 0.05089214, 0.10278594, 0.06949714,\n",
              "         0.08618999, 0.09217083],\n",
              "        [0.06040806, 0.0901994 , 0.03527799, 0.09478931, 0.04698731,\n",
              "         0.16602011, 0.1034363 , 0.04319282, 0.11064598, 0.07751279,\n",
              "         0.08932592, 0.08220395],\n",
              "        [0.05838025, 0.0976936 , 0.04050993, 0.11656898, 0.05230108,\n",
              "         0.15842348, 0.10815699, 0.0403192 , 0.10056987, 0.09268498,\n",
              "         0.06567447, 0.06871716]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "-yXszHzg6GnW",
        "colab_type": "code",
        "outputId": "8c11d4f8-f309-4734-df43-9c09f7f902e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# output decoded by only showing highest score for digit\n",
        "model.predict_classes(np.array([x_val[0]]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 5, 5, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "cdW2FJVl6GnZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4: Train"
      ]
    },
    {
      "metadata": {
        "id": "izY-B-UF6Gna",
        "colab_type": "code",
        "outputId": "0e6f5431-2d61-43d4-cda6-cbde985bca19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13593
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "\n",
        "merged_losses = {\n",
        "    \"loss\": [],\n",
        "    \"val_loss\": []\n",
        "}\n",
        "\n",
        "for iteration in range(1, 50):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    iteration_history = model.fit(x_train, y_train,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "    \n",
        "    merged_losses[\"loss\"].append(iteration_history.history[\"loss\"])\n",
        "    merged_losses[\"val_loss\"].append(iteration_history.history[\"val_loss\"])\n",
        "\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = model.predict_classes(rowx, verbose=0)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct == guess:\n",
        "            print(colors.ok + '☑' + colors.close, end=' ')\n",
        "        else:\n",
        "            print(colors.fail + '☒' + colors.close, end=' ')\n",
        "        print(guess)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 124us/step - loss: 1.1818 - acc: 0.5528 - val_loss: 1.1146 - val_acc: 0.5736\n",
            "Q 203+184 T 387  \u001b[91m☒\u001b[0m 414 \n",
            "Q 964+71  T 1035 \u001b[91m☒\u001b[0m 1044\n",
            "Q 50+985  T 1035 \u001b[91m☒\u001b[0m 1044\n",
            "Q 844+486 T 1330 \u001b[91m☒\u001b[0m 1312\n",
            "Q 584+764 T 1348 \u001b[91m☒\u001b[0m 1446\n",
            "Q 224+14  T 238  \u001b[91m☒\u001b[0m 237 \n",
            "Q 81+0    T 81   \u001b[91m☒\u001b[0m 88  \n",
            "Q 68+194  T 262  \u001b[91m☒\u001b[0m 259 \n",
            "Q 306+562 T 868  \u001b[91m☒\u001b[0m 774 \n",
            "Q 652+931 T 1583 \u001b[91m☒\u001b[0m 1406\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 1.0473 - acc: 0.6013 - val_loss: 1.0548 - val_acc: 0.6030\n",
            "Q 34+303  T 337  \u001b[91m☒\u001b[0m 339 \n",
            "Q 17+732  T 749  \u001b[91m☒\u001b[0m 740 \n",
            "Q 3+533   T 536  \u001b[92m☑\u001b[0m 536 \n",
            "Q 83+446  T 529  \u001b[91m☒\u001b[0m 520 \n",
            "Q 16+905  T 921  \u001b[91m☒\u001b[0m 901 \n",
            "Q 90+259  T 349  \u001b[91m☒\u001b[0m 341 \n",
            "Q 68+299  T 367  \u001b[91m☒\u001b[0m 376 \n",
            "Q 482+494 T 976  \u001b[91m☒\u001b[0m 1075\n",
            "Q 371+56  T 427  \u001b[91m☒\u001b[0m 420 \n",
            "Q 1+653   T 654  \u001b[92m☑\u001b[0m 654 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 129us/step - loss: 0.9535 - acc: 0.6367 - val_loss: 0.9425 - val_acc: 0.6354\n",
            "Q 17+732  T 749  \u001b[91m☒\u001b[0m 740 \n",
            "Q 33+395  T 428  \u001b[91m☒\u001b[0m 420 \n",
            "Q 62+294  T 356  \u001b[91m☒\u001b[0m 353 \n",
            "Q 689+9   T 698  \u001b[91m☒\u001b[0m 690 \n",
            "Q 926+55  T 981  \u001b[91m☒\u001b[0m 983 \n",
            "Q 685+813 T 1498 \u001b[91m☒\u001b[0m 1595\n",
            "Q 577+462 T 1039 \u001b[91m☒\u001b[0m 1049\n",
            "Q 350+949 T 1299 \u001b[91m☒\u001b[0m 1393\n",
            "Q 762+472 T 1234 \u001b[91m☒\u001b[0m 1238\n",
            "Q 17+62   T 79   \u001b[91m☒\u001b[0m 88  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 128us/step - loss: 0.8691 - acc: 0.6678 - val_loss: 0.8321 - val_acc: 0.6811\n",
            "Q 535+22  T 557  \u001b[91m☒\u001b[0m 555 \n",
            "Q 887+9   T 896  \u001b[91m☒\u001b[0m 895 \n",
            "Q 65+66   T 131  \u001b[91m☒\u001b[0m 136 \n",
            "Q 8+473   T 481  \u001b[92m☑\u001b[0m 481 \n",
            "Q 901+4   T 905  \u001b[91m☒\u001b[0m 911 \n",
            "Q 31+939  T 970  \u001b[91m☒\u001b[0m 971 \n",
            "Q 182+0   T 182  \u001b[91m☒\u001b[0m 181 \n",
            "Q 154+21  T 175  \u001b[91m☒\u001b[0m 165 \n",
            "Q 78+825  T 903  \u001b[91m☒\u001b[0m 814 \n",
            "Q 72+686  T 758  \u001b[91m☒\u001b[0m 757 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.7958 - acc: 0.6945 - val_loss: 0.7789 - val_acc: 0.6985\n",
            "Q 3+262   T 265  \u001b[92m☑\u001b[0m 265 \n",
            "Q 8+578   T 586  \u001b[91m☒\u001b[0m 686 \n",
            "Q 84+482  T 566  \u001b[91m☒\u001b[0m 567 \n",
            "Q 73+862  T 935  \u001b[91m☒\u001b[0m 936 \n",
            "Q 93+265  T 358  \u001b[91m☒\u001b[0m 359 \n",
            "Q 551+729 T 1280 \u001b[91m☒\u001b[0m 1277\n",
            "Q 38+916  T 954  \u001b[92m☑\u001b[0m 954 \n",
            "Q 95+992  T 1087 \u001b[92m☑\u001b[0m 1087\n",
            "Q 37+99   T 136  \u001b[91m☒\u001b[0m 134 \n",
            "Q 682+7   T 689  \u001b[91m☒\u001b[0m 685 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 0.7290 - acc: 0.7204 - val_loss: 0.7124 - val_acc: 0.7223\n",
            "Q 775+59  T 834  \u001b[92m☑\u001b[0m 834 \n",
            "Q 59+739  T 798  \u001b[91m☒\u001b[0m 887 \n",
            "Q 34+750  T 784  \u001b[91m☒\u001b[0m 774 \n",
            "Q 14+900  T 914  \u001b[91m☒\u001b[0m 915 \n",
            "Q 978+259 T 1237 \u001b[91m☒\u001b[0m 1232\n",
            "Q 644+685 T 1329 \u001b[91m☒\u001b[0m 1324\n",
            "Q 972+97  T 1069 \u001b[91m☒\u001b[0m 1079\n",
            "Q 74+872  T 946  \u001b[91m☒\u001b[0m 956 \n",
            "Q 2+829   T 831  \u001b[91m☒\u001b[0m 830 \n",
            "Q 140+99  T 239  \u001b[91m☒\u001b[0m 241 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 7\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6665 - acc: 0.7434 - val_loss: 0.6511 - val_acc: 0.7456\n",
            "Q 6+503   T 509  \u001b[91m☒\u001b[0m 508 \n",
            "Q 637+812 T 1449 \u001b[91m☒\u001b[0m 1441\n",
            "Q 533+57  T 590  \u001b[91m☒\u001b[0m 599 \n",
            "Q 17+533  T 550  \u001b[91m☒\u001b[0m 540 \n",
            "Q 6+466   T 472  \u001b[92m☑\u001b[0m 472 \n",
            "Q 341+21  T 362  \u001b[91m☒\u001b[0m 364 \n",
            "Q 44+871  T 915  \u001b[92m☑\u001b[0m 915 \n",
            "Q 82+100  T 182  \u001b[91m☒\u001b[0m 183 \n",
            "Q 523+605 T 1128 \u001b[91m☒\u001b[0m 1126\n",
            "Q 593+78  T 671  \u001b[91m☒\u001b[0m 672 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 8\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6176 - acc: 0.7619 - val_loss: 0.6083 - val_acc: 0.7672\n",
            "Q 47+183  T 230  \u001b[91m☒\u001b[0m 229 \n",
            "Q 817+99  T 916  \u001b[91m☒\u001b[0m 909 \n",
            "Q 925+490 T 1415 \u001b[92m☑\u001b[0m 1415\n",
            "Q 702+9   T 711  \u001b[92m☑\u001b[0m 711 \n",
            "Q 48+74   T 122  \u001b[91m☒\u001b[0m 123 \n",
            "Q 859+34  T 893  \u001b[91m☒\u001b[0m 895 \n",
            "Q 313+3   T 316  \u001b[91m☒\u001b[0m 313 \n",
            "Q 84+688  T 772  \u001b[92m☑\u001b[0m 772 \n",
            "Q 71+993  T 1064 \u001b[91m☒\u001b[0m 1055\n",
            "Q 7+856   T 863  \u001b[92m☑\u001b[0m 863 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 9\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.5656 - acc: 0.7820 - val_loss: 0.5540 - val_acc: 0.7871\n",
            "Q 64+196  T 260  \u001b[91m☒\u001b[0m 250 \n",
            "Q 579+3   T 582  \u001b[92m☑\u001b[0m 582 \n",
            "Q 614+60  T 674  \u001b[91m☒\u001b[0m 673 \n",
            "Q 599+70  T 669  \u001b[92m☑\u001b[0m 669 \n",
            "Q 14+192  T 206  \u001b[92m☑\u001b[0m 206 \n",
            "Q 57+676  T 733  \u001b[91m☒\u001b[0m 732 \n",
            "Q 6+223   T 229  \u001b[92m☑\u001b[0m 229 \n",
            "Q 85+868  T 953  \u001b[92m☑\u001b[0m 953 \n",
            "Q 33+310  T 343  \u001b[91m☒\u001b[0m 353 \n",
            "Q 944+68  T 1012 \u001b[91m☒\u001b[0m 1010\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 10\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.5196 - acc: 0.7995 - val_loss: 0.5263 - val_acc: 0.7921\n",
            "Q 14+14   T 28   \u001b[92m☑\u001b[0m 28  \n",
            "Q 75+10   T 85   \u001b[92m☑\u001b[0m 85  \n",
            "Q 4+190   T 194  \u001b[92m☑\u001b[0m 194 \n",
            "Q 3+948   T 951  \u001b[92m☑\u001b[0m 951 \n",
            "Q 445+92  T 537  \u001b[92m☑\u001b[0m 537 \n",
            "Q 60+853  T 913  \u001b[92m☑\u001b[0m 913 \n",
            "Q 59+413  T 472  \u001b[92m☑\u001b[0m 472 \n",
            "Q 93+88   T 181  \u001b[91m☒\u001b[0m 172 \n",
            "Q 885+41  T 926  \u001b[91m☒\u001b[0m 927 \n",
            "Q 52+155  T 207  \u001b[91m☒\u001b[0m 108 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 11\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 132us/step - loss: 0.4793 - acc: 0.8160 - val_loss: 0.4953 - val_acc: 0.8056\n",
            "Q 80+258  T 338  \u001b[92m☑\u001b[0m 338 \n",
            "Q 8+693   T 701  \u001b[92m☑\u001b[0m 701 \n",
            "Q 14+14   T 28   \u001b[91m☒\u001b[0m 27  \n",
            "Q 131+86  T 217  \u001b[92m☑\u001b[0m 217 \n",
            "Q 28+445  T 473  \u001b[92m☑\u001b[0m 473 \n",
            "Q 896+6   T 902  \u001b[91m☒\u001b[0m 905 \n",
            "Q 587+53  T 640  \u001b[91m☒\u001b[0m 740 \n",
            "Q 57+37   T 94   \u001b[92m☑\u001b[0m 94  \n",
            "Q 22+274  T 296  \u001b[91m☒\u001b[0m 286 \n",
            "Q 45+598  T 643  \u001b[92m☑\u001b[0m 643 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 12\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.4482 - acc: 0.8281 - val_loss: 0.4521 - val_acc: 0.8255\n",
            "Q 51+604  T 655  \u001b[92m☑\u001b[0m 655 \n",
            "Q 764+224 T 988  \u001b[91m☒\u001b[0m 997 \n",
            "Q 460+5   T 465  \u001b[91m☒\u001b[0m 466 \n",
            "Q 80+886  T 966  \u001b[92m☑\u001b[0m 966 \n",
            "Q 189+512 T 701  \u001b[91m☒\u001b[0m 709 \n",
            "Q 327+69  T 396  \u001b[91m☒\u001b[0m 306 \n",
            "Q 887+9   T 896  \u001b[91m☒\u001b[0m 897 \n",
            "Q 3+366   T 369  \u001b[92m☑\u001b[0m 369 \n",
            "Q 76+76   T 152  \u001b[91m☒\u001b[0m 153 \n",
            "Q 295+98  T 393  \u001b[92m☑\u001b[0m 393 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 13\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 0.4175 - acc: 0.8414 - val_loss: 0.4283 - val_acc: 0.8350\n",
            "Q 44+170  T 214  \u001b[92m☑\u001b[0m 214 \n",
            "Q 352+7   T 359  \u001b[91m☒\u001b[0m 350 \n",
            "Q 907+93  T 1000 \u001b[91m☒\u001b[0m 1001\n",
            "Q 66+203  T 269  \u001b[92m☑\u001b[0m 269 \n",
            "Q 9+848   T 857  \u001b[92m☑\u001b[0m 857 \n",
            "Q 942+4   T 946  \u001b[92m☑\u001b[0m 946 \n",
            "Q 631+485 T 1116 \u001b[91m☒\u001b[0m 1110\n",
            "Q 53+23   T 76   \u001b[91m☒\u001b[0m 78  \n",
            "Q 644+58  T 702  \u001b[92m☑\u001b[0m 702 \n",
            "Q 76+717  T 793  \u001b[92m☑\u001b[0m 793 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 14\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 132us/step - loss: 0.3876 - acc: 0.8526 - val_loss: 0.4027 - val_acc: 0.8426\n",
            "Q 724+73  T 797  \u001b[92m☑\u001b[0m 797 \n",
            "Q 38+912  T 950  \u001b[91m☒\u001b[0m 959 \n",
            "Q 695+792 T 1487 \u001b[91m☒\u001b[0m 1483\n",
            "Q 489+32  T 521  \u001b[92m☑\u001b[0m 521 \n",
            "Q 1+704   T 705  \u001b[92m☑\u001b[0m 705 \n",
            "Q 47+395  T 442  \u001b[92m☑\u001b[0m 442 \n",
            "Q 55+929  T 984  \u001b[92m☑\u001b[0m 984 \n",
            "Q 974+8   T 982  \u001b[91m☒\u001b[0m 981 \n",
            "Q 667+379 T 1046 \u001b[91m☒\u001b[0m 1044\n",
            "Q 841+344 T 1185 \u001b[91m☒\u001b[0m 1182\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 15\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.3643 - acc: 0.8607 - val_loss: 0.3892 - val_acc: 0.8457\n",
            "Q 26+98   T 124  \u001b[92m☑\u001b[0m 124 \n",
            "Q 446+86  T 532  \u001b[92m☑\u001b[0m 532 \n",
            "Q 781+475 T 1256 \u001b[92m☑\u001b[0m 1256\n",
            "Q 93+404  T 497  \u001b[91m☒\u001b[0m 597 \n",
            "Q 2+238   T 240  \u001b[92m☑\u001b[0m 240 \n",
            "Q 966+2   T 968  \u001b[91m☒\u001b[0m 967 \n",
            "Q 55+738  T 793  \u001b[91m☒\u001b[0m 892 \n",
            "Q 906+532 T 1438 \u001b[91m☒\u001b[0m 1437\n",
            "Q 19+589  T 608  \u001b[92m☑\u001b[0m 608 \n",
            "Q 954+13  T 967  \u001b[92m☑\u001b[0m 967 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 16\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.3441 - acc: 0.8671 - val_loss: 0.3614 - val_acc: 0.8617\n",
            "Q 849+59  T 908  \u001b[91m☒\u001b[0m 808 \n",
            "Q 5+208   T 213  \u001b[92m☑\u001b[0m 213 \n",
            "Q 676+5   T 681  \u001b[92m☑\u001b[0m 681 \n",
            "Q 716+96  T 812  \u001b[91m☒\u001b[0m 811 \n",
            "Q 188+4   T 192  \u001b[92m☑\u001b[0m 192 \n",
            "Q 38+734  T 772  \u001b[92m☑\u001b[0m 772 \n",
            "Q 69+159  T 228  \u001b[92m☑\u001b[0m 228 \n",
            "Q 89+589  T 678  \u001b[92m☑\u001b[0m 678 \n",
            "Q 15+688  T 703  \u001b[91m☒\u001b[0m 603 \n",
            "Q 973+214 T 1187 \u001b[91m☒\u001b[0m 1196\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 17\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.3186 - acc: 0.8772 - val_loss: 0.3380 - val_acc: 0.8664\n",
            "Q 381+4   T 385  \u001b[91m☒\u001b[0m 386 \n",
            "Q 30+550  T 580  \u001b[92m☑\u001b[0m 580 \n",
            "Q 44+57   T 101  \u001b[91m☒\u001b[0m 102 \n",
            "Q 12+546  T 558  \u001b[92m☑\u001b[0m 558 \n",
            "Q 256+217 T 473  \u001b[92m☑\u001b[0m 473 \n",
            "Q 741+474 T 1215 \u001b[92m☑\u001b[0m 1215\n",
            "Q 843+244 T 1087 \u001b[92m☑\u001b[0m 1087\n",
            "Q 33+634  T 667  \u001b[92m☑\u001b[0m 667 \n",
            "Q 685+372 T 1057 \u001b[91m☒\u001b[0m 106 \n",
            "Q 876+90  T 966  \u001b[92m☑\u001b[0m 966 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 18\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.3009 - acc: 0.8840 - val_loss: 0.3164 - val_acc: 0.8743\n",
            "Q 109+62  T 171  \u001b[92m☑\u001b[0m 171 \n",
            "Q 178+235 T 413  \u001b[91m☒\u001b[0m 402 \n",
            "Q 385+84  T 469  \u001b[92m☑\u001b[0m 469 \n",
            "Q 187+1   T 188  \u001b[92m☑\u001b[0m 188 \n",
            "Q 0+245   T 245  \u001b[92m☑\u001b[0m 245 \n",
            "Q 882+807 T 1689 \u001b[91m☒\u001b[0m 1678\n",
            "Q 57+517  T 574  \u001b[92m☑\u001b[0m 574 \n",
            "Q 66+62   T 128  \u001b[92m☑\u001b[0m 128 \n",
            "Q 802+163 T 965  \u001b[91m☒\u001b[0m 954 \n",
            "Q 83+638  T 721  \u001b[92m☑\u001b[0m 721 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 19\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 0.2800 - acc: 0.8935 - val_loss: 0.2959 - val_acc: 0.8868\n",
            "Q 89+685  T 774  \u001b[92m☑\u001b[0m 774 \n",
            "Q 661+69  T 730  \u001b[92m☑\u001b[0m 730 \n",
            "Q 517+99  T 616  \u001b[91m☒\u001b[0m 615 \n",
            "Q 53+902  T 955  \u001b[92m☑\u001b[0m 955 \n",
            "Q 588+569 T 1157 \u001b[92m☑\u001b[0m 1157\n",
            "Q 5+256   T 261  \u001b[92m☑\u001b[0m 261 \n",
            "Q 264+27  T 291  \u001b[91m☒\u001b[0m 201 \n",
            "Q 42+603  T 645  \u001b[92m☑\u001b[0m 645 \n",
            "Q 627+794 T 1421 \u001b[91m☒\u001b[0m 1422\n",
            "Q 886+53  T 939  \u001b[91m☒\u001b[0m 930 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 20\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.2530 - acc: 0.9035 - val_loss: 0.2812 - val_acc: 0.8897\n",
            "Q 649+0   T 649  \u001b[92m☑\u001b[0m 649 \n",
            "Q 172+34  T 206  \u001b[91m☒\u001b[0m 207 \n",
            "Q 76+741  T 817  \u001b[92m☑\u001b[0m 817 \n",
            "Q 172+504 T 676  \u001b[92m☑\u001b[0m 676 \n",
            "Q 505+64  T 569  \u001b[91m☒\u001b[0m 560 \n",
            "Q 541+37  T 578  \u001b[91m☒\u001b[0m 568 \n",
            "Q 272+324 T 596  \u001b[92m☑\u001b[0m 596 \n",
            "Q 584+764 T 1348 \u001b[91m☒\u001b[0m 1448\n",
            "Q 81+211  T 292  \u001b[92m☑\u001b[0m 292 \n",
            "Q 417+196 T 613  \u001b[91m☒\u001b[0m 615 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 21\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.2447 - acc: 0.9063 - val_loss: 0.2768 - val_acc: 0.8944\n",
            "Q 604+65  T 669  \u001b[92m☑\u001b[0m 669 \n",
            "Q 68+96   T 164  \u001b[91m☒\u001b[0m 165 \n",
            "Q 703+95  T 798  \u001b[92m☑\u001b[0m 798 \n",
            "Q 927+448 T 1375 \u001b[92m☑\u001b[0m 1375\n",
            "Q 301+776 T 1077 \u001b[91m☒\u001b[0m 997 \n",
            "Q 86+132  T 218  \u001b[92m☑\u001b[0m 218 \n",
            "Q 64+14   T 78   \u001b[92m☑\u001b[0m 78  \n",
            "Q 528+39  T 567  \u001b[92m☑\u001b[0m 567 \n",
            "Q 951+90  T 1041 \u001b[91m☒\u001b[0m 1022\n",
            "Q 41+154  T 195  \u001b[92m☑\u001b[0m 195 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 22\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.2320 - acc: 0.9122 - val_loss: 0.2362 - val_acc: 0.9100\n",
            "Q 79+939  T 1018 \u001b[92m☑\u001b[0m 1018\n",
            "Q 208+848 T 1056 \u001b[91m☒\u001b[0m 1057\n",
            "Q 53+23   T 76   \u001b[92m☑\u001b[0m 76  \n",
            "Q 84+82   T 166  \u001b[92m☑\u001b[0m 166 \n",
            "Q 754+36  T 790  \u001b[92m☑\u001b[0m 790 \n",
            "Q 7+184   T 191  \u001b[92m☑\u001b[0m 191 \n",
            "Q 821+5   T 826  \u001b[92m☑\u001b[0m 826 \n",
            "Q 512+850 T 1362 \u001b[92m☑\u001b[0m 1362\n",
            "Q 890+599 T 1489 \u001b[91m☒\u001b[0m 1588\n",
            "Q 59+510  T 569  \u001b[92m☑\u001b[0m 569 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 23\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.2160 - acc: 0.9189 - val_loss: 0.2234 - val_acc: 0.9140\n",
            "Q 137+455 T 592  \u001b[92m☑\u001b[0m 592 \n",
            "Q 659+830 T 1489 \u001b[92m☑\u001b[0m 1489\n",
            "Q 172+90  T 262  \u001b[91m☒\u001b[0m 252 \n",
            "Q 823+207 T 1030 \u001b[91m☒\u001b[0m 1020\n",
            "Q 928+71  T 999  \u001b[91m☒\u001b[0m 1000\n",
            "Q 656+915 T 1571 \u001b[91m☒\u001b[0m 1570\n",
            "Q 612+47  T 659  \u001b[92m☑\u001b[0m 659 \n",
            "Q 870+82  T 952  \u001b[92m☑\u001b[0m 952 \n",
            "Q 204+5   T 209  \u001b[92m☑\u001b[0m 209 \n",
            "Q 75+104  T 179  \u001b[92m☑\u001b[0m 179 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 24\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.2179 - acc: 0.9175 - val_loss: 0.2103 - val_acc: 0.9218\n",
            "Q 594+46  T 640  \u001b[92m☑\u001b[0m 640 \n",
            "Q 31+57   T 88   \u001b[92m☑\u001b[0m 88  \n",
            "Q 468+136 T 604  \u001b[91m☒\u001b[0m 505 \n",
            "Q 458+52  T 510  \u001b[91m☒\u001b[0m 509 \n",
            "Q 247+84  T 331  \u001b[92m☑\u001b[0m 331 \n",
            "Q 224+27  T 251  \u001b[92m☑\u001b[0m 251 \n",
            "Q 49+507  T 556  \u001b[92m☑\u001b[0m 556 \n",
            "Q 948+4   T 952  \u001b[91m☒\u001b[0m 951 \n",
            "Q 601+479 T 1080 \u001b[92m☑\u001b[0m 1080\n",
            "Q 539+50  T 589  \u001b[92m☑\u001b[0m 589 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 25\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 132us/step - loss: 0.1945 - acc: 0.9276 - val_loss: 0.2258 - val_acc: 0.9120\n",
            "Q 41+571  T 612  \u001b[92m☑\u001b[0m 612 \n",
            "Q 483+527 T 1010 \u001b[92m☑\u001b[0m 1010\n",
            "Q 505+64  T 569  \u001b[92m☑\u001b[0m 569 \n",
            "Q 150+284 T 434  \u001b[92m☑\u001b[0m 434 \n",
            "Q 4+190   T 194  \u001b[92m☑\u001b[0m 194 \n",
            "Q 270+72  T 342  \u001b[91m☒\u001b[0m 332 \n",
            "Q 895+29  T 924  \u001b[92m☑\u001b[0m 924 \n",
            "Q 513+329 T 842  \u001b[91m☒\u001b[0m 841 \n",
            "Q 794+29  T 823  \u001b[92m☑\u001b[0m 823 \n",
            "Q 18+23   T 41   \u001b[91m☒\u001b[0m 40  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 26\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.1880 - acc: 0.9302 - val_loss: 0.2084 - val_acc: 0.9199\n",
            "Q 807+6   T 813  \u001b[92m☑\u001b[0m 813 \n",
            "Q 3+741   T 744  \u001b[92m☑\u001b[0m 744 \n",
            "Q 794+40  T 834  \u001b[92m☑\u001b[0m 834 \n",
            "Q 68+962  T 1030 \u001b[92m☑\u001b[0m 1030\n",
            "Q 0+662   T 662  \u001b[92m☑\u001b[0m 662 \n",
            "Q 573+30  T 603  \u001b[92m☑\u001b[0m 603 \n",
            "Q 219+223 T 442  \u001b[92m☑\u001b[0m 442 \n",
            "Q 951+25  T 976  \u001b[92m☑\u001b[0m 976 \n",
            "Q 204+5   T 209  \u001b[92m☑\u001b[0m 209 \n",
            "Q 450+22  T 472  \u001b[92m☑\u001b[0m 472 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 27\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.1834 - acc: 0.9320 - val_loss: 0.2449 - val_acc: 0.9032\n",
            "Q 9+782   T 791  \u001b[92m☑\u001b[0m 791 \n",
            "Q 33+679  T 712  \u001b[92m☑\u001b[0m 712 \n",
            "Q 539+347 T 886  \u001b[91m☒\u001b[0m 876 \n",
            "Q 16+374  T 390  \u001b[91m☒\u001b[0m 490 \n",
            "Q 8+701   T 709  \u001b[92m☑\u001b[0m 709 \n",
            "Q 76+76   T 152  \u001b[92m☑\u001b[0m 152 \n",
            "Q 332+71  T 403  \u001b[92m☑\u001b[0m 403 \n",
            "Q 17+211  T 228  \u001b[92m☑\u001b[0m 228 \n",
            "Q 42+528  T 570  \u001b[91m☒\u001b[0m 560 \n",
            "Q 62+294  T 356  \u001b[92m☑\u001b[0m 356 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 28\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.1707 - acc: 0.9373 - val_loss: 0.1949 - val_acc: 0.9262\n",
            "Q 90+76   T 166  \u001b[92m☑\u001b[0m 166 \n",
            "Q 517+385 T 902  \u001b[92m☑\u001b[0m 902 \n",
            "Q 977+920 T 1897 \u001b[92m☑\u001b[0m 1897\n",
            "Q 556+19  T 575  \u001b[92m☑\u001b[0m 575 \n",
            "Q 71+463  T 534  \u001b[92m☑\u001b[0m 534 \n",
            "Q 888+5   T 893  \u001b[92m☑\u001b[0m 893 \n",
            "Q 373+163 T 536  \u001b[92m☑\u001b[0m 536 \n",
            "Q 698+33  T 731  \u001b[92m☑\u001b[0m 731 \n",
            "Q 55+627  T 682  \u001b[91m☒\u001b[0m 692 \n",
            "Q 27+656  T 683  \u001b[92m☑\u001b[0m 683 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 29\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.1655 - acc: 0.9391 - val_loss: 0.1836 - val_acc: 0.9320\n",
            "Q 614+36  T 650  \u001b[92m☑\u001b[0m 650 \n",
            "Q 681+71  T 752  \u001b[92m☑\u001b[0m 752 \n",
            "Q 0+175   T 175  \u001b[92m☑\u001b[0m 175 \n",
            "Q 450+22  T 472  \u001b[92m☑\u001b[0m 472 \n",
            "Q 623+417 T 1040 \u001b[92m☑\u001b[0m 1040\n",
            "Q 95+35   T 130  \u001b[92m☑\u001b[0m 130 \n",
            "Q 820+38  T 858  \u001b[92m☑\u001b[0m 858 \n",
            "Q 39+705  T 744  \u001b[92m☑\u001b[0m 744 \n",
            "Q 973+214 T 1187 \u001b[92m☑\u001b[0m 1187\n",
            "Q 364+18  T 382  \u001b[92m☑\u001b[0m 382 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 30\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.1575 - acc: 0.9422 - val_loss: 0.1827 - val_acc: 0.9318\n",
            "Q 506+6   T 512  \u001b[91m☒\u001b[0m 511 \n",
            "Q 13+99   T 112  \u001b[92m☑\u001b[0m 112 \n",
            "Q 28+223  T 251  \u001b[92m☑\u001b[0m 251 \n",
            "Q 41+589  T 630  \u001b[92m☑\u001b[0m 630 \n",
            "Q 278+34  T 312  \u001b[92m☑\u001b[0m 312 \n",
            "Q 734+448 T 1182 \u001b[92m☑\u001b[0m 1182\n",
            "Q 555+786 T 1341 \u001b[92m☑\u001b[0m 1341\n",
            "Q 691+5   T 696  \u001b[92m☑\u001b[0m 696 \n",
            "Q 209+9   T 218  \u001b[92m☑\u001b[0m 218 \n",
            "Q 33+20   T 53   \u001b[92m☑\u001b[0m 53  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 31\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.1532 - acc: 0.9435 - val_loss: 0.2160 - val_acc: 0.9189\n",
            "Q 505+769 T 1274 \u001b[92m☑\u001b[0m 1274\n",
            "Q 68+679  T 747  \u001b[92m☑\u001b[0m 747 \n",
            "Q 86+516  T 602  \u001b[92m☑\u001b[0m 602 \n",
            "Q 847+450 T 1297 \u001b[92m☑\u001b[0m 1297\n",
            "Q 659+830 T 1489 \u001b[91m☒\u001b[0m 1589\n",
            "Q 35+70   T 105  \u001b[91m☒\u001b[0m 106 \n",
            "Q 84+482  T 566  \u001b[92m☑\u001b[0m 566 \n",
            "Q 261+66  T 327  \u001b[92m☑\u001b[0m 327 \n",
            "Q 57+92   T 149  \u001b[92m☑\u001b[0m 149 \n",
            "Q 713+618 T 1331 \u001b[92m☑\u001b[0m 1331\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 32\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.1612 - acc: 0.9404 - val_loss: 0.2402 - val_acc: 0.9095\n",
            "Q 33+80   T 113  \u001b[92m☑\u001b[0m 113 \n",
            "Q 83+191  T 274  \u001b[92m☑\u001b[0m 274 \n",
            "Q 49+98   T 147  \u001b[91m☒\u001b[0m 137 \n",
            "Q 462+29  T 491  \u001b[91m☒\u001b[0m 481 \n",
            "Q 24+412  T 436  \u001b[92m☑\u001b[0m 436 \n",
            "Q 4+624   T 628  \u001b[92m☑\u001b[0m 628 \n",
            "Q 982+943 T 1925 \u001b[92m☑\u001b[0m 1925\n",
            "Q 861+477 T 1338 \u001b[92m☑\u001b[0m 1338\n",
            "Q 22+730  T 752  \u001b[92m☑\u001b[0m 752 \n",
            "Q 250+31  T 281  \u001b[91m☒\u001b[0m 271 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 33\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 0.1486 - acc: 0.9454 - val_loss: 0.1670 - val_acc: 0.9377\n",
            "Q 5+424   T 429  \u001b[92m☑\u001b[0m 429 \n",
            "Q 797+99  T 896  \u001b[91m☒\u001b[0m 897 \n",
            "Q 80+79   T 159  \u001b[92m☑\u001b[0m 159 \n",
            "Q 90+76   T 166  \u001b[92m☑\u001b[0m 166 \n",
            "Q 82+865  T 947  \u001b[92m☑\u001b[0m 947 \n",
            "Q 80+387  T 467  \u001b[92m☑\u001b[0m 467 \n",
            "Q 815+3   T 818  \u001b[92m☑\u001b[0m 818 \n",
            "Q 0+443   T 443  \u001b[92m☑\u001b[0m 443 \n",
            "Q 821+471 T 1292 \u001b[92m☑\u001b[0m 1292\n",
            "Q 104+287 T 391  \u001b[91m☒\u001b[0m 491 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 34\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 0.1414 - acc: 0.9487 - val_loss: 0.1657 - val_acc: 0.9366\n",
            "Q 523+25  T 548  \u001b[92m☑\u001b[0m 548 \n",
            "Q 718+35  T 753  \u001b[91m☒\u001b[0m 752 \n",
            "Q 12+247  T 259  \u001b[91m☒\u001b[0m 269 \n",
            "Q 11+310  T 321  \u001b[92m☑\u001b[0m 321 \n",
            "Q 90+318  T 408  \u001b[92m☑\u001b[0m 408 \n",
            "Q 775+907 T 1682 \u001b[92m☑\u001b[0m 1682\n",
            "Q 460+5   T 465  \u001b[92m☑\u001b[0m 465 \n",
            "Q 44+170  T 214  \u001b[92m☑\u001b[0m 214 \n",
            "Q 8+286   T 294  \u001b[92m☑\u001b[0m 294 \n",
            "Q 111+37  T 148  \u001b[92m☑\u001b[0m 148 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 35\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 129us/step - loss: 0.1426 - acc: 0.9483 - val_loss: 0.1698 - val_acc: 0.9354\n",
            "Q 879+829 T 1708 \u001b[92m☑\u001b[0m 1708\n",
            "Q 219+893 T 1112 \u001b[91m☒\u001b[0m 1111\n",
            "Q 644+58  T 702  \u001b[92m☑\u001b[0m 702 \n",
            "Q 24+2    T 26   \u001b[92m☑\u001b[0m 26  \n",
            "Q 13+436  T 449  \u001b[92m☑\u001b[0m 449 \n",
            "Q 301+558 T 859  \u001b[92m☑\u001b[0m 859 \n",
            "Q 965+680 T 1645 \u001b[92m☑\u001b[0m 1645\n",
            "Q 12+266  T 278  \u001b[92m☑\u001b[0m 278 \n",
            "Q 80+43   T 123  \u001b[92m☑\u001b[0m 123 \n",
            "Q 696+55  T 751  \u001b[92m☑\u001b[0m 751 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 36\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 0.1274 - acc: 0.9536 - val_loss: 0.1474 - val_acc: 0.9440\n",
            "Q 79+262  T 341  \u001b[92m☑\u001b[0m 341 \n",
            "Q 736+47  T 783  \u001b[92m☑\u001b[0m 783 \n",
            "Q 73+862  T 935  \u001b[92m☑\u001b[0m 935 \n",
            "Q 890+599 T 1489 \u001b[91m☒\u001b[0m 1589\n",
            "Q 883+626 T 1509 \u001b[91m☒\u001b[0m 1519\n",
            "Q 3+83    T 86   \u001b[91m☒\u001b[0m 85  \n",
            "Q 85+101  T 186  \u001b[92m☑\u001b[0m 186 \n",
            "Q 329+825 T 1154 \u001b[92m☑\u001b[0m 1154\n",
            "Q 5+254   T 259  \u001b[92m☑\u001b[0m 259 \n",
            "Q 692+68  T 760  \u001b[91m☒\u001b[0m 750 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 37\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 0.1273 - acc: 0.9546 - val_loss: 0.1848 - val_acc: 0.9289\n",
            "Q 55+537  T 592  \u001b[92m☑\u001b[0m 592 \n",
            "Q 93+265  T 358  \u001b[92m☑\u001b[0m 358 \n",
            "Q 19+753  T 772  \u001b[92m☑\u001b[0m 772 \n",
            "Q 1+395   T 396  \u001b[92m☑\u001b[0m 396 \n",
            "Q 4+614   T 618  \u001b[91m☒\u001b[0m 619 \n",
            "Q 1+412   T 413  \u001b[92m☑\u001b[0m 413 \n",
            "Q 437+4   T 441  \u001b[92m☑\u001b[0m 441 \n",
            "Q 594+9   T 603  \u001b[92m☑\u001b[0m 603 \n",
            "Q 61+83   T 144  \u001b[92m☑\u001b[0m 144 \n",
            "Q 352+84  T 436  \u001b[91m☒\u001b[0m 426 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 38\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.1154 - acc: 0.9588 - val_loss: 0.1933 - val_acc: 0.9258\n",
            "Q 326+423 T 749  \u001b[92m☑\u001b[0m 749 \n",
            "Q 89+335  T 424  \u001b[92m☑\u001b[0m 424 \n",
            "Q 11+592  T 603  \u001b[92m☑\u001b[0m 603 \n",
            "Q 45+327  T 372  \u001b[92m☑\u001b[0m 372 \n",
            "Q 137+52  T 189  \u001b[91m☒\u001b[0m 190 \n",
            "Q 996+14  T 1010 \u001b[92m☑\u001b[0m 1010\n",
            "Q 788+679 T 1467 \u001b[92m☑\u001b[0m 1467\n",
            "Q 631+64  T 695  \u001b[92m☑\u001b[0m 695 \n",
            "Q 338+440 T 778  \u001b[91m☒\u001b[0m 788 \n",
            "Q 84+120  T 204  \u001b[91m☒\u001b[0m 205 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 39\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 131us/step - loss: 0.1304 - acc: 0.9522 - val_loss: 0.1654 - val_acc: 0.9384\n",
            "Q 117+839 T 956  \u001b[91m☒\u001b[0m 955 \n",
            "Q 309+344 T 653  \u001b[92m☑\u001b[0m 653 \n",
            "Q 644+68  T 712  \u001b[92m☑\u001b[0m 712 \n",
            "Q 314+2   T 316  \u001b[92m☑\u001b[0m 316 \n",
            "Q 421+53  T 474  \u001b[92m☑\u001b[0m 474 \n",
            "Q 23+40   T 63   \u001b[92m☑\u001b[0m 63  \n",
            "Q 0+668   T 668  \u001b[91m☒\u001b[0m 669 \n",
            "Q 846+82  T 928  \u001b[91m☒\u001b[0m 929 \n",
            "Q 51+995  T 1046 \u001b[92m☑\u001b[0m 1046\n",
            "Q 0+170   T 170  \u001b[92m☑\u001b[0m 170 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 40\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 129us/step - loss: 0.1403 - acc: 0.9489 - val_loss: 0.1792 - val_acc: 0.9315\n",
            "Q 572+14  T 586  \u001b[92m☑\u001b[0m 586 \n",
            "Q 34+303  T 337  \u001b[92m☑\u001b[0m 337 \n",
            "Q 405+89  T 494  \u001b[92m☑\u001b[0m 494 \n",
            "Q 207+3   T 210  \u001b[91m☒\u001b[0m 209 \n",
            "Q 166+0   T 166  \u001b[92m☑\u001b[0m 166 \n",
            "Q 46+432  T 478  \u001b[92m☑\u001b[0m 478 \n",
            "Q 64+196  T 260  \u001b[91m☒\u001b[0m 250 \n",
            "Q 779+55  T 834  \u001b[92m☑\u001b[0m 834 \n",
            "Q 3+510   T 513  \u001b[92m☑\u001b[0m 513 \n",
            "Q 5+238   T 243  \u001b[92m☑\u001b[0m 243 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 41\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 128us/step - loss: 0.1174 - acc: 0.9582 - val_loss: 0.1440 - val_acc: 0.9469\n",
            "Q 644+685 T 1329 \u001b[92m☑\u001b[0m 1329\n",
            "Q 106+48  T 154  \u001b[91m☒\u001b[0m 164 \n",
            "Q 815+622 T 1437 \u001b[92m☑\u001b[0m 1437\n",
            "Q 599+70  T 669  \u001b[92m☑\u001b[0m 669 \n",
            "Q 518+13  T 531  \u001b[91m☒\u001b[0m 541 \n",
            "Q 2+876   T 878  \u001b[92m☑\u001b[0m 878 \n",
            "Q 228+74  T 302  \u001b[91m☒\u001b[0m 312 \n",
            "Q 45+311  T 356  \u001b[92m☑\u001b[0m 356 \n",
            "Q 486+96  T 582  \u001b[92m☑\u001b[0m 582 \n",
            "Q 33+720  T 753  \u001b[92m☑\u001b[0m 753 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 42\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 129us/step - loss: 0.1096 - acc: 0.9601 - val_loss: 0.1370 - val_acc: 0.9485\n",
            "Q 679+20  T 699  \u001b[91m☒\u001b[0m 609 \n",
            "Q 966+920 T 1886 \u001b[92m☑\u001b[0m 1886\n",
            "Q 526+8   T 534  \u001b[92m☑\u001b[0m 534 \n",
            "Q 10+95   T 105  \u001b[92m☑\u001b[0m 105 \n",
            "Q 47+629  T 676  \u001b[92m☑\u001b[0m 676 \n",
            "Q 48+53   T 101  \u001b[92m☑\u001b[0m 101 \n",
            "Q 870+88  T 958  \u001b[92m☑\u001b[0m 958 \n",
            "Q 29+886  T 915  \u001b[92m☑\u001b[0m 915 \n",
            "Q 125+655 T 780  \u001b[92m☑\u001b[0m 780 \n",
            "Q 5+215   T 220  \u001b[92m☑\u001b[0m 220 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 43\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 130us/step - loss: 0.1066 - acc: 0.9614 - val_loss: 0.1416 - val_acc: 0.9483\n",
            "Q 95+986  T 1081 \u001b[92m☑\u001b[0m 1081\n",
            "Q 559+6   T 565  \u001b[92m☑\u001b[0m 565 \n",
            "Q 178+235 T 413  \u001b[92m☑\u001b[0m 413 \n",
            "Q 966+2   T 968  \u001b[91m☒\u001b[0m 969 \n",
            "Q 290+218 T 508  \u001b[92m☑\u001b[0m 508 \n",
            "Q 21+24   T 45   \u001b[92m☑\u001b[0m 45  \n",
            "Q 830+94  T 924  \u001b[92m☑\u001b[0m 924 \n",
            "Q 99+805  T 904  \u001b[91m☒\u001b[0m 804 \n",
            "Q 30+10   T 40   \u001b[92m☑\u001b[0m 40  \n",
            "Q 90+818  T 908  \u001b[92m☑\u001b[0m 908 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 44\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 128us/step - loss: 0.1111 - acc: 0.9600 - val_loss: 0.1428 - val_acc: 0.9473\n",
            "Q 469+97  T 566  \u001b[92m☑\u001b[0m 566 \n",
            "Q 4+598   T 602  \u001b[92m☑\u001b[0m 602 \n",
            "Q 2+401   T 403  \u001b[92m☑\u001b[0m 403 \n",
            "Q 10+685  T 695  \u001b[92m☑\u001b[0m 695 \n",
            "Q 589+1   T 590  \u001b[91m☒\u001b[0m 580 \n",
            "Q 551+61  T 612  \u001b[92m☑\u001b[0m 612 \n",
            "Q 219+893 T 1112 \u001b[92m☑\u001b[0m 1112\n",
            "Q 305+67  T 372  \u001b[92m☑\u001b[0m 372 \n",
            "Q 962+80  T 1042 \u001b[92m☑\u001b[0m 1042\n",
            "Q 921+9   T 930  \u001b[91m☒\u001b[0m 920 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 45\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 128us/step - loss: 0.1107 - acc: 0.9597 - val_loss: 0.2269 - val_acc: 0.9200\n",
            "Q 151+577 T 728  \u001b[92m☑\u001b[0m 728 \n",
            "Q 203+76  T 279  \u001b[92m☑\u001b[0m 279 \n",
            "Q 749+9   T 758  \u001b[92m☑\u001b[0m 758 \n",
            "Q 239+112 T 351  \u001b[91m☒\u001b[0m 341 \n",
            "Q 844+13  T 857  \u001b[92m☑\u001b[0m 857 \n",
            "Q 352+4   T 356  \u001b[92m☑\u001b[0m 356 \n",
            "Q 555+690 T 1245 \u001b[92m☑\u001b[0m 1245\n",
            "Q 453+44  T 497  \u001b[92m☑\u001b[0m 497 \n",
            "Q 976+45  T 1021 \u001b[91m☒\u001b[0m 1010\n",
            "Q 348+25  T 373  \u001b[92m☑\u001b[0m 373 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 46\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 132us/step - loss: 0.1046 - acc: 0.9628 - val_loss: 0.1339 - val_acc: 0.9486\n",
            "Q 511+967 T 1478 \u001b[92m☑\u001b[0m 1478\n",
            "Q 788+679 T 1467 \u001b[91m☒\u001b[0m 1457\n",
            "Q 732+35  T 767  \u001b[92m☑\u001b[0m 767 \n",
            "Q 5+916   T 921  \u001b[92m☑\u001b[0m 921 \n",
            "Q 882+8   T 890  \u001b[92m☑\u001b[0m 890 \n",
            "Q 650+51  T 701  \u001b[92m☑\u001b[0m 701 \n",
            "Q 10+540  T 550  \u001b[92m☑\u001b[0m 550 \n",
            "Q 29+13   T 42   \u001b[91m☒\u001b[0m 52  \n",
            "Q 36+999  T 1035 \u001b[91m☒\u001b[0m 1045\n",
            "Q 561+87  T 648  \u001b[91m☒\u001b[0m 649 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 47\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 129us/step - loss: 0.1135 - acc: 0.9592 - val_loss: 0.1424 - val_acc: 0.9461\n",
            "Q 109+490 T 599  \u001b[91m☒\u001b[0m 609 \n",
            "Q 761+12  T 773  \u001b[92m☑\u001b[0m 773 \n",
            "Q 462+29  T 491  \u001b[92m☑\u001b[0m 491 \n",
            "Q 519+75  T 594  \u001b[92m☑\u001b[0m 594 \n",
            "Q 282+585 T 867  \u001b[91m☒\u001b[0m 857 \n",
            "Q 839+86  T 925  \u001b[92m☑\u001b[0m 925 \n",
            "Q 948+134 T 1082 \u001b[92m☑\u001b[0m 1082\n",
            "Q 20+221  T 241  \u001b[92m☑\u001b[0m 241 \n",
            "Q 666+71  T 737  \u001b[92m☑\u001b[0m 737 \n",
            "Q 50+6    T 56   \u001b[91m☒\u001b[0m 57  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 48\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 132us/step - loss: 0.1084 - acc: 0.9607 - val_loss: 0.1481 - val_acc: 0.9453\n",
            "Q 23+27   T 50   \u001b[92m☑\u001b[0m 50  \n",
            "Q 447+84  T 531  \u001b[92m☑\u001b[0m 531 \n",
            "Q 8+753   T 761  \u001b[92m☑\u001b[0m 761 \n",
            "Q 482+769 T 1251 \u001b[92m☑\u001b[0m 1251\n",
            "Q 7+399   T 406  \u001b[92m☑\u001b[0m 406 \n",
            "Q 33+36   T 69   \u001b[92m☑\u001b[0m 69  \n",
            "Q 59+480  T 539  \u001b[91m☒\u001b[0m 549 \n",
            "Q 355+118 T 473  \u001b[91m☒\u001b[0m 474 \n",
            "Q 352+84  T 436  \u001b[92m☑\u001b[0m 436 \n",
            "Q 749+399 T 1148 \u001b[92m☑\u001b[0m 1148\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 49\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 6s 132us/step - loss: 0.0883 - acc: 0.9692 - val_loss: 0.1109 - val_acc: 0.9580\n",
            "Q 163+94  T 257  \u001b[92m☑\u001b[0m 257 \n",
            "Q 13+166  T 179  \u001b[92m☑\u001b[0m 179 \n",
            "Q 46+554  T 600  \u001b[91m☒\u001b[0m 500 \n",
            "Q 905+444 T 1349 \u001b[92m☑\u001b[0m 1349\n",
            "Q 90+818  T 908  \u001b[92m☑\u001b[0m 908 \n",
            "Q 76+344  T 420  \u001b[92m☑\u001b[0m 420 \n",
            "Q 90+797  T 887  \u001b[92m☑\u001b[0m 887 \n",
            "Q 853+4   T 857  \u001b[92m☑\u001b[0m 857 \n",
            "Q 722+6   T 728  \u001b[92m☑\u001b[0m 728 \n",
            "Q 667+34  T 701  \u001b[91m☒\u001b[0m 601 \n",
            "CPU times: user 6min 6s, sys: 50.1 s, total: 6min 57s\n",
            "Wall time: 4min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7apd-uAFjVHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3928e528-1a09-465e-90d0-5b0e535c26a4"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.plot(merged_losses['loss'], 'b')\n",
        "plt.plot(merged_losses['val_loss'], 'r')\n",
        "\n",
        "plt.legend(['loss', 'validation loss'])\n",
        "plt.plot()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bxojIpIhngkT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}