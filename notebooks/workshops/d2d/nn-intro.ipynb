{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in Neuronale Netzwerke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from distutils.version import StrictVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "assert StrictVersion(sklearn.__version__ ) >= StrictVersion('0.18.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print(tf.__version__)\n",
    "\n",
    "assert StrictVersion(tf.__version__) >= StrictVersion('1.1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "assert StrictVersion(keras.__version__) >= StrictVersion('2.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris mit Neuronalen Netzwerken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das künstliche Neuron\n",
    "![Das künstliche Neuron](https://djcordhose.github.io/ai/img/sketch/neuron.jpg \"Das künstliche Neuron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hands-On\n",
    "## Erzeuge eine Python-Implementierung eines Neurons mit zwei Eingabevariablen ohne Activation Funktion\n",
    "* Denke die Werte für w1, w2 und den Bias aus\n",
    "* Kannst du eine Skizze des Graphs der Funktion mit x1 und x2 an den Achsen erstellen?\n",
    "* Was ist das für eine Funktion?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load https://djcordhose.github.io/ai/fragments/neuron.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wir probieren unser Modell mit dem Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.1,  3.5,  1.4,  0.2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.399999999999999"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_no_activation(5.1, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wie sollen wir das interpretieren? Damit können wir nicht viel anfangen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centerAxis(uses_negative=False):\n",
    "    # http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_position('center')\n",
    "    if uses_negative:\n",
    "        ax.spines['bottom'].set_position('center')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_sigmoid(X):\n",
    "    return 1 / (1 + np.exp(X * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f53a21f9128>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEACAYAAACTXJylAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHQVJREFUeJzt3Xl0VGW+7vHvSxJBgWZUJIMxyJC0Molh0tbCVhSUgALK\nQZfXJhpsodXuc7pb+zrg4fbhYrtcbQsqt7FBUcCZiA0RjSIHPXRURESaZlCmUpFJQEUg1L5/vCS7\nQhLIUKm9a+f5rFUr71vZVfkhlYfX356M4ziIiEjiaOJ1ASIiUjsKbhGRBKPgFhFJMApuEZEEo+AW\nEUkwCm4RkQSj4BZfMsY8ZYzZYYxZfYJt/mKM2WCMWWWM6RXP+kS8pOAWv5oFXFHdN40xQ4BzHMfp\nAowHnoxXYSJeU3CLLzmOsxzYe4JNhgPPHNv2H0ArY0yHeNQm4jUFtySqNGBb1Dx87DmRwFNwi4gk\nmOQYvpcueiIxtXnzZoYNGwZVfLbGjx/PoEGDri6bd+vWjXffffejqt7HGMMDDzxQPg+FQoRCodgX\nnKCOHoXPP4c1a2DTJvjiC/exeTP8+KPXFQab42Bq+5pYBrdITDmOQ3UXQcvLy2P69Olcf/31rFix\ngtatW9OhQ/Ut7kmTJjVQlYnl8GFYtQr+53/g449tWK9dCwcPxvbnNG8OLVvCaafBqafar9Hjsq/N\nmsEpp0BKSs0fycmQlARNmlR8GFP5uZN9r+x5Y+wDTv61JtvUZtu6UHCLL40dO5alS5eye/duzjrr\nLB588EEOHz6MMYaCggKGDh3KokWL6Ny5M82bN2fWrFlel+xLhw/De+/BkiWwfDl8+GHtV9CtWkHH\njtChA5x5pvv1jDOgTRto3dp9tGplH8lKlgZlYnhZV7VKxJeMMdWu3INozx545RVYuBDefhu+++7k\nr+nYEc47D7p1g6ysio9WrRq+5kZOrRKRxuiHH2xYz58Pb7wBpaXVb9upEwwYAP36QY8eNrDbtYtf\nrVJ/Cm6RBLZxIzzxBMyaBXurOeo9KwuGDIHLLoOBA22rQxKbglskAa1cCZMnw4IFVX+/Xz+47joY\nNgw6d67fjjDxHwW3SAL55BO49154/fXK38vKgltugTFjbDtEgkvBLZIAdu6E++6Dv/4VIpGK37vq\nKpgwAa64wh7aJsGn4BbxMcexYf2738G+fe7zxsDo0Xb13b27d/WJNxTcIj61dattfbz5ZsXnr7gC\nHn7YHg0ijZOCW8SHXn4Zxo2D/fvd5zp3hj//GYYO1c7Gxk4dMREfKS2F//gPGDXKDW1j7HOrV9t+\ntkJbtOIW8Ym9e+Haa2HpUve5rCyYMwcuvNCzssSHFNwiPrB1qz1JZu1a97mrr4ZnnrHXAxGJplaJ\niMfWrLGnoEeH9uTJUFio0JaqacUt4qE1a2DQINi1y85TUmD2bBg71tOyxOcU3CIeWbMGLr3UDe2W\nLe0qe9Agb+sS/9NlXSXw/HhZ188/txd82rHDzlu2tNfM7t/f27rEE7U+Tkg9bpE4273b7ohUaEtd\nKbhF4ujgQcjLg/Xr7bxpU1i0SKEttaPgFokTx4GCAnj/fTs3Bp57Di66yNu6JPEouEXi5PHH4dln\n3fkjj8DIkd7VI4lLOycl8Pywc/L99+GSS9xbit1yi73qnwh12Dmp4JbA8zq4d++Gnj0hHLbzPn3s\nHdebNfOsJPEXHVUi4ieOA7fd5oZ227b2yn8KbakPBbdIA3r2WXjpJXf+9NOQmeldPRIMapVI4HnV\nKtmyBXr0cC/POn48PPlk3MsQ/1OPW+R4XgS348CVV9oTa8DeBOHjj6FFi7iWIYlBPW4RP5g/3w3t\nJk3s5VkV2hIrCm6RGPv2W/j1r935xIn2sq0isaLgFomxe+5xr0OSmmqvrS0SS+pxS+DFs8f90UeQ\nm2t73GCPKNHZkXIS6nGLeMVx4De/cUP7qqvsPSRFYk0rbgm8eK24FyyAa66x4+Rk+Owz6Nq1wX+s\nJD6tuEW8cPgw/Pa37vz22xXa0nAU3CIx8MQTsHGjHbduDfff7209EmwKbpF6+v57+OMf3fl990G7\ndt7VI8Gn4Bapp+nTYedOO87IgAkTvK1Hgk/BLVIPBw7AQw+583vvtbcjE2lICm7xraKiIrKzs+na\ntStTp06t9P39+/eTl5dHr1696N69O7Nnz457jdOm2ettg73q3803x70EaYR0OKD4UiQSoWvXrhQX\nF5Oamkpubi7z588nOzu7fJspU6awf/9+pkyZwq5du+jWrRs7duwgOTm5wns11OGA+/dDVhbs2WPn\nM2dCfn7Mf4wEnw4HlGAoKSmhS5cuZGZmkpKSwpgxYygsLKywjTGGAwcOAHDgwAHatWtXKbQb0pNP\nuqHdqRPcdFPcfrQ0cgpu8aVwOExGRkb5PD09nXDZbWSOmThxImvXriU1NZWePXvy6KOPxq2+Q4cg\n+sf94Q+QkhK3Hy+NXPyWJyIx9sYbb9C7d2/efvttNm3axOWXX87q1atpUcX1UydNmlQ+DoVChEKh\nev3suXPhyy/tuGNHuPHGer2dSK0ouMWX0tLS2Lp1a/l8+/btpKWlVdhm1qxZ3HPPPQCcc845ZGVl\nsW7dOi644IJK7xcd3PUVicDDD7vzO+/UkSQSX2qViC/l5uayceNGtmzZwuHDh5k/fz55eXkVtsnM\nzOStt94CYMeOHaxfv55OnTo1eG2LFsHatXbcooW9JZlIPGnFLb6UlJTEtGnTGDx4MJFIhPz8fHJy\ncpgxYwbGGAoKCrj33nu5+eab6dGjBwAPPfQQbdu2bfDa/vQndzx+vD3FXSSedDigBF4sDwf8+GM4\n/3w7Tk6Gzz+3Z0uK1IMOBxRpSNOnu+PRoxXa4g2tuCXwYrXi3rsX0tLg4EE7f+89GDiw3m8rohW3\nSEOZNcsN7V69dANg8Y6CW6QGIhF4/HF3PmECmFqvk0RiQ60SCbxYtEqKimDIEDtu3RrCYTjttBgU\nJ6JWiUjDiN4p+YtfKLTFW1pxS+DVd8W9fbu9ZGskYufr10OXLjEqTkQrbpHYe+YZN7QvvVShLd5T\ncIucgOPA3/7mzseN864WkTJqlUjg1adVsmwZXHKJHbdqBV99BaeeGsPiRNQqEYmt6NX22LEKbfEH\nrbgl8Oq64t6/315r+4cf7PyDD6CKK8aK1JdW3CKx8sILbmh37w59+nhbj0gZBbdINY7fKakzJcUv\n1CqRwKtLq2TjRvewv+Rke5uy009vgOJE1CoRiY1589zxkCEKbfEXBbfIcRwHnnvOnY8d610tIlVR\nq0QCr7atkpUr3R2RzZvDN9/o2iTSoNQqEamvuXPd8TXXKLTFfxTcIlGOHq3Y377hBu9qEamOglsk\nyrJl9ggSsDskL7vM23pEqqLgFokSvVPy+uvtoYAifqOdkxJ4Nd05eegQdOgA+/bZ+fvv676SEhfa\nOSlSV0VFbmhnZUH//t7WI1IdBbfIMS+95I6vv16nuIt/qVUigVeTVsmhQ3DGGfaKgAAffQTnnx+H\n4kTUKhGpm7feckM7Kwt69/a2HpETUXCLULFNMnq02iTib2qVSOCdrFVy+LA9muTbb+28pARyc+NU\nnIhaJSK19847bmifdZbuciP+p+CWRi+6TTJqlNok4n9qlUjgnahVUloKZ54Ju3fbuU66EQ+oVSJS\nG0uXuqGdng79+nlajkiNKLilUYtuk4wcCU30GyEJQB9TabSOHoVXX3Xno0Z5V4tIbSi4xbeKiorI\nzs6ma9euTJ06tcptli5dSu/evTnvvPMYNGhQrd7//fft3W3A9rkHDqxvxSLxoYtWii9FIhEmTpxI\ncXExqamp5ObmMnz4cLKzs8u32bdvHxMmTGDJkiWkpaWxa9euWv2MBQvc8YgRapNI4tBHVXyppKSE\nLl26kJmZSUpKCmPGjKGwsLDCNnPnzmXkyJGkpaUB0L59+xq/v+NA9NsNHx6TskXiQsEtvhQOh8nI\nyCifp6enEw6HK2yzfv169uzZw6BBg8jNzWXOnDk1fv+1a2HTJjtu2RJq2WUR8ZRaJZKwSktLWbly\nJW+//Tbff/89AwYMYMCAAXTu3Pmkr41ebV95JTRt2oCFisSYglt8KS0tja1bt5bPt2/fXt4SKZOe\nnk779u1p1qwZzZo14+KLL+aTTz6pMrgnTZpUPg6FQhQWhsrnapNIotGZk+JLR48epVu3bhQXF9Ox\nY0f69u3LvHnzyMnJKd9m3bp1/OpXv6KoqIhDhw7Rr18/nn/+eX76059WeK/jz5z88kso+zcgKQl2\n7oQ2beLyxxKpSq3PnNSKW3wpKSmJadOmMXjwYCKRCPn5+eTk5DBjxgyMMRQUFJCdnc0VV1xBjx49\nSEpKoqCgoFJoV2XhQnd8ySUKbUk8WnFL4B2/4h46FBYvtuNHH4U77vCoMBGr1ituBbcEXnRwHzgA\n7dvba3ADbN4MmZne1SaCLjIlcmJvvOGGds+eCm1JTApuaVR00o0EgVolEnhlrZIjR+wtyvbutc/r\nTu7iE2qViFRn+XI3tDMydCd3SVwKbmk0otskeXm6RZkkLgW3NAqOU/FqgOpvSyJTj1sCzxjDqlUO\nvXrZeatW9jrcp5zibV0ix6jHLVKV115zx0OHKrQlsSm4pVGIPs09L8+7OkRiQa0SCTxjDGUfz+Rk\ne1Gp1q29rUkkilolIifys58ptCXxKbilUVGbRIJAwS2B9sMPFefDhnlTh0gsKbgl0IqL3XFODpxz\njne1iMSKglsCLfpoEq22JSgU3BJYkQi8/ro7V3BLUCi4JbBWroSvvrLjdu1gwABv6xGJFQW3BFZ0\nm+Sqq+yNgUWCQMEtgRV9mrvaJBIkOnNSAmnbNjjrrLKZYd8+h5/8xMuKRKqlMydFoOJOSUChLYGi\n4JZAiu5viwSNWiUSON99B+3bw6FDZc/Ye06K+JRaJSJvvumGdvfu3tYi0hAU3BI4OltSgk7BLYES\nicDf/+7OFdwSRApuCZSSEns/SYAzzoC+fb2tR6QhKLglUKJPurn6amiiT7gEkD7WEijqb0tjoMMB\nJTA2b4asLDtu2hR274bmze09J3U4oPiYDgeUxit6tX3ppTa0RYJIwS2BoTaJNBZqlUgg7N9vz5Y8\ncsTOt22D9HQ7VqtEfE6tEmmcFi92Q7t3bze0RYJIwS2BsGCBOx4xwrs6ROJBwS2+VVRURHZ2Nl27\ndmXq1KnVbvfeex8wf34K8Aqg4JbgU49bfCkSidC1a1eKi4tJTU0lNzeX+fPnk52dXWm7Pn0uZ9Wq\nU4FxZGVdy6ZNYKK6hupxi8+pxy3BUFJSQpcuXcjMzCQlJYUxY8ZQWFhYabvHHnuMFi1GAWcAdrVt\nav1rIJJYFNziS+FwmIyMjPJ5eno64XC4wjZffvklCxYsYOPGX1L2P3zXXBPPKkW8oeCWhHXXXXdx\n441T+fprO2/Z0mHgQG9rEomHZK8LEKlKWloaW7duLZ9v376dtLS0Ctt8+OGHLFkyBrva3kVp6WL+\n/vcU8vLyKr3fpEmTysehUIhQKNQwhYvEgXZOii8dPXqUbt26UVxcTMeOHenbty/z5s0jJyenfBvH\ngexsWL8e4Bfcffcwpky5ttJ7aeek+Fyt98poxS2+lJSUxLRp0xg8eDCRSIT8/HxycnKYMWMGxhgK\nCgpYt64stCE52dCjh7c1i8SLVtySsKZMgT/8wY5HjoSXXqp6O624xed0OKA0HjpbUhorrbglIYXD\n7vVIkpPt7cratKl6W624xee04pbG4dVX3XEoVH1oiwSRglsS0osvuuNrKx9IIhJoapVIwvnqK0hL\ns4cDNmkCX34JHTpUv71aJeJzapVI8L3yig1tgIsvPnFoiwSRglsSzgsvuOPRo72rQ8QrapVIQolu\nkxhj2yRnnnni16hVIj6nVokE2/FtkpOFtkgQKbgloUQfTaI2iTRWapVIwvj6a0hNrV2bBNQqEd9T\nq0SCS20SEUvBLQlDR5OIWGqVSELYvh3OOsttk4TD0LFjzV6rVon4nFolEkzz5rltkksvrXloiwSR\nglsSwnPPueMbbvCuDhE/UKtEfO+zz+C88+y4WTN7dEmrVjV/vVol4nNqlUjwRK+2hw2rXWiLBJGC\nW3wtEoG5c9252iQiapWIzy1fDj/7mR23aWPbJKecUrv3UKtEfE6tEgmWZ591x9ddV/vQFgkirbjF\nt3780Z7ivnevnS9b5q6+a0MrbvE5rbglOBYscEP77LPhwgs9LUfENxTc4lt/+5s7HjfO3qZMRNQq\nEZ/asgWystxT3Ddvtqe814VaJeJzapVIMMye7Z7iPnhw3UNbJIgU3OI7kQjMmuXOx43zrhYRP1Kr\nRHynuBguu8yO27a1N0xo2rTu76dWificWiWS+GbOdMc33li/0BYJIq24xVd27ICMDDhyxM5XrYKe\nPev3nlpxi89pxS2JbeZMN7QHDKh/aIsEkYJbfKO0FJ580p1PmOBdLSJ+puAW31i40N6iDOD002HU\nKG/rEfErBbf4xvTp7vjWW7VTUqQ62jkpvrBuHeTk2HGTJvDFF7E76UY7J8XntHNSEtOjj7rjYcN0\npqTIiSi4xXPffGNPcS9z5532a1FREdnZ2XTt2pWpU6dWet3cuXPp2bMnPXv25KKLLuLTTz+NT8Ei\nHkv2ugCR6dPttbcB+vSBUAgikQgTJ06kuLiY1NRUcnNzGT58ONnZ2eWv69SpE8uWLaNVq1YUFRVx\n6623smLFCm/+ECJxpBW3eOqHHyrulPztb+3VAEtKSujSpQuZmZmkpKQwZswYCgsLK7y2f//+tDp2\n5+D+/fsTDofjWbqIZxTc4qnZs2H3bjs++2wYOdKOw+EwGRkZ5dulp6efMJhnzpzJkCFDGq5QER9R\nq0Q8U1oKjzzizn/9a0iuwyfynXfeYdasWSxfvrzabSZNmlQ+DoVChEKh2v8gEZ9QcItn5s2DTZvs\nuE2bipdvTUtLY+vWreXz7du3k5aWVuk9Vq9eTUFBAUVFRbRp06banxUd3CKJTq0S8URpKUye7M7v\nvBNatHDnubm5bNy4kS1btnD48GHmz59PXl5ehffYunUrI0eOZM6cOZxzzjlxqlzEe1pxiyfmzYMN\nG+y4dWv3EMAySUlJTJs2jcGDBxOJRMjPzycnJ4cZM2ZgjKGgoIDJkyezZ88ebr/9dhzHISUlhZKS\nkvj/YUTiTGdOStyVltqzJDdutPMHH4T772+4n6czJ8XndOak+N9zz7mhXdVqW0ROTMEtcXXwINx3\nnzv/zW/g2KHYIlJDCm6Jq7/8BbZts+PTT9dqW6QuFNwSNzt3wn/9lzt/8EH4yU+8q0ckUSm4JW4m\nT4b9++04OxtuucXbekQSlY4qkbj47DPo1cseUQJQWAjHHZbdYHRUificjioR/3Ec+OUv3dAOhew1\nt0WkbhTc0uCefhr++7/tODkZpk2zVwAUkbpRcEuD2r3bXqq1zL//O5x7rnf1iASBetzSoG6+2a64\nATIzba+7efP41qAet/icetziH4WFbmiDPYY73qEtEkRacUuD2LkTzjvP3k8SYOxYe6q7F7TiFp+r\n9YpbwS0x5zj2TjavvmrnHTvCmjXQtq039Si4xefUKhHvTZvmhjbAU095F9oiQaQVt8RUSQlcdBEc\nOWLnt99e8WbAXtCKW3xOrRLxzq5dcMEFsGWLnffpA++9B02beluXglt8Tq0S8cahQzBihBvarVrB\niy96H9oiQaTglnpzHMjPt6trsGdFzpkDWVne1iUSVApuqbf77694qN/DD+taJCINST1uqZepU+Hu\nu915QQE8+aS/rkWiHrf4nHZOSvw89hjccYc7v/JKeO01SEnxrqaqKLjF57RzUuLjT3+qGNqhELz8\nsv9CWySIkr0uQBKL48Dvfmf72GUGDICFC+G007yrS6QxUXBLjf3wg73d2Lx57nMXX2zbIy1aeFeX\nSGOj4JYa2bwZrrkGVq1ynxsxwoZ4s2aelSXSKKnHLSe1cKE9IzI6tG+7zZ5go9AWiT8Ft1TrwAG4\n9VZ7U9/du+1zKSkwYwY88YS9DZmIxJ9+9aQSx7F96zvvdE9hB0hNtavsgQO9q01EtOKW42zYAFdf\nXfG6IwCjR8Onnyq0RfxAwS2A3fmYnw85ObBokft827b2uiPPP69raov4hVoljdwnn9h7Qc6Z415D\nG+wp6wUF8Mc/Qrt23tUnIpUpuBuhgwftkSKPPw7vvlv5+z//OUyZArm58a9NRE5Owd1IHDkCy5bZ\nq/i9/DLs3195m4sugsmT7enrIuJfCu4A+/prKCqyPeslS2DfvsrbJCXBqFH2uiMDBvjrqn4iUjUF\nd0CUlsL69fZmBmWPjRur375zZ7jhBnsKe3p6/OoUkfpTcCeYw4ftYXqbNsHatfYQvdWr7fjHH0/8\n2owMe5jfjTfa/rXfV9dFRUXcddddRCIR8vPz+f3vf19pmzvuuIPFixfTvHlzZs+eTa9evTyoVCS+\nYhbcS5cuJaTmaL18951tbyxevJSOHUN8/TXs2AHhMHzxBXz+OWzbZk+QqYlTTrHtj6FD7ePcc/0f\n1mUikQgTJ06kuLiY1NRUcnNzGT58ONnZ2eXbLF68mE2bNrFhwwb+8Y9/cNttt7FixQoPq24c9Lse\nW8aYkOM4S2vzGgX3STgOHD1qWxFVPX780R6lEf2o6rmDB+0OwX374Ntvq/7qrpiXAqFa15qaalfS\nF15oH336JO7NektKSujSpQuZmZkAjBkzhsLCwgrBXVhYyE033QRAv3792LdvHzt27KBDhw6e1NxY\nBPV33UMh7C99jcUsuJ99FlassEFXtiIsG1f3XE22acjXnSiQS0vt948ejdV/odgwxvakO3Wyfeoe\nPeyje/dgHW8dDofJyMgon6enp1NSUnLCbdLS0giHwwpuCbyYBfemTfYhdde0KZx5pv1H44IL7Ljs\ncfbZNqwzMxN3FS0isRGze04aY3RTPxGROnAcp1Z7n2J5s2CRmDHGJAH/An4OfAWUAP/mOM4/o7YZ\nCkxwHOcqY0x/4M+O4/T3pGCRONLhgOJLjuMcNcZMBJZgL4b2lOM4/zTGjLffdv6f4ziLjDFDjTEb\nge+BX3hZs0i8aMUtIpJg6nVZV2PMKGPMGmPMUWPM+cd97x5jzAZjzD+NMYPrV2bjY4x5wBiz3Riz\n8tjjSq9rSkTGmCuNMeuMMeuNMZXP4JEaM8ZsNsZ8Yoz52BhTcvJXSDRjzFPGmB3GmNVRz7Uxxiwx\nxvzLGPOGMaZVTd6rvtfj/hS4BqhwjTljTA5wHZADDAEeNyZRTv3wlUccxzn/2KPI62ISjTGmCTAN\nuAI4F/g3Y0z2iV8lJxABQo7j9HYcp6/XxSSgWdjPYrS7gbccx+kGvA3cU5M3qldwO47zL8dxNgDH\nh/JwYL7jOKWO42wGNgD6i649/WNXP32BDY7jbHEc5wgwH/vZlLox6OYrdeY4znJg73FPDweePjZ+\nGhhRk/dqqL+ENGBb1Dx87DmpnYnGmFXGmJk1/V8oqeD4z+F29DmsDwd40xjzgTHmVq+LCYgzHMfZ\nAeA4ztfAGTV50UmPKjHGvAlEn4pmsH+B/9txnIV1KFSOOdF/W+Bx4D8dx3GMMf8HeATIj3+VIuUu\ndBznK2PM6dgA/+exVaTETo2OFjlpcDuOc3kdfngYyIiapx97TqLU4r/tXwH9I1l7YeCsqLk+h/Xg\nOM5Xx77uNMa8im1FKbjrZ4cxpoPjODuMMWcC39TkRbFslUT3Y18DxhhjTjHGZAGdsSdQSA0d+0ss\ncy2wxqtaEtgHQGdjTKYx5hRgDPazKbVkjDnNGNPi2Lg5MBh9JuvCUDkrbz42/l9AYU3epF4n4Bhj\nRgCPAe2B140xqxzHGeI4zlpjzAvAWuAIcLujA8Zr6yFjTC/snvzNwHhvy0k81Z3E43FZiaoD8Oqx\nS1skA885jrPE45oSijFmLvZKgO2MMVuBB4D/C7xojBkHbMEejXfy91KeiogkFh3aIyKSYBTcIiIJ\nRsEtIpJgFNwiIglGwS0ikmAU3CIiCUbBLSKSYBTcIiIJ5v8D9YtDzsr5xtYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53a95cd630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10,10,0.01)\n",
    "y = np_sigmoid(x)\n",
    "\n",
    "centerAxis()\n",
    "plt.plot(x,y,lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f53a2155b00>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEACAYAAACTXJylAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wftR2BQN/ShFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5366313710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10, 10, 0.01)\n",
    "y = np_relu(x)\n",
    "\n",
    "centerAxis()\n",
    "plt.plot(x,y,lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das komplette Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w0 = 3\n",
    "w1 = -4\n",
    "w2 = 2\n",
    "\n",
    "import math as math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(x * -1))\n",
    "\n",
    "def neuron(x1, x2):\n",
    "    sum = w0 + x1 * w1 + x2 * w2\n",
    "    return sigmoid(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.043155690056538e-05"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron(5.1, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unser erste Neuronales Netz mit Keras\n",
    "![Neuron zu Netz](https://djcordhose.github.io/ai/img/sketch/neuron_to_layers.jpg \"Neuron zu Netz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "inputs = Input(shape=(4, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "fc = Dense(3)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model = Model(input=inputs, output=fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.23584461, -1.13255548, -3.45655632]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[ 5.1,  3.5,  1.4,  0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fully Connected](https://djcordhose.github.io/ai/img/sketch/fc_nn.jpg \"Fully Connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(4, ))\n",
    "fc = Dense(3)(inputs)\n",
    "predictions = Dense(3, activation='softmax')(fc)\n",
    "model = Model(input=inputs, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09841966,  0.87404394,  0.02753644]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[ 5.1,  3.5,  1.4,  0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(iris.data)\n",
    "y = np.array(iris.target)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tiny little pieces of feature engeneering\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "num_categories = 3\n",
    "\n",
    "y = to_categorical(y, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120, 3), (30, 3))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !rm -r tf_log\n",
    "# tb_callback = keras.callbacks.TensorBoard(log_dir='./tf_log')\n",
    "\n",
    "# https://keras.io/callbacks/#tensorboard\n",
    "# To start tensorboard\n",
    "# tensorboard --logdir=/mnt/c/Users/olive/Development/ml/tf_log\n",
    "# open http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 36 samples\n",
      "Epoch 1/500\n",
      "84/84 [==============================] - 0s - loss: 1.6569 - acc: 0.3690 - val_loss: 2.0478 - val_acc: 0.2222\n",
      "Epoch 2/500\n",
      "84/84 [==============================] - 0s - loss: 1.6029 - acc: 0.3690 - val_loss: 1.9716 - val_acc: 0.2222\n",
      "Epoch 3/500\n",
      "84/84 [==============================] - 0s - loss: 1.5480 - acc: 0.3690 - val_loss: 1.8985 - val_acc: 0.2222\n",
      "Epoch 4/500\n",
      "84/84 [==============================] - 0s - loss: 1.4995 - acc: 0.3690 - val_loss: 1.8268 - val_acc: 0.2222\n",
      "Epoch 5/500\n",
      "84/84 [==============================] - 0s - loss: 1.4511 - acc: 0.3690 - val_loss: 1.7574 - val_acc: 0.2222\n",
      "Epoch 6/500\n",
      "84/84 [==============================] - 0s - loss: 1.4036 - acc: 0.3690 - val_loss: 1.6917 - val_acc: 0.2222\n",
      "Epoch 7/500\n",
      "84/84 [==============================] - 0s - loss: 1.3624 - acc: 0.3690 - val_loss: 1.6280 - val_acc: 0.2222\n",
      "Epoch 8/500\n",
      "84/84 [==============================] - 0s - loss: 1.3182 - acc: 0.3690 - val_loss: 1.5681 - val_acc: 0.2222\n",
      "Epoch 9/500\n",
      "84/84 [==============================] - 0s - loss: 1.2816 - acc: 0.3690 - val_loss: 1.5108 - val_acc: 0.2222\n",
      "Epoch 10/500\n",
      "84/84 [==============================] - 0s - loss: 1.2443 - acc: 0.3690 - val_loss: 1.4566 - val_acc: 0.2222\n",
      "Epoch 11/500\n",
      "84/84 [==============================] - 0s - loss: 1.2100 - acc: 0.3690 - val_loss: 1.4059 - val_acc: 0.2222\n",
      "Epoch 12/500\n",
      "84/84 [==============================] - 0s - loss: 1.1789 - acc: 0.3690 - val_loss: 1.3584 - val_acc: 0.2222\n",
      "Epoch 13/500\n",
      "84/84 [==============================] - 0s - loss: 1.1506 - acc: 0.3690 - val_loss: 1.3140 - val_acc: 0.2222\n",
      "Epoch 14/500\n",
      "84/84 [==============================] - 0s - loss: 1.1242 - acc: 0.3690 - val_loss: 1.2732 - val_acc: 0.2222\n",
      "Epoch 15/500\n",
      "84/84 [==============================] - 0s - loss: 1.1006 - acc: 0.3690 - val_loss: 1.2355 - val_acc: 0.2222\n",
      "Epoch 16/500\n",
      "84/84 [==============================] - 0s - loss: 1.0785 - acc: 0.3690 - val_loss: 1.2008 - val_acc: 0.2222\n",
      "Epoch 17/500\n",
      "84/84 [==============================] - 0s - loss: 1.0588 - acc: 0.3690 - val_loss: 1.1691 - val_acc: 0.2222\n",
      "Epoch 18/500\n",
      "84/84 [==============================] - 0s - loss: 1.0415 - acc: 0.3690 - val_loss: 1.1396 - val_acc: 0.2222\n",
      "Epoch 19/500\n",
      "84/84 [==============================] - 0s - loss: 1.0253 - acc: 0.3810 - val_loss: 1.1126 - val_acc: 0.2222\n",
      "Epoch 20/500\n",
      "84/84 [==============================] - 0s - loss: 1.0110 - acc: 0.3810 - val_loss: 1.0874 - val_acc: 0.2222\n",
      "Epoch 21/500\n",
      "84/84 [==============================] - 0s - loss: 0.9981 - acc: 0.3810 - val_loss: 1.0642 - val_acc: 0.2222\n",
      "Epoch 22/500\n",
      "84/84 [==============================] - 0s - loss: 0.9863 - acc: 0.3810 - val_loss: 1.0435 - val_acc: 0.2222\n",
      "Epoch 23/500\n",
      "84/84 [==============================] - 0s - loss: 0.9769 - acc: 0.3929 - val_loss: 1.0243 - val_acc: 0.2778\n",
      "Epoch 24/500\n",
      "84/84 [==============================] - 0s - loss: 0.9663 - acc: 0.4524 - val_loss: 1.0079 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "84/84 [==============================] - 0s - loss: 0.9581 - acc: 0.5000 - val_loss: 0.9925 - val_acc: 0.3611\n",
      "Epoch 26/500\n",
      "84/84 [==============================] - 0s - loss: 0.9502 - acc: 0.5238 - val_loss: 0.9785 - val_acc: 0.4722\n",
      "Epoch 27/500\n",
      "84/84 [==============================] - 0s - loss: 0.9430 - acc: 0.5714 - val_loss: 0.9659 - val_acc: 0.4444\n",
      "Epoch 28/500\n",
      "84/84 [==============================] - 0s - loss: 0.9357 - acc: 0.5714 - val_loss: 0.9549 - val_acc: 0.4444\n",
      "Epoch 29/500\n",
      "84/84 [==============================] - 0s - loss: 0.9297 - acc: 0.5952 - val_loss: 0.9443 - val_acc: 0.5278\n",
      "Epoch 30/500\n",
      "84/84 [==============================] - 0s - loss: 0.9232 - acc: 0.5952 - val_loss: 0.9350 - val_acc: 0.5556\n",
      "Epoch 31/500\n",
      "84/84 [==============================] - 0s - loss: 0.9180 - acc: 0.5714 - val_loss: 0.9254 - val_acc: 0.5556\n",
      "Epoch 32/500\n",
      "84/84 [==============================] - 0s - loss: 0.9120 - acc: 0.5714 - val_loss: 0.9171 - val_acc: 0.5556\n",
      "Epoch 33/500\n",
      "84/84 [==============================] - 0s - loss: 0.9065 - acc: 0.5714 - val_loss: 0.9093 - val_acc: 0.5556\n",
      "Epoch 34/500\n",
      "84/84 [==============================] - 0s - loss: 0.9014 - acc: 0.5833 - val_loss: 0.9013 - val_acc: 0.5833\n",
      "Epoch 35/500\n",
      "84/84 [==============================] - 0s - loss: 0.8959 - acc: 0.5833 - val_loss: 0.8944 - val_acc: 0.5833\n",
      "Epoch 36/500\n",
      "84/84 [==============================] - 0s - loss: 0.8909 - acc: 0.5833 - val_loss: 0.8872 - val_acc: 0.5833\n",
      "Epoch 37/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.9152 - acc: 0.500 - 0s - loss: 0.8862 - acc: 0.5833 - val_loss: 0.8806 - val_acc: 0.5556\n",
      "Epoch 38/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.8614 - acc: 0.593 - 0s - loss: 0.8805 - acc: 0.5714 - val_loss: 0.8749 - val_acc: 0.5833\n",
      "Epoch 39/500\n",
      "84/84 [==============================] - 0s - loss: 0.8759 - acc: 0.5714 - val_loss: 0.8693 - val_acc: 0.5833\n",
      "Epoch 40/500\n",
      "84/84 [==============================] - 0s - loss: 0.8711 - acc: 0.5714 - val_loss: 0.8642 - val_acc: 0.5833\n",
      "Epoch 41/500\n",
      "84/84 [==============================] - 0s - loss: 0.8661 - acc: 0.5714 - val_loss: 0.8591 - val_acc: 0.5833\n",
      "Epoch 42/500\n",
      "84/84 [==============================] - 0s - loss: 0.8613 - acc: 0.5714 - val_loss: 0.8541 - val_acc: 0.5833\n",
      "Epoch 43/500\n",
      "84/84 [==============================] - 0s - loss: 0.8565 - acc: 0.5714 - val_loss: 0.8492 - val_acc: 0.5833\n",
      "Epoch 44/500\n",
      "84/84 [==============================] - 0s - loss: 0.8519 - acc: 0.5714 - val_loss: 0.8452 - val_acc: 0.5833\n",
      "Epoch 45/500\n",
      "84/84 [==============================] - 0s - loss: 0.8469 - acc: 0.5714 - val_loss: 0.8405 - val_acc: 0.5833\n",
      "Epoch 46/500\n",
      "84/84 [==============================] - 0s - loss: 0.8424 - acc: 0.5714 - val_loss: 0.8359 - val_acc: 0.5833\n",
      "Epoch 47/500\n",
      "84/84 [==============================] - 0s - loss: 0.8372 - acc: 0.5714 - val_loss: 0.8319 - val_acc: 0.5833\n",
      "Epoch 48/500\n",
      "84/84 [==============================] - 0s - loss: 0.8326 - acc: 0.5714 - val_loss: 0.8278 - val_acc: 0.6111\n",
      "Epoch 49/500\n",
      "84/84 [==============================] - 0s - loss: 0.8280 - acc: 0.5833 - val_loss: 0.8230 - val_acc: 0.6111\n",
      "Epoch 50/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.8040 - acc: 0.687 - 0s - loss: 0.8232 - acc: 0.5833 - val_loss: 0.8189 - val_acc: 0.5833\n",
      "Epoch 51/500\n",
      "84/84 [==============================] - 0s - loss: 0.8188 - acc: 0.5833 - val_loss: 0.8142 - val_acc: 0.5833\n",
      "Epoch 52/500\n",
      "84/84 [==============================] - 0s - loss: 0.8140 - acc: 0.5833 - val_loss: 0.8090 - val_acc: 0.6111\n",
      "Epoch 53/500\n",
      "84/84 [==============================] - 0s - loss: 0.8092 - acc: 0.5833 - val_loss: 0.8046 - val_acc: 0.6111\n",
      "Epoch 54/500\n",
      "84/84 [==============================] - 0s - loss: 0.8050 - acc: 0.5833 - val_loss: 0.8002 - val_acc: 0.6111\n",
      "Epoch 55/500\n",
      "84/84 [==============================] - 0s - loss: 0.8002 - acc: 0.5833 - val_loss: 0.7964 - val_acc: 0.5833\n",
      "Epoch 56/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7841 - acc: 0.687 - 0s - loss: 0.7956 - acc: 0.5833 - val_loss: 0.7922 - val_acc: 0.6111\n",
      "Epoch 57/500\n",
      "84/84 [==============================] - 0s - loss: 0.7914 - acc: 0.5952 - val_loss: 0.7877 - val_acc: 0.6111\n",
      "Epoch 58/500\n",
      "84/84 [==============================] - 0s - loss: 0.7868 - acc: 0.6190 - val_loss: 0.7821 - val_acc: 0.6389\n",
      "Epoch 59/500\n",
      "84/84 [==============================] - 0s - loss: 0.7823 - acc: 0.6310 - val_loss: 0.7772 - val_acc: 0.6944\n",
      "Epoch 60/500\n",
      "84/84 [==============================] - 0s - loss: 0.7779 - acc: 0.6667 - val_loss: 0.7729 - val_acc: 0.7222\n",
      "Epoch 61/500\n",
      "84/84 [==============================] - 0s - loss: 0.7738 - acc: 0.7024 - val_loss: 0.7690 - val_acc: 0.7778\n",
      "Epoch 62/500\n",
      "84/84 [==============================] - 0s - loss: 0.7693 - acc: 0.7381 - val_loss: 0.7645 - val_acc: 0.8333\n",
      "Epoch 63/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7676 - acc: 0.843 - 0s - loss: 0.7651 - acc: 0.7619 - val_loss: 0.7601 - val_acc: 0.8333\n",
      "Epoch 64/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7493 - acc: 0.843 - 0s - loss: 0.7609 - acc: 0.7976 - val_loss: 0.7552 - val_acc: 0.8333\n",
      "Epoch 65/500\n",
      "84/84 [==============================] - 0s - loss: 0.7566 - acc: 0.8214 - val_loss: 0.7508 - val_acc: 0.8333\n",
      "Epoch 66/500\n",
      "84/84 [==============================] - 0s - loss: 0.7527 - acc: 0.8214 - val_loss: 0.7460 - val_acc: 0.8056\n",
      "Epoch 67/500\n",
      "84/84 [==============================] - 0s - loss: 0.7485 - acc: 0.8214 - val_loss: 0.7420 - val_acc: 0.8333\n",
      "Epoch 68/500\n",
      "84/84 [==============================] - 0s - loss: 0.7442 - acc: 0.8571 - val_loss: 0.7377 - val_acc: 0.8611\n",
      "Epoch 69/500\n",
      "84/84 [==============================] - 0s - loss: 0.7405 - acc: 0.8571 - val_loss: 0.7332 - val_acc: 0.8611\n",
      "Epoch 70/500\n",
      "84/84 [==============================] - 0s - loss: 0.7361 - acc: 0.8690 - val_loss: 0.7294 - val_acc: 0.8611\n",
      "Epoch 71/500\n",
      "84/84 [==============================] - 0s - loss: 0.7323 - acc: 0.8690 - val_loss: 0.7254 - val_acc: 0.8889\n",
      "Epoch 72/500\n",
      "84/84 [==============================] - 0s - loss: 0.7281 - acc: 0.8929 - val_loss: 0.7222 - val_acc: 0.9167\n",
      "Epoch 73/500\n",
      "84/84 [==============================] - 0s - loss: 0.7244 - acc: 0.8929 - val_loss: 0.7195 - val_acc: 0.9167\n",
      "Epoch 74/500\n",
      "84/84 [==============================] - 0s - loss: 0.7202 - acc: 0.9048 - val_loss: 0.7158 - val_acc: 0.9167\n",
      "Epoch 75/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7205 - acc: 0.906 - 0s - loss: 0.7165 - acc: 0.9048 - val_loss: 0.7121 - val_acc: 0.9167\n",
      "Epoch 76/500\n",
      "84/84 [==============================] - 0s - loss: 0.7125 - acc: 0.9048 - val_loss: 0.7077 - val_acc: 0.9167\n",
      "Epoch 77/500\n",
      "84/84 [==============================] - 0s - loss: 0.7086 - acc: 0.9048 - val_loss: 0.7041 - val_acc: 0.9167\n",
      "Epoch 78/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6891 - acc: 0.937 - 0s - loss: 0.7050 - acc: 0.9048 - val_loss: 0.7005 - val_acc: 0.9167\n",
      "Epoch 79/500\n",
      "84/84 [==============================] - 0s - loss: 0.7010 - acc: 0.9048 - val_loss: 0.6976 - val_acc: 0.9167\n",
      "Epoch 80/500\n",
      "84/84 [==============================] - 0s - loss: 0.6973 - acc: 0.9048 - val_loss: 0.6949 - val_acc: 0.9167\n",
      "Epoch 81/500\n",
      "84/84 [==============================] - 0s - loss: 0.6935 - acc: 0.9167 - val_loss: 0.6920 - val_acc: 0.9167\n",
      "Epoch 82/500\n",
      "84/84 [==============================] - 0s - loss: 0.6899 - acc: 0.9167 - val_loss: 0.6890 - val_acc: 0.9167\n",
      "Epoch 83/500\n",
      "84/84 [==============================] - 0s - loss: 0.6863 - acc: 0.9167 - val_loss: 0.6852 - val_acc: 0.9167\n",
      "Epoch 84/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6639 - acc: 0.937 - 0s - loss: 0.6824 - acc: 0.9167 - val_loss: 0.6819 - val_acc: 0.9167\n",
      "Epoch 85/500\n",
      "84/84 [==============================] - 0s - loss: 0.6788 - acc: 0.9167 - val_loss: 0.6786 - val_acc: 0.9167\n",
      "Epoch 86/500\n",
      "84/84 [==============================] - 0s - loss: 0.6752 - acc: 0.9167 - val_loss: 0.6753 - val_acc: 0.9167\n",
      "Epoch 87/500\n",
      "84/84 [==============================] - 0s - loss: 0.6717 - acc: 0.9167 - val_loss: 0.6722 - val_acc: 0.9167\n",
      "Epoch 88/500\n",
      "84/84 [==============================] - 0s - loss: 0.6685 - acc: 0.9167 - val_loss: 0.6679 - val_acc: 0.9167\n",
      "Epoch 89/500\n",
      "84/84 [==============================] - 0s - loss: 0.6648 - acc: 0.9167 - val_loss: 0.6638 - val_acc: 0.9167\n",
      "Epoch 90/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6654 - acc: 0.906 - 0s - loss: 0.6611 - acc: 0.9286 - val_loss: 0.6608 - val_acc: 0.9167\n",
      "Epoch 91/500\n",
      "84/84 [==============================] - 0s - loss: 0.6576 - acc: 0.9286 - val_loss: 0.6581 - val_acc: 0.9167\n",
      "Epoch 92/500\n",
      "84/84 [==============================] - 0s - loss: 0.6541 - acc: 0.9286 - val_loss: 0.6550 - val_acc: 0.9167\n",
      "Epoch 93/500\n",
      "84/84 [==============================] - 0s - loss: 0.6508 - acc: 0.9286 - val_loss: 0.6513 - val_acc: 0.9167\n",
      "Epoch 94/500\n",
      "84/84 [==============================] - 0s - loss: 0.6473 - acc: 0.9286 - val_loss: 0.6476 - val_acc: 0.9167\n",
      "Epoch 95/500\n",
      "84/84 [==============================] - 0s - loss: 0.6440 - acc: 0.9286 - val_loss: 0.6438 - val_acc: 0.9167\n",
      "Epoch 96/500\n",
      "84/84 [==============================] - 0s - loss: 0.6407 - acc: 0.9286 - val_loss: 0.6397 - val_acc: 0.9444\n",
      "Epoch 97/500\n",
      "84/84 [==============================] - 0s - loss: 0.6373 - acc: 0.9286 - val_loss: 0.6366 - val_acc: 0.9444\n",
      "Epoch 98/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6078 - acc: 0.937 - 0s - loss: 0.6341 - acc: 0.9286 - val_loss: 0.6332 - val_acc: 0.9444\n",
      "Epoch 99/500\n",
      "84/84 [==============================] - 0s - loss: 0.6308 - acc: 0.9286 - val_loss: 0.6310 - val_acc: 0.9167\n",
      "Epoch 100/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6982 - acc: 0.843 - 0s - loss: 0.6279 - acc: 0.9286 - val_loss: 0.6290 - val_acc: 0.9167\n",
      "Epoch 101/500\n",
      "84/84 [==============================] - 0s - loss: 0.6243 - acc: 0.9286 - val_loss: 0.6255 - val_acc: 0.9167\n",
      "Epoch 102/500\n",
      "84/84 [==============================] - 0s - loss: 0.6213 - acc: 0.9286 - val_loss: 0.6224 - val_acc: 0.9167\n",
      "Epoch 103/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6260 - acc: 0.906 - 0s - loss: 0.6182 - acc: 0.9286 - val_loss: 0.6202 - val_acc: 0.9167\n",
      "Epoch 104/500\n",
      "84/84 [==============================] - 0s - loss: 0.6150 - acc: 0.9286 - val_loss: 0.6168 - val_acc: 0.9167\n",
      "Epoch 105/500\n",
      "84/84 [==============================] - 0s - loss: 0.6119 - acc: 0.9286 - val_loss: 0.6136 - val_acc: 0.9167\n",
      "Epoch 106/500\n",
      "84/84 [==============================] - 0s - loss: 0.6087 - acc: 0.9286 - val_loss: 0.6107 - val_acc: 0.9167\n",
      "Epoch 107/500\n",
      "84/84 [==============================] - 0s - loss: 0.6057 - acc: 0.9286 - val_loss: 0.6081 - val_acc: 0.9167\n",
      "Epoch 108/500\n",
      "84/84 [==============================] - 0s - loss: 0.6028 - acc: 0.9286 - val_loss: 0.6054 - val_acc: 0.9167\n",
      "Epoch 109/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6026 - acc: 0.875 - 0s - loss: 0.5999 - acc: 0.9286 - val_loss: 0.6025 - val_acc: 0.9167\n",
      "Epoch 110/500\n",
      "84/84 [==============================] - 0s - loss: 0.5967 - acc: 0.9286 - val_loss: 0.5990 - val_acc: 0.9167\n",
      "Epoch 111/500\n",
      "84/84 [==============================] - 0s - loss: 0.5939 - acc: 0.9286 - val_loss: 0.5950 - val_acc: 0.9444\n",
      "Epoch 112/500\n",
      "84/84 [==============================] - 0s - loss: 0.5910 - acc: 0.9286 - val_loss: 0.5920 - val_acc: 0.9444\n",
      "Epoch 113/500\n",
      "84/84 [==============================] - 0s - loss: 0.5880 - acc: 0.9286 - val_loss: 0.5890 - val_acc: 0.9444\n",
      "Epoch 114/500\n",
      "84/84 [==============================] - 0s - loss: 0.5851 - acc: 0.9286 - val_loss: 0.5864 - val_acc: 0.9444\n",
      "Epoch 115/500\n",
      "84/84 [==============================] - 0s - loss: 0.5823 - acc: 0.9286 - val_loss: 0.5833 - val_acc: 0.9444\n",
      "Epoch 116/500\n",
      "84/84 [==============================] - 0s - loss: 0.5795 - acc: 0.9286 - val_loss: 0.5803 - val_acc: 0.9444\n",
      "Epoch 117/500\n",
      "84/84 [==============================] - 0s - loss: 0.5769 - acc: 0.9286 - val_loss: 0.5770 - val_acc: 0.9444\n",
      "Epoch 118/500\n",
      "84/84 [==============================] - 0s - loss: 0.5740 - acc: 0.9286 - val_loss: 0.5745 - val_acc: 0.9444\n",
      "Epoch 119/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5774 - acc: 0.968 - 0s - loss: 0.5713 - acc: 0.9286 - val_loss: 0.5725 - val_acc: 0.9444\n",
      "Epoch 120/500\n",
      "84/84 [==============================] - 0s - loss: 0.5686 - acc: 0.9286 - val_loss: 0.5703 - val_acc: 0.9444\n",
      "Epoch 121/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5552 - acc: 0.906 - 0s - loss: 0.5659 - acc: 0.9286 - val_loss: 0.5680 - val_acc: 0.9444\n",
      "Epoch 122/500\n",
      "84/84 [==============================] - 0s - loss: 0.5634 - acc: 0.9286 - val_loss: 0.5661 - val_acc: 0.9444\n",
      "Epoch 123/500\n",
      "84/84 [==============================] - 0s - loss: 0.5606 - acc: 0.9286 - val_loss: 0.5631 - val_acc: 0.9444\n",
      "Epoch 124/500\n",
      "84/84 [==============================] - 0s - loss: 0.5580 - acc: 0.9286 - val_loss: 0.5609 - val_acc: 0.9444\n",
      "Epoch 125/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4979 - acc: 1.000 - 0s - loss: 0.5555 - acc: 0.9286 - val_loss: 0.5585 - val_acc: 0.9444\n",
      "Epoch 126/500\n",
      "84/84 [==============================] - 0s - loss: 0.5529 - acc: 0.9286 - val_loss: 0.5569 - val_acc: 0.9444\n",
      "Epoch 127/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - ETA: 0s - loss: 0.5301 - acc: 0.968 - 0s - loss: 0.5502 - acc: 0.9286 - val_loss: 0.5547 - val_acc: 0.9444\n",
      "Epoch 128/500\n",
      "84/84 [==============================] - 0s - loss: 0.5478 - acc: 0.9286 - val_loss: 0.5531 - val_acc: 0.9167\n",
      "Epoch 129/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5464 - acc: 0.937 - 0s - loss: 0.5453 - acc: 0.9286 - val_loss: 0.5515 - val_acc: 0.9167\n",
      "Epoch 130/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5672 - acc: 0.906 - 0s - loss: 0.5427 - acc: 0.9286 - val_loss: 0.5501 - val_acc: 0.9167\n",
      "Epoch 131/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5083 - acc: 0.937 - 0s - loss: 0.5403 - acc: 0.9286 - val_loss: 0.5487 - val_acc: 0.9167\n",
      "Epoch 132/500\n",
      "84/84 [==============================] - 0s - loss: 0.5379 - acc: 0.9524 - val_loss: 0.5473 - val_acc: 0.9167\n",
      "Epoch 133/500\n",
      "84/84 [==============================] - 0s - loss: 0.5355 - acc: 0.9524 - val_loss: 0.5452 - val_acc: 0.9167\n",
      "Epoch 134/500\n",
      "84/84 [==============================] - 0s - loss: 0.5331 - acc: 0.9524 - val_loss: 0.5430 - val_acc: 0.9167\n",
      "Epoch 135/500\n",
      "84/84 [==============================] - 0s - loss: 0.5307 - acc: 0.9524 - val_loss: 0.5412 - val_acc: 0.9167\n",
      "Epoch 136/500\n",
      "84/84 [==============================] - 0s - loss: 0.5285 - acc: 0.9524 - val_loss: 0.5390 - val_acc: 0.9167\n",
      "Epoch 137/500\n",
      "84/84 [==============================] - 0s - loss: 0.5260 - acc: 0.9524 - val_loss: 0.5366 - val_acc: 0.9167\n",
      "Epoch 138/500\n",
      "84/84 [==============================] - 0s - loss: 0.5238 - acc: 0.9524 - val_loss: 0.5344 - val_acc: 0.9167\n",
      "Epoch 139/500\n",
      "84/84 [==============================] - 0s - loss: 0.5215 - acc: 0.9524 - val_loss: 0.5316 - val_acc: 0.9167\n",
      "Epoch 140/500\n",
      "84/84 [==============================] - 0s - loss: 0.5192 - acc: 0.9524 - val_loss: 0.5295 - val_acc: 0.9167\n",
      "Epoch 141/500\n",
      "84/84 [==============================] - 0s - loss: 0.5170 - acc: 0.9524 - val_loss: 0.5268 - val_acc: 0.9167\n",
      "Epoch 142/500\n",
      "84/84 [==============================] - 0s - loss: 0.5147 - acc: 0.9524 - val_loss: 0.5242 - val_acc: 0.9167\n",
      "Epoch 143/500\n",
      "84/84 [==============================] - 0s - loss: 0.5125 - acc: 0.9524 - val_loss: 0.5220 - val_acc: 0.9167\n",
      "Epoch 144/500\n",
      "84/84 [==============================] - 0s - loss: 0.5103 - acc: 0.9524 - val_loss: 0.5195 - val_acc: 0.9167\n",
      "Epoch 145/500\n",
      "84/84 [==============================] - 0s - loss: 0.5081 - acc: 0.9524 - val_loss: 0.5167 - val_acc: 0.9444\n",
      "Epoch 146/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5039 - acc: 1.000 - 0s - loss: 0.5060 - acc: 0.9524 - val_loss: 0.5143 - val_acc: 0.9444\n",
      "Epoch 147/500\n",
      "84/84 [==============================] - 0s - loss: 0.5038 - acc: 0.9524 - val_loss: 0.5120 - val_acc: 0.9444\n",
      "Epoch 148/500\n",
      "84/84 [==============================] - 0s - loss: 0.5018 - acc: 0.9286 - val_loss: 0.5098 - val_acc: 0.9444\n",
      "Epoch 149/500\n",
      "84/84 [==============================] - 0s - loss: 0.4996 - acc: 0.9524 - val_loss: 0.5088 - val_acc: 0.9444\n",
      "Epoch 150/500\n",
      "84/84 [==============================] - 0s - loss: 0.4975 - acc: 0.9524 - val_loss: 0.5072 - val_acc: 0.9444\n",
      "Epoch 151/500\n",
      "84/84 [==============================] - 0s - loss: 0.4953 - acc: 0.9524 - val_loss: 0.5058 - val_acc: 0.9167\n",
      "Epoch 152/500\n",
      "84/84 [==============================] - 0s - loss: 0.4934 - acc: 0.9524 - val_loss: 0.5044 - val_acc: 0.9167\n",
      "Epoch 153/500\n",
      "84/84 [==============================] - 0s - loss: 0.4913 - acc: 0.9524 - val_loss: 0.5025 - val_acc: 0.9167\n",
      "Epoch 154/500\n",
      "84/84 [==============================] - 0s - loss: 0.4893 - acc: 0.9524 - val_loss: 0.5010 - val_acc: 0.9167\n",
      "Epoch 155/500\n",
      "84/84 [==============================] - 0s - loss: 0.4873 - acc: 0.9524 - val_loss: 0.4996 - val_acc: 0.9167\n",
      "Epoch 156/500\n",
      "84/84 [==============================] - 0s - loss: 0.4853 - acc: 0.9524 - val_loss: 0.4975 - val_acc: 0.9167\n",
      "Epoch 157/500\n",
      "84/84 [==============================] - 0s - loss: 0.4834 - acc: 0.9524 - val_loss: 0.4961 - val_acc: 0.9167\n",
      "Epoch 158/500\n",
      "84/84 [==============================] - 0s - loss: 0.4815 - acc: 0.9524 - val_loss: 0.4947 - val_acc: 0.9167\n",
      "Epoch 159/500\n",
      "84/84 [==============================] - 0s - loss: 0.4795 - acc: 0.9524 - val_loss: 0.4924 - val_acc: 0.9167\n",
      "Epoch 160/500\n",
      "84/84 [==============================] - 0s - loss: 0.4776 - acc: 0.9524 - val_loss: 0.4904 - val_acc: 0.9167\n",
      "Epoch 161/500\n",
      "84/84 [==============================] - 0s - loss: 0.4757 - acc: 0.9524 - val_loss: 0.4885 - val_acc: 0.9167\n",
      "Epoch 162/500\n",
      "84/84 [==============================] - 0s - loss: 0.4738 - acc: 0.9524 - val_loss: 0.4874 - val_acc: 0.9167\n",
      "Epoch 163/500\n",
      "84/84 [==============================] - 0s - loss: 0.4719 - acc: 0.9524 - val_loss: 0.4857 - val_acc: 0.9167\n",
      "Epoch 164/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4623 - acc: 0.968 - 0s - loss: 0.4702 - acc: 0.9643 - val_loss: 0.4839 - val_acc: 0.9167\n",
      "Epoch 165/500\n",
      "84/84 [==============================] - 0s - loss: 0.4683 - acc: 0.9762 - val_loss: 0.4824 - val_acc: 0.9167\n",
      "Epoch 166/500\n",
      "84/84 [==============================] - 0s - loss: 0.4668 - acc: 0.9524 - val_loss: 0.4793 - val_acc: 0.9444\n",
      "Epoch 167/500\n",
      "84/84 [==============================] - 0s - loss: 0.4648 - acc: 0.9762 - val_loss: 0.4783 - val_acc: 0.9167\n",
      "Epoch 168/500\n",
      "84/84 [==============================] - 0s - loss: 0.4628 - acc: 0.9762 - val_loss: 0.4767 - val_acc: 0.9444\n",
      "Epoch 169/500\n",
      "84/84 [==============================] - 0s - loss: 0.4611 - acc: 0.9762 - val_loss: 0.4753 - val_acc: 0.9167\n",
      "Epoch 170/500\n",
      "84/84 [==============================] - 0s - loss: 0.4593 - acc: 0.9762 - val_loss: 0.4733 - val_acc: 0.9444\n",
      "Epoch 171/500\n",
      "84/84 [==============================] - 0s - loss: 0.4579 - acc: 0.9524 - val_loss: 0.4710 - val_acc: 0.9444\n",
      "Epoch 172/500\n",
      "84/84 [==============================] - 0s - loss: 0.4558 - acc: 0.9762 - val_loss: 0.4706 - val_acc: 0.9444\n",
      "Epoch 173/500\n",
      "84/84 [==============================] - 0s - loss: 0.4541 - acc: 0.9762 - val_loss: 0.4699 - val_acc: 0.9167\n",
      "Epoch 174/500\n",
      "84/84 [==============================] - 0s - loss: 0.4525 - acc: 0.9762 - val_loss: 0.4692 - val_acc: 0.9167\n",
      "Epoch 175/500\n",
      "84/84 [==============================] - 0s - loss: 0.4507 - acc: 0.9762 - val_loss: 0.4682 - val_acc: 0.9167\n",
      "Epoch 176/500\n",
      "84/84 [==============================] - 0s - loss: 0.4492 - acc: 0.9762 - val_loss: 0.4670 - val_acc: 0.9167\n",
      "Epoch 177/500\n",
      "84/84 [==============================] - 0s - loss: 0.4475 - acc: 0.9762 - val_loss: 0.4667 - val_acc: 0.9167\n",
      "Epoch 178/500\n",
      "84/84 [==============================] - 0s - loss: 0.4458 - acc: 0.9762 - val_loss: 0.4655 - val_acc: 0.9167\n",
      "Epoch 179/500\n",
      "84/84 [==============================] - 0s - loss: 0.4442 - acc: 0.9762 - val_loss: 0.4638 - val_acc: 0.9167\n",
      "Epoch 180/500\n",
      "84/84 [==============================] - 0s - loss: 0.4425 - acc: 0.9762 - val_loss: 0.4616 - val_acc: 0.9167\n",
      "Epoch 181/500\n",
      "84/84 [==============================] - 0s - loss: 0.4409 - acc: 0.9762 - val_loss: 0.4597 - val_acc: 0.9167\n",
      "Epoch 182/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4329 - acc: 0.968 - 0s - loss: 0.4393 - acc: 0.9762 - val_loss: 0.4578 - val_acc: 0.9167\n",
      "Epoch 183/500\n",
      "84/84 [==============================] - 0s - loss: 0.4377 - acc: 0.9762 - val_loss: 0.4565 - val_acc: 0.9167\n",
      "Epoch 184/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4332 - acc: 0.968 - 0s - loss: 0.4361 - acc: 0.9762 - val_loss: 0.4552 - val_acc: 0.9167\n",
      "Epoch 185/500\n",
      "84/84 [==============================] - 0s - loss: 0.4347 - acc: 0.9762 - val_loss: 0.4535 - val_acc: 0.9167\n",
      "Epoch 186/500\n",
      "84/84 [==============================] - 0s - loss: 0.4330 - acc: 0.9762 - val_loss: 0.4532 - val_acc: 0.9167\n",
      "Epoch 187/500\n",
      "84/84 [==============================] - 0s - loss: 0.4315 - acc: 0.9762 - val_loss: 0.4526 - val_acc: 0.9167\n",
      "Epoch 188/500\n",
      "84/84 [==============================] - 0s - loss: 0.4300 - acc: 0.9762 - val_loss: 0.4512 - val_acc: 0.9167\n",
      "Epoch 189/500\n",
      "84/84 [==============================] - 0s - loss: 0.4284 - acc: 0.9762 - val_loss: 0.4494 - val_acc: 0.9167\n",
      "Epoch 190/500\n",
      "84/84 [==============================] - 0s - loss: 0.4269 - acc: 0.9762 - val_loss: 0.4479 - val_acc: 0.9167\n",
      "Epoch 191/500\n",
      "84/84 [==============================] - 0s - loss: 0.4254 - acc: 0.9762 - val_loss: 0.4458 - val_acc: 0.9167\n",
      "Epoch 192/500\n",
      "84/84 [==============================] - 0s - loss: 0.4240 - acc: 0.9762 - val_loss: 0.4429 - val_acc: 0.9444\n",
      "Epoch 193/500\n",
      "84/84 [==============================] - 0s - loss: 0.4225 - acc: 0.9762 - val_loss: 0.4404 - val_acc: 0.9444\n",
      "Epoch 194/500\n",
      "84/84 [==============================] - 0s - loss: 0.4210 - acc: 0.9881 - val_loss: 0.4393 - val_acc: 0.9444\n",
      "Epoch 195/500\n",
      "84/84 [==============================] - 0s - loss: 0.4195 - acc: 0.9881 - val_loss: 0.4377 - val_acc: 0.9444\n",
      "Epoch 196/500\n",
      "84/84 [==============================] - 0s - loss: 0.4180 - acc: 0.9881 - val_loss: 0.4365 - val_acc: 0.9444\n",
      "Epoch 197/500\n",
      "84/84 [==============================] - 0s - loss: 0.4166 - acc: 0.9881 - val_loss: 0.4352 - val_acc: 0.9444\n",
      "Epoch 198/500\n",
      "84/84 [==============================] - 0s - loss: 0.4151 - acc: 0.9881 - val_loss: 0.4341 - val_acc: 0.9444\n",
      "Epoch 199/500\n",
      "84/84 [==============================] - 0s - loss: 0.4138 - acc: 0.9881 - val_loss: 0.4340 - val_acc: 0.9444\n",
      "Epoch 200/500\n",
      "84/84 [==============================] - 0s - loss: 0.4123 - acc: 0.9762 - val_loss: 0.4325 - val_acc: 0.9444\n",
      "Epoch 201/500\n",
      "84/84 [==============================] - 0s - loss: 0.4109 - acc: 0.9881 - val_loss: 0.4319 - val_acc: 0.9444\n",
      "Epoch 202/500\n",
      "84/84 [==============================] - 0s - loss: 0.4100 - acc: 0.9762 - val_loss: 0.4320 - val_acc: 0.9167\n",
      "Epoch 203/500\n",
      "84/84 [==============================] - 0s - loss: 0.4081 - acc: 0.9762 - val_loss: 0.4302 - val_acc: 0.9167\n",
      "Epoch 204/500\n",
      "84/84 [==============================] - 0s - loss: 0.4067 - acc: 0.9762 - val_loss: 0.4281 - val_acc: 0.9444\n",
      "Epoch 205/500\n",
      "84/84 [==============================] - 0s - loss: 0.4054 - acc: 0.9881 - val_loss: 0.4258 - val_acc: 0.9444\n",
      "Epoch 206/500\n",
      "84/84 [==============================] - 0s - loss: 0.4041 - acc: 0.9881 - val_loss: 0.4240 - val_acc: 0.9444\n",
      "Epoch 207/500\n",
      "84/84 [==============================] - 0s - loss: 0.4027 - acc: 0.9881 - val_loss: 0.4237 - val_acc: 0.9444\n",
      "Epoch 208/500\n",
      "84/84 [==============================] - 0s - loss: 0.4015 - acc: 0.9881 - val_loss: 0.4232 - val_acc: 0.9444\n",
      "Epoch 209/500\n",
      "84/84 [==============================] - 0s - loss: 0.3999 - acc: 0.9881 - val_loss: 0.4213 - val_acc: 0.9444\n",
      "Epoch 210/500\n",
      "84/84 [==============================] - 0s - loss: 0.3987 - acc: 0.9881 - val_loss: 0.4201 - val_acc: 0.9444\n",
      "Epoch 211/500\n",
      "84/84 [==============================] - 0s - loss: 0.3973 - acc: 0.9881 - val_loss: 0.4183 - val_acc: 0.9444\n",
      "Epoch 212/500\n",
      "84/84 [==============================] - 0s - loss: 0.3961 - acc: 0.9881 - val_loss: 0.4166 - val_acc: 0.9444\n",
      "Epoch 213/500\n",
      "84/84 [==============================] - 0s - loss: 0.3948 - acc: 0.9881 - val_loss: 0.4160 - val_acc: 0.9444\n",
      "Epoch 214/500\n",
      "84/84 [==============================] - 0s - loss: 0.3934 - acc: 0.9881 - val_loss: 0.4147 - val_acc: 0.9444\n",
      "Epoch 215/500\n",
      "84/84 [==============================] - 0s - loss: 0.3922 - acc: 0.9881 - val_loss: 0.4141 - val_acc: 0.9444\n",
      "Epoch 216/500\n",
      "84/84 [==============================] - 0s - loss: 0.3909 - acc: 0.9881 - val_loss: 0.4123 - val_acc: 0.9444\n",
      "Epoch 217/500\n",
      "84/84 [==============================] - 0s - loss: 0.3896 - acc: 0.9881 - val_loss: 0.4114 - val_acc: 0.9444\n",
      "Epoch 218/500\n",
      "84/84 [==============================] - 0s - loss: 0.3883 - acc: 0.9881 - val_loss: 0.4110 - val_acc: 0.9444\n",
      "Epoch 219/500\n",
      "84/84 [==============================] - 0s - loss: 0.3870 - acc: 0.9881 - val_loss: 0.4103 - val_acc: 0.9444\n",
      "Epoch 220/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4505 - acc: 0.968 - 0s - loss: 0.3858 - acc: 0.9881 - val_loss: 0.4099 - val_acc: 0.9444\n",
      "Epoch 221/500\n",
      "84/84 [==============================] - 0s - loss: 0.3845 - acc: 0.9881 - val_loss: 0.4094 - val_acc: 0.9444\n",
      "Epoch 222/500\n",
      "84/84 [==============================] - 0s - loss: 0.3832 - acc: 0.9881 - val_loss: 0.4101 - val_acc: 0.9167\n",
      "Epoch 223/500\n",
      "84/84 [==============================] - 0s - loss: 0.3820 - acc: 0.9881 - val_loss: 0.4105 - val_acc: 0.9167\n",
      "Epoch 224/500\n",
      "84/84 [==============================] - 0s - loss: 0.3808 - acc: 0.9762 - val_loss: 0.4103 - val_acc: 0.8889\n",
      "Epoch 225/500\n",
      "84/84 [==============================] - 0s - loss: 0.3798 - acc: 0.9762 - val_loss: 0.4111 - val_acc: 0.8889\n",
      "Epoch 226/500\n",
      "84/84 [==============================] - 0s - loss: 0.3784 - acc: 0.9762 - val_loss: 0.4100 - val_acc: 0.8889\n",
      "Epoch 227/500\n",
      "84/84 [==============================] - 0s - loss: 0.3772 - acc: 0.9762 - val_loss: 0.4085 - val_acc: 0.8889\n",
      "Epoch 228/500\n",
      "84/84 [==============================] - 0s - loss: 0.3760 - acc: 0.9762 - val_loss: 0.4069 - val_acc: 0.8889\n",
      "Epoch 229/500\n",
      "84/84 [==============================] - 0s - loss: 0.3747 - acc: 0.9762 - val_loss: 0.4050 - val_acc: 0.8889\n",
      "Epoch 230/500\n",
      "84/84 [==============================] - 0s - loss: 0.3735 - acc: 0.9762 - val_loss: 0.4029 - val_acc: 0.8889\n",
      "Epoch 231/500\n",
      "84/84 [==============================] - 0s - loss: 0.3723 - acc: 0.9881 - val_loss: 0.4005 - val_acc: 0.9444\n",
      "Epoch 232/500\n",
      "84/84 [==============================] - 0s - loss: 0.3713 - acc: 0.9881 - val_loss: 0.3979 - val_acc: 0.9444\n",
      "Epoch 233/500\n",
      "84/84 [==============================] - 0s - loss: 0.3699 - acc: 0.9881 - val_loss: 0.3969 - val_acc: 0.9444\n",
      "Epoch 234/500\n",
      "84/84 [==============================] - 0s - loss: 0.3687 - acc: 0.9881 - val_loss: 0.3961 - val_acc: 0.9444\n",
      "Epoch 235/500\n",
      "84/84 [==============================] - 0s - loss: 0.3676 - acc: 0.9881 - val_loss: 0.3960 - val_acc: 0.9444\n",
      "Epoch 236/500\n",
      "84/84 [==============================] - 0s - loss: 0.3664 - acc: 0.9881 - val_loss: 0.3954 - val_acc: 0.9444\n",
      "Epoch 237/500\n",
      "84/84 [==============================] - 0s - loss: 0.3652 - acc: 0.9881 - val_loss: 0.3944 - val_acc: 0.9444\n",
      "Epoch 238/500\n",
      "84/84 [==============================] - 0s - loss: 0.3641 - acc: 0.9881 - val_loss: 0.3936 - val_acc: 0.9444\n",
      "Epoch 239/500\n",
      "84/84 [==============================] - 0s - loss: 0.3630 - acc: 0.9881 - val_loss: 0.3925 - val_acc: 0.9444\n",
      "Epoch 240/500\n",
      "84/84 [==============================] - 0s - loss: 0.3617 - acc: 0.9881 - val_loss: 0.3913 - val_acc: 0.9444\n",
      "Epoch 241/500\n",
      "84/84 [==============================] - 0s - loss: 0.3607 - acc: 0.9881 - val_loss: 0.3900 - val_acc: 0.9444\n",
      "Epoch 242/500\n",
      "84/84 [==============================] - 0s - loss: 0.3594 - acc: 0.9881 - val_loss: 0.3894 - val_acc: 0.9444\n",
      "Epoch 243/500\n",
      "84/84 [==============================] - 0s - loss: 0.3583 - acc: 0.9881 - val_loss: 0.3890 - val_acc: 0.9444\n",
      "Epoch 244/500\n",
      "84/84 [==============================] - 0s - loss: 0.3572 - acc: 0.9881 - val_loss: 0.3882 - val_acc: 0.9167\n",
      "Epoch 245/500\n",
      "84/84 [==============================] - 0s - loss: 0.3561 - acc: 0.9881 - val_loss: 0.3865 - val_acc: 0.9444\n",
      "Epoch 246/500\n",
      "84/84 [==============================] - 0s - loss: 0.3550 - acc: 0.9881 - val_loss: 0.3855 - val_acc: 0.9444\n",
      "Epoch 247/500\n",
      "84/84 [==============================] - 0s - loss: 0.3540 - acc: 0.9881 - val_loss: 0.3856 - val_acc: 0.9167\n",
      "Epoch 248/500\n",
      "84/84 [==============================] - 0s - loss: 0.3527 - acc: 0.9881 - val_loss: 0.3841 - val_acc: 0.9167\n",
      "Epoch 249/500\n",
      "84/84 [==============================] - 0s - loss: 0.3516 - acc: 0.9881 - val_loss: 0.3832 - val_acc: 0.9167\n",
      "Epoch 250/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3350 - acc: 1.000 - 0s - loss: 0.3505 - acc: 0.9881 - val_loss: 0.3812 - val_acc: 0.9444\n",
      "Epoch 251/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3523 - acc: 1.000 - 0s - loss: 0.3494 - acc: 0.9881 - val_loss: 0.3797 - val_acc: 0.9444\n",
      "Epoch 252/500\n",
      "84/84 [==============================] - 0s - loss: 0.3483 - acc: 0.9881 - val_loss: 0.3787 - val_acc: 0.9444\n",
      "Epoch 253/500\n",
      "84/84 [==============================] - 0s - loss: 0.3471 - acc: 0.9881 - val_loss: 0.3782 - val_acc: 0.9444\n",
      "Epoch 254/500\n",
      "84/84 [==============================] - 0s - loss: 0.3460 - acc: 0.9881 - val_loss: 0.3784 - val_acc: 0.9167\n",
      "Epoch 255/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s - loss: 0.3450 - acc: 0.9881 - val_loss: 0.3794 - val_acc: 0.8889\n",
      "Epoch 256/500\n",
      "84/84 [==============================] - 0s - loss: 0.3440 - acc: 0.9881 - val_loss: 0.3801 - val_acc: 0.8889\n",
      "Epoch 257/500\n",
      "84/84 [==============================] - 0s - loss: 0.3428 - acc: 0.9881 - val_loss: 0.3793 - val_acc: 0.8889\n",
      "Epoch 258/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3816 - acc: 1.000 - 0s - loss: 0.3418 - acc: 0.9881 - val_loss: 0.3789 - val_acc: 0.8889\n",
      "Epoch 259/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3556 - acc: 1.000 - 0s - loss: 0.3408 - acc: 0.9881 - val_loss: 0.3771 - val_acc: 0.8889\n",
      "Epoch 260/500\n",
      "84/84 [==============================] - 0s - loss: 0.3396 - acc: 0.9881 - val_loss: 0.3759 - val_acc: 0.8889\n",
      "Epoch 261/500\n",
      "84/84 [==============================] - 0s - loss: 0.3386 - acc: 0.9881 - val_loss: 0.3750 - val_acc: 0.8889\n",
      "Epoch 262/500\n",
      "84/84 [==============================] - 0s - loss: 0.3376 - acc: 0.9881 - val_loss: 0.3725 - val_acc: 0.9167\n",
      "Epoch 263/500\n",
      "84/84 [==============================] - 0s - loss: 0.3364 - acc: 0.9881 - val_loss: 0.3717 - val_acc: 0.9167\n",
      "Epoch 264/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3150 - acc: 1.000 - 0s - loss: 0.3353 - acc: 0.9881 - val_loss: 0.3708 - val_acc: 0.9167\n",
      "Epoch 265/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3157 - acc: 0.968 - 0s - loss: 0.3344 - acc: 0.9881 - val_loss: 0.3701 - val_acc: 0.9167\n",
      "Epoch 266/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3483 - acc: 1.000 - 0s - loss: 0.3333 - acc: 0.9881 - val_loss: 0.3677 - val_acc: 0.9167\n",
      "Epoch 267/500\n",
      "84/84 [==============================] - 0s - loss: 0.3322 - acc: 0.9881 - val_loss: 0.3662 - val_acc: 0.9167\n",
      "Epoch 268/500\n",
      "84/84 [==============================] - 0s - loss: 0.3311 - acc: 0.9881 - val_loss: 0.3646 - val_acc: 0.9167\n",
      "Epoch 269/500\n",
      "84/84 [==============================] - 0s - loss: 0.3300 - acc: 0.9881 - val_loss: 0.3628 - val_acc: 0.9444\n",
      "Epoch 270/500\n",
      "84/84 [==============================] - 0s - loss: 0.3292 - acc: 0.9881 - val_loss: 0.3606 - val_acc: 0.9444\n",
      "Epoch 271/500\n",
      "84/84 [==============================] - 0s - loss: 0.3281 - acc: 0.9881 - val_loss: 0.3595 - val_acc: 0.9444\n",
      "Epoch 272/500\n",
      "84/84 [==============================] - 0s - loss: 0.3272 - acc: 0.9881 - val_loss: 0.3595 - val_acc: 0.9444\n",
      "Epoch 273/500\n",
      "84/84 [==============================] - 0s - loss: 0.3261 - acc: 0.9881 - val_loss: 0.3591 - val_acc: 0.9444\n",
      "Epoch 274/500\n",
      "84/84 [==============================] - 0s - loss: 0.3250 - acc: 0.9881 - val_loss: 0.3581 - val_acc: 0.9444\n",
      "Epoch 275/500\n",
      "84/84 [==============================] - 0s - loss: 0.3241 - acc: 0.9881 - val_loss: 0.3574 - val_acc: 0.9444\n",
      "Epoch 276/500\n",
      "84/84 [==============================] - 0s - loss: 0.3230 - acc: 0.9881 - val_loss: 0.3566 - val_acc: 0.9444\n",
      "Epoch 277/500\n",
      "84/84 [==============================] - 0s - loss: 0.3220 - acc: 0.9881 - val_loss: 0.3557 - val_acc: 0.9444\n",
      "Epoch 278/500\n",
      "84/84 [==============================] - 0s - loss: 0.3210 - acc: 0.9881 - val_loss: 0.3548 - val_acc: 0.9444\n",
      "Epoch 279/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3293 - acc: 1.000 - 0s - loss: 0.3200 - acc: 0.9881 - val_loss: 0.3550 - val_acc: 0.9167\n",
      "Epoch 280/500\n",
      "84/84 [==============================] - 0s - loss: 0.3189 - acc: 0.9881 - val_loss: 0.3551 - val_acc: 0.9167\n",
      "Epoch 281/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3197 - acc: 1.000 - 0s - loss: 0.3179 - acc: 0.9881 - val_loss: 0.3550 - val_acc: 0.9167\n",
      "Epoch 282/500\n",
      "84/84 [==============================] - 0s - loss: 0.3169 - acc: 0.9881 - val_loss: 0.3558 - val_acc: 0.9167\n",
      "Epoch 283/500\n",
      "84/84 [==============================] - 0s - loss: 0.3159 - acc: 0.9881 - val_loss: 0.3558 - val_acc: 0.9167\n",
      "Epoch 284/500\n",
      "84/84 [==============================] - 0s - loss: 0.3152 - acc: 0.9881 - val_loss: 0.3566 - val_acc: 0.8889\n",
      "Epoch 285/500\n",
      "84/84 [==============================] - 0s - loss: 0.3142 - acc: 0.9881 - val_loss: 0.3561 - val_acc: 0.8889\n",
      "Epoch 286/500\n",
      "84/84 [==============================] - 0s - loss: 0.3130 - acc: 0.9881 - val_loss: 0.3540 - val_acc: 0.9167\n",
      "Epoch 287/500\n",
      "84/84 [==============================] - 0s - loss: 0.3120 - acc: 0.9881 - val_loss: 0.3517 - val_acc: 0.9167\n",
      "Epoch 288/500\n",
      "84/84 [==============================] - 0s - loss: 0.3111 - acc: 0.9881 - val_loss: 0.3493 - val_acc: 0.9167\n",
      "Epoch 289/500\n",
      "84/84 [==============================] - 0s - loss: 0.3103 - acc: 0.9881 - val_loss: 0.3470 - val_acc: 0.9167\n",
      "Epoch 290/500\n",
      "84/84 [==============================] - 0s - loss: 0.3091 - acc: 0.9881 - val_loss: 0.3457 - val_acc: 0.9167\n",
      "Epoch 291/500\n",
      "84/84 [==============================] - 0s - loss: 0.3082 - acc: 0.9881 - val_loss: 0.3451 - val_acc: 0.9167\n",
      "Epoch 292/500\n",
      "84/84 [==============================] - 0s - loss: 0.3074 - acc: 0.9881 - val_loss: 0.3434 - val_acc: 0.9167\n",
      "Epoch 293/500\n",
      "84/84 [==============================] - 0s - loss: 0.3063 - acc: 0.9881 - val_loss: 0.3435 - val_acc: 0.9167\n",
      "Epoch 294/500\n",
      "84/84 [==============================] - 0s - loss: 0.3056 - acc: 0.9881 - val_loss: 0.3438 - val_acc: 0.9167\n",
      "Epoch 295/500\n",
      "84/84 [==============================] - 0s - loss: 0.3045 - acc: 0.9881 - val_loss: 0.3433 - val_acc: 0.9167\n",
      "Epoch 296/500\n",
      "84/84 [==============================] - 0s - loss: 0.3034 - acc: 0.9881 - val_loss: 0.3419 - val_acc: 0.9167\n",
      "Epoch 297/500\n",
      "84/84 [==============================] - 0s - loss: 0.3025 - acc: 0.9881 - val_loss: 0.3401 - val_acc: 0.9167\n",
      "Epoch 298/500\n",
      "84/84 [==============================] - 0s - loss: 0.3018 - acc: 0.9881 - val_loss: 0.3388 - val_acc: 0.9167\n",
      "Epoch 299/500\n",
      "84/84 [==============================] - 0s - loss: 0.3006 - acc: 0.9881 - val_loss: 0.3392 - val_acc: 0.9167\n",
      "Epoch 300/500\n",
      "84/84 [==============================] - 0s - loss: 0.2998 - acc: 0.9881 - val_loss: 0.3404 - val_acc: 0.9167\n",
      "Epoch 301/500\n",
      "84/84 [==============================] - 0s - loss: 0.2987 - acc: 0.9881 - val_loss: 0.3404 - val_acc: 0.9167\n",
      "Epoch 302/500\n",
      "84/84 [==============================] - 0s - loss: 0.2978 - acc: 0.9881 - val_loss: 0.3404 - val_acc: 0.9167\n",
      "Epoch 303/500\n",
      "84/84 [==============================] - 0s - loss: 0.2970 - acc: 0.9881 - val_loss: 0.3402 - val_acc: 0.9167\n",
      "Epoch 304/500\n",
      "84/84 [==============================] - 0s - loss: 0.2960 - acc: 0.9881 - val_loss: 0.3385 - val_acc: 0.9167\n",
      "Epoch 305/500\n",
      "84/84 [==============================] - 0s - loss: 0.2950 - acc: 0.9881 - val_loss: 0.3369 - val_acc: 0.9167\n",
      "Epoch 306/500\n",
      "84/84 [==============================] - 0s - loss: 0.2942 - acc: 0.9881 - val_loss: 0.3347 - val_acc: 0.9167\n",
      "Epoch 307/500\n",
      "84/84 [==============================] - 0s - loss: 0.2935 - acc: 0.9881 - val_loss: 0.3328 - val_acc: 0.9167\n",
      "Epoch 308/500\n",
      "84/84 [==============================] - 0s - loss: 0.2923 - acc: 0.9881 - val_loss: 0.3323 - val_acc: 0.9167\n",
      "Epoch 309/500\n",
      "84/84 [==============================] - 0s - loss: 0.2914 - acc: 0.9881 - val_loss: 0.3322 - val_acc: 0.9167\n",
      "Epoch 310/500\n",
      "84/84 [==============================] - 0s - loss: 0.2905 - acc: 0.9881 - val_loss: 0.3328 - val_acc: 0.9167\n",
      "Epoch 311/500\n",
      "84/84 [==============================] - 0s - loss: 0.2896 - acc: 0.9881 - val_loss: 0.3329 - val_acc: 0.9167\n",
      "Epoch 312/500\n",
      "84/84 [==============================] - 0s - loss: 0.2887 - acc: 0.9881 - val_loss: 0.3324 - val_acc: 0.9167\n",
      "Epoch 313/500\n",
      "84/84 [==============================] - 0s - loss: 0.2878 - acc: 0.9881 - val_loss: 0.3316 - val_acc: 0.9167\n",
      "Epoch 314/500\n",
      "84/84 [==============================] - 0s - loss: 0.2869 - acc: 0.9881 - val_loss: 0.3311 - val_acc: 0.9167\n",
      "Epoch 315/500\n",
      "84/84 [==============================] - 0s - loss: 0.2861 - acc: 0.9881 - val_loss: 0.3308 - val_acc: 0.9167\n",
      "Epoch 316/500\n",
      "84/84 [==============================] - 0s - loss: 0.2851 - acc: 0.9881 - val_loss: 0.3303 - val_acc: 0.9167\n",
      "Epoch 317/500\n",
      "84/84 [==============================] - 0s - loss: 0.2845 - acc: 0.9881 - val_loss: 0.3313 - val_acc: 0.9167\n",
      "Epoch 318/500\n",
      "84/84 [==============================] - 0s - loss: 0.2835 - acc: 0.9881 - val_loss: 0.3309 - val_acc: 0.9167\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s - loss: 0.2825 - acc: 0.9881 - val_loss: 0.3289 - val_acc: 0.9167\n",
      "Epoch 320/500\n",
      "84/84 [==============================] - 0s - loss: 0.2818 - acc: 0.9881 - val_loss: 0.3261 - val_acc: 0.9167\n",
      "Epoch 321/500\n",
      "84/84 [==============================] - 0s - loss: 0.2807 - acc: 0.9881 - val_loss: 0.3251 - val_acc: 0.9167\n",
      "Epoch 322/500\n",
      "84/84 [==============================] - 0s - loss: 0.2798 - acc: 0.9881 - val_loss: 0.3236 - val_acc: 0.9167\n",
      "Epoch 323/500\n",
      "84/84 [==============================] - 0s - loss: 0.2794 - acc: 0.9881 - val_loss: 0.3216 - val_acc: 0.9167\n",
      "Epoch 324/500\n",
      "84/84 [==============================] - 0s - loss: 0.2781 - acc: 0.9881 - val_loss: 0.3216 - val_acc: 0.9167\n",
      "Epoch 325/500\n",
      "84/84 [==============================] - 0s - loss: 0.2774 - acc: 0.9881 - val_loss: 0.3229 - val_acc: 0.9167\n",
      "Epoch 326/500\n",
      "84/84 [==============================] - 0s - loss: 0.2764 - acc: 0.9881 - val_loss: 0.3224 - val_acc: 0.9167\n",
      "Epoch 327/500\n",
      "84/84 [==============================] - 0s - loss: 0.2755 - acc: 0.9881 - val_loss: 0.3226 - val_acc: 0.9167\n",
      "Epoch 328/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2790 - acc: 1.000 - 0s - loss: 0.2748 - acc: 0.9881 - val_loss: 0.3234 - val_acc: 0.9167\n",
      "Epoch 329/500\n",
      "84/84 [==============================] - 0s - loss: 0.2738 - acc: 0.9881 - val_loss: 0.3235 - val_acc: 0.9167\n",
      "Epoch 330/500\n",
      "84/84 [==============================] - 0s - loss: 0.2730 - acc: 0.9881 - val_loss: 0.3240 - val_acc: 0.8889\n",
      "Epoch 331/500\n",
      "84/84 [==============================] - 0s - loss: 0.2722 - acc: 0.9881 - val_loss: 0.3235 - val_acc: 0.8889\n",
      "Epoch 332/500\n",
      "84/84 [==============================] - 0s - loss: 0.2714 - acc: 0.9881 - val_loss: 0.3230 - val_acc: 0.8889\n",
      "Epoch 333/500\n",
      "84/84 [==============================] - 0s - loss: 0.2708 - acc: 0.9881 - val_loss: 0.3215 - val_acc: 0.9167\n",
      "Epoch 334/500\n",
      "84/84 [==============================] - 0s - loss: 0.2697 - acc: 0.9881 - val_loss: 0.3211 - val_acc: 0.9167\n",
      "Epoch 335/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2561 - acc: 1.000 - 0s - loss: 0.2690 - acc: 0.9881 - val_loss: 0.3197 - val_acc: 0.9167\n",
      "Epoch 336/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2707 - acc: 1.000 - 0s - loss: 0.2680 - acc: 0.9881 - val_loss: 0.3186 - val_acc: 0.9167\n",
      "Epoch 337/500\n",
      "84/84 [==============================] - 0s - loss: 0.2672 - acc: 0.9881 - val_loss: 0.3169 - val_acc: 0.9167\n",
      "Epoch 338/500\n",
      "84/84 [==============================] - 0s - loss: 0.2664 - acc: 0.9881 - val_loss: 0.3147 - val_acc: 0.9167\n",
      "Epoch 339/500\n",
      "84/84 [==============================] - 0s - loss: 0.2655 - acc: 0.9881 - val_loss: 0.3138 - val_acc: 0.9167\n",
      "Epoch 340/500\n",
      "84/84 [==============================] - 0s - loss: 0.2647 - acc: 0.9881 - val_loss: 0.3118 - val_acc: 0.9167\n",
      "Epoch 341/500\n",
      "84/84 [==============================] - 0s - loss: 0.2638 - acc: 0.9881 - val_loss: 0.3110 - val_acc: 0.9167\n",
      "Epoch 342/500\n",
      "84/84 [==============================] - 0s - loss: 0.2630 - acc: 0.9881 - val_loss: 0.3102 - val_acc: 0.9167\n",
      "Epoch 343/500\n",
      "84/84 [==============================] - 0s - loss: 0.2622 - acc: 0.9881 - val_loss: 0.3097 - val_acc: 0.9167\n",
      "Epoch 344/500\n",
      "84/84 [==============================] - 0s - loss: 0.2615 - acc: 0.9881 - val_loss: 0.3078 - val_acc: 0.9167\n",
      "Epoch 345/500\n",
      "84/84 [==============================] - 0s - loss: 0.2605 - acc: 0.9881 - val_loss: 0.3076 - val_acc: 0.9167\n",
      "Epoch 346/500\n",
      "84/84 [==============================] - 0s - loss: 0.2597 - acc: 0.9881 - val_loss: 0.3073 - val_acc: 0.9167\n",
      "Epoch 347/500\n",
      "84/84 [==============================] - 0s - loss: 0.2591 - acc: 0.9881 - val_loss: 0.3058 - val_acc: 0.9167\n",
      "Epoch 348/500\n",
      "84/84 [==============================] - 0s - loss: 0.2581 - acc: 0.9881 - val_loss: 0.3053 - val_acc: 0.9167\n",
      "Epoch 349/500\n",
      "84/84 [==============================] - 0s - loss: 0.2573 - acc: 0.9881 - val_loss: 0.3053 - val_acc: 0.9167\n",
      "Epoch 350/500\n",
      "84/84 [==============================] - 0s - loss: 0.2565 - acc: 0.9881 - val_loss: 0.3054 - val_acc: 0.9167\n",
      "Epoch 351/500\n",
      "84/84 [==============================] - 0s - loss: 0.2557 - acc: 0.9881 - val_loss: 0.3050 - val_acc: 0.9167\n",
      "Epoch 352/500\n",
      "84/84 [==============================] - 0s - loss: 0.2550 - acc: 0.9881 - val_loss: 0.3056 - val_acc: 0.9167\n",
      "Epoch 353/500\n",
      "84/84 [==============================] - 0s - loss: 0.2542 - acc: 0.9881 - val_loss: 0.3054 - val_acc: 0.9167\n",
      "Epoch 354/500\n",
      "84/84 [==============================] - 0s - loss: 0.2534 - acc: 0.9881 - val_loss: 0.3052 - val_acc: 0.9167\n",
      "Epoch 355/500\n",
      "84/84 [==============================] - 0s - loss: 0.2526 - acc: 0.9881 - val_loss: 0.3039 - val_acc: 0.9167\n",
      "Epoch 356/500\n",
      "84/84 [==============================] - 0s - loss: 0.2518 - acc: 0.9881 - val_loss: 0.3036 - val_acc: 0.9167\n",
      "Epoch 357/500\n",
      "84/84 [==============================] - 0s - loss: 0.2511 - acc: 0.9881 - val_loss: 0.3018 - val_acc: 0.9167\n",
      "Epoch 358/500\n",
      "84/84 [==============================] - 0s - loss: 0.2502 - acc: 0.9881 - val_loss: 0.3009 - val_acc: 0.9167\n",
      "Epoch 359/500\n",
      "84/84 [==============================] - 0s - loss: 0.2495 - acc: 0.9881 - val_loss: 0.3009 - val_acc: 0.9167\n",
      "Epoch 360/500\n",
      "84/84 [==============================] - 0s - loss: 0.2486 - acc: 0.9881 - val_loss: 0.2997 - val_acc: 0.9167\n",
      "Epoch 361/500\n",
      "84/84 [==============================] - 0s - loss: 0.2479 - acc: 0.9881 - val_loss: 0.2993 - val_acc: 0.9167\n",
      "Epoch 362/500\n",
      "84/84 [==============================] - 0s - loss: 0.2470 - acc: 0.9881 - val_loss: 0.2977 - val_acc: 0.9167\n",
      "Epoch 363/500\n",
      "84/84 [==============================] - 0s - loss: 0.2464 - acc: 0.9881 - val_loss: 0.2961 - val_acc: 0.9167\n",
      "Epoch 364/500\n",
      "84/84 [==============================] - 0s - loss: 0.2455 - acc: 0.9881 - val_loss: 0.2957 - val_acc: 0.9167\n",
      "Epoch 365/500\n",
      "84/84 [==============================] - 0s - loss: 0.2448 - acc: 0.9881 - val_loss: 0.2943 - val_acc: 0.9167\n",
      "Epoch 366/500\n",
      "84/84 [==============================] - 0s - loss: 0.2440 - acc: 0.9881 - val_loss: 0.2938 - val_acc: 0.9167\n",
      "Epoch 367/500\n",
      "84/84 [==============================] - 0s - loss: 0.2432 - acc: 0.9881 - val_loss: 0.2937 - val_acc: 0.9167\n",
      "Epoch 368/500\n",
      "84/84 [==============================] - 0s - loss: 0.2430 - acc: 0.9881 - val_loss: 0.2948 - val_acc: 0.9167\n",
      "Epoch 369/500\n",
      "84/84 [==============================] - 0s - loss: 0.2417 - acc: 0.9881 - val_loss: 0.2928 - val_acc: 0.9167\n",
      "Epoch 370/500\n",
      "84/84 [==============================] - 0s - loss: 0.2409 - acc: 0.9881 - val_loss: 0.2913 - val_acc: 0.9167\n",
      "Epoch 371/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2342 - acc: 1.000 - 0s - loss: 0.2403 - acc: 0.9881 - val_loss: 0.2901 - val_acc: 0.9444\n",
      "Epoch 372/500\n",
      "84/84 [==============================] - 0s - loss: 0.2396 - acc: 0.9881 - val_loss: 0.2903 - val_acc: 0.9167\n",
      "Epoch 373/500\n",
      "84/84 [==============================] - 0s - loss: 0.2389 - acc: 0.9881 - val_loss: 0.2889 - val_acc: 0.9444\n",
      "Epoch 374/500\n",
      "84/84 [==============================] - 0s - loss: 0.2380 - acc: 0.9881 - val_loss: 0.2891 - val_acc: 0.9167\n",
      "Epoch 375/500\n",
      "84/84 [==============================] - 0s - loss: 0.2373 - acc: 0.9881 - val_loss: 0.2885 - val_acc: 0.9167\n",
      "Epoch 376/500\n",
      "84/84 [==============================] - 0s - loss: 0.2365 - acc: 0.9881 - val_loss: 0.2887 - val_acc: 0.9167\n",
      "Epoch 377/500\n",
      "84/84 [==============================] - 0s - loss: 0.2358 - acc: 0.9881 - val_loss: 0.2893 - val_acc: 0.9167\n",
      "Epoch 378/500\n",
      "84/84 [==============================] - 0s - loss: 0.2351 - acc: 0.9881 - val_loss: 0.2892 - val_acc: 0.9167\n",
      "Epoch 379/500\n",
      "84/84 [==============================] - 0s - loss: 0.2343 - acc: 0.9881 - val_loss: 0.2882 - val_acc: 0.9167\n",
      "Epoch 380/500\n",
      "84/84 [==============================] - 0s - loss: 0.2336 - acc: 0.9881 - val_loss: 0.2871 - val_acc: 0.9167\n",
      "Epoch 381/500\n",
      "84/84 [==============================] - 0s - loss: 0.2329 - acc: 0.9881 - val_loss: 0.2867 - val_acc: 0.9167\n",
      "Epoch 382/500\n",
      "84/84 [==============================] - 0s - loss: 0.2322 - acc: 0.9881 - val_loss: 0.2857 - val_acc: 0.9167\n",
      "Epoch 383/500\n",
      "84/84 [==============================] - 0s - loss: 0.2315 - acc: 0.9881 - val_loss: 0.2849 - val_acc: 0.9444\n",
      "Epoch 384/500\n",
      "84/84 [==============================] - 0s - loss: 0.2308 - acc: 0.9881 - val_loss: 0.2846 - val_acc: 0.9167\n",
      "Epoch 385/500\n",
      "84/84 [==============================] - 0s - loss: 0.2300 - acc: 0.9881 - val_loss: 0.2839 - val_acc: 0.9444\n",
      "Epoch 386/500\n",
      "84/84 [==============================] - 0s - loss: 0.2293 - acc: 0.9881 - val_loss: 0.2833 - val_acc: 0.9444\n",
      "Epoch 387/500\n",
      "84/84 [==============================] - 0s - loss: 0.2286 - acc: 0.9881 - val_loss: 0.2823 - val_acc: 0.9444\n",
      "Epoch 388/500\n",
      "84/84 [==============================] - 0s - loss: 0.2279 - acc: 0.9881 - val_loss: 0.2813 - val_acc: 0.9444\n",
      "Epoch 389/500\n",
      "84/84 [==============================] - 0s - loss: 0.2273 - acc: 0.9881 - val_loss: 0.2808 - val_acc: 0.9444\n",
      "Epoch 390/500\n",
      "84/84 [==============================] - 0s - loss: 0.2267 - acc: 0.9881 - val_loss: 0.2783 - val_acc: 0.9444\n",
      "Epoch 391/500\n",
      "84/84 [==============================] - 0s - loss: 0.2258 - acc: 0.9881 - val_loss: 0.2778 - val_acc: 0.9444\n",
      "Epoch 392/500\n",
      "84/84 [==============================] - 0s - loss: 0.2251 - acc: 0.9881 - val_loss: 0.2781 - val_acc: 0.9444\n",
      "Epoch 393/500\n",
      "84/84 [==============================] - 0s - loss: 0.2243 - acc: 0.9881 - val_loss: 0.2788 - val_acc: 0.9444\n",
      "Epoch 394/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2114 - acc: 1.000 - 0s - loss: 0.2236 - acc: 0.9881 - val_loss: 0.2795 - val_acc: 0.9444\n",
      "Epoch 395/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1955 - acc: 1.000 - 0s - loss: 0.2229 - acc: 0.9881 - val_loss: 0.2793 - val_acc: 0.9444\n",
      "Epoch 396/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2013 - acc: 1.000 - 0s - loss: 0.2222 - acc: 0.9881 - val_loss: 0.2793 - val_acc: 0.9444\n",
      "Epoch 397/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2219 - acc: 0.968 - 0s - loss: 0.2217 - acc: 0.9881 - val_loss: 0.2801 - val_acc: 0.9167\n",
      "Epoch 398/500\n",
      "84/84 [==============================] - 0s - loss: 0.2209 - acc: 0.9881 - val_loss: 0.2794 - val_acc: 0.9167\n",
      "Epoch 399/500\n",
      "84/84 [==============================] - 0s - loss: 0.2202 - acc: 0.9881 - val_loss: 0.2787 - val_acc: 0.9167\n",
      "Epoch 400/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2128 - acc: 0.968 - 0s - loss: 0.2195 - acc: 0.9881 - val_loss: 0.2775 - val_acc: 0.9444\n",
      "Epoch 401/500\n",
      "84/84 [==============================] - 0s - loss: 0.2189 - acc: 0.9881 - val_loss: 0.2757 - val_acc: 0.9444\n",
      "Epoch 402/500\n",
      "84/84 [==============================] - 0s - loss: 0.2181 - acc: 0.9881 - val_loss: 0.2753 - val_acc: 0.9444\n",
      "Epoch 403/500\n",
      "84/84 [==============================] - 0s - loss: 0.2174 - acc: 0.9881 - val_loss: 0.2737 - val_acc: 0.9444\n",
      "Epoch 404/500\n",
      "84/84 [==============================] - 0s - loss: 0.2168 - acc: 0.9881 - val_loss: 0.2733 - val_acc: 0.9444\n",
      "Epoch 405/500\n",
      "84/84 [==============================] - 0s - loss: 0.2161 - acc: 0.9881 - val_loss: 0.2724 - val_acc: 0.9444\n",
      "Epoch 406/500\n",
      "84/84 [==============================] - 0s - loss: 0.2154 - acc: 0.9881 - val_loss: 0.2708 - val_acc: 0.9444\n",
      "Epoch 407/500\n",
      "84/84 [==============================] - 0s - loss: 0.2147 - acc: 0.9881 - val_loss: 0.2695 - val_acc: 0.9444\n",
      "Epoch 408/500\n",
      "84/84 [==============================] - 0s - loss: 0.2141 - acc: 0.9881 - val_loss: 0.2688 - val_acc: 0.9444\n",
      "Epoch 409/500\n",
      "84/84 [==============================] - 0s - loss: 0.2134 - acc: 0.9881 - val_loss: 0.2687 - val_acc: 0.9444\n",
      "Epoch 410/500\n",
      "84/84 [==============================] - 0s - loss: 0.2127 - acc: 0.9881 - val_loss: 0.2685 - val_acc: 0.9444\n",
      "Epoch 411/500\n",
      "84/84 [==============================] - 0s - loss: 0.2121 - acc: 0.9881 - val_loss: 0.2680 - val_acc: 0.9444\n",
      "Epoch 412/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2321 - acc: 0.968 - 0s - loss: 0.2115 - acc: 0.9881 - val_loss: 0.2670 - val_acc: 0.9444\n",
      "Epoch 413/500\n",
      "84/84 [==============================] - 0s - loss: 0.2107 - acc: 0.9881 - val_loss: 0.2665 - val_acc: 0.9444\n",
      "Epoch 414/500\n",
      "84/84 [==============================] - 0s - loss: 0.2101 - acc: 0.9881 - val_loss: 0.2661 - val_acc: 0.9444\n",
      "Epoch 415/500\n",
      "84/84 [==============================] - 0s - loss: 0.2096 - acc: 0.9881 - val_loss: 0.2665 - val_acc: 0.9444\n",
      "Epoch 416/500\n",
      "84/84 [==============================] - 0s - loss: 0.2089 - acc: 0.9881 - val_loss: 0.2649 - val_acc: 0.9444\n",
      "Epoch 417/500\n",
      "84/84 [==============================] - 0s - loss: 0.2081 - acc: 0.9881 - val_loss: 0.2642 - val_acc: 0.9444\n",
      "Epoch 418/500\n",
      "84/84 [==============================] - 0s - loss: 0.2075 - acc: 0.9881 - val_loss: 0.2636 - val_acc: 0.9444\n",
      "Epoch 419/500\n",
      "84/84 [==============================] - 0s - loss: 0.2068 - acc: 0.9881 - val_loss: 0.2634 - val_acc: 0.9444\n",
      "Epoch 420/500\n",
      "84/84 [==============================] - 0s - loss: 0.2062 - acc: 0.9881 - val_loss: 0.2639 - val_acc: 0.9444\n",
      "Epoch 421/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2447 - acc: 0.968 - 0s - loss: 0.2055 - acc: 0.9881 - val_loss: 0.2638 - val_acc: 0.9444\n",
      "Epoch 422/500\n",
      "84/84 [==============================] - 0s - loss: 0.2049 - acc: 0.9881 - val_loss: 0.2633 - val_acc: 0.9444\n",
      "Epoch 423/500\n",
      "84/84 [==============================] - 0s - loss: 0.2043 - acc: 0.9881 - val_loss: 0.2631 - val_acc: 0.9444\n",
      "Epoch 424/500\n",
      "84/84 [==============================] - 0s - loss: 0.2039 - acc: 0.9881 - val_loss: 0.2647 - val_acc: 0.9444\n",
      "Epoch 425/500\n",
      "84/84 [==============================] - 0s - loss: 0.2030 - acc: 0.9881 - val_loss: 0.2643 - val_acc: 0.9444\n",
      "Epoch 426/500\n",
      "84/84 [==============================] - 0s - loss: 0.2024 - acc: 0.9881 - val_loss: 0.2639 - val_acc: 0.9444\n",
      "Epoch 427/500\n",
      "84/84 [==============================] - 0s - loss: 0.2018 - acc: 0.9881 - val_loss: 0.2633 - val_acc: 0.9444\n",
      "Epoch 428/500\n",
      "84/84 [==============================] - 0s - loss: 0.2011 - acc: 0.9881 - val_loss: 0.2622 - val_acc: 0.9444\n",
      "Epoch 429/500\n",
      "84/84 [==============================] - 0s - loss: 0.2005 - acc: 0.9881 - val_loss: 0.2609 - val_acc: 0.9444\n",
      "Epoch 430/500\n",
      "84/84 [==============================] - 0s - loss: 0.2000 - acc: 0.9881 - val_loss: 0.2591 - val_acc: 0.9444\n",
      "Epoch 431/500\n",
      "84/84 [==============================] - 0s - loss: 0.1993 - acc: 0.9881 - val_loss: 0.2581 - val_acc: 0.9444\n",
      "Epoch 432/500\n",
      "84/84 [==============================] - 0s - loss: 0.1986 - acc: 0.9881 - val_loss: 0.2557 - val_acc: 0.9444\n",
      "Epoch 433/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1985 - acc: 0.968 - 0s - loss: 0.1981 - acc: 0.9881 - val_loss: 0.2535 - val_acc: 0.9444\n",
      "Epoch 434/500\n",
      "84/84 [==============================] - 0s - loss: 0.1977 - acc: 0.9881 - val_loss: 0.2519 - val_acc: 0.9444\n",
      "Epoch 435/500\n",
      "84/84 [==============================] - 0s - loss: 0.1970 - acc: 0.9881 - val_loss: 0.2524 - val_acc: 0.9444\n",
      "Epoch 436/500\n",
      "84/84 [==============================] - 0s - loss: 0.1965 - acc: 0.9881 - val_loss: 0.2531 - val_acc: 0.9444\n",
      "Epoch 437/500\n",
      "84/84 [==============================] - 0s - loss: 0.1957 - acc: 0.9881 - val_loss: 0.2529 - val_acc: 0.9444\n",
      "Epoch 438/500\n",
      "84/84 [==============================] - 0s - loss: 0.1951 - acc: 0.9881 - val_loss: 0.2535 - val_acc: 0.9444\n",
      "Epoch 439/500\n",
      "84/84 [==============================] - 0s - loss: 0.1945 - acc: 0.9881 - val_loss: 0.2533 - val_acc: 0.9444\n",
      "Epoch 440/500\n",
      "84/84 [==============================] - 0s - loss: 0.1942 - acc: 0.9881 - val_loss: 0.2547 - val_acc: 0.9444\n",
      "Epoch 441/500\n",
      "84/84 [==============================] - 0s - loss: 0.1932 - acc: 0.9881 - val_loss: 0.2541 - val_acc: 0.9444\n",
      "Epoch 442/500\n",
      "84/84 [==============================] - 0s - loss: 0.1927 - acc: 0.9881 - val_loss: 0.2535 - val_acc: 0.9444\n",
      "Epoch 443/500\n",
      "84/84 [==============================] - 0s - loss: 0.1920 - acc: 0.9881 - val_loss: 0.2541 - val_acc: 0.9444\n",
      "Epoch 444/500\n",
      "84/84 [==============================] - 0s - loss: 0.1914 - acc: 0.9881 - val_loss: 0.2542 - val_acc: 0.9444\n",
      "Epoch 445/500\n",
      "84/84 [==============================] - 0s - loss: 0.1912 - acc: 0.9881 - val_loss: 0.2548 - val_acc: 0.9444\n",
      "Epoch 446/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s - loss: 0.1903 - acc: 0.9881 - val_loss: 0.2528 - val_acc: 0.9444\n",
      "Epoch 447/500\n",
      "84/84 [==============================] - 0s - loss: 0.1898 - acc: 0.9881 - val_loss: 0.2513 - val_acc: 0.9444\n",
      "Epoch 448/500\n",
      "84/84 [==============================] - 0s - loss: 0.1891 - acc: 0.9881 - val_loss: 0.2509 - val_acc: 0.9444\n",
      "Epoch 449/500\n",
      "84/84 [==============================] - 0s - loss: 0.1887 - acc: 0.9881 - val_loss: 0.2511 - val_acc: 0.9444\n",
      "Epoch 450/500\n",
      "84/84 [==============================] - 0s - loss: 0.1880 - acc: 0.9881 - val_loss: 0.2494 - val_acc: 0.9444\n",
      "Epoch 451/500\n",
      "84/84 [==============================] - 0s - loss: 0.1874 - acc: 0.9881 - val_loss: 0.2490 - val_acc: 0.9444\n",
      "Epoch 452/500\n",
      "84/84 [==============================] - 0s - loss: 0.1868 - acc: 0.9881 - val_loss: 0.2481 - val_acc: 0.9444\n",
      "Epoch 453/500\n",
      "84/84 [==============================] - 0s - loss: 0.1863 - acc: 0.9881 - val_loss: 0.2478 - val_acc: 0.9444\n",
      "Epoch 454/500\n",
      "84/84 [==============================] - 0s - loss: 0.1857 - acc: 0.9881 - val_loss: 0.2471 - val_acc: 0.9444\n",
      "Epoch 455/500\n",
      "84/84 [==============================] - 0s - loss: 0.1851 - acc: 0.9881 - val_loss: 0.2456 - val_acc: 0.9444\n",
      "Epoch 456/500\n",
      "84/84 [==============================] - 0s - loss: 0.1846 - acc: 0.9881 - val_loss: 0.2450 - val_acc: 0.9444\n",
      "Epoch 457/500\n",
      "84/84 [==============================] - 0s - loss: 0.1842 - acc: 0.9881 - val_loss: 0.2434 - val_acc: 0.9444\n",
      "Epoch 458/500\n",
      "84/84 [==============================] - 0s - loss: 0.1835 - acc: 0.9881 - val_loss: 0.2434 - val_acc: 0.9444\n",
      "Epoch 459/500\n",
      "84/84 [==============================] - 0s - loss: 0.1830 - acc: 0.9881 - val_loss: 0.2437 - val_acc: 0.9444\n",
      "Epoch 460/500\n",
      "84/84 [==============================] - 0s - loss: 0.1823 - acc: 0.9881 - val_loss: 0.2438 - val_acc: 0.9444\n",
      "Epoch 461/500\n",
      "84/84 [==============================] - 0s - loss: 0.1818 - acc: 0.9881 - val_loss: 0.2437 - val_acc: 0.9444\n",
      "Epoch 462/500\n",
      "84/84 [==============================] - 0s - loss: 0.1812 - acc: 0.9881 - val_loss: 0.2436 - val_acc: 0.9444\n",
      "Epoch 463/500\n",
      "84/84 [==============================] - 0s - loss: 0.1807 - acc: 0.9881 - val_loss: 0.2430 - val_acc: 0.9444\n",
      "Epoch 464/500\n",
      "84/84 [==============================] - 0s - loss: 0.1801 - acc: 0.9881 - val_loss: 0.2423 - val_acc: 0.9444\n",
      "Epoch 465/500\n",
      "84/84 [==============================] - 0s - loss: 0.1796 - acc: 0.9881 - val_loss: 0.2428 - val_acc: 0.9444\n",
      "Epoch 466/500\n",
      "84/84 [==============================] - 0s - loss: 0.1790 - acc: 0.9881 - val_loss: 0.2431 - val_acc: 0.9444\n",
      "Epoch 467/500\n",
      "84/84 [==============================] - 0s - loss: 0.1785 - acc: 0.9881 - val_loss: 0.2434 - val_acc: 0.9444\n",
      "Epoch 468/500\n",
      "84/84 [==============================] - 0s - loss: 0.1779 - acc: 0.9881 - val_loss: 0.2430 - val_acc: 0.9444\n",
      "Epoch 469/500\n",
      "84/84 [==============================] - 0s - loss: 0.1775 - acc: 0.9881 - val_loss: 0.2415 - val_acc: 0.9444\n",
      "Epoch 470/500\n",
      "84/84 [==============================] - 0s - loss: 0.1771 - acc: 0.9881 - val_loss: 0.2402 - val_acc: 0.9444\n",
      "Epoch 471/500\n",
      "84/84 [==============================] - 0s - loss: 0.1764 - acc: 0.9881 - val_loss: 0.2400 - val_acc: 0.9444\n",
      "Epoch 472/500\n",
      "84/84 [==============================] - 0s - loss: 0.1758 - acc: 0.9881 - val_loss: 0.2385 - val_acc: 0.9444\n",
      "Epoch 473/500\n",
      "84/84 [==============================] - 0s - loss: 0.1753 - acc: 0.9881 - val_loss: 0.2382 - val_acc: 0.9444\n",
      "Epoch 474/500\n",
      "84/84 [==============================] - 0s - loss: 0.1748 - acc: 0.9881 - val_loss: 0.2380 - val_acc: 0.9444\n",
      "Epoch 475/500\n",
      "84/84 [==============================] - 0s - loss: 0.1744 - acc: 0.9881 - val_loss: 0.2366 - val_acc: 0.9444\n",
      "Epoch 476/500\n",
      "84/84 [==============================] - 0s - loss: 0.1738 - acc: 0.9881 - val_loss: 0.2362 - val_acc: 0.9444\n",
      "Epoch 477/500\n",
      "84/84 [==============================] - 0s - loss: 0.1733 - acc: 0.9881 - val_loss: 0.2348 - val_acc: 0.9444\n",
      "Epoch 478/500\n",
      "84/84 [==============================] - 0s - loss: 0.1727 - acc: 0.9881 - val_loss: 0.2345 - val_acc: 0.9444\n",
      "Epoch 479/500\n",
      "84/84 [==============================] - 0s - loss: 0.1722 - acc: 0.9881 - val_loss: 0.2342 - val_acc: 0.9444\n",
      "Epoch 480/500\n",
      "84/84 [==============================] - 0s - loss: 0.1717 - acc: 0.9881 - val_loss: 0.2345 - val_acc: 0.9444\n",
      "Epoch 481/500\n",
      "84/84 [==============================] - 0s - loss: 0.1711 - acc: 0.9881 - val_loss: 0.2340 - val_acc: 0.9444\n",
      "Epoch 482/500\n",
      "84/84 [==============================] - 0s - loss: 0.1706 - acc: 0.9881 - val_loss: 0.2340 - val_acc: 0.9444\n",
      "Epoch 483/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1585 - acc: 1.000 - 0s - loss: 0.1701 - acc: 0.9881 - val_loss: 0.2347 - val_acc: 0.9444\n",
      "Epoch 484/500\n",
      "84/84 [==============================] - 0s - loss: 0.1696 - acc: 0.9881 - val_loss: 0.2350 - val_acc: 0.9444\n",
      "Epoch 485/500\n",
      "84/84 [==============================] - 0s - loss: 0.1691 - acc: 0.9881 - val_loss: 0.2344 - val_acc: 0.9444\n",
      "Epoch 486/500\n",
      "84/84 [==============================] - 0s - loss: 0.1686 - acc: 0.9881 - val_loss: 0.2353 - val_acc: 0.9444\n",
      "Epoch 487/500\n",
      "84/84 [==============================] - 0s - loss: 0.1681 - acc: 0.9881 - val_loss: 0.2354 - val_acc: 0.9444\n",
      "Epoch 488/500\n",
      "84/84 [==============================] - 0s - loss: 0.1676 - acc: 0.9881 - val_loss: 0.2348 - val_acc: 0.9444\n",
      "Epoch 489/500\n",
      "84/84 [==============================] - 0s - loss: 0.1671 - acc: 0.9881 - val_loss: 0.2345 - val_acc: 0.9444\n",
      "Epoch 490/500\n",
      "84/84 [==============================] - 0s - loss: 0.1666 - acc: 0.9881 - val_loss: 0.2343 - val_acc: 0.9444\n",
      "Epoch 491/500\n",
      "84/84 [==============================] - 0s - loss: 0.1661 - acc: 0.9881 - val_loss: 0.2335 - val_acc: 0.9444\n",
      "Epoch 492/500\n",
      "84/84 [==============================] - 0s - loss: 0.1657 - acc: 0.9881 - val_loss: 0.2331 - val_acc: 0.9444\n",
      "Epoch 493/500\n",
      "84/84 [==============================] - 0s - loss: 0.1651 - acc: 0.9881 - val_loss: 0.2332 - val_acc: 0.9444\n",
      "Epoch 494/500\n",
      "84/84 [==============================] - 0s - loss: 0.1647 - acc: 0.9881 - val_loss: 0.2339 - val_acc: 0.9444\n",
      "Epoch 495/500\n",
      "84/84 [==============================] - 0s - loss: 0.1642 - acc: 0.9881 - val_loss: 0.2331 - val_acc: 0.9444\n",
      "Epoch 496/500\n",
      "84/84 [==============================] - 0s - loss: 0.1637 - acc: 0.9881 - val_loss: 0.2324 - val_acc: 0.9444\n",
      "Epoch 497/500\n",
      "84/84 [==============================] - 0s - loss: 0.1633 - acc: 0.9881 - val_loss: 0.2325 - val_acc: 0.9444\n",
      "Epoch 498/500\n",
      "84/84 [==============================] - 0s - loss: 0.1628 - acc: 0.9881 - val_loss: 0.2306 - val_acc: 0.9444\n",
      "Epoch 499/500\n",
      "84/84 [==============================] - 0s - loss: 0.1622 - acc: 0.9881 - val_loss: 0.2301 - val_acc: 0.9444\n",
      "Epoch 500/500\n",
      "84/84 [==============================] - 0s - loss: 0.1621 - acc: 0.9881 - val_loss: 0.2281 - val_acc: 0.9444\n",
      "CPU times: user 4.48 s, sys: 984 ms, total: 5.46 s\n",
      "Wall time: 4.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f535008b278>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %time model.fit(X_train, y_train, epochs=500, validation_split=0.3, callbacks=[tb_callback])\n",
    "%time model.fit(X_train, y_train, epochs=500, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.82259035e-01,   1.77392866e-02,   1.65961740e-06]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[ 5.1,  3.5,  1.4,  0.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.1,  3.5,  1.4,  0.2]), array([ 1.,  0.,  0.]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/120 [=======>......................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.18136776983737946, 0.97499999602635701)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.19082625210285187, 0.96666663885116577)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hands-On\n",
    "## Vollziehe das Notebook bis hier nach und spiele mit den einigen Parametern\n",
    "* Variiere die Anzahl der Neuronen im Hidden Layer. Wieso geht das überhaupt mit 3 Neuronen\n",
    "* Ziehe eine weitere Schicht ein\n",
    "* Kannst du eine Skizze des Graphs der Funktion mit x1 und x2 an den Achsen erstellen?\n",
    "* Was ist das für eine Funktion?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optionaler Teil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model im Keras und TensorFlow Format speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('nn-iris.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export as raw tf model\n",
    "\n",
    "* https://tensorflow.github.io/serving/serving_basic.html\n",
    "* https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_saved_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -r tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_integer('model_version', 1, 'version number of the model.')\n",
    "tf.app.flags.DEFINE_string('work_dir', '/tmp', 'Working directory.')\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_path_base = 'tf'\n",
    "export_path = os.path.join(\n",
    "  tf.compat.as_bytes(export_path_base),\n",
    "  tf.compat.as_bytes(str(FLAGS.model_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_inputs = tf.saved_model.utils.build_tensor_info(model.input)\n",
    "classification_outputs_scores = tf.saved_model.utils.build_tensor_info(model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signature = predict_signature_def(inputs={'inputs': model.input},\n",
    "                                  outputs={'scores': model.output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "builder = tf.saved_model.builder.SavedModelBuilder(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "builder.add_meta_graph_and_variables(\n",
    "      sess, \n",
    "     tags=[tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls -lhR tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dieses Tensorflow Modell kann man bei Google Cloud ML hochladen und für Berechnungen nutzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cd tf\n",
    "# gsutil cp -R 1 gs://irisnn\n",
    "# create model and version at https://console.cloud.google.com/mlengine\n",
    "# gcloud ml-engine predict --model=irisnn --json-instances=./sample_iris.json\n",
    "# SCORES\n",
    "# [0.9954029321670532, 0.004596732556819916, 3.3544753819114703e-07]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
