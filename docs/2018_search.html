<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Search</title>

    <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
    <meta name="author" content="Hakim El Hattab">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
      
          <!-- Code syntax highlighting -->
          <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }
      
                      .reveal h2,
                      .reveal h3,
                      .reveal h4 {
                          letter-spacing: 2px;
                          font-family: 'Amiri', serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          font-weight: bold;
                          font-style: italic;
                          letter-spacing: -2px;
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
                      .reveal .step-subtitle h1 {
                          letter-spacing: 1px;
                      }
                      .reveal .step-subtitle h2,
                      .reveal .step-subtitle h3 {
                          text-transform: none;
                          font-style: italic;
                          font-weight: normal;
                          /* font-weight: 400; */
                          /* font-family: 'Amiri', serif; */
                          font-family: 'Lobster', serif;
                          letter-spacing: 1px;
                          color: #2aa198;
                          text-decoration: underline;
                      }
      
                      .reveal .front-page h1,
                      .reveal .front-page h2 {
                          font-family: "League Gothic";
                          font-style: normal;
                          text-transform: uppercase !important;
                          letter-spacing: 1px;
                      }
      
                      .reveal .front-page h1 {
                          font-size: 2.5em !important;
                      }
      
                      .reveal .highlight {
                          background-color: #D3337B;
                          color: white;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }
          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

<div class="reveal">
    <div class="slides">

<!-- 
    
All the AI hype these days is around deep learning and that machines eventually are getting rid of us humans. However,
the ground work of AI without which no self driving car and no AlphaGo Zero would work is search algorithms.

In this talk we will use a simple game of exiting a maze to illustrate the differences between depth first and breadth
first search. We will also solve the mystery around A* and what makes it such a powerful approach.

In the next step we will look at how to compete against other players using adversarial search like the one used in the
leading chess engine stockfish. You will understand Monte Carlo Tree Search which was used in Alpha(Go) Zero to beat
the world’s best Go players.
-->

<!-- <section data-markdown class="todo">
        <textarea data-template>
https://code.fb.com/web/rapid-release-at-massive-scale/
</textarea>
</section> -->

<!-- <section data-markdown class="todo">
<textarea data-template>
### High level look at Search

<img src='img/j2bryson-search.jpg'>

<p><small>
<a href='https://twitter.com/j2bryson'>@j2bryson</a> at 
<a href='https://www.mcubed.london/sessions/human-minds-and-machine-intelligence/'>MCubded London 2018</a>
</small>
</p>
<small>
https://www.dur.ac.uk/research/directory/staff/?mode=pdetail&id=12916&sid=12916&pdetail=93713
</small>
</textarea>
</section> -->

<section data-markdown class="preparation">
        <textarea data-template>
### Preparation

1. Go through MCTS phases
    </textarea>
</section>

<section>
        <h2>Graph Search:</h2>
        <h3>The Silver Bullet of Symbolic AI and the Secret of AlphaGo Zero</h3>
<p><a target="_blank" href="https://mlconference.ai/machine-learning-advanced-development/search-the-silver-bullet-of-symbolic-ai-and-the-secret-of-alphago-zero/">
    ML Conference, December 2018
</a></p>
<h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / <a href="http://twitter.com/djcordhose">@DJCordhose</a>
</h4>
<p><small><a href="http://bit.ly/mlconf-search">
    http://bit.ly/mlconf-search
</a></small></p>
</section>

<section data-markdown>
        <textarea data-template>
### Our Story

1. from path Finding
1. to game search
1. to monte carlo game search and tree search to
1. to Alpha(Go) Zero

</textarea>
</section>

<section data-markdown>
<textarea data-template>
### AlphaGo Zero

* Two algorithms
  * Reinforcement Learning
  * Monte Carlo Tree Search

* One ML Approach: deep-learning function approx
    </textarea>
</section>

<section>
        <h3>Machine Learning and AI</h3>
        <p>Why I like the term artificial intelligence: I think it's good to have an umbrella term for the field that encompasses a
        range of techniques – ML, knowledge rep, planning, heuristic search, goal formation, behavior modeling, etc. – and it's the
        one we have.</p>
        <p><small><a target="_blank" href="https://twitter.com/mjntendency/status/970091564864286726">https://twitter.com/mjntendency/status/970091564864286726</a></small></p>
    </section>

        

        <section data-markdown>
    <textarea data-template>
## Part I
### Path Finding

* Games
* Route Planing

http://theory.stanford.edu/~amitp/GameProgramming/Applications.html
</textarea>
</section>

        <section data-markdown>
    <textarea data-template>
### A simple Example - Robot Run
<img src="img/search/robot_run.jpg" alt="Alpha Beta" height="450px">

Robot needs to find Portal/Goal

</textarea>
</section>

<section>
        <h2>Step 1: Knowledge Representation</h2>
<p class="fragment">Find a way to encode the maze to make it accesible for a search algorithm</p>

<pre><code contenteditable data-trim class="line-numbers python fragment">
terrain = [
    ["_", "R", "_", "_"],
    ["B", "_", "B", "_"],
    ["_", "_", "B", "_"],
    ["B", "_", "G", "_"]
]
</code></pre>
<p class="fragment"><small><a href='https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/ai/Search.ipynb'>
    https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/ai/Search.ipynb</a></small></p>
</section>
        

<section data-markdown>
    <textarea data-template>
### How to find a path

<img src="img/search/search.jpg" height="500px">

<small>By incrementally expanding possibilities</small>
</textarea>
</section>
    
<section data-markdown>
        <textarea data-template>
### Depth First

* traverses exapnded tree in a depth first notion
* simple: can even be implemented usign a stack and recursion
* not guarenteed to find the best route
* probably not very efficient
    
https://en.wikipedia.org/wiki/Depth-first_search
    </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Breadth First

* traverses exapnded tree level by level
* typically implemented using open/closed-list
* guranteed to find the best path
* needs much more memory (to store nodes yet to be expanded in open list)
* might still expand too many nodes
                
https://en.wikipedia.org/wiki/Breadth-first_search
    </textarea>
    </section>
    

<section data-markdown>
        <textarea data-template>
### Understanding Breadth First Search

<img src='img/breadth-first-search.png' height="500px">
                
<small>
https://qiao.github.io/PathFinding.js/visual/
</small>
    </textarea>
    </section>


<section data-markdown>
        <textarea data-template>
### A*
Why do we blindly wander around, don't we know in which direction to walk?    
            
* informed search, expands much less nodes than breadth first
* cost spent + estimated rest cost defines path to try
* guranteed to find the best path when heuristic underestimates rest cost
* variations used for games or route planing

<small>
https://en.wikipedia.org/wiki/A*_search_algorithm
<br>
https://en.wikipedia.org/wiki/Admissible_heuristic
http://theory.stanford.edu/~amitp/GameProgramming/
</small>
</textarea>
    </section>

<section>
<h3>Admissible Search Heuristics</h3>
<div class="fragment" style="float: left">
    <img src="img/search/search-problem.png" height="300">
    <p><small>Search, diagonal allowed</small></p>
</div>
<div class="fragment" style="float: left; padding-left: 25px">
        <img src="img/search/non-admissible-manhattan.png" height="300">
        <p><small>Manhattan (non-admissible):<br> length 16.24</small></p>
    </div>
<div class="fragment" style="float: left; padding-left: 25px">
    <img src="img/search/admissible-euclidean.png" height="300">
    <p><small>Euclidean (admissible):<br> length 15.07</small></p>
</div>
<p style="clear: both">
        <br>
        <small><em>
<a href='https://qiao.github.io/PathFinding.js/visual/'>
        https://qiao.github.io/PathFinding.js/visual/
    </a>
</em>
</small>
</p>
</section>                                

<section data-markdown>
    <textarea data-template>
<img src='img/best-first.png'>
<small>
https://twitter.com/mbostock/status/1055484629090631685
</small>
</textarea>
</section>

        <section data-markdown>
    <textarea data-template>
## Part II
### Adverserial Search
### Applying Search to Games    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Example: 3 in a row

<img src='img/3-in-a-row.jpg' height="500px">

<small>
A game the ancient Vikings played as well
</small>
<!-- TODO: Tackle with alpha beta or min max -->
        </textarea>
        </section>

<!-- http://www.dokchess.de/_downloads/szoerner_majug2012_architekturentwurf_schach_deploy.pdf -->
<section data-markdown >
    <textarea data-template>
### On the importance of looking ahead

Why looking ahead? Isn't a heuristic evaluation good enough?

Kudos for position to https://twitter.com/StefanZoerner

https://www.embarc.de/schachbegriffe-auf-englisch/
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Checkmate unavoidable?

<img src="img/search/pos1.jpg" height="450px">

FEN: 2R5/8/p7/7p/6pP/5pP1/5P1K/k4q2 w - - 0 1
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Using a heuristic to avoid loss of a piece

<img src="img/search/pos2_no_loss.jpg" height="450px">

Random move of Rook, but no loss
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### But Checkmate in next move

<img src="img/search/pos3_mate.jpg" height="450px">

Rook saved, but not effectively used
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Rewind to initial position

<img src="img/search/pos1.jpg" height="450px">

This time we look ahead
</textarea>
</section>
<section data-markdown>
    <textarea data-template>
### Certain loss of Rook

<img src="img/search/pos2_check.jpg" height="450px">

Bad local evaluation
</textarea>
</section>
<section data-markdown>
    <textarea data-template>
### Of course Queen has to capture Rook

<img src="img/search/pos3_stalemate.jpg" height="450px">

But this means Stalemate and a Draw
</textarea>
</section>


<section>
    <p>Chess Computers have defeated humans because</p>
    <div class="fragment" style="float: left">
        <img src="img/cray2.png" height="250">
        <p><small>Cray X-MP<br> Supercomputer (1982)</small></p>
    </div>
    <div class="fragment" style="float: left; padding-left: 20px; padding-top: 120px; font-weight: bold">
    x 100.000 =
    </div>
    <div class="fragment" style="float: left">
      <img src="img/titan5.jpg" height="250" style="float: right">
        <p><small><br>Titan 5 im Gamer PC (2017)</small></p>
    </div>
</section>


<section data-markdown style="font-size: xx-large">
        <textarea data-template>
### Size of complete Search Tree

* _Tic Tac Toe_: 10<sup>5</sup>
* _Connect Four_: 10<sup>21</sup>
* _Chess_: 10<sup>123</sup>
* _Backgammon_: 10<sup>144</sup>
* _Go_: 10<sup>360</sup>

To compare
* _Number of Atoms in Human Body_: 10<sup>27</sup>
* _Atoms in Earth_: 10<sup>49</sup>
* _Atoms in Milky Way_: 10<sup>68</sup>
* _Atoms in Universe_: 10<sup>78</sup>

    </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
### Average number of moves

* _Connect Four_: 18
* _Backgammon_: 28
* _Chess_: 40
* _Go_: 75

        </textarea>
        </section>

<!-- <section data-markdown class="todo">
        <textarea data-template>
### Alpha-Beta Pruning

<img src='img/haw/alpha_beta_pruning.jpg'>
            </textarea>
            </section> -->
<section data-markdown>
        <textarea data-template>
### Game Search

Full search mostly just not feasible
* Limit in Depth: Mini Max / Alpha Beta Pruning
* Limit in Breadth: Monte-Carlo Tree Search
  * Do we have a evaluation heuristic? No? MCTS
    </textarea>
    </section>
    
    <section data-markdown>
            <textarea data-template>
### Reasonable Heuristic is cruical

* Good solutions available for chess
* No good solutions for Go
    * Only a win as a state is a reliable indication
    * Need to search to the end
    * Branching Factor Higher than Chess as well

        </textarea>
        </section>

<section data-markdown>
    <textarea data-template>
### Mini Max

<img src='img/search/Minimax.png'>

<small>
https://en.wikipedia.org/wiki/Minimax    
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Alpha–beta pruning

* maintains two values, alpha and beta
* alpha: minimum score of the maximizing player in a branch
* beta: maximum score of the minimizing player in a branch
* branch can be pruned if
  * beta ≤ alpha
  * as this will never happen if players play well
* can reach approx. twice the depth of minimax in the same amount of time  

<small>
https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning    
</small>
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Intuition for Alpha Beta Pruning
<img src="img/search/alpha-beta-intuition.png" alt="Alpha Beta Intuition" height="400px">

No matter what Min does, Max can always win in leftmost branch, no need to check for the others
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Complete Search Tree for Robot Run
<img src="img/search/mini-max-tree.jpg" alt="Alpha Beta" height="450px">

<small>
Top Right Branch can be pruned completely
https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/ai/Play.ipynb
</small>
</textarea>
</section>

<section data-markdown style="font-size: xx-large">
    <textarea data-template>
### How does Stockfish Play

* Alpha-Beta Search Pruning: https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_search
* Bitboards: https://en.wikipedia.org/wiki/Bitboard
* Transposition Tables: https://en.wikipedia.org/wiki/Transposition_table
* Late Move Reductions:: https://en.wikipedia.org/wiki/Late_Move_Reductions 

https://en.wikipedia.org/wiki/Stockfish_(chess)

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Part III
### Monte Carlo Methods
</textarea>
</section>

        
        <section data-markdown>
                <textarea data-template>
### Monte Carlo Game Search

* Start from a next move beginning from an initial state
* For each next move
    * Play a game to the _end_ using a random set of moves
    * Repeat for a number of times
    * Count number of times for win, loose, draw
* Choose the move with the best probability for a win

<small>
Choose number of random experiment wisely based on branching factor
https://en.wikipedia.org/wiki/Monte_Carlo_tree_search#Pure_Monte_Carlo_game_search
</small>
            </textarea>
            </section>
        
            <section data-markdown>
                    <textarea data-template>
### Example: Monte Carlo Game Search

<img src='img/search/monte_carlo_game_search.jpg' height="550px">
                        </textarea>
                        </section>

                        
        <section data-markdown>
            <textarea data-template>
### Monte Carlo Tree Search

Loops in four phases
1. Selection
2. Expansion
3. Simulation
4. Back-Propagation

<small>
https://jeffbradberry.com/posts/2015/09/intro-to-monte-carlo-tree-search/
</small>
        </textarea>
        </section>

        <section data-markdown>
            <textarea data-template>
### Selection

Choose a node to expand next 

<img src='img/search/mcts_selection.png'>

<small>
<code>wins / number of times played</code>
</small>
        </textarea>
        </section>

        <section data-markdown style="font-size: xx-large">
            <textarea data-template>
### Exploration vs Exploitation

_Rather improve on states known as good or have a look at unknown moves?_

* wi: number of wins for the node considered after the i-th move
* ni: number of simulations for the node considered after the i-th move
* Ni: total number of simulations after the i-th move
* c: exploration parameter - theoretically equal to 2; in practice usually chosen empirically

<script type="math/tex; mode=display">
{\displaystyle {\frac {w_{i}}{n_{i}}}+{\sqrt (c {\frac {\ln N_{i}}{n_{i}})}}}    
            </script>

* first component: exploitation; it is high for moves with high average win ratio
* second component: exploration; it is high for moves with few simulations            
            
<small>
https://en.wikipedia.org/wiki/Monte_Carlo_tree_search
</small>
        </textarea>
        </section>

        <section data-markdown>
            <textarea data-template>
### Expansion

Expand node, add a random child

<img src='img/search/mcts_expansion.png'>

        </textarea>
        </section>

        <section data-markdown>
            <textarea data-template>
### Simulation

Play a Monte Carlo Simulation

<img src='img/search/mcts_simulation.png'>

        </textarea>
        </section>

        <section data-markdown>
            <textarea data-template>
### Back-Propagation

Update Scores

<img src='img/search/mcts_backprop.png'>

        </textarea>
        </section>

        <section data-markdown>
            <textarea data-template>
### More Applications of MCTS

<img src='img/search/mcts-molecules.jpg' height="450px">

<small>
    make molecules tailored to a specific problem            
    https://twitter.com/DJCordhose/status/1017886304384831488  
</small>     
            </textarea>
            </section>
            
<section data-markdown>
    <textarea data-template>
## Part IV
### MCTS and Alpha(Go) Zero
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Alpha(Go) Zero

<a href='https://applied-data.science/static/main/res/alpha_go_zero_cheat_sheet.png' target="_blank">
<img src='img/rf/alpha_go_zero_cheat_sheet_small.png' height="400px">
</a>

<small>
Tutorial: https://medium.com/applied-data-science/how-to-build-your-own-alphazero-ai-using-python-and-keras-7f664945c188
<br>
Code: https://github.com/AppliedDataSciencePartners/DeepReinforcementLearning
<br>
Explanation: http://tim.hibal.org/blog/alpha-zero-how-and-why-it-works/
</small>
</textarea>
</section>
        
        <section data-markdown>
            <textarea data-template>
<img src='img/TrainingTime-Graph-171019-r01.gif'>

<small>
https://deepmind.com/blog/alphago-zero-learning-scratch/    
</small>
            </textarea>
        </section>
        
        <section data-markdown>
            <textarea data-template>
### MCTS in AlphaGo Zero

* choose child to expand using heuristic of game state
* determined by Convolutional Neural Network
* CNN trained by which state leads to a win
* CNN also gives estimation of which player is going to win
* on other information went into training

<small>
https://deepmind.com/blog/alphago-zero-learning-scratch/    
</small>
            </textarea>
        </section>

        <section data-markdown>
                <textarea data-template>
### Alpha Zero
    
* generalized version of AlphaGo Zero
* can learn to play any deterministic full information game
* actually trained to play chess and shogi
* beat a version of chess world champion Stockfish

<small>
https://en.wikipedia.org/wiki/AlphaZero
<br>
https://deepmind.com/research/alphago/alphazero-resources/
</small>
                </textarea>
            </section>
    
    

        <section data-markdown>
            <textarea data-template>
### Links for AlphaGo Zero

* https://deepmind.com/blog/alphago-zero-learning-scratch/
* https://web.stanford.edu/~surag/posts/alphazero.html
* https://hackernoon.com/the-3-tricks-that-made-alphago-zero-work-f3d47b6686ef
            </textarea>
        </section>


<section style="font-size: xx-large">
    <h2>Wrap Up</h2>
    <p><em>Search is omnipresent in AI</em></p>
    <ul>
        <li class="fragment">Path finding is dominated by variants of A*
        <li class="fragment">Chess can be solved using tweaked Alpha-Beta-Search
        <li class="fragment">For a high branching factor and/or no good heuristic use Monte Carlo Methods 
        <li class="fragment">Monte Carlo is an advanced Monte Carlo Method 
        <li class="fragment">Alpha(Go) Zero uses MCTS together with Supervised Deep Learning and CNNs 
        <li class="fragment">AlphaGo Zero beats all known Go players 

    </ul>
    <p>
            <em>Graph Search: The Silver Bullet of Symbolic AI and the Secret of AlphaGo Zero</em>
        <br>
        <br>
        <small>
    <a href="http://zeigermann.eu">Oliver Zeigermann</a> / <a href="http://twitter.com/djcordhose">@DJCordhose</a>
        <br>
<a href="http://bit.ly/mlconf-search">
    http://bit.ly/mlconf-search</a>
</small>
    </p>
</section>

        

    </div>

</div>

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>
<script src="lib/jquery-2.2.4.js"></script>

<script>
        if (window.location.hostname.indexOf('localhost') !== -1) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }
        Reveal.addEventListener( 'ready', function( event ) {
                // do we want this???
                $('li').addClass('fragment')

            if (window.location.hostname.indexOf('localhost') !== -1) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
            // applies to all versions
            $('code').addClass('line-numbers');

            // make all links open in new tab
            $('a').attr('target', '_blank')

        } );
        // $('section').attr('data-background-image', "backgrounds/light-metal.jpg");
        // $('section').attr('data-background-image', "backgrounds/pink.jpg");
        $('section').attr('data-background-image', "backgrounds/white.jpg");
    //    $('section').attr('data-background-image', "backgrounds/code.jpg");
    </script>
    
<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        width: 1100,


        transition: 'fade', // none/fade/slide/convex/concave/zoom

        math: {
            mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true},
            // https://github.com/mikemiles86/reveal-line-numbers
            {src: 'lib/js/line-numbers.js'},
            { src: 'reveal.js/plugin/math/math.js', async: true }
        ]
    });

</script>

</body>
</html>
