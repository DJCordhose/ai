<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>DL Workshop</title>

    <meta name="description" content="Manning Course Material">
    <meta name="author" content="Oliver Zeigermann">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
      
          <!-- Code syntax highlighting -->
          <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              .beginning:before {
                  content: 'BEGINNING';
              }
              .beginning {
                color: red !important;
              }
              .end:before {
                  content: 'END';
              }
              .end {
                color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }
      
                      .reveal h2,
                      .reveal h3,
                      .reveal h4 {
                          letter-spacing: 2px;
                          font-family: 'Calibri', sans-serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          font-weight: bold;
                          color: black;
                          font-style: italic;
                          letter-spacing: -2px;
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
                      .reveal .step-subtitle h1 {
                          letter-spacing: 1px;
                      }
                      .reveal .step-subtitle h2,
                      .reveal .step-subtitle h3 {
                          text-transform: none;
                          font-style: italic;
                          font-weight: normal;
                          /* font-weight: 400; */
                          /* font-family: 'Amiri', serif; */
                          font-family: 'Lobster', serif;
                          letter-spacing: 1px;
                          color: #2aa198;
                          text-decoration: underline;
                      }
      
                      .reveal .front-page h1,
                      .reveal .front-page h2 {
                          font-family: "League Gothic";
                          font-style: normal;
                          text-transform: uppercase !important;
                          letter-spacing: 1px;
                      }
      
                      .reveal .front-page h1 {
                          font-size: 2.5em !important;
                      }
      
                      .reveal .highlight {
                          background-color: #D3337B;
                          color: white;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }
          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>


<div class="reveal">
    <div class="slides">

<!-- Dieser Workshop ist für Einsteiger in Deep Learning gedacht, die einen realistischen Einblick in die Entwicklung mit TensorFlow und Keras erhalten möchten.

Im ersten Teil lernst du die Grundbegriffe des Deep Supervised Learnings kennen und wie Neuronale Netze aufgebaut sind. Hier werden wir mit dem TensorFlow Playground arbeiten.

Im zweiten Teil trainieren wir dann ein Neuronales Netzwerk. Wir wählen dafür ein praxisnahes Beispiel aus und gehen so
vor, wie Sie es auch bei einer echten Problemstellung machen würden. Dies machen wir anhand von Python-Code, der in
Colab Notebooks läuft. Zum Einsatz kommen Keras und TensorFlow.

Im dritten Teil gucken wir uns weitere Anwendungsgebiete an. Mit dabei sein werden Bilderkennung und Textklassifikation.

Am Ende setzen wir unser trainiertes Modell produktiv. Wir werden uns unterschiedliche Arten der Produktivsetzung
ansehen: Google Cloud ML, TensorFlow Serving und TensorFlow.js. Die Installation der notwendigen Software ist zum Teil
sehr komplex, daher werden wir zur Produktivsetzung keine Übung haben.

Alle Software wird im Browser laufen, daher brauchen Sie als Vorbereitung nur eine aktuelle Version des Chrome-Browsers
und ein Google-Nutzerkonto (kann auch während des Kurses angelegt werden).

Agenda
ab 8.30 Uhr Registrierung und Begrüßungskaffee

9.30 Uhr Beginn

Was ist die Idee von Deep Supervised Learning?
Wie funktioniert ein Fully Connected Feed-Forward Netzwerk?
Was ist Klassifikation und wie macht man das mit Neuronalen Netzwerken?
Was ist Overfitting? Was Underfitting?

11.00 - 11.15 Uhr: Kaffeepause

Training eines Neuronalen Netzwerks mit TensorFlow und Keras

12.30 - 13.30 Uhr: Mittagspause

Optimierung und unseres Netzwerks, um Overfitting zu verhindern
Produktivsetzung mit Google Cloud ML, TensorFlow Serving und TensorFlow.js

15.30 - 15.45 Uhr: Kaffeepause

Neuronale Netzwerke (CNNs) für Bildverarbeitung (Grundlagen)
Recurrente Neuronale Netzwerke (RNNs) für Sequenzen und Textverarbeitung (Grundlagen)

ca. 17.00 Uhr: Ende -->

<section data-markdown class="preparation">
        <textarea data-template>
### Preparation

    </textarea>
</section>

<section>
    <h2>Einführung in Deep Learning mit TensorFlow und Keras</h2>
    <p><a target="_blank" href="https://www.data2day.de/veranstaltung-7590-einf%E3%BChrung-in-deep-learning-mit-tensorflow-und-keras.html?id=7590">
        data2day, September 2018
    </a></p>
    <h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / 
        <a href="http://twitter.com/djcordhose">@DJCordhose</a>
    </h4>
    <em>Folien: 
    <a href="http://bit.ly/d2d-dl">
        http://bit.ly/d2d-dl</a>
    </em>
</section>

<section data-markdown>
        <textarea data-template>

<img src='img/twitter-fchollet-trend.png' height="500px">            

<small>
https://twitter.com/fchollet/status/1029477656876613632
<br>
https://trends.google.com/trends/explore?cat=1299&date=today%205-y&q=tensorflow,keras,pytorch,caffe,theano
</small>
</textarea>
</section>

<section data-markdown style="font-size: large">
        <textarea data-template>
### Agenda

_9.30 Uhr Beginn_

* Was ist die Idee von Deep Supervised Learning?
* Wie funktioniert ein Fully Connected Feed-Forward Netzwerk?
* Was ist Klassifikation und wie macht man das mit Neuronalen Netzwerken?
* Was ist Overfitting? Was Underfitting?

_11.00 - 11.15 Uhr: Kaffeepause_

* Training eines Neuronalen Netzwerks mit TensorFlow und Keras

_12.30 - 13.30 Uhr: Mittagspause_

* Optimierung und unseres Netzwerks, um Overfitting zu verhindern
* Produktivsetzung mit Google Cloud ML, TensorFlow Serving und TensorFlow.js

_15.30 - 15.45 Uhr: Kaffeepause_

* Neuronale Netzwerke (CNNs) für Bildverarbeitung (Grundlagen)
* Recurrente Neuronale Netzwerke (RNNs) für Sequenzen und Textverarbeitung (Grundlagen)

_16.45 Uhr: Ende_
</textarea>
</section>

<!-- <section data-markdown>
        <textarea data-template>
### Our Plan for Toady

1. Introduction to Deep Supervised Machine Learning
   1. Why Machine Learning / Our Use Case
   1. Basic Concepts of Machine Learning Using the TensorFlow Playground
1. Deep Neural Networks using TensorFlow and Keras
1. Bringing our Modell into Production
1. Advanced Topics
   1. CNNs
   1. RNNs 
</textarea>
</section> -->

<section data-markdown>
        <textarea data-template>
## Introduce yourself, please
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
## Questions are welcome at any time

### First question wins a book
        </textarea>
    </section>
    
    <section data-markdown>
            <textarea data-template>
### PART 0
## Overview of Tools
            </textarea>
        </section>

<section data-markdown>
        <textarea data-template>
### TensorFlow and Keras

* https://www.tensorflow.org 
* https://www.tensorflow.org/guide/low_level_intro 
* https://www.tensorflow.org/guide/keras 

        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Why Keras High Level API?

<img src='img/why-keras.png' height="450">

<small>
https://twitter.com/karpathy/status/1013244313327681536    
https://twitter.com/martin_wicke/status/1013550466125328384    
</small>
        </textarea>
    </section>


<section data-markdown>
        <textarea data-template>
### Colab Notebooks

https://colab.research.google.com
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
### TensorFlow Playground

https://playground.tensorflow.org
            </textarea>
        </section>

            <section data-markdown>
                    <textarea data-template>
### PART I
## Introduction to Deep Supervised Machine Learning
                    </textarea>
                </section>

                <section data-markdown>
                    <textarea data-template>
## Our Use Case / Why Machine Learning
                    </textarea>
                </section>

    <section data-markdown>
        <textarea data-template>
### Objective for this Course

_Imagine we are in the car insurance business and want a system that predicts the risk of accidents for prospective customers_

<img src='img/pixabay/accident-151668_1280.png'>
        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### ML Car Insurance Risk Calculator

<a href='html/calculator.html'>
<img src='img/manning/calculator.png' height="450">
</a>
<!-- <p><small>
    <a href='html/calculator.html' target="_blank">
        https://djcordhose.github.io/ai/html/calculator.html</a></small>
</small></p> -->
</textarea>
    </section>
    
    <section>
            <h3>Example: Customer Data - Risk of Accidents</h3>
            <img src="img/manning/all.png" height="400px" class="fragment">
            <p class="fragment">
                <small>How would you rank me (47) for a car having 100 mph top speed, driving 10k miles per year?</small>
            </p>
        </section>

        <section>
                <h3>Programmer's approach: Code Rules by Hand</h3>
                <div class="fragment">
                <pre><code contenteditable data-trim class="line-numbers python">
if age < 25:
    if speed > 140:
        return red # young people, fast cars: high risk
    else:
        return yellow # young people: medium risk
                    </code></pre>
                </div>
                <div class="fragment">
                <pre><code contenteditable data-trim class="line-numbers python">
if age > 75:
    return red # old people: high risk
                    </code></pre>
                </div>
                <div class="fragment">
                <pre><code contenteditable data-trim class="line-numbers python">
if miles_per_year > 30:
    return red # a lot of driving: high risk
if miles_per_year > 20:
    return yellow #  a bit of driving: medium risk
                    </code></pre>
                </div>
                <div class="fragment">
                <pre><code contenteditable data-trim class="line-numbers python">
return green # otherwise: low risk
                    </code></pre>
                </div>
            </section>

            <section data-markdown>
                    <textarea data-template>
### Plotting the predictions as a background
<img src='img/manning/manual.png' class="fragment" height="450px">

<div class="fragment">
<p><small>approx. 43% predictions correct</small></p>
</div>        
</textarea>
                </section>

    <section data-markdown>
            <textarea data-template>
### How good is this?

<!-- <p class="fragment"><em>How well have we mastered the domain?</em></p> -->

* Is it better than guessing?
* Are all the rules correct?
* Are some missing?
* How would we even know?

        </textarea>
    </section>                    

    <section data-markdown>
            <textarea data-template>
### Our Approach
## Deep Supervised Machine
## Learning
        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
<!-- ### ML rather is research and a bit of engineering than a craft -->
### Machine Learning = Lab Work
<img src='img/ml_is_not_programming.jpg' height="450px">
    </textarea>
    </section>


    <section data-markdown>
            <textarea data-template>
### The model we will create in this course

<img src='img/manning/nn-reg.png' class="fragment" height="450px">

<div class="fragment">
<p><small>up to 80% predictions correct on previously unknown data possible</small></p>
</div>        
</textarea>
        </section>

<section data-markdown>
        <textarea data-template>
### Our problem in the TensorFlow Playground

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
<img src="img/manning/classicifation.png" height="500px">
</a>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### How does an artificial neuron work?

http://explained.ai/matrix-calculus/index.html#intro

</textarea>
</section>



<section data-markdown>
        <textarea data-template>
### Affine Function

<img src='img/scans/neuron21.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Example

<img src='img/scans/neuron211.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Hand crafting a classification with a single neuron

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
<img src="img/manning/nn.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise 1 (of 2)
### What kind of decision boundary can a single neuron represent?

* Experiment with the different weights and the bias of our neuron to separate the two classes ‘high risk’ / ‘low risk’.
* Are there limitations to the decision boundaries you can create?

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
https://playground.tensorflow.org
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise 2 (of 2)
### Why does an artificial neuron need a bias?

* Experiment with the Playground
* How does changing the Bias influence the decision boundary? 
* You can change the Bias of the neuron by clicking on the small box on the bottom left corner of the neuron.

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
https://playground.tensorflow.org
</a>

</textarea>
</section>

    <section data-markdown>
        <textarea data-template>
## Activation Functions

Activation functions take a single numerical input and perform a certain mathematical operation on it
        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Activation Function

<img src='img/scans/neuron212.jpg'>

</textarea>
</section>


        <section data-markdown>
        <textarea data-template>
### Step

<img src="img/cnn/step.png" height="450">

<small>switching from zero to one,
    original version simulating transition from passive to active</small>
</textarea>
    </section>

            <section data-markdown>
        <textarea data-template>
### Sigmoid

<img src="img/cnn/sigmoid.png" height="450">

<small>compressing between 0 and 1,
        continuously differentiable version of step function</small>
</textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Hyperbolic Tangent

<img src="img/tanh-activation.png" height="450">

<small>floating from -1 to 1,
        like Sigmoid, but can also be negative</small>
</textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Relu: Rectified Linear Unit

<img src="img/cnn/relu.png" height="450">

<small>negative values zeroed out, positive linear,
        fights vanishing gradient</small>
</textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Complete Example

<img src='img/scans/neuron213.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Fully Connected Feed Forward Networks
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### A more complex example

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=false&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/classification4.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Training with 2 neurons

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=2&amp;seed=0.90689&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=false&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/2nn.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise
_How many neurons do you need to decently separate the two classes from each other?_

* You might have noticed that two neurons do not give good results. 
* Can you figure out a minimal number of neurons to get a good result? 
* As weights and biases are initialized randomly, training results are not deterministic. You might have to train several times.

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=2&amp;seed=0.90689&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=false&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
https://playground.tensorflow.org
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## How does a network learn?
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Determining Error is the key to learning

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=2&amp;seed=0.90689&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=false&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/error.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown id='mse'>
    <textarea data-template>
### Mean Squared Error

<script type="math/tex; mode=display">
MSE = {\frac {1}{n}}\sum _{i=1}^{n}(Y_{i}-{\hat {Y_{i}}})^{2}
</script>

https://en.wikipedia.org/wiki/Mean_squared_error
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### From error to optimal parameters

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/bias-to-loss.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Job of the optimizer

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/optimizer.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Backpropagation

_Propagating the error from output layer backward_

<img src="img/backprop.png" height="400px">

<small>
https://twitter.com/dsmilkov/status/1011974815811596288
<br>
https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/    
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Overfitting

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/overfit.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Underfitting

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/underfit.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sweet Spot

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/sweet-spot.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sweet Spot shown by Error

<a class="hide-controls-link" href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/test-sweet-spot.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Overfitting shown by Error

<a class="hide-controls-link" href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/test-overfit.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise
_Train a network on a complex shape_

* Choose the most complex data set (spiral) from the playground (link below) 
* Play with the learning rate, activation function, ratio of training, noise, the number of neurons and also the number of hidden layers. 
* Experiments have shown that 2-3 hidden layers are good rule of thumb. Are you able to create a model that overfits heavily?

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=spiral&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=40&amp;networkShape=4,2&amp;seed=0.31018&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;problem_hide=true&amp;regularization_hide=true&amp;batchSize_hide=true&amp;regularizationRate_hide=true">
https://playground.tensorflow.org
</a>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### PART II
## Deep Neural Networks using TensorFlow and Keras
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
### Working with Colab Notebooks

https://colab.research.google.com
            </textarea>
        </section>
    
<section data-markdown>
    <textarea data-template>
### Hands-On
_Run your first Colab Notbook_

* Go to https://colab.research.google.com 
* Sign into your Google account or register a new one 
* Switch on GPU support
* Execute some code cells

https://colab.research.google.com

</textarea>
</section>
    
<section data-markdown>
        <textarea data-template>
## Notebook            
### Getting to know our data

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M3-data.ipynb

    </textarea>
    </section>

<section data-markdown>
    <textarea data-template>
### Exercise
_Change our pairplot to_

* plot more samples 
* reduce the number of variables to the first three (leave out the group) 
* Switch on GPU support
* make the plot a bit larger

Use the help function built into the notebook to explore Seaborns API by typing

<em>sns.pairplot?</em>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
# OPTIONAL
## Notebook            
### Creating a base line

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M3-baseline.ipynb

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
## Encoding our data
        </textarea>
    </section>

 
    <section data-markdown>
            <textarea data-template>
### Data Encoding in Deep Learning
* in Classic Machine Learning selecting and pre-processing is crucial
* Deep Neural Networks often allow to just stick in our data as is
* the rest is done by the first layers of our deep neural network   
* Deep Learning can still benefit from preprocessing and normalizing your data 
* Often you can compensate with more training data

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### What goes in?

<img src='img/scans/data_encoding.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### What comes out?

<img src='img/scans/encoding2.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Role of the Hidden Layer(s)

<img src='img/scans/encoding3.jpg'>

</textarea>
</section>

<!-- <section data-markdown>
        <textarea data-template>
### Animated Powerpoint 

<a href="data-encoding.pptx">
<img src='img/data-encoding.png' height="500">
</a>

</textarea>
</section> -->

<section data-markdown>
        <textarea data-template>
## Notebook            
### Setting Up Our neural Network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M5-nn-intro.ipynb
    </textarea>
    </section>

<section>
    <h3>Exercise</h3>
    <p>Run through the notebook and make sure it makes sense to you</p>
    <p><em>Can you explain the number of parameters for each layer?</em></p>
    <pre><code contenteditable data-trim class="line-numbers python">
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
hidden1 (Dense)              (None, 50)                200       
_________________________________________________________________
softmax (Dense)              (None, 3)                 153       
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________</code></pre>
<p><em>Add a second layer and increase the number of neurons: do the numbers of parameters still make sense to you?</em></p>
</section>

    
<section data-markdown>
        <textarea data-template>
### Generalization

_We do not have any idea how well our model performs, yet_

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Evaluating our model

* The most important property of a model is if it generalizes well to unknown data
* A machine learning model is of no use if it only works well on the data it has been trained on
  * If it was, the easiest way to achieve this would be a dictionary translating from a set of inputs to the known output
* Conceptually it is a little bit hard to optimize for something you do not know
* So, we introduce a little trick here

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Split known data into training and test

<img class='fragment' src='img/scans/generalization.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Use some training data for validation

<img class='fragment' src='img/scans/generalization1.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Understand Generalization

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M7-nn-training.ipynb

_Stop at exercise_
</textarea>
</section>


<section>
    <h2>Exercise</h2>
    <p><em>Understanding Generalization</em></p>
    <p>Manually cluster areas of different customer types </p>
    <ol>
        <li>
            <em>dark (green)</em>: good customer</li>
        <li><em>light (yellow)</em>: mediocre customers</li>
        <li>
            <em>middle (red)</em>: red customers</li>
    </ol>
    <p>Use a <em>pen</em> and make sure you apply <em>pressure</em> when you draw</p>
</section>

<section>
    <h3>Plot Twist</h3>
    <p>Remenber, <em>Generalisation</em>, not perfect reproduction is the objective</p>
    <ol>
        <li class="fragment">We split existing data into two sets</li>
        <li class="fragment">The test set is on the second page</li>
    </ol>
</section>

<section>
    <h2>Exercise, Part2</h2>
    <p><em>How well did you generalize?</em></p>
    <p>Turn the page to the test set and redraw the lines you printed through from the first page</p>
    <p>What do you think, is this result worse?</p>
    <p>What would you have done differently if you had been given the information about this test set before?</p>
</section>

<section data-markdown>
        <textarea data-template>
## Notebook            
### Train the neural network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M7-nn-training.ipynb

    </textarea>
    </section>


<section data-markdown>
        <textarea data-template>
## Exercise

_Train the model_

* Run the notebook as is
* Adapt the model to your parameters from the previous exercise (or any other model)
* How well does it perform?
* Do you see overfitting?
* Any idea why it performs the way it does?
* Experiment with the parameters you know
    </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### Best known model using 2 dimensions

<img src='img/manning/nn-reg.png' height="500">

<p><small>up to 77% predictions correct on previously unknown data possible</small></p>
</textarea>
    </section>



<section data-markdown>
    <textarea data-template>
## Regularization
    </textarea>
</section>

<section id='overfitting'>
        <h3>The Issue: Overfitting</h2>
    <div>
    <div style="float: left">
        <img src="img/scans/elements/80_percent.jpg" height="200" class="fragment" data-fragment-index='1'>
        <p>
            <small><em>Training Score</em></small>
        </p>
    </div>
    <div style="float: left" class="fragment" data-fragment-index='5'>
        <img src="img/scans/elements/down.jpg" height="200">
    </div>
    <div style="float: left" class="fragment" data-fragment-index='4'>
        <img src="img/scans/elements/up.jpg" height="200">
    </div>
    <div style="float: left">
            <img src="img/scans/elements/70_percent.jpg" height="225"  class="fragment" data-fragment-index='2'>
            <p>
                <small><em>Test Score</em></small>
            </p>
    </div>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='3'><em>Training and Test scores clearly divert</em></p>

    </section>

    <section data-markdown>
        <textarea data-template>
### Regularization

_Process to counter Overfitting_
            </textarea>
            </section>
    
    <section data-markdown>
        <textarea data-template>
### First approach: Train for less epochs

<img src='img/accuracy.png'>

_Watch where training and validation accuracy diverge and stop training there_


            </textarea>
            </section>
    
<section id='overfitting-capacity'>
        <h3>Second approach: Reduce Capacity of model</h2>
    <div style="float: left; width: 400px" class="fragment" data-fragment-index='1'>
        <img src="img/scans/elements/model-large.jpg" height="200">
        <p>
            <small><em>Original Model</em></small>
        </p>
    </div>
    <div style="float: left; width: 200px" class="fragment" data-fragment-index='2'>
        <br>
        <img src="img/scans/elements/right.jpg">
        <br>
    </div>
    <div style="float: left; width: 500px"   class="fragment" data-fragment-index='3'>
            <br>
            <img src="img/scans/elements/model-small.jpg" height="100">
            <br>
            <br>
            <p>
                <small><em>Smaller Model</em><br>less Hidden Layers, less Neurons per Layer</small>
            </p>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='4'><em>Intuition: Give model less capacity to simply memorize data</em></p>
    </section>

<section id='overfitting-dropout'>
        <h3>Third approach: Use Dropout to only train a certain percentage of neurons per Batch</h2>
    <div style="float: left; width: 400px" class="fragment" data-fragment-index='1'>
        <img src="img/scans/elements/model-large.jpg" height="225">
        <p>
            <small><em>Original Model</em></small>
        </p>
    </div>
    <div style="float: left; width: 200px" class="fragment" data-fragment-index='2'>
        <br>
        <img src="img/scans/elements/right.jpg">
        <br>
    </div>
    <div style="float: left; width: 500px"   class="fragment" data-fragment-index='3'>
            <br>
            <img src="img/scans/elements/model-emsemble.jpg" height="100">
            <br>
            <br>
            <p>
                <small><em>Ensemble of Small Models</em> (each one overfits on its specific batch)<br></small>
            </p>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='4'><em>Intuition: Combination of models makes result more robust</em></p>
    </section>

    <section data-markdown id='overfitting-bn'>
            <textarea data-template>
### Fourth approach: Batch Normalization

<ul>
    <li class="fragment">Subtracts Batch Mean
    <li class="fragment">Multiplies by Standard Deviation     
</ul>

<img src='img/scans/elements/sigmoid.jpg' class="fragment" height="200">
    
<p class="fragment"><em>Intuition: Makes Model robust by adding noise</em></p>

<p class="fragment"><em>Bonus:</em> Lets Model train faster by fighting vanishing gradients</p>

                </textarea>
                </section>
<section data-markdown>
    <textarea data-template>
### Links Batch Normalization

https://www.quora.com/Is-there-a-theory-for-why-batch-normalization-has-a-regularizing-effect

https://www.quora.com/Why-does-Batch-Normalization-for-deep-Neural-Networks-fix-the-vanishing-gradient-problem

https://stats.stackexchange.com/questions/227114/are-there-any-ways-to-deal-with-the-vanishing-gradient-for-saturating-non-linear

https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras

    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Regularize your neural network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M9-regularization.ipynb

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
## Exercise

_Apply regularizations to your model_

- keep adding regularization to make test and train scores come closer to each other
- this will come at the cost of train scores going down
- if both values start going down you have gone too far
- each experiment takes some time
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Our final model ready for production

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M10-final-model.ipynb

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Exercise

_Make some predictions and download your model_

- Check how you would be assessed by our model
- Prediction for my data would look like: ```model.predict(np.array([[100, 47, 10]]))```
- Upload your model to transfer.sh where you can download it from for 14 days
- ```!curl --upload-file insurance.h5 https://transfer.sh```
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### PART III
## Bringing our Model in Production
        </textarea>
    </section>

<section data-markdown>
    <textarea data-template>
## Preparing our Keras model for serving

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U4-M4-tf-prep.ipynb
    </textarea>
</section>


<section>
<h3>Creating the Signature</h3>

<div class="fragment">
<pre><code contenteditable data-trim class="python">
signature = saved_model.signature_def_utils.build_signature_def(
    inputs={'inputs': build_tensor_info(model.input)},
    outputs={'scores': build_tensor_info(model.output)},
    method_name=saved_model.signature_constants.PREDICT_METHOD_NAME)
</code></pre>
<p><small><a href='https://www.tensorflow.org/serving/signature_defs'>https://www.tensorflow.org/serving/signature_defs</a></small></p>
</div>

</section>

<section>
<h3>Creating the builder and save model</h3>

<pre><code contenteditable data-trim class="fragment python">
builder = saved_model.builder.SavedModelBuilder("tf/1") # path to model
</code></pre>
<pre><code contenteditable data-trim class="fragment python">
builder.add_meta_graph_and_variables(
    sess, [saved_model.tag_constants.SERVING],
    signature_def_map={
    saved_model.signature_constants.
        DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature
    })
</code></pre>
<pre><code contenteditable data-trim class="fragment python">
builder.save()
</code></pre>
</section>

<section data-markdown>
    <textarea data-template>
## Checking our TensorFlow (.pb) model

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U4-M5-tf-check.ipynb
    </textarea>
</section>

        <section>
<h3>Using saved_model_cli</h3>

<div class="fragment">
<pre><code contenteditable data-trim class="python">
saved_model_cli show --dir tf/1 \
  --tag_set serve --signature_def serving_default
</code></pre>
<pre><code contenteditable data-trim class="fragment python">
The given SavedModel SignatureDef contains the following input(s)
  inputs['inputs'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 3)
      name: hidden1_input:0
The given SavedModel SignatureDef contains the following output(s)
  outputs['scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 3)
      name: softmax/Softmax:0
Method name is: tensorflow/serving/predict
</code></pre>
</div>

<div class="fragment">
<pre><code contenteditable data-trim class="python">
saved_model_cli run --dir tf/1 --signature_def serving_default \
--tag_set serve --input_exprs inputs=[[100.0,47.0,10.0]]
</code></pre>
<pre><code contenteditable data-trim class="fragment python">
Result for output key scores: [[0.0027608  0.8720881  0.12515119]]
</code></pre>
</div>
<p><small><a href='https://www.tensorflow.org/guide/saved_model#cli_to_inspect_and_execute_savedmodel'>https://www.tensorflow.org/guide/saved_model#cli_to_inspect_and_execute_savedmodel</a></small></p>
    </section>

<section data-markdown>
    <textarea data-template>
## Hosting your model on Google Cloud ML

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U4-M6-cloud.ipynb
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Deploying to Google Cloud ML

* Takes away the scaling and installation burden
* Requires to convert your Keras model to a TensorFlow model
* You need to define Signatures for input and output
* The generated serving model also works for your local model servers (more on that later)
* Can use CPU or GPU

        </textarea>
    </section>
                
        <section>
<h3>Deploying to Google Clound ML</h3>

<div class="fragment">
    <p>Copy your model to a Cloud Bucket</p>
<pre><code contenteditable data-trim class="python">
gsutil mb gs://my_bucket
gsutil cp -R tf/1 gs://my_bucket
</code></pre>
<p><small>
Needs Google Cloud SDK:         
    <a href='https://cloud.google.com/sdk/install'>https://cloud.google.com/sdk/install</a></small></p>
</div>
<div class="fragment">
    <p>Deploy from this bucket</p>
<pre><code contenteditable data-trim class="python">
gcloud ml-engine models create "ml_insurance" --enable-logging
gcloud ml-engine versions create "v1" --model "ml_insurance" \
 --origin "gs://my_bucket/1"
gcloud ml-engine versions describe "v1" --model "ml_insurance"
</code></pre>
<p><small>
<a href='https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models'>
    https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models</a>
<br>
<a href='https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview#prediction_logging'>
    https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview#prediction_logging</a></small></p>
</div>

    </section>

        <section>
<h3>Making Predictions</h3>

<div class="fragment">
    <p>Input format is a bit special</p>
<pre><code contenteditable data-trim class="python">
# sample_insurance.json    
{"inputs": [ 160,  18,  100]}
{"inputs": [ 100,  47,  10]}
{"inputs": [ 90,  20,  20]}    
</code></pre>
</div>
<div class="fragment">
    <p>Call from Google Cloud Console</p>
<pre><code contenteditable data-trim class="python fragment">
gcloud ml-engine predict --model "ml_insurance" --version "v1" \
 --json-instances ./sample_insurance.json
</code></pre>
<pre><code contenteditable data-trim class="python fragment">
SCORES
[0.8658562898635864, 7.318668918511809e-14, 0.13414366543293]
[0.002760800765827298, 0.8720880746841431, 0.12515118718147278]
[5.452934419736266e-05, 0.005952719133347273, 0.9939927458763123]    
</code></pre>
</div>

<p><small>
<a href='https://cloud.google.com/ml-engine/docs/tensorflow/online-predict'>https://cloud.google.com/ml-engine/docs/tensorflow/online-predict</a>
</small></p>

    </section>

<section data-markdown>
    <textarea data-template>
## Running on a dedicated Linux server

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U4-M7-local.ipynb
    </textarea>
</section>

        <section>
<h3>TensorFlow Serving REST API</h3>

<div class="fragment">
<p>Starting the Model Server in Rest Mode (needs Linux)</p>

<pre><code contenteditable data-trim>
tensorflow_model_server --rest_api_port=8501 \
--model_name=manning_insurance_1 \
--model_base_path=$(pwd)/tf
</code></pre>
<p><small><a href='https://www.tensorflow.org/serving/api_rest'>https://www.tensorflow.org/serving/api_rest</a></small></p>
</div>
<div class="fragment">
<p>Curling to it</p>

<pre><code contenteditable data-trim class="python">
curl -X POST \
http://localhost:8501/v1/models/manning_insurance_1:predict  \
-d '{ "instances": [{"inputs": [ 100.0,  47.0,  10.0]}]}' 
# {
#     "predictions": [[0.0027608, 0.872088, 0.125151]]
# }</code></pre>
</div>

    </section>

        <section data-markdown>
            <textarea data-template>
## Deploying to the browser

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U4-M3-tensorflowjs.ipynb
            </textarea>
        </section>

    <section data-markdown>
        <textarea data-template>
### ML Car Insurance Risk Calculator

<a href='html/calculator.html'>
<img src='img/manning/calculator.png' height="400">
</a>
<p><small>
    <a href='html/calculator.html' target="_blank">
https://djcordhose.github.io/deep-learning-crash-course-notebooks/</a></small>
</small></p>
</textarea>
    </section>

        <section>
            <img src="img/tensorflowjs.png" height="500">
            <p><small><a href="https://js.tensorflow.org/" target="_blank">https://js.tensorflow.org/</a></small></p>
        </section>
    
        <section>
<h3>Converting our Keras Model to tensorflow.js</h3>

<div class="fragment">

<pre><code contenteditable data-trim class="python">
tensorflowjs_converter --input_format keras \
./model/insurance.hdf5 \
./tfjs    
</code></pre>
<p><small><a href='https://js.tensorflow.org/tutorials/import-keras.html'>
    https://js.tensorflow.org/tutorials/import-keras.html</a></small></p>

</div>

    </section>

        <section>
<h3>Loading and using directly from the Browser</h3>

<div class="fragment">

            <pre><code contenteditable data-trim class="fragment line-numbers javascript">
const model = await tf.loadModel('tfjs/model.json');
            </code></pre>
            <pre><code contenteditable data-trim class="fragment line-numbers javascript">
// max speed, age, thousand miles per year
const example = tf.tensor([[100, 47, 10]]);
const prediction = model.predict(example);
console.log(await prediction.data());
//[0.00334801129065454, 0.8710343241691589, 0.12561771273612976]
    </code></pre>

<p><small>
            <a href='js/tensorflow-sandbox/load_manning_model.html' target="_blank">
                https://djcordhose.github.io/deep-learning-crash-course-notebooks/load_model.html</a></small>
        </small></p>
    </div>   
    </section>

        <section data-markdown style="font-size: xx-large">
    <textarea data-template>
## Exercise

_Install the Risk Calculator locally and change it to use your data_

- clone or download https://github.com/DJCordhose/deep-learning-crash-course-notebooks
- in the _docs_ folder you find the complete Risk Calculator in _index.html_
- run a local web server in that directory
  - if you do not have one you can use https://www.npmjs.com/package/http-server
- in your favorite editor or IDE open _index.html_
- find the line where I entered my own personal data
- change it to yours and try it in the browser

</textarea>
</section>

    
    <section data-markdown>
        <textarea data-template>
### PART IV
## Other types of neural networks
        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### deep learning is straight up magic

<img src='img/state-of-dl.png' height="500">

<small>
https://twitter.com/Smerity/status/947278008385028096
</small>
</textarea>
</section>


    <section>
            <img src='img/applications/decisions/data.png'>
    </section>

    <section data-markdown>
        <textarea data-template>
## CNN - Convolutional neural networks
### Let the GPU burn
        </textarea>
    </section>

        <section>
            <h3>Neural Networks are best for non symbolic data</h3>
            <p>Like classifying images</p>
            <p>Reference:
                    <a href="http://cs231n.github.io/convolutional-networks/" target="_blank">
                         http://cs231n.github.io/convolutional-networks/</a>
            </p>
             
        </section>

        <section>
            <h3>Use of GPU for non symbolic data</h3>
            <img src="albon-gpu-gaming.png">
            <p>
                <small>
                    <a href="https://twitter.com/chrisalbon/status/907028933693947904?s=03" target="_blank">
                        https://twitter.com/chrisalbon/status/907028933693947904?s=03</a>
                </small>
            </p>
        </section>
        
        <section>
            <h3>Why the recent break throughs?</h3>
            <div class="fragment" style="float: left">
                <img src="img/cray2.png" height="250">
                <p>
                    <small>Cray X-MP
                        <br> Supercomputer (1982)</small>
                </p>
            </div>
            <div class="fragment" style="float: left; padding-left: 20px; padding-top: 120px; font-weight: bold">
                x 100.000 =
            </div>
            <div class="fragment" style="float: left">
                <img src="img/titan5.jpg" height="250" style="float: right">
                <p>
                    <small>
                        <br>Titan 5 im Gamer PC (2017)</small>
                </p>
            </div>
        </section>

                <section>
                    <h3>... but we also have</h3>
                    <ol>
                        <li>Smarter Learning Strategies (more hidden layers = Deep Learning, Convolutional Layers)
                        <li>Big Data
                    </ol>
                </section>

        <section>
            <h3>GPUs work in parallel</h3>
            <div class="fragment" style="float: left; padding-left: 100px">
                <img src="img/sequential-knive.jpg" height="400">
                <p><small><em>sequential</em>, <br>slow but flexible</small>
                </p>
            </div>
            <div class="fragment" style="float: right; padding-right: 100px">
                <img src="img/parallel-knive.jpg" height="400">
                <p><small><em>parallel</em>, <br>fast but same operation for all data
                        </small>
                </p>
            </div>
        </section>


<section>
    <h3>Architectures of Convolutional Neural Networks: VGG</h3>
        <img src="img/sketch/vgg.png" height="350px">
        <p>
            <small>There are a number of specialized neural network layers</small>
        </p>
</section>

<!-- <section data-markdown>
    <textarea data-template>
### Classic VGG like Architecture
* we use a VGG like architecture
* based on https://arxiv.org/abs/1409.1556
* basic idea: sequential, deep, small convolutional filters, use dropouts to reduce overfitting
* 16/19 layers are typical
* many architectures are based on that
</textarea>
</section> -->

<section data-markdown>
    <textarea data-template>
### Convolutional Blocks: Cascading many Convolutional Layers having down sampling in between

![Applying filters](http://cs231n.github.io/assets/cnn/cnn.jpeg)

http://cs231n.github.io/convolutional-networks/#conv
</textarea>
</section>

<section data-markdown style="font-size: x-large">
    <textarea data-template>
### Example of a Convolution
![Dog](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/conv/dog.png)
#### Many convolutional filters applied over all channels
![Dog after Convolutional Filters applied](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/conv/dog-conv1.png)
http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html
</textarea>
</section>


<section>
        <h3>How do Convolutions work - Image Kernels</h3>
        <p><small>You might know from Photoshop etc., used in Convolutional Neural Networks</small></p>
        <a href="http://setosa.io/ev/image-kernels/" target="_blank">
            <img src="img/browser/setosa_io_image-kernels.png" height="300px">
        </a>
        <p>
            <small>
                <a href="http://setosa.io/ev/image-kernels/" target="_blank">http://setosa.io/ev/image-kernels/</a>
            </small>
        </p>
    </section>

<section>
    <h3>Experiment with Image Kernels</h3>
    <ol>
        <li class="fragment">How can a matrix of numbers can represent an image? How could you encode color?</li>
        <li class="fragment">Explain the effect the filter kernels Sharpen and Blur have on the sample image - explain the effect of the specific values to the result</li>
        <li class="fragment">Starting from the identity kernel - how can you create a filter that highlights edges on the top of shown digits? What about the bottom?</li>
    </ol>
    <p>
            <small>
                <a href="http://setosa.io/ev/image-kernels/" target="_blank">http://setosa.io/ev/image-kernels/</a>
                <br>
                Sample image: <a 
                href="https://github.com/DJCordhose/speed-limit-signs/raw/master/data/real-world/4/100-sky-cutoff-detail.jpg" target="_blank">
                https://github.com/DJCordhose/speed-limit-signs/raw/master/data/real-world/4/100-sky-cutoff-detail.jpg</a>
                
            </small>
        </p>
</section>
    
<section data-markdown>
    <textarea data-template>
### Downsampling Layer: Reduces data sizes and risk of overfitting
![Pooling](http://cs231n.github.io/assets/cnn/pool.jpeg)
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Max Pooling
![Max Pooling](http://cs231n.github.io/assets/cnn/maxpool.jpeg)
http://cs231n.github.io/convolutional-networks/#pool
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Standard CNN Architecture

![Performance of CNN Architectures](https://cdn-images-1.medium.com/max/1600/1*kBpEOy4fzLiFxRLjpxAX6A.png)

<small>
https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
    ### Typical Architecture of a CNN 
![VGG architecture](img/sketch/vgg.png)

_The classifier more or less is what we used for our previous example_    
    </textarea>
    </section>

    <section>
            <h3>MNIST - Using a model <em>already trained</em></h3>
            <p>Exploring the different types layers together</p>
            <a href="https://transcranial.github.io/keras-js/#/mnist-cnn" target="_blank">
                <img src="img/browser/keras-browser.png" height="350px">
            </a>
            <p><small>
                <a href="https://transcranial.github.io/keras-js/#/mnist-cnn" target="_blank">https://transcranial.github.io/keras-js/#/mnist-cnn</a>
            </small></p>
        </section>

    <section>
            <h3>Keras layers</h3>

            <p><small>Convolution</small></p>
            <pre><code contenteditable data-trim class="fragment line-numbers javascript">
    model.add(Conv2D(filters=32, padding='same', activation='relu'))
                </code></pre>

                <p><small>Max Pooling</small></p>
                <pre><code contenteditable data-trim class="fragment line-numbers javascript">
model.add(MaxPooling2D())
                </code></pre>
                                    
                <p><small>Flatten 2d to make it accessible to Dense layers</small></p>
            <pre><code contenteditable data-trim class="fragment line-numbers javascript">
model.add(Flatten())
            </code></pre>
        <p>
            <small>
                    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers">
                        https://www.tensorflow.org/api_docs/python/tf/keras/layers
                    </a>
            </small>
        </p>
    </section>
    
    
        
        <section>
            <h3>More complex architecture: Google Inception V3</h3>
            <img src="img/inception_v3_architecture.png" height="400px">
            <p>
                <small>
                    Paper: <a href="https://arxiv.org/abs/1409.4842" target="_blank">Going Deeper with Convolutions</a>
                    <br>
                    <a href="https://stackoverflow.com/questions/39352108/does-the-inception-model-have-two-softmax-outputs" target="_blank">
                    Why two classifiers?</a>
                </small>
            </p>
        </section>

                </section>
        <section data-markdown>
                <textarea data-template>
### Fashion MNINST example

28x28 grayscale images of fashion Items

<img src="img/fashion-mnist-sprite.png" height="300px">

<small>
Tutorial: https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a
<br><br>
Colab Notebook: https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb
</small>
        </textarea>
        </section>
        
        <section data-markdown>
                <textarea data-template>
### Exercise

_Can you improve the model for Fashion MNINST notebook?_

* other/more/less layers
* different Sequence, less/more filters
* prevent overfitting even better 
</textarea>
</section>


    <section data-markdown>
        <textarea data-template>
## RNNs
### Recurrent Neural Networks
        </textarea>
    </section>

    <!-- <section data-markdown>
            <textarea data-template>
    ### RNN Approach
    <img src='img/approach-rnn.jpg' height="500">
    
                </textarea>
                </section>
     -->
    <section>
            <h3>Text and sequences are special</h3>
            <img src='img/applications/decisions/data.png'>
        </section>
    
        <section data-markdown>
        <textarea data-template>
### Challenge for traditional neural networks

How would you solve sequence to sequence translation?

Simple and theoretical example: addition digit by digit

```
216
+648
===
864
```


What is the challenge?
        </textarea>
    </section>
                        

    <section>
        <h3>Motivation</h3>
        <p>Traditional Networks have no memory of previous events</p>
        <p>Number to Number enconding needs to factor in carry</p>
    </section>

        
    <section data-markdown>
        <textarea data-template>
### Solution: RNNs - Networks with Loops
<img src='img/nlp/colah/RNN-rolled.png' height="450px">

<small>
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
</small>
        </textarea>
    </section>
        
    <section data-markdown>
        <textarea data-template>
### Unrolling the loop
<img src='img/nlp/colah/RNN-unrolled.png'>

<small>
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
</small>
        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### Simple RNN

<img src='img/nlp/fchollet_rnn.png'>

<script type="math/tex; mode=display">
output_t = \tanh(W input_t + U output_{t-1} + b)
</script>

<small>
<a href="https://livebook.manning.com/#!/book/deep-learning-with-python/chapter-6/129">
Deep Learning with Python, Chapter 6, François Chollet, Manning            
</a>

</small>

</textarea>
</section>

    <section data-markdown>
            <textarea data-template>
### Generating musical sequences        

Training a latent space and generating a new sequences

<img src='img/nsynth-ae.png'>

<small>
https://magenta.tensorflow.org/music-vae
</small>
</textarea>
</section>
    
    <section data-markdown>
            <textarea data-template>
### Also perfect for natural language Sequence to Sequence translations

<img src='img/nlp/encdec.jpg'>

<small>
https://www.tensorflow.org/tutorials/seq2seq
</small>
</textarea>
</section>
    <section data-markdown>
            <textarea data-template>
### Encoding addition as seq2seq

<img src='img/nlp/rnn-adder-input.png' height="500px">
                </textarea>
                </section>
    
    <section data-markdown>
            <textarea data-template>
### Each time step generates a digit of the result

<img src='img/nlp/rnn-adder-output.png' height="500px">
                </textarea>
                </section>

<section data-markdown>
    <textarea data-template>
### Transforming Text into Vectors of numerical values
    
Making it accessible to Machine Learning

Only numerical values can be processed by most machine learning algorithms

</textarea>
</section>

    <section data-markdown>
    <textarea data-template>
### Seeing the network at work in a notebook


```
Input: "216+648"
Output: "864"
```

Padding is handled by using a repeated sentinel character (space)

<small>
Notebook: https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/rnn-add-example.ipynb
<br>
https://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Exercise

_Run the notebook and make experiments_

* Reverse the sequence of time stamps (there is a flag for it) - why might this be beneficial?
* Change the encoding of the input, maybe just a single character per time stamp

Can you improve on the results?
<small>
https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/rnn-add-example.ipynb
</small>        
    </textarea>
</section>


<section data-markdown>
        <textarea data-template>
### Example Application: Using sequences of events
<img src='img/magenta-rnn-duck.png' height="400px">

<small>
https://twitter.com/random_forests/status/987394050914385927
<br>
https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html
</small>
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
### Main issues with RNNs

_Vanishing or exploding gradient problem:_
* Each step in training applies the same weights to the output, also in back-propagation  
* The further we move backwards, the bigger (explodes) or smaller (vanishes) the gradient becomes

<small>
https://towardsdatascience.com/learn-how-recurrent-neural-networks-work-84e975feaaf7
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Intution of effect

_Effectively long term memory does not work:_

* RNNs experiences difficulty in memorising words from far away in the sequence
* Predictions based on most recent words only

<small>
    https://towardsdatascience.com/learn-how-recurrent-neural-networks-work-84e975feaaf7
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### GRU (Gated Recurrent Unit) / LSTMS (Long short-term memory)

_allow past information
to be reinjected at a later time, thus fighting the vanishing-gradient problem_

<small>
https://en.wikipedia.org/wiki/Long_short-term_memory
<br>            
<a href="https://www.manning.com/books/deep-learning-with-python">
    Deep Learning with Python, Chapter 6.2.2, François Chollet, Manning            
</a>            
https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be
<br>
<br>
https://datascience.stackexchange.com/questions/14581/when-to-use-gru-over-lstm
<br>
<br>
https://arxiv.org/ftp/arxiv/papers/1701/1701.05923.pdf
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## NLP
        </textarea>
        </section>


<section data-markdown>
    <textarea data-template>
### What is Natural Language Processing (NLP)?

Natural language processing (NLP) is the skill of a machine to understand and process human language within the context
in which it is spoken.

<small>
https://www.smartdatacollective.com/natural-language-processing-essential-element-ai/    
</small>
    </textarea>
</section>

<section data-markdown style="font-size: xx-large">
    <textarea data-template>
### Applications of NLP

* _Machine Translation_: automatic translation of one human language into another
* _Name Entity Recognition (NER)_: recognizing and identifying proper names and types (person, location or an organization) in text
* _Optical Character Recognition (OCR)_: text from the image of the printed text
* _Question-Answer Session_: determine the answer to a question asked in human language
* _Topic Segmentation_: separate text into parts being related to a specific topic
* _Speech Recognition_: convert spoken lanuage to its corresponding textual representation
* _Sentiment Analysis_: judge emotions in texts

https://www.smartdatacollective.com/natural-language-processing-essential-element-ai/    
    </textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Motivation: What makes text and sequences so different?
<img src="img/tf/audio-image-text.png">

<small>
https://www.tensorflow.org/tutorials/word2vec
</small>
        </textarea>
</section>

<section data-markdown>
        <textarea data-template>
### One Hot Encoding
<img src="img/nlp/acolyer/word2vec-one-hot.png">
<small>
https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/
</small>
        </textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Limitations of One Hot Encoding / Bag of Words

* Positions and context of words get lost
* No notion of semantics to words

    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src="img/nlp/word_embeddings.png" height="550px">

<small>
<a href="https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.1-using-word-embeddings.ipynb">
Deep Learning with Python
</a>
</small>
    </textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Visualizing Embeddings

<a href='https://projector.tensorflow.org'>
<img src="img/nlp/embedding-projector.png" height="500px">
</a>

<small>
https://projector.tensorflow.org
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Exercise: Get an intuition for Word Embeddings

* Switch to T-SNE projections
* Zoom into a cluster
* Have a look at the words in the cluster
* Are they semantically related?

<small>
https://projector.tensorflow.org
</small>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Classic Application: Sentiment Analysis in Written Texts

<small>
https://en.wikipedia.org/wiki/Sentiment_analysis
</small>

Generally speaking, sentiment analysis aims to determine the attitude of a speaker, writer, or other subject with respect
to some topic or the overall contextual polarity or emotional reaction to a document, interaction, or event.

_Example: Does a Tweet mention something negative about my company?_

        </textarea>
    </section>

            <section>
                <h3>Cloud Natural Language: Google's ML API for Speech</h3>
                <img src="img/screenshot_sentiment_analysis.png">
                <p><small><a target="_blank" href="https://cloud.google.com/natural-language/">
                    https://cloud.google.com/natural-language/
                </a></small></p>
            </section>
                    

<section data-markdown>
        <textarea data-template>
## Creating our very own sentiment analyzis
### Using embeddings to train recurrent networks

Notebooks:
<small>
* https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/2-rnn.ipynb
* https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/2-lstm.ipynb
* https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/3-gru-dropout.ipynb (final version avoiding overfitting)

</small>
   
        </textarea>
        </section>

<section data-markdown>
        <textarea data-template>
### Exercise

* Tweak Regularisation
* Make the RNN bidirectional

Can you improve on the results?

https://keras.io/layers/wrappers/#bidirectional

    </textarea>
</section>


<section data-markdown>
        <textarea data-template>
### What's next?

<img src='img/colah-next.png'>

<small>
https://distill.pub/2016/augmented-rnns/
<br>
Attention is all you need: https://arxiv.org/pdf/1706.03762.pdf
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Neural Machine Translation with Attention

_Using TensorFlow and Keras_

<img src='img/nmt-attention-twitter.png' height="400">

<small>
https://twitter.com/dennybritz/status/1011464747877838848/
</small>
</textarea>
</section>

<section data-markdown style="font-size: xx-large">
    <textarea data-template>
### Finding data sets to play with
    
* Google released a search engine for datasets: https://t.co/HSFhz8RyYL
  * Launch blog post: https://t.co/dkFseCu3mB
  * https://twitter.com/domoritz/status/1037419117504999424
* Kaggle Datasets: https://www.kaggle.com/datasets    
    </textarea>
    </section>
    



    </div>

</div>

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>
<script src="lib/jquery-2.2.4.js"></script>

<script>
        if (window.location.hostname.indexOf('localhost') !== -1 && !printMode) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }
        Reveal.addEventListener( 'ready', function( event ) {
            // do we want this???
            $('li').addClass('fragment')

            if (window.location.hostname.indexOf('localhost') !== -1) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
            // applies to all versions
            $('code').addClass('line-numbers');

            // make all links open in new tab
            $('a').attr('target', '_blank')

        } );
        // $('section').attr('data-background-image', "backgrounds/light-metal.jpg");
        // $('section').attr('data-background-image', "backgrounds/pink.jpg");
        $('section').attr('data-background-image', "backgrounds/white.jpg");
        // $('section').attr('data-background-image', "backgrounds/murmel2.jpg");
        // $('section').attr('data-background', "img/manning/background/m0.jpg");
        // $('section').attr('data-background', "img/manning/background/m1.jpg");
        // $('section:not([data-background])').attr('data-background', "img/manning/background/m1.jpg");
        // $('section').attr('data-background-size', "1620px");

    //    $('section').attr('data-background-image', "backgrounds/code.jpg");
    </script>
    
<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: false,
        history: true,
        center: true,
        width: 1100,

        transition: 'fade', // none/fade/slide/convex/concave/zoom

        math: {
            mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true},
            // https://github.com/mikemiles86/reveal-line-numbers
            {src: 'lib/js/line-numbers.js'},
            { src: 'reveal.js/plugin/math/math.js', async: true }
        ]
    });

</script>

</body>
</html>
