<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>DL Workshop</title>

    <meta name="description" content="Manning Course Material">
    <meta name="author" content="Oliver Zeigermann">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
      
          <!-- Code syntax highlighting -->
          <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              .beginning:before {
                  content: 'BEGINNING';
              }
              .beginning {
                color: red !important;
              }
              .end:before {
                  content: 'END';
              }
              .end {
                color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }
      
                      .reveal h2,
                      .reveal h3,
                      .reveal h4 {
                          letter-spacing: 2px;
                          font-family: 'Calibri', sans-serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          font-weight: bold;
                          color: black;
                          font-style: italic;
                          letter-spacing: -2px;
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
                      .reveal .step-subtitle h1 {
                          letter-spacing: 1px;
                      }
                      .reveal .step-subtitle h2,
                      .reveal .step-subtitle h3 {
                          text-transform: none;
                          font-style: italic;
                          font-weight: normal;
                          /* font-weight: 400; */
                          /* font-family: 'Amiri', serif; */
                          font-family: 'Lobster', serif;
                          letter-spacing: 1px;
                          color: #2aa198;
                          text-decoration: underline;
                      }
      
                      .reveal .front-page h1,
                      .reveal .front-page h2 {
                          font-family: "League Gothic";
                          font-style: normal;
                          text-transform: uppercase !important;
                          letter-spacing: 1px;
                      }
      
                      .reveal .front-page h1 {
                          font-size: 2.5em !important;
                      }
      
                      .reveal .highlight {
                          background-color: #D3337B;
                          color: white;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }
          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>


<div class="reveal">
    <div class="slides">

<!-- Dieser Workshop ist für Einsteiger in Deep Learning gedacht, die einen realistischen Einblick in die Entwicklung mit TensorFlow und Keras erhalten möchten.

Im ersten Teil lernst du die Grundbegriffe des Deep Supervised Learnings kennen und wie Neuronale Netze aufgebaut sind. Hier werden wir mit dem TensorFlow Playground arbeiten.

Im zweiten Teil trainieren wir dann ein Neuronales Netzwerk. Wir wählen dafür ein praxisnahes Beispiel aus und gehen so
vor, wie Sie es auch bei einer echten Problemstellung machen würden. Dies machen wir anhand von Python-Code, der in
Colab Notebooks läuft. Zum Einsatz kommen Keras und TensorFlow.

Im dritten Teil gucken wir uns weitere Anwendungsgebiete an. Mit dabei sein werden Bilderkennung und Textklassifikation.

Am Ende setzen wir unser trainiertes Modell produktiv. Wir werden uns unterschiedliche Arten der Produktivsetzung
ansehen: Google Cloud ML, TensorFlow Serving und TensorFlow.js. Die Installation der notwendigen Software ist zum Teil
sehr komplex, daher werden wir zur Produktivsetzung keine Übung haben.

Alle Software wird im Browser laufen, daher brauchen Sie als Vorbereitung nur eine aktuelle Version des Chrome-Browsers
und ein Google-Nutzerkonto (kann auch während des Kurses angelegt werden).

Agenda
ab 8.30 Uhr Registrierung und Begrüßungskaffee

9.30 Uhr Beginn

Was ist die Idee von Deep Supervised Learning?
Wie funktioniert ein Fully Connected Feed-Forward Netzwerk?
Was ist Klassifikation und wie macht man das mit Neuronalen Netzwerken?
Was ist Overfitting? Was Underfitting?

11.00 - 11.15 Uhr: Kaffeepause

Training eines Neuronalen Netzwerks mit TensorFlow und Keras

12.30 - 13.30 Uhr: Mittagspause

Optimierung und unseres Netzwerks, um Overfitting zu verhindern
Produktivsetzung mit Google Cloud ML, TensorFlow Serving und TensorFlow.js

15.30 - 15.45 Uhr: Kaffeepause

Neuronale Netzwerke (CNNs) für Bildverarbeitung (Grundlagen)
Recurrente Neuronale Netzwerke (RNNs) für Sequenzen und Textverarbeitung (Grundlagen)

ca. 17.00 Uhr: Ende -->

<section data-markdown class="preparation">
        <textarea data-template>
### Preparation

* Print Exercises: https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/exercise/manual-decision-boundaries.pdf
    </textarea>
</section>

<section>
    <h2>Einführung in Deep Learning mit TensorFlow und Keras</h2>
    <p><a target="_blank" href="https://www.data2day.de/veranstaltung-7590-einf%E3%BChrung-in-deep-learning-mit-tensorflow-und-keras.html?id=7590">
        data2day, September 2018
    </a></p>
    <h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / 
        <a href="http://twitter.com/djcordhose">@DJCordhose</a>
    </h4>
    <small>
    <a href="https://djcordhose.github.io/ai/2018_d2d_dl_workshop.html">
        https://djcordhose.github.io/ai/2018_d2d_dl_workshop.html</a>
    </small>
</section>

<section data-markdown>
        <textarea data-template>

<img src='img/twitter-fchollet-trend.png' height="500px">            

<small>
https://twitter.com/fchollet/status/1029477656876613632
<br>
https://trends.google.com/trends/explore?cat=1299&date=today%205-y&q=tensorflow,keras,pytorch,caffe,theano
</small>
</textarea>
</section>

<section data-markdown style="font-size: large">
        <textarea data-template>
### Agenda

_9.30 Uhr Beginn_

* Was ist die Idee von Deep Supervised Learning?
* Wie funktioniert ein Fully Connected Feed-Forward Netzwerk?
* Was ist Klassifikation und wie macht man das mit Neuronalen Netzwerken?
* Was ist Overfitting? Was Underfitting?

_11.00 - 11.15 Uhr: Kaffeepause_

* Training eines Neuronalen Netzwerks mit TensorFlow und Keras

_12.30 - 13.30 Uhr: Mittagspause_

* Optimierung und unseres Netzwerks, um Overfitting zu verhindern
* Produktivsetzung mit Google Cloud ML, TensorFlow Serving und TensorFlow.js

_15.30 - 15.45 Uhr: Kaffeepause_

* Neuronale Netzwerke (CNNs) für Bildverarbeitung (Grundlagen)
* Recurrente Neuronale Netzwerke (RNNs) für Sequenzen und Textverarbeitung (Grundlagen)

_ca. 17.00 Uhr: Ende_
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Our Plan for Toady

1. Introduction to Deep Supervised Machine Learning
   1. Why Machine Learning / Our Use Case
   1. Basic Concepts of Machine Learning Using the TensorFlow Playground
1. Deep Neural Networks using TensorFlow and Keras
1. Bringing our Modell into Production
1. Advanced Topics
   1. CNNs
   1. RNNs 
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
## Introduce Yourself, Please
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
## Questions are welcome at any time
        </textarea>
    </section>
    
    <section data-markdown>
            <textarea data-template>
### PART 0
## Overview of Tools
            </textarea>
        </section>

<section data-markdown>
        <textarea data-template>
### TensorFlow and Keras

* https://www.tensorflow.org 
* https://www.tensorflow.org/guide/low_level_intro 
* https://www.tensorflow.org/guide/keras 

        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Colab Notebooks

https://colab.research.google.com
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
### TensorFlow Playground

https://playground.tensorflow.org
            </textarea>
        </section>

            <section data-markdown>
                    <textarea data-template>
### PART I
## Introduction to Deep Supervised Machine Learning
                    </textarea>
                </section>

                <section data-markdown>
                    <textarea data-template>
## Our Use Case / Why Machine Learning
                    </textarea>
                </section>

    <section data-markdown>
        <textarea data-template>
### Objective for this Course

_Imagine we are in the car insurance business and want a system that predicts the risk of accidents for prospective customers_

<img src='img/pixabay/accident-151668_1280.png'>
        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### ML Car Insurance Risk Calculator

<a href='html/calculator.html'>
<img src='img/manning/calculator.png' height="450">
</a>
<!-- <p><small>
    <a href='html/calculator.html' target="_blank">
        https://djcordhose.github.io/ai/html/calculator.html</a></small>
</small></p> -->
</textarea>
    </section>
    
    <section>
            <h3>Example: Customer Data - Risk of Accidents</h3>
            <img src="img/manning/all.png" height="400px" class="fragment">
            <p class="fragment">
                <small>How would you rank me (47) for a car having 100 mph top speed, driving 10k miles per year?</small>
            </p>
        </section>

        <section>
                <h3>Programmer's approach: Code Rules by Hand</h3>
                <div class="fragment">
                <pre><code contenteditable data-trim class="line-numbers python">
if age < 25:
    if speed > 140:
        return red # young people, fast cars: high risk
    else:
        return yellow # young people: medium risk
                    </code></pre>
                </div>
                <div class="fragment">
                <pre><code contenteditable data-trim class="line-numbers python">
if age > 75:
    return red # old people: high risk
                    </code></pre>
                </div>
                <div class="fragment">
                <pre><code contenteditable data-trim class="line-numbers python">
if miles_per_year > 30:
    return red # a lot of driving: high risk
if miles_per_year > 20:
    return yellow #  a bit of driving: medium risk
                    </code></pre>
                </div>
                <div class="fragment">
                <pre><code contenteditable data-trim class="line-numbers python">
return green # otherwise: low risk
                    </code></pre>
                </div>
            </section>

            <section data-markdown>
                    <textarea data-template>
### Plotting the predictions as a background
<img src='img/manning/manual.png' class="fragment" height="450px">

<div class="fragment">
<p><small>approx. 43% predictions correct</small></p>
</div>        
</textarea>
                </section>

    <section data-markdown>
            <textarea data-template>
### How good is this?

<!-- <p class="fragment"><em>How well have we mastered the domain?</em></p> -->

* Is it better than guessing?
* Are all the rules correct?
* Are some missing?
* How would we even know?

        </textarea>
    </section>                    

    <section data-markdown>
            <textarea data-template>
### Our Approach
## Deep Supervised Machine
## Learning
        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
<!-- ### ML rather is research and a bit of engineering than a craft -->
### Machine Learning = Lab Work
<img src='img/ml_is_not_programming.jpg' height="450px">
    </textarea>
    </section>


    <section data-markdown>
            <textarea data-template>
### The model we will create in this course

<img src='img/manning/nn-reg.png' class="fragment" height="450px">

<div class="fragment">
<p><small>up to 80% predictions correct on previously unknown data possible</small></p>
</div>        
</textarea>
        </section>

            <section data-markdown>
            <textarea data-template>
### Classification using Neural Networks

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
<img src='img/manning/classicifation.png' class="fragment" height="450px">
</a>


<div class="fragment">
    <small>
<a href="https://playground.tensorflow.org">
https://playground.tensorflow.org
</a>
</small>

</div>        
</textarea>
        </section>

        <section data-markdown>
                <textarea data-template>
## Basic Concepts of Machine Learning Using the TensorFlow Playground
                </textarea>
            </section>
            
<section data-markdown>
        <textarea data-template>
### Our problem in the TensorFlow Playground

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
<img src="img/manning/classicifation.png" height="500px">
</a>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### How does an artificial neuron work?

http://explained.ai/matrix-calculus/index.html#intro

</textarea>
</section>



<section data-markdown>
        <textarea data-template>
### Affine Function

<img src='img/scans/neuron21.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Example

<img src='img/scans/neuron211.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Hand crafting a classification with a single neuron

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
<img src="img/manning/nn.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise 1 (of 2)
### What kind of decision boundary can a single neuron represent?

* Experiment with the different weights and the bias of our neuron to separate the two classes ‘high risk’ / ‘low risk’.
* Are there limitations to the decision boundaries you can create?

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
https://playground.tensorflow.org
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise 2 (of 2)
### Why does an artificial neuron need a bias?

* Experiment with the Playground
* How does changing the Bias influence the decision boundary? 
* You can change the Bias of the neuron by clicking on the small box on the bottom left corner of the neuron.

<a href="https://playground.tensorflow.org/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.05973&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;discretize_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;playButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">
https://playground.tensorflow.org
</a>

</textarea>
</section>

    <section data-markdown>
        <textarea data-template>
## Activation Functions

Activation functions take a single numerical input and perform a certain mathematical operation on it
        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Activation Function

<img src='img/scans/neuron212.jpg'>

</textarea>
</section>


        <section data-markdown>
        <textarea data-template>
### Step

<img src="img/cnn/step.png" height="450">

<small>switching from zero to one,
    original version simulating transition from passive to active</small>
</textarea>
    </section>

            <section data-markdown>
        <textarea data-template>
### Sigmoid

<img src="img/cnn/sigmoid.png" height="450">

<small>compressing between 0 and 1,
        continuously differentiable version of step function</small>
</textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Hyperbolic Tangent

<img src="img/tanh-activation.png" height="450">

<small>floating from -1 to 1,
        like Sigmoid, but can also be negative</small>
</textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Relu: Rectified Linear Unit

<img src="img/cnn/relu.png" height="450">

<small>negative values zeroed out, positive linear,
        fights vanishing gradient</small>
</textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Complete Example

<img src='img/scans/neuron213.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Fully Connected Feed Forward Networks
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### A more complex example

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=false&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/classification4.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Training with 2 neurons

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=2&amp;seed=0.90689&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=false&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/2nn.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise
_How many neurons do you need to decently separate the two classes from each other?_

* You might have noticed that two neurons do not give good results. 
* Can you figure out a minimal number of neurons to get a good result? 
* As weights and biases are initialized randomly, training results are not deterministic. You might have to train several times.

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=2&amp;seed=0.90689&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=false&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
https://playground.tensorflow.org
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## How does a network learn?
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Determining Error is the key to learning

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=2&amp;seed=0.90689&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=false&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/error.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown id='mse'>
    <textarea data-template>
### Mean Squared Error

<script type="math/tex; mode=display">
MSE = {\frac {1}{n}}\sum _{i=1}^{n}(Y_{i}-{\hat {Y_{i}}})^{2}
</script>

https://en.wikipedia.org/wiki/Mean_squared_error
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### From Error to Optimal Parameters

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/bias-to-loss.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Job of the Optimizer

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/optimizer.png" height="400px">
</a>

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Overfitting

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/overfit.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Underfitting

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/underfit.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sweet Spot

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/sweet-spot.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Sweet Spot Shown by Error

<a class="hide-controls-link" href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/test-sweet-spot.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Overfitting Shown by Error

<a class="hide-controls-link" href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.90689&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=false&amp;stepButton_hide=false&amp;activation_hide=false&amp;problem_hide=true&amp;noise_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=false&amp;regularizationRate_hide=true&amp;percTrainData_hide=false&amp;numHiddenLayers_hide=true&amp;discretize_hide=true">
<img src="img/manning/test-overfit.png" height="400px">
</a>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise
_Train a network on a complex shape_

* Choose the most complex data set (spiral) from the playground (link below) 
* Play with the learning rate, activation function, ratio of training, noise, the number of neurons and also the number of hidden layers. 
* Experiments have shown that 2-3 hidden layers are good rule of thumb. Are you able to create a model that overfits heavily?

<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=spiral&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=40&amp;networkShape=4,2&amp;seed=0.31018&amp;showTestData=true&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;problem_hide=true&amp;regularization_hide=true&amp;batchSize_hide=true&amp;regularizationRate_hide=true">
https://playground.tensorflow.org
</a>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### PART II
## Deep Neural Networks using TensorFlow and Keras
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
### Working with Colab Notebooks

https://colab.research.google.com
            </textarea>
        </section>
    
<section data-markdown>
    <textarea data-template>
### Hands-On
_Run your first Colab Notbook_

* Go to https://colab.research.google.com 
* Sign into your Google account or register a new one 
* Switch on GPU support
* Execute some code cells

https://colab.research.google.com

</textarea>
</section>
    
<section data-markdown>
        <textarea data-template>
## Notebook            
### Getting to know our data

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M3-data.ipynb

    </textarea>
    </section>

<section data-markdown>
    <textarea data-template>
### Exercise
_Change our pairplot to_

* plot more samples 
* reduce the number of variables to the first three (leave out the group) 
* Switch on GPU support
* make the plot a bit larger

Use the help function built into the notebook to explore Seaborns API by typing

<em>sns.pairplot?</em>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
# OPTIONAL
## Notebook            
### Creating a base line

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M3-baseline.ipynb

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
## Encoding our data
        </textarea>
    </section>

 
    <section data-markdown>
            <textarea data-template>
### Data Encoding in Deep Learning
* in Classic Machine Learning selecting and pre-processing is crucial
* Deep Neural Networks often allow to just stick in our data as is
* the rest is done by the first layers of our deep neural network   
* Deep Learning can still benefit from preprocessing and normalizing your data 
* Often you can compensate with more training data

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### What goes in?

<img src='img/scans/data_encoding.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### What comes out?

<img src='img/scans/encoding2.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Role of the Hidden Layer(s)

<img src='img/scans/encoding3.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Animated Powerpoint 

<a href="data-encoding.pptx">
<img src='img/data-encoding.png' height="500">
</a>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
## Notebook            
### Setting Up Our neural Network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M5-nn-intro

    </textarea>
    </section>

<section>
    <h3>Exercise</h3>
    <p>Run through the notebook and make sure it makes sense to you</p>
    <p><em>Can you explain the number of parameters for each layer?</em></p>
    <pre><code contenteditable data-trim class="line-numbers python">
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
hidden1 (Dense)              (None, 50)                200       
_________________________________________________________________
softmax (Dense)              (None, 3)                 153       
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________</code></pre>
<p><em>Add a second layer and increase the number of neurons: do the numbers of parameters still make sense to you?</em></p>
</section>

    
<section data-markdown>
        <textarea data-template>
### Generalization

_We do not have any idea how well our model performs, yet_

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Evaluating our model

* The most important property of a model is if it generalizes well to unknown data
* A machine learning model is of no use if it only works well on the data it has been trained on
  * If it was, the easiest way to achieve this would be a dictionary translating from a set of inputs to the known output
* Conceptually it is a little bit hard to optimize for something you do not know
* So, we introduce a little trick here

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Split known data into training and test

<img class='fragment' src='img/scans/generalization.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Use some training data for validation

<img class='fragment' src='img/scans/generalization1.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Understand Generalization

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M7-nn-training.ipynb

_Stop at exercise_
</textarea>
</section>


<section>
    <h2>Exercise</h2>
    <p><em>Understanding Generalization</em></p>
    <p>Manually cluster areas of different customer types </p>
    <ol>
        <li>
            <em>dark (green)</em>: good customer</li>
        <li><em>light (yellow)</em>: mediocre customers</li>
        <li>
            <em>middle (red)</em>: red customers</li>
    </ol>
    <p>Use a <em>pen</em> and make sure you apply <em>pressure</em> when you draw</p>
</section>

<section>
    <h3>Plot Twist</h3>
    <p>Remenber, <em>Generalisation</em>, not perfect reproduction is the objective</p>
    <ol>
        <li class="fragment">We split existing data into two sets</li>
        <li class="fragment">The test set is on the second page</li>
    </ol>
</section>

<section>
    <h2>Exercise, Part2</h2>
    <p><em>How well did you generalize?</em></p>
    <p>Turn the page to the test set and redraw the lines you printed through from the first page</p>
    <p>What do you think, is this result worse?</p>
    <p>What would you have done differently if you had been given the information about this test set before?</p>
</section>

<section data-markdown>
        <textarea data-template>
## Notebook            
### Train the neural network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M7-nn-training.ipynb

    </textarea>
    </section>


<section data-markdown>
        <textarea data-template>
## Exercise

_Train the model_

* Run the notebook as is
* Adapt the model to your parameters from the previous exercise (or any other model)
* How well does it perform?
* Do you see overfitting?
* Any idea why it performs the way it does?
* Experiment with the parameters you know
    </textarea>
    </section>

<section data-markdown>
    <textarea data-template>
## Regularization
    </textarea>
</section>

<section id='overfitting'>
        <h3>The Issue: Overfitting</h2>
    <div>
    <div style="float: left">
        <img src="img/scans/elements/80_percent.jpg" height="200" class="fragment" data-fragment-index='1'>
        <p>
            <small><em>Training Score</em></small>
        </p>
    </div>
    <div style="float: left" class="fragment" data-fragment-index='5'>
        <img src="img/scans/elements/down.jpg" height="200">
    </div>
    <div style="float: left" class="fragment" data-fragment-index='4'>
        <img src="img/scans/elements/up.jpg" height="200">
    </div>
    <div style="float: left">
            <img src="img/scans/elements/70_percent.jpg" height="225"  class="fragment" data-fragment-index='2'>
            <p>
                <small><em>Test Score</em></small>
            </p>
    </div>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='3'><em>Training and Test scores clearly divert</em></p>

    </section>

    <section data-markdown>
        <textarea data-template>
### Regularization

_Process to counter Overfitting_
            </textarea>
            </section>
    
    <section data-markdown>
        <textarea data-template>
### First approach: Train for less epochs

<img src='img/accuracy.png'>

_Watch where training and validation accuracy diverge and stop training there_


            </textarea>
            </section>
    
<section id='overfitting-capacity'>
        <h3>Second approach: Reduce Capacity of model</h2>
    <div style="float: left; width: 400px" class="fragment" data-fragment-index='1'>
        <img src="img/scans/elements/model-large.jpg" height="200">
        <p>
            <small><em>Original Model</em></small>
        </p>
    </div>
    <div style="float: left; width: 200px" class="fragment" data-fragment-index='2'>
        <br>
        <img src="img/scans/elements/right.jpg">
        <br>
    </div>
    <div style="float: left; width: 500px"   class="fragment" data-fragment-index='3'>
            <br>
            <img src="img/scans/elements/model-small.jpg" height="100">
            <br>
            <br>
            <p>
                <small><em>Smaller Model</em><br>less Hidden Layers, less Neurons per Layer</small>
            </p>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='4'><em>Intuition: Give model less capacity to simply memorize data</em></p>
    </section>

<section id='overfitting-dropout'>
        <h3>Third approach: Use Dropout to only train a certain percentage of neurons per Batch</h2>
    <div style="float: left; width: 400px" class="fragment" data-fragment-index='1'>
        <img src="img/scans/elements/model-large.jpg" height="225">
        <p>
            <small><em>Original Model</em></small>
        </p>
    </div>
    <div style="float: left; width: 200px" class="fragment" data-fragment-index='2'>
        <br>
        <img src="img/scans/elements/right.jpg">
        <br>
    </div>
    <div style="float: left; width: 500px"   class="fragment" data-fragment-index='3'>
            <br>
            <img src="img/scans/elements/model-emsemble.jpg" height="100">
            <br>
            <br>
            <p>
                <small><em>Ensemble of Small Models</em> (each one overfits on its specific batch)<br></small>
            </p>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='4'><em>Intuition: Combination of models makes result more robust</em></p>
    </section>

    <section data-markdown id='overfitting-bn'>
            <textarea data-template>
### Fourth approach: Batch Normalization

<ul>
    <li class="fragment">Subtracts Batch Mean
    <li class="fragment">Multiplies by Standard Deviation     
</ul>

<img src='img/scans/elements/sigmoid.jpg' class="fragment" height="200">
    
<p class="fragment"><em>Intuition: Makes Model robust by adding noise</em></p>

<p class="fragment"><em>Bonus:</em> Lets Model train faster by fighting vanishing gradients</p>

    
    
                </textarea>
                </section>
<section data-markdown>
    <textarea data-template>
### Links Batch Normalization

https://www.quora.com/Is-there-a-theory-for-why-batch-normalization-has-a-regularizing-effect

https://www.quora.com/Why-does-Batch-Normalization-for-deep-Neural-Networks-fix-the-vanishing-gradient-problem

https://stats.stackexchange.com/questions/227114/are-there-any-ways-to-deal-with-the-vanishing-gradient-for-saturating-non-linear

https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras

    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Regularize your neural network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M9-regularization.ipynb

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
## Exercise

_Apply regularizations to your model_

- keep adding regularization to make test and train scores come closer to each other
- this will come at the cost of train scores going down
- if both values start going down you have gone too far
- each experiment takes some time
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Our final model ready for production

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M10-final-model.ipynb.ipynb

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### PART III
## Bringing our Modell into Production
        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### PART IV
## Advanced Topics
        </textarea>
    </section>

    <section data-markdown class="todo">
        <textarea data-template>
### RNN Approach
<img src='img/approach-rnn.jpg'>

            </textarea>
            </section>

<section data-markdown class="todo">
        <textarea data-template>
### Part IV

Jonas Kubilius (@qbilius) tweeted at 6:59 PM on Wed, Sep 05, 2018:
Ever wondered which deep nets were most brain-like? (spoiler: not the best ImageNet models) Check out https://t.co/DOMEA5rjvq and our latest paper https://t.co/NH5248OwIM! Winners: DenseNet-169, ResNet-101 and... CORnet-S - read on... https://t.co/z23WouiBN7
(https://twitter.com/qbilius/status/1037384681480773633?s=03)            
</textarea>
</section>

<section data-markdown class="todo">
        <textarea data-template>
### Part IV

Sean Pedersen (@SeanPedersen96) tweeted at 0:07 AM on Wed, Aug 15, 2018:
Python Colab notebook comparing tf-idf log.-reg., embeddings and LSTM for sentiment analysis done with Scikit-learn & Keras. Feedback is welcome!

https://t.co/gQhNz27kY3

#python #keras #NLP
(https://twitter.com/SeanPedersen96/status/1029489757955534849?s=03)
</textarea>
</section>

<section data-markdown class="todo">
        <textarea data-template>
Optimizer finding its way through the parameter space
- https://twitter.com/zzznah/status/1022233456791703558
- https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/xy2rgb.ipynb#scrollTo=Opq53mH1v8TF
- https://distill.pub/2018/differentiable-parameterizations/
    </textarea>
</section>

<section data-markdown class="todo">
        <textarea data-template>
### Part IV

[]https://twitter.com/Smerity/status/947278008385028096?s=03
	* 
Smerity (@Smerity) tweeted at 2:27 AM on Sun, Dec 31, 2017:


Q: Does anyone have a clue how any of this all really works?
A: Nope! It’s like the Wright brothers + Haskell era of flight.
Something’s obviously working but mostly we’re just bolting bigger engines and wings onto our plane and seeing if it works ^_^
(https://twitter.com/Smerity/status/947278008385028096?s=03)
	* 
Smerity (@Smerity) tweeted at 2:27 AM on Sun, Dec 31, 2017:


I sat down with my parents in Australia over a cup of tea and biscuits and they asked what I actually do. During my explanation I became thoroughly convinced: deep learning is straight up magic. I knew this before but if you actually have to explain it you feel light headed. https://t.co/FUCCYBoC99
(https://twitter.com/Smerity/status/947277980287483905?s=03)
</textarea>
</section>

    <section data-markdown>
        <textarea data-template>
## CNNs
        </textarea>
    </section>

    <section data-markdown style="font-size: large">
        <textarea data-template>
<img src='img/cnn/object-detection.png' height="500px">

https://twitter.com/TensorFlow/status/1039219454398418946    
https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1
https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb
        </textarea>
    </section>
    
    

    <section data-markdown>
        <textarea data-template>
## RNNs
        </textarea>
    </section>

    </div>

</div>

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>
<script src="lib/jquery-2.2.4.js"></script>

<script>
        if (window.location.hostname.indexOf('localhost') !== -1 && !printMode) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }
        Reveal.addEventListener( 'ready', function( event ) {
            // do we want this???
            $('li').addClass('fragment')

            if (window.location.hostname.indexOf('localhost') !== -1) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
            // applies to all versions
            $('code').addClass('line-numbers');

            // make all links open in new tab
            $('a').attr('target', '_blank')

        } );
        // $('section').attr('data-background-image', "backgrounds/light-metal.jpg");
        // $('section').attr('data-background-image', "backgrounds/pink.jpg");
        $('section').attr('data-background-image', "backgrounds/white.jpg");
        // $('section').attr('data-background-image', "backgrounds/murmel2.jpg");
        // $('section').attr('data-background', "img/manning/background/m0.jpg");
        // $('section').attr('data-background', "img/manning/background/m1.jpg");
        // $('section:not([data-background])').attr('data-background', "img/manning/background/m1.jpg");
        // $('section').attr('data-background-size', "1620px");

    //    $('section').attr('data-background-image', "backgrounds/code.jpg");
    </script>
    
<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: false,
        history: true,
        center: true,
        width: 1100,

        transition: 'fade', // none/fade/slide/convex/concave/zoom

        math: {
            mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true},
            // https://github.com/mikemiles86/reveal-line-numbers
            {src: 'lib/js/line-numbers.js'},
            { src: 'reveal.js/plugin/math/math.js', async: true }
        ]
    });

</script>

</body>
</html>
