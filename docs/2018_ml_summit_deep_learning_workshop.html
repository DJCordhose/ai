<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>DL Workshop</title>

    <meta name="description" content="Manning Course Material">
    <meta name="author" content="Oliver Zeigermann">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
      
          <!-- Code syntax highlighting -->
          <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              .beginning:before {
                  content: 'BEGINNING';
              }
              .beginning {
                color: red !important;
              }
              .end:before {
                  content: 'END';
              }
              .end {
                color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }
      
                      .reveal h2,
                      .reveal h3,
                      .reveal h4 {
                          letter-spacing: 2px;
                          font-family: 'Calibri', sans-serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          font-weight: bold;
                          color: black;
                          font-style: italic;
                          letter-spacing: -2px;
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
                      .reveal .step-subtitle h1 {
                          letter-spacing: 1px;
                      }
                      .reveal .step-subtitle h2,
                      .reveal .step-subtitle h3 {
                          text-transform: none;
                          font-style: italic;
                          font-weight: normal;
                          /* font-weight: 400; */
                          /* font-family: 'Amiri', serif; */
                          font-family: 'Lobster', serif;
                          letter-spacing: 1px;
                          color: #2aa198;
                          text-decoration: underline;
                      }
      
                      .reveal .front-page h1,
                      .reveal .front-page h2 {
                          font-family: "League Gothic";
                          font-style: normal;
                          text-transform: uppercase !important;
                          letter-spacing: 1px;
                      }
      
                      .reveal .front-page h1 {
                          font-size: 2.5em !important;
                      }
      
                      .reveal .highlight {
                          background-color: #D3337B;
                          color: white;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }
          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>


<div class="reveal">
    <div class="slides">

<!-- 
Man erzählt sich tolle Dinge von Deep Learning und auch TensorFlow. Die spannendsten Neuerungen basieren auf diesem
Ansatz und dieser Software.

Dazu passend lernst du im ersten Teil dieses Workshops wie Neuronale Netzwerke funktionieren und was du mit ihnen
machen kannst. Wir werden dabei eigene Netzwerke für ein Klassifikationsproblem aufbauen und trainieren.

Im zweiten Teil beschäftigen wir uns mit den besonderen Netzwerkarten für Bilderkennung (CNNs) und
Textklassifikation/Sequenzen (RNNs). Dieser Teil wird durch Notebooks mit TensorFlow und Keras Code unterstützt.

Vorausgesetzt wird grundlegendes Wissen über Machine Learning wie du es z.B. beim Workshop ‚Machine Learning auch für
Dein Projekt‘ erwerben kannst. Du musst nichts auf deinem Rechner installieren, es reicht ein Laptop mit einem
aktuellen Browser, am besten Chrome.
 -->

<section data-markdown class="preparation">
        <textarea data-template>
### Preparation

    </textarea>
</section>

<section>
    <h2>Einführung in Deep Learning</h2>
    <h3> mit TensorFlow und Keras, NNs, CNNs, RNNs, LSTMS/GRUs</h3>
    <p><a target="_blank" href="https://ml-summit.de/machine-learning-basics-and-tools/einfuehrung-in-deep-learning-mit-tensorflow-und-keras-nns-cnns-rnns-lstmsgrus/">
        ML Summit, Berlin, October 2018
    </a></p>
    <h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / 
        <a href="http://twitter.com/djcordhose">@DJCordhose</a> /
        <a href="https://www.embarc.de/ ">embarc GmbH</a>
    </h4>
    <small>
    <a href="https://djcordhose.github.io/ai/2018_ml_summit_deep_learning_workshop.html">
        https://djcordhose.github.io/ai/2018_ml_summit_deep_learning_workshop.html</a>
    </small>
</section>

<section data-markdown>
        <textarea data-template>

<img src='img/twitter-fchollet-trend.png' height="500px">            

<small>
https://twitter.com/fchollet/status/1029477656876613632
<br>
https://trends.google.com/trends/explore?cat=1299&date=today%205-y&q=tensorflow,keras,pytorch,caffe,theano
</small>
</textarea>
</section>

<section data-markdown style="font-size: large">
        <textarea data-template>
### Agenda


_14:00 Uhr: Mittagspause_

* Training eines Neuronalen Netzwerks mit TensorFlow und Keras
* Optimierung und unseres Netzwerks, um Overfitting zu verhindern

_15.30 - 15.45 Uhr: Kaffeepause_

* Neuronale Netzwerke (CNNs) für Bildverarbeitung (Grundlagen)
* Recurrente Neuronale Netzwerke (RNNs) für Sequenzen und Textverarbeitung (Grundlagen)

_ca. 17.30 Uhr: Ende_
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
## Introduce Yourself, Please
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
## Questions are welcome at any time

### First question wins a book
        </textarea>
    </section>
    
    <section data-markdown>
            <textarea data-template>
### PART 0
## Overview of Tools
            </textarea>
        </section>

<section data-markdown>
        <textarea data-template>
### TensorFlow and Keras

* https://www.tensorflow.org 
* https://www.tensorflow.org/guide/low_level_intro 
* https://www.tensorflow.org/guide/keras 

        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### Why Keras High Level API?

<img src='img/why-keras.png' height="450">

<small>
https://twitter.com/karpathy/status/1013244313327681536    
https://twitter.com/martin_wicke/status/1013550466125328384    
</small>
        </textarea>
    </section>


<section data-markdown>
        <textarea data-template>
### Colab Notebooks

https://colab.research.google.com
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
### TensorFlow Playground

https://playground.tensorflow.org
            </textarea>
        </section>

<section data-markdown>
        <textarea data-template>
### PART I
## Deep Neural Networks using TensorFlow and Keras
        </textarea>
    </section>

    <section>
        <h3>Example: Customer Data - Risk of Accidents</h3>
        <img src="img/manning/all.png" height="400px" class="fragment">
        <p class="fragment">
            <small>How would you rank me (47) for a car having 100 mph top speed, driving 10k miles per year?</small>
        </p>
    </section>

<section data-markdown>
            <textarea data-template>
### Working with Colab Notebooks

https://colab.research.google.com
            </textarea>
        </section>
    
<section data-markdown>
    <textarea data-template>
### Hands-On
_Run your first Colab Notbook_

* Go to https://colab.research.google.com 
* Sign into your Google account or register a new one 
* Switch on GPU support
* Execute some code cells

https://colab.research.google.com

</textarea>
</section>
    
<section data-markdown>
        <textarea data-template>
## Notebook            
### Getting to know our data

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M3-data.ipynb

    </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
## How does an artificial neuron work?

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/scans/neuron21.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/scans/neuron211.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/scans/neuron212.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src='img/scans/neuron213.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
## Setting up a complete network from neurons
        </textarea>
    </section>
 
    <section data-markdown>
            <textarea data-template>
### Data Encoding in Deep Learning
* in Classic Machine Learning selecting and pre-processing is crucial
* Deep Neural Networks often allow to just stick in our data as is
* the rest is done by the first layers of our deep neural network   
* Deep Learning can still benefit from preprocessing and normalizing your data 
* Often you can compensate with more training data

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### What goes in?

<img src='img/scans/data_encoding.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### What comes out?

<img src='img/scans/encoding2.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Role of the Hidden Layer(s)

<img src='img/scans/encoding3.jpg'>

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
## Notebook            
### Setting Up Our neural Network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M5-nn-intro.ipynb
    </textarea>
    </section>

<section>
    <h3>Exercise</h3>
    <p>Run through the notebook and make sure it makes sense to you</p>
    <p><em>Can you explain the number of parameters for each layer?</em></p>
    <pre><code contenteditable data-trim class="line-numbers python">
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
hidden1 (Dense)              (None, 50)                200       
_________________________________________________________________
softmax (Dense)              (None, 3)                 153       
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________</code></pre>
<p><em>Add a second layer and increase the number of neurons: do the numbers of parameters still make sense to you?</em></p>
</section>

    
<section data-markdown>
        <textarea data-template>
### Generalization

_We do not have any idea how well our model performs, yet_

</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Evaluating our model

* The most important property of a model is if it generalizes well to unknown data
* A machine learning model is of no use if it only works well on the data it has been trained on
  * If it was, the easiest way to achieve this would be a dictionary translating from a set of inputs to the known output
* Conceptually it is a little bit hard to optimize for something you do not know
* So, we introduce a little trick here

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Split known data into training and test

<img class='fragment' src='img/scans/generalization.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Use some training data for validation

<img class='fragment' src='img/scans/generalization1.jpg'>

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Understand Generalization

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M7-nn-training.ipynb

_Stop at exercise_
</textarea>
</section>


<section data-markdown>
        <textarea data-template>
## Notebook            
### Train the neural network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M7-nn-training.ipynb

    </textarea>
    </section>


<section data-markdown>
        <textarea data-template>
## Exercise

_Train the model_

* Run the notebook as is
* Adapt the model to your parameters from the previous exercise (or any other model)
* How well does it perform?
* Do you see overfitting?
* Any idea why it performs the way it does?
* Experiment with the parameters you know
    </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### Best known model using 2 dimensions

<img src='img/manning/nn-reg.png' height="500">

<p><small>up to 77% predictions correct on previously unknown data possible</small></p>
</textarea>
    </section>



<section data-markdown>
    <textarea data-template>
## Regularization
    </textarea>
</section>

<section id='overfitting'>
        <h3>The Issue: Overfitting</h2>
    <div>
    <div style="float: left">
        <img src="img/scans/elements/80_percent.jpg" height="200" class="fragment" data-fragment-index='1'>
        <p>
            <small><em>Training Score</em></small>
        </p>
    </div>
    <div style="float: left" class="fragment" data-fragment-index='5'>
        <img src="img/scans/elements/down.jpg" height="200">
    </div>
    <div style="float: left" class="fragment" data-fragment-index='4'>
        <img src="img/scans/elements/up.jpg" height="200">
    </div>
    <div style="float: left">
            <img src="img/scans/elements/70_percent.jpg" height="225"  class="fragment" data-fragment-index='2'>
            <p>
                <small><em>Test Score</em></small>
            </p>
    </div>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='3'><em>Training and Test scores clearly divert</em></p>

    </section>

    <section data-markdown>
        <textarea data-template>
### Regularization

_Process to counter Overfitting_
            </textarea>
            </section>
    
    <section data-markdown>
        <textarea data-template>
### First approach: Train for less epochs

<img src='img/accuracy.png'>

_Watch where training and validation accuracy diverge and stop training there_


            </textarea>
            </section>
    
<section id='overfitting-capacity'>
        <h3>Second approach: Reduce Capacity of model</h2>
    <div style="float: left; width: 400px" class="fragment" data-fragment-index='1'>
        <img src="img/scans/elements/model-large.jpg" height="200">
        <p>
            <small><em>Original Model</em></small>
        </p>
    </div>
    <div style="float: left; width: 200px" class="fragment" data-fragment-index='2'>
        <br>
        <img src="img/scans/elements/right.jpg">
        <br>
    </div>
    <div style="float: left; width: 500px"   class="fragment" data-fragment-index='3'>
            <br>
            <img src="img/scans/elements/model-small.jpg" height="100">
            <br>
            <br>
            <p>
                <small><em>Smaller Model</em><br>less Hidden Layers, less Neurons per Layer</small>
            </p>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='4'><em>Intuition: Give model less capacity to simply memorize data</em></p>
    </section>

<section id='overfitting-dropout'>
        <h3>Third approach: Use Dropout to only train a certain percentage of neurons per Batch</h2>
    <div style="float: left; width: 400px" class="fragment" data-fragment-index='1'>
        <img src="img/scans/elements/model-large.jpg" height="225">
        <p>
            <small><em>Original Model</em></small>
        </p>
    </div>
    <div style="float: left; width: 200px" class="fragment" data-fragment-index='2'>
        <br>
        <img src="img/scans/elements/right.jpg">
        <br>
    </div>
    <div style="float: left; width: 500px"   class="fragment" data-fragment-index='3'>
            <br>
            <img src="img/scans/elements/model-emsemble.jpg" height="100">
            <br>
            <br>
            <p>
                <small><em>Ensemble of Small Models</em> (each one overfits on its specific batch)<br></small>
            </p>
    </div>
    <p style="clear: both" class="fragment" data-fragment-index='4'><em>Intuition: Combination of models makes result more robust</em></p>
    </section>

    <section data-markdown id='overfitting-bn'>
            <textarea data-template>
### Fourth approach: Batch Normalization

<ul>
    <li class="fragment">Subtracts Batch Mean
    <li class="fragment">Multiplies by Standard Deviation     
</ul>

<img src='img/scans/elements/sigmoid.jpg' class="fragment" height="200">
    
<p class="fragment"><em>Intuition: Makes Model robust by adding noise</em></p>

<p class="fragment"><em>Bonus:</em> Lets Model train faster by fighting vanishing gradients</p>

                </textarea>
                </section>
<section data-markdown>
    <textarea data-template>
### Links Batch Normalization

https://www.quora.com/Is-there-a-theory-for-why-batch-normalization-has-a-regularizing-effect

https://www.quora.com/Why-does-Batch-Normalization-for-deep-Neural-Networks-fix-the-vanishing-gradient-problem

https://stats.stackexchange.com/questions/227114/are-there-any-ways-to-deal-with-the-vanishing-gradient-for-saturating-non-linear

https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras

    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Regularize your neural network

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M9-regularization.ipynb

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
## Exercise

_Apply regularizations to your model_

- keep adding regularization to make test and train scores come closer to each other
- this will come at the cost of train scores going down
- if both values start going down you have gone too far
- each experiment takes some time
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Notebook            
### Our final model

https://colab.research.google.com/github/djcordhose/deep-learning-crash-course-notebooks/blob/master/U3-M10-final-model.ipynb

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Exercise

_Make some predictions and download your model_

- Check how you would be assessed by our model
- Prediction for my data would look like: ```model.predict(np.array([[100, 47, 10]]))```
- Upload your model to transfer.sh where you can download it from for 14 days
- ```!curl --upload-file insurance.h5 https://transfer.sh```
</textarea>
</section>

    <section data-markdown>
        <textarea data-template>
### PART II
## Other types of neural networks
        </textarea>
    </section>

<section data-markdown>
        <textarea data-template>
### deep learning is straight up magic

<img src='img/state-of-dl.png' height="500">

<small>
https://twitter.com/Smerity/status/947278008385028096
</small>
</textarea>
</section>


    <section>
            <img src='img/applications/decisions/data.png'>
    </section>

    <section data-markdown>
        <textarea data-template>
## CNN - Convolutional neural networks
### Let the GPU burn
        </textarea>
    </section>

        <section>
            <h3>Neural Networks are best for non symbolic data</h3>
            <p>Like classifying images</p>
            <p>Reference:
                    <a href="http://cs231n.github.io/convolutional-networks/" target="_blank">
                         http://cs231n.github.io/convolutional-networks/</a>
            </p>
             
        </section>

        <section>
            <h3>Use of GPU for non symbolic data</h3>
            <img src="albon-gpu-gaming.png">
            <p>
                <small>
                    <a href="https://twitter.com/chrisalbon/status/907028933693947904?s=03" target="_blank">
                        https://twitter.com/chrisalbon/status/907028933693947904?s=03</a>
                </small>
            </p>
        </section>
        
        <section>
            <h3>Why the recent break throughs?</h3>
            <div class="fragment" style="float: left">
                <img src="img/cray2.png" height="250">
                <p>
                    <small>Cray X-MP
                        <br> Supercomputer (1982)</small>
                </p>
            </div>
            <div class="fragment" style="float: left; padding-left: 20px; padding-top: 120px; font-weight: bold">
                x 100.000 =
            </div>
            <div class="fragment" style="float: left">
                <img src="img/titan5.jpg" height="250" style="float: right">
                <p>
                    <small>
                        <br>Titan 5 im Gamer PC (2017)</small>
                </p>
            </div>
        </section>

                <section>
                    <h3>... but we also have</h3>
                    <ol>
                        <li>Smarter Learning Strategies (more hidden layers = Deep Learning, Convolutional Layers)
                        <li>Big Data
                    </ol>
                </section>

        <section>
            <h3>GPUs work in parallel</h3>
            <div class="fragment" style="float: left; padding-left: 100px">
                <img src="img/sequential-knive.jpg" height="400">
                <p><small><em>sequential</em>, <br>slow but flexible</small>
                </p>
            </div>
            <div class="fragment" style="float: right; padding-right: 100px">
                <img src="img/parallel-knive.jpg" height="400">
                <p><small><em>parallel</em>, <br>fast but same operation for all data
                        </small>
                </p>
            </div>
        </section>


<section>
    <h3>Architectures of Convolutional Neural Networks: VGG</h3>
        <img src="img/sketch/vgg.png" height="350px">
        <p>
            <small>There are a number of specialized neural network layers</small>
        </p>
</section>

<!-- <section data-markdown>
    <textarea data-template>
### Classic VGG like Architecture
* we use a VGG like architecture
* based on https://arxiv.org/abs/1409.1556
* basic idea: sequential, deep, small convolutional filters, use dropouts to reduce overfitting
* 16/19 layers are typical
* many architectures are based on that
</textarea>
</section> -->

<section data-markdown>
    <textarea data-template>
### Convolutional Blocks: Cascading many Convolutional Layers having down sampling in between

![Applying filters](http://cs231n.github.io/assets/cnn/cnn.jpeg)

http://cs231n.github.io/convolutional-networks/#conv
</textarea>
</section>

<section data-markdown style="font-size: x-large">
    <textarea data-template>
### Example of a Convolution
![Dog](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/conv/dog.png)
#### Many convolutional filters applied over all channels
![Dog after Convolutional Filters applied](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/conv/dog-conv1.png)
http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html
</textarea>
</section>


<section>
        <h3>How do Convolutions work - Image Kernels</h3>
        <p><small>You might know from Photoshop etc., used in Convolutional Neural Networks</small></p>
        <a href="http://setosa.io/ev/image-kernels/" target="_blank">
            <img src="img/browser/setosa_io_image-kernels.png" height="300px">
        </a>
        <p>
            <small>
                <a href="http://setosa.io/ev/image-kernels/" target="_blank">http://setosa.io/ev/image-kernels/</a>
            </small>
        </p>
    </section>

<section>
    <h3>Experiment with Image Kernels</h3>
    <ol>
        <li class="fragment">How can a matrix of numbers can represent an image? How could you encode color?</li>
        <li class="fragment">Explain the effect the filter kernels Sharpen and Blur have on the sample image - explain the effect of the specific values to the result</li>
        <li class="fragment">Starting from the identity kernel - how can you create a filter that highlights edges on the top of shown digits? What about the bottom?</li>
    </ol>
    <p>
            <small>
                <a href="http://setosa.io/ev/image-kernels/" target="_blank">http://setosa.io/ev/image-kernels/</a>
                <br>
                Sample image: <a 
                href="https://github.com/DJCordhose/speed-limit-signs/raw/master/data/real-world/4/100-sky-cutoff-detail.jpg" target="_blank">
                https://github.com/DJCordhose/speed-limit-signs/raw/master/data/real-world/4/100-sky-cutoff-detail.jpg</a>
                
            </small>
        </p>
</section>
    
<section data-markdown>
    <textarea data-template>
### Downlsampling Layer: Reduces data sizes and risk of overfitting
![Pooling](http://cs231n.github.io/assets/cnn/pool.jpeg)
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Max Pooling
![Max Pooling](http://cs231n.github.io/assets/cnn/maxpool.jpeg)
http://cs231n.github.io/convolutional-networks/#pool
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Standard CNN Architecture

![Performance of CNN Architectures](https://cdn-images-1.medium.com/max/1600/1*kBpEOy4fzLiFxRLjpxAX6A.png)

<small>
https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
    ### Typical Architecture of a CNN 
![VGG architecture](img/sketch/vgg.png)

_The classifier more or less is what we used for our previous example_    
    </textarea>
    </section>

    <section>
            <h3>MNIST - Using a model <em>already trained</em></h3>
            <p>Exploring the different types layers together</p>
            <a href="https://transcranial.github.io/keras-js/#/mnist-cnn" target="_blank">
                <img src="img/browser/keras-browser.png" height="350px">
            </a>
            <p><small>
                <a href="https://transcranial.github.io/keras-js/#/mnist-cnn" target="_blank">https://transcranial.github.io/keras-js/#/mnist-cnn</a>
            </small></p>
        </section>

    <section>
            <h3>Keras layers</h3>

            <p><small>Convolution</small></p>
            <pre><code contenteditable data-trim class="fragment line-numbers javascript">
    model.add(Conv2D(filters=32, padding='same', activation='relu'))
                </code></pre>

                <p><small>Max Pooling</small></p>
                <pre><code contenteditable data-trim class="fragment line-numbers javascript">
model.add(MaxPooling2D())
                </code></pre>
                                    
                <p><small>Flatten 2d to make it accessible to Dense layers</small></p>
            <pre><code contenteditable data-trim class="fragment line-numbers javascript">
model.add(Flatten())
            </code></pre>
        <p>
            <small>
                    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers">
                        https://www.tensorflow.org/api_docs/python/tf/keras/layers
                    </a>
            </small>
        </p>
    </section>
    
    
        
        <section>
            <h3>More complex architecture: Google Inception V3</h3>
            <img src="img/inception_v3_architecture.png" height="400px">
            <p>
                <small>
                    Paper: <a href="https://arxiv.org/abs/1409.4842" target="_blank">Going Deeper with Convolutions</a>
                    <br>
                    <a href="https://stackoverflow.com/questions/39352108/does-the-inception-model-have-two-softmax-outputs" target="_blank">
                    Why two classifiers?</a>
                </small>
            </p>
        </section>

                </section>
        <section data-markdown>
                <textarea data-template>
### Fashion MNINST example

28x28 grayscale images of fashion Items

<img src="img/fashion-mnist-sprite.png" height="300px">

<small>
Tutorial: https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a
<br><br>
Colab Notebook: https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb
</small>
        </textarea>
        </section>
        
        <section data-markdown>
                <textarea data-template>
### Exercise

_Can you improve the model for Fashion MNINST notebook?_

* other/more/less layers
* different Sequence, less/more filters
* prevent overfitting even better 
</textarea>
</section>


    <section data-markdown>
        <textarea data-template>
## RNNs
### Recurrent Neural Networks
        </textarea>
    </section>

    <section>
            <h3>Text and sequences are special</h3>
            <img src='img/applications/decisions/data.png'>
        </section>
    
        <section data-markdown>
        <textarea data-template>
### Challenge for traditional neural networks

How would you solve sequence to sequence translation?

Simple and theoretical example: addition digit by digit

```
216
+648
===
864
```


What is the challenge?
        </textarea>
    </section>
                        

    <section>
        <h3>Motivation</h3>
        <p>Traditional Networks have no memory of previous events</p>
        <p>Number to Number enconding needs to factor in carry</p>
    </section>

        
    <section data-markdown>
        <textarea data-template>
### Solution: RNNs - Networks with Loops
<img src='img/nlp/colah/RNN-rolled.png' height="450px">

<small>
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
</small>
        </textarea>
    </section>
        
    <section data-markdown>
        <textarea data-template>
### Unrolling the loop
<img src='img/nlp/colah/RNN-unrolled.png'>

<small>
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
</small>
        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### Simple RNN

<img src='img/nlp/fchollet_rnn.png'>

<script type="math/tex; mode=display">
output_t = \tanh(W input_t + U output_{t-1} + b)
</script>

<small>
<a href="https://livebook.manning.com/#!/book/deep-learning-with-python/chapter-6/129">
Deep Learning with Python, Chapter 6, François Chollet, Manning            
</a>

</small>

</textarea>
</section>

    <section data-markdown>
            <textarea data-template>
### Generating musical sequences        

Training a latent space and generating a new sequences

<img src='img/nsynth-ae.png'>

<small>
https://magenta.tensorflow.org/music-vae
</small>
</textarea>
</section>
    
    <section data-markdown>
            <textarea data-template>
### Also perfect for natural language Sequence to Sequence translations

<img src='img/nlp/encdec.jpg'>

<small>
https://www.tensorflow.org/tutorials/seq2seq
</small>
</textarea>
</section>
    <section data-markdown>
            <textarea data-template>
### Encoding addition as seq2seq

<img src='img/nlp/rnn-adder-input.png' height="500px">
                </textarea>
                </section>
    
    <section data-markdown>
            <textarea data-template>
### Each time step generates a digit of the result

<img src='img/nlp/rnn-adder-output.png' height="500px">
                </textarea>
                </section>

    <section data-markdown>
    <textarea data-template>
### Seeing the network at work in a notebook


```
Input: "216+648"
Output: "864"
```

Padding is handled by using a repeated sentinel character (space)

<small>
Notebook: https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/rnn-add-example.ipynb
<br>
https://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Exercise

_Run the notebook and make experiments_

* Reverse the sequence of time stamps (there is a flag for it) - why might this be beneficial?
* Change the encoding of the input, maybe just a single character per time stamp

Can you improve on the results?
<small>
https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/rnn-add-example.ipynb
</small>        
    </textarea>
</section>


<section data-markdown>
        <textarea data-template>
### Example Application: Using sequences of events
<img src='img/magenta-rnn-duck.png' height="400px">

<small>
https://twitter.com/random_forests/status/987394050914385927
<br>
https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html
</small>
        </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
### Main issues with RNNs

_Vanishing or exploding gradient problem:_
* Each step in training applies the same weights to the output, also in back-propagation  
* The further we move backwards, the bigger (explodes) or smaller (vanishes) the gradient becomes

<small>
https://towardsdatascience.com/learn-how-recurrent-neural-networks-work-84e975feaaf7
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Intution of effect

_Effectively long term memory does not work:_

* RNNs experiences difficulty in memorising words from far away in the sequence
* Predictions based on most recent words only

<small>
    https://towardsdatascience.com/learn-how-recurrent-neural-networks-work-84e975feaaf7
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### GRU (Gated Recurrent Unit) / LSTMS (Long short-term memory)

_allow past information
to be reinjected at a later time, thus fighting the vanishing-gradient problem_

<small>
https://en.wikipedia.org/wiki/Long_short-term_memory
<br>            
<a href="https://www.manning.com/books/deep-learning-with-python">
    Deep Learning with Python, Chapter 6.2.2, François Chollet, Manning            
</a>            
https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be
<br>
<br>
https://datascience.stackexchange.com/questions/14581/when-to-use-gru-over-lstm
<br>
<br>
https://arxiv.org/ftp/arxiv/papers/1701/1701.05923.pdf
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Motivation: What makes text and sequences so different?
<img src="img/tf/audio-image-text.png">

<small>
https://www.tensorflow.org/tutorials/word2vec
</small>
        </textarea>
</section>

<section data-markdown>
        <textarea data-template>
### One Hot Encoding
<img src="img/nlp/acolyer/word2vec-one-hot.png">
<small>
https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/
</small>
        </textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Limitations of One Hot Encoding / Bag of Words

* Positions and context of words get lost
* No notion of semantics to words

    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src="img/nlp/word_embeddings.png" height="550px">

<small>
<a href="https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.1-using-word-embeddings.ipynb">
Deep Learning with Python
</a>
</small>
    </textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Visualizing Embeddings

<a href='https://projector.tensorflow.org'>
<img src="img/nlp/embedding-projector.png" height="500px">
</a>

<small>
https://projector.tensorflow.org
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Exercise: Get an intuition for Word Embeddings

* Switch to T-SNE projections
* Zoom into a cluster
* Have a look at the words in the cluster
* Are they semantically related?

<small>
https://projector.tensorflow.org
</small>

</textarea>
</section>


<section data-markdown>
        <textarea data-template>
## Creating our very own sentiment analysis
### Using embeddings to train recurrent networks

Notebooks:
<small>
* https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/2-rnn.ipynb
* https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/2-lstm.ipynb
* https://colab.research.google.com/github/djcordhose/ai/blob/master/notebooks/nlp/3-gru-dropout.ipynb (final version avoiding overfitting)

</small>
   
        </textarea>
        </section>

<section data-markdown>
        <textarea data-template>
### Exercise

* Tweak Regularisation
* Make the RNN bidirectional

Can you improve on the results?

https://keras.io/layers/wrappers/#bidirectional

    </textarea>
</section>


<section data-markdown>
        <textarea data-template>
### What's next?

<img src='img/colah-next.png'>

<small>
https://distill.pub/2016/augmented-rnns/
<br>
Attention is all you need: https://arxiv.org/pdf/1706.03762.pdf
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Neural Machine Translation with Attention

_Using TensorFlow and Keras_

<img src='img/nmt-attention-twitter.png' height="400">

<small>
https://twitter.com/dennybritz/status/1011464747877838848/
</small>
</textarea>
</section>


    </div>

</div>

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>
<script src="lib/jquery-2.2.4.js"></script>

<script>
        if (window.location.hostname.indexOf('localhost') !== -1 && !printMode) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }
        Reveal.addEventListener( 'ready', function( event ) {
            // do we want this???
            $('li').addClass('fragment')

            if (window.location.hostname.indexOf('localhost') !== -1) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
            // applies to all versions
            $('code').addClass('line-numbers');

            // make all links open in new tab
            $('a').attr('target', '_blank')

        } );
        // $('section').attr('data-background-image', "backgrounds/light-metal.jpg");
        // $('section').attr('data-background-image', "backgrounds/pink.jpg");
        $('section').attr('data-background-image', "backgrounds/white.jpg");
        // $('section').attr('data-background-image', "backgrounds/murmel2.jpg");
        // $('section').attr('data-background', "img/manning/background/m0.jpg");
        // $('section').attr('data-background', "img/manning/background/m1.jpg");
        // $('section:not([data-background])').attr('data-background', "img/manning/background/m1.jpg");
        // $('section').attr('data-background-size', "1620px");

    //    $('section').attr('data-background-image', "backgrounds/code.jpg");
    </script>
    
<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: false,
        history: true,
        center: true,
        width: 1100,

        transition: 'fade', // none/fade/slide/convex/concave/zoom

        math: {
            mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true},
            // https://github.com/mikemiles86/reveal-line-numbers
            {src: 'lib/js/line-numbers.js'},
            { src: 'reveal.js/plugin/math/math.js', async: true }
        ]
    });

</script>

</body>
</html>
