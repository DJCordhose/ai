<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Deep Machine Learning</title>

    <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
    <meta name="author" content="Hakim El Hattab">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
      
          <!-- Code syntax highlighting -->
          <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }
      
                      .reveal h2,
                      .reveal h3,
                      .reveal h4 {
                          letter-spacing: 2px;
                          font-family: 'Amiri', serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          font-weight: bold;
                          font-style: italic;
                          letter-spacing: -2px;
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
                      .reveal .step-subtitle h1 {
                          letter-spacing: 1px;
                      }
                      .reveal .step-subtitle h2,
                      .reveal .step-subtitle h3 {
                          text-transform: none;
                          font-style: italic;
                          font-weight: normal;
                          /* font-weight: 400; */
                          /* font-family: 'Amiri', serif; */
                          font-family: 'Lobster', serif;
                          letter-spacing: 1px;
                          color: #2aa198;
                          text-decoration: underline;
                      }
      
                      .reveal .front-page h1,
                      .reveal .front-page h2 {
                          font-family: "League Gothic";
                          font-style: normal;
                          text-transform: uppercase !important;
                          letter-spacing: 1px;
                      }
      
                      .reveal .front-page h1 {
                          font-size: 2.5em !important;
                      }
      
                      .reveal .highlight {
                          background-color: #D3337B;
                          color: white;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }
          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

<div class="reveal">
    <div class="slides">

<section class="preparation">
<pre>
- TS Playground Übung selbst machen
- Toolbox ausprobieren und Übung selbst machen


- Add Star Treck Background Noise: https://youtu.be/ZPoqNeR3_UA 
- Use Hourglass to show remaining time

</pre>
</section>

        <section>
            <h2>Neural Networks and Deep Learning</h2>
            <h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / <a href="http://twitter.com/djcordhose">@DJCordhose</a>
            </h4>
            <a href="https://djcordhose.github.io/ai/2018_haw_ml_nn.html">
                https://djcordhose.github.io/ai/2018_haw_ml_nn.html</a>
        </section>

        <section class="todo local">
<pre>
- js.tensorflow im Codepen für mninst Beispiel    
- wie funktioniert categorical_crossentropy, Algorithm
- Distill Pub (https://distill.pub/2018/building-blocks/) als Praktikum: Also Erklärung wie CNNs funktionieren
- https://beta.observablehq.com/@nsthorat/visualizing-activations-of-mobilenet-with-tensorflow-js
- Convert mninst to observablehq notebook if possible https://beta.observablehq.com/@zaidalyafeai/an-intractive-introduction-to-tensorflow-js
</pre>
        </section>

        <section data-markdown>
                <textarea data-template>
<img src='img/dl_paper_2018.png' height="550px">

<small>
https://twitter.com/dennybritz/status/984972760039342082
</small>        
</textarea>
</section>
        <section data-markdown>
                <textarea data-template>
### Glossary

There are quite a few terms already and many more to come

https://developers.google.com/machine-learning/crash-course/glossary        
</textarea>
</section>

<section>
    <h2>The Artificial Neuron</h2>
    <p>The basis of Neural Networks</p>
</section>
        <section>
            <h3>How does an artificial neuron work?</h3>
                <div class="fragment">
                    <img src="img/sketch/neuron.jpg" height="550px">
                </div>
        </section>

    <section data-markdown>
    <textarea data-template>
### Activation Functions

An activation function (or non-linearity) takes a single number and performs a certain fixed mathematical operation on it.

http://cs231n.github.io/neural-networks-1/#actfun
</textarea>
</section>

        <section>
            <p>There are several activation functions you may encounter in practice:</p>
        </section>
        <section>
            <h3>Step</h3>
            <img src="img/cnn/step.png" height="400px">
            <p>original version simulating transition from passive to active</p>
        </section>

        <section>
            <h3>Sigmoid</h3>
            <img src="img/cnn/sigmoid.png" height="400px">
            <p>continuously differentiable version of step function</p>
        </section>

        <section>
            <h3>Relu: Rectified Linear Unit</h3>
            <img src="img/cnn/relu.png" height="400px">
            <p>Mostly used for Convolutional Networks (more later)</p>
        </section>

        <section>
            <h3>Artificial neuron to neural networks</h3>
                <div class="fragment">
                    <img src="img/sketch/neuron_to_layers.jpg" height="550px">
                </div>
        </section>

        <section data-markdown>
                <textarea data-template>
<img src='img/flashcards/Basic_Parts_Of_Deep_Learning_print.png'>
            </textarea>
            </section>
                            
        <section>
            <img src="img/flashcards/Architecture_Of_A_Neural_Network_print.png">
        </section>

        <section>
            <p>In Theory a single hidden can approximate any function</p>
            <p>In practice 2-3 hidden layers seem optimal</p>
            <p>Convolutional Networks often have more than 100 layers (more on that later)</p>
                        <p>
                            <small>
                                <a href="http://cs231n.github.io/neural-networks-1/#power">
                                     http://cs231n.github.io/neural-networks-1/#power
                                </a>
                            </small>
                        </p>

         
        </section>


                <section>
                    <h3>Tensorflow Playground</h3>
                    <p>Understanding the Basics of Neural Networks</p>
                    <a href="http://playground.tensorflow.org" target="_blank">
                        <img src="img/browser/playground.png">
                    </a>
                    <p>
                        <a href="http://playground.tensorflow.org" target="_blank">http://playground.tensorflow.org</a>
                    </p>
                </section>
                
    <section>
        <h3>Experiment</h3>
        <p>Make some sense of artificial neurons and neural networks using the TensorFlow Playground</p>
        <ol>
            <li class="fragment">What can you do with a single neuron and why?</li>
            <li class="fragment">Configure a minimal network to deliver a good result on the initial data set</li>
            <li class="fragment">Get an intuition for the learning rate - can you change the learning rate in such a way the network no longer trains properly?</li>
        </ol>
        <p>
            <a href="http://playground.tensorflow.org" target="_blank">http://playground.tensorflow.org</a>
        </p>
    </section>

    <section>
            <h3>Applying Deep Neural Networks to our problem</h3>
            <p>Using TensorFlow</p>
            <img src='img/tf.png'>
            <a href="https://www.tensorflow.org/" target="_blank">https://www.tensorflow.org/</a>
        </section>

        <section>
                <img src="img/flashcards/Tensors_print.png" height="550px">
                <p><small><a target="_blank" href="https://towardsdatascience.com/linear-algebra-for-deep-learning-f21d7e7d7f23">
                    Tensors and Operations on them
                </a></small></p>
        </section>
    
        <section>
                <h3>A sample architecture using 2 fully connected hidden layers</h3>
                <pre><code contenteditable data-trim class="fragment line-numbers python">
inputs = Input(name='input', shape=(3, ))
                </code></pre>
                <pre><code contenteditable data-trim class="fragment line-numbers python">
x = Dense(100, name='hidden1', activation='relu')(inputs)
x = Dense(100, name='hidden2', activation='relu')(x)
                </code></pre>
            </section>

            <section>
                    <h3>Softmax: Categories with likelyhoods</h3>
                        <div class="fragment">
                            <img src="img/sketch/fc_nn.jpg" height="450px">
                        </div>
                <pre><code contenteditable data-trim class="line-numbers python fragment">
predictions = Dense(3, name='softmax', activation='softmax')(x)
                </code></pre>
                </section>
        
                <section>
                    <h3>Where is the cost / loss / error?</h3>
                    <p class="fragment">The loss is calculated from the difference between the softmax output and the known true category</p>
                    <p class="fragment"><code>categorical_crossentropy</code> is the algorithm to calculate this loss</p>
                            <pre><code contenteditable data-trim class="fragment line-numbers python">
model = Model(input=inputs, output=predictions)
model.compile(optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy'])
                            </code></pre>
                    <p class="fragment"><code>adam</code> is the algorithm to minimize loss</p>
                </section>
                            
    <section>
        <h3>Bringing it all together</h3>
                <pre><code contenteditable data-trim class="fragment line-numbers python">
# splitting test from training data
X_train, X_test, y_train, y_test = 
    train_test_split(X, y, test_size=0.4)
                </code></pre>
                <pre><code contenteditable data-trim class="fragment line-numbers python">
# convert the numerical encoding of category
#  to one hot to match softmax
y_train_categorical = to_categorical(y_train, 3)
            </code></pre>
                <pre><code contenteditable data-trim class="fragment line-numbers python">
# kick off training for 1000 iterations
model.fit(X_train, y_train_categorical, epochs=1000)
                </code></pre>
    </section>
    
            <section>
                <h3>What does the neural network learn?</h3>
                <p class="fragment">All the weights of a the neurons</p>
                <pre><code contenteditable data-trim class="fragment line-numbers python">
model.summary()</code></pre>
                <pre><code contenteditable data-trim class="fragment line-numbers python">
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 3)                 0         
_________________________________________________________________
hidden1 (Dense)              (None, 100)               400       
_________________________________________________________________
hidden2 (Dense)              (None, 100)               10100     
_________________________________________________________________
softmax (Dense)              (None, 3)                 303       
=================================================================
Total params: 10,803
Trainable params: 10,803
Non-trainable params: 0
_________________________________________________________________</code></pre>
            </section>

            <section>
                    <img src="img/flashcards/Learning_Rate_print.png">
                </section>


        
            <section>
                <h3>Visualizing the learning Process</h3>
                <p>(Stochastic) Gradient Descent (SGD)</p>
                <p><small>Minimizing the error by changing the trainable parameters</small></p>
                <p><small>For just 2 parameters you can image a scenary with hills and you try to find the deepest valley</small></p>
                <a href="http://www.benfrederickson.com/numerical-optimization/" target="_blank">
                    <img src="img/browser/screenshot-numerical-optimizaion.png" height="250px">
                </a>
                <p>
                    <small>
                        <a href="http://www.benfrederickson.com/numerical-optimization/" target="_blank">http://www.benfrederickson.com/numerical-optimization/</a>
                    </small>
                </p>
                <p>
                    <small>A too high learning rate might miss the mimimum, a too low one might be slow
                    </small>
                </p>
            </section>

            <section data-markdown>
                    <textarea data-template>
### Which parameter to change?
<img src='img/flashcards/Partial_Derivative_print.png' height="550px">
                </textarea>
                </section>
                                

            <!-- <section>
                <h3>More on SGD</h3>
                <img src="img/sgd.png">
                <p>
                    <small>
                        <a href="https://towardsdatascience.com/improving-vanilla-gradient-descent-f9d91031ab1d">
                         https://towardsdatascience.com/improving-vanilla-gradient-descent-f9d91031ab1d</a>

                    </small>
                </p>
                 
            </section> -->

    <section>
        <img src="img/flashcards/BackProp_print.png">
    </section>
    <section>
        <h3>Regularization: Avoid Overfitting</h3>
    </section>

    <section>
        <img src="img/flashcards/Dropout_print.png">
    </section>

    <section>
        <img src="img/flashcards/The_Effect_Of_Dropout_On_Hidden_Units_print.png">
    </section>

    <section>
        <pre><code data-trim>
from keras.layers import Dropout

x = Dense(100, name='hidden1', activation='relu')(inputs)
x = Dropout(0.15)(x)
x = Dense(100, name='hidden2', activation='relu')(x)
x = Dropout(0.15)(x)
            </code></pre>
    </section>

<section data-markdown>
    <textarea data-template>
### Install TensorFlow
#### Local Installation depends on OS
* https://www.tensorflow.org/install/

#### Azure Notebooks:
* TensorFlow already installed
</textarea>
</section>

    <section>
        <h3>Shared Programming Exercise</h3>
        <p>Configure a deep neural network to solve our problem</p>
        <ul>
            <li>We Use all available input features (3)</li>
            <li>Change the configured number of neurons per layer</li>
            <li>Add dropout to reduce overfitting</li>
            <li>Change the number of layers</li>
            <li>Can you explain the number of trainable parameters?</li>
            <li>How do you explain the very different decision boundaries per km per year?</li>
        </ul>
        <p>Do your work in <em>4-tf-keras-nn</em>
        </p>
    </section>

    <section>
        <h3>Best known results using Dropout</h3>
        <div class="fragment">
    
            <img src="img/insurance/cnn.png" height="400px">
            <p>
                <small>only approx. 79% accuracy on train data, but also 77% on test data</small>
            </p>
        </div>
        <p class="fragment">Boundaries even more smooth</p>
    </section>

    <section>
        <h3>Matching Model</h3>
        <pre><code data-trim class="python">
drop_out = 0.15

inputs = Input(name='input', shape=(3, ))
x = Dense(100, name='hidden1', activation='relu')(inputs)
x = Dropout(drop_out)(x)
x = Dense(100, name='hidden2', activation='relu')(x)
x = Dropout(drop_out)(x)
x = Dense(100, name='hidden3', activation='relu')(x)
x = Dropout(drop_out)(x)
predictions = Dense(3, name='softmax', activation='softmax')(x)
            </code></pre>
    </section>
        <section>
            <h1>Let the GPU burn</h1>
            <h2>Convolutional neural networks</h2>
        </section>

        <section>
            <h3>Not bad, but: Neural Networks are best for non symbolic data</h3>
            <p>Like classifying images</p>
            <p>Reference:
                    <a href="http://cs231n.github.io/convolutional-networks/" target="_blank">
                         http://cs231n.github.io/convolutional-networks/</a>
            </p>
             
        </section>

        <section>
                <h3>Ansatz nach Art der Daten</h3>
                <img src='img/applications/decisions/data.png'>
        </section>

        <section>
            <h3>Use of GPU for non symbolic data</h3>
            <img src="albon-gpu-gaming.png">
            <p>
                <small>
                    <a href="https://twitter.com/chrisalbon/status/907028933693947904?s=03" target="_blank">
                        https://twitter.com/chrisalbon/status/907028933693947904?s=03</a>
                </small>
            </p>
        </section>
        
        <section>
            <h3>Why the recent break throughs?</h3>
            <div class="fragment" style="float: left">
                <img src="img/cray2.png" height="250">
                <p>
                    <small>Cray X-MP
                        <br> Supercomputer (1982)</small>
                </p>
            </div>
            <div class="fragment" style="float: left; padding-left: 20px; padding-top: 120px; font-weight: bold">
                x 100.000 =
            </div>
            <div class="fragment" style="float: left">
                <img src="img/titan5.jpg" height="250" style="float: right">
                <p>
                    <small>
                        <br>Titan 5 im Gamer PC (2017)</small>
                </p>
            </div>
        </section>

                <section>
                    <h3>... but we also have</h3>
                    <ol>
                        <li>Smarter Learning Strategies (more hidden layers = Deep Learning)
                        <li>Big Data
                    </ol>
                </section>

                <section>
                    <h3>Unfortunately...</h3>
                    <p class="fragment">For all real problems you will need powerful GPU(s)</p>
                    <p class="fragment">And even then you might have to wait several minutes, hours, days, or even weeks for the result of a single training run</p>
                    <p class="fragment">To make matters worse: TensorFlow only supports NVIDIA GPUs and installation of drivers is no fun</p>
                    <p class="fragment"><strong>We restrict ourselves to basic examples on the web that work with any GPU</strong></p>
                </section>

                    <section>
                        <p>Additionally...</p>
                        <img src="img/flashcards/Supervised_Deep_Learning_Rule_Of_Thumb_print.png" height="500px">
                    </section>

<section>
    <h3>Architectures of Convolutional Neural Networks: VGG</h3>
        <img src="img/sketch/vgg.png" height="350px">
        <p>
            <small>There are a number of specialized neural network layers</small>
        </p>
</section>

<section data-markdown>
    <textarea data-template>
### Classic VGG like Architecture
* we use a VGG like architecture
* based on https://arxiv.org/abs/1409.1556
* basic idea: sequential, deep, small convolutional filters, use dropouts to reduce overfitting
* 16/19 layers are typical
* many architectures are based on that
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Convolutional Blocks: Cascading many Convolutional Layers having down sampling in between

![Applying filters](http://cs231n.github.io/assets/cnn/cnn.jpeg)

http://cs231n.github.io/convolutional-networks/#conv
</textarea>
</section>

<section data-markdown style="font-size: x-large">
    <textarea data-template>
### Example of a Convolution
![Dog](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/conv/dog.png)
#### Many convolutional filters applied over all channels
![Dog after Convolutional Filters applied](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/conv/dog-conv1.png)
http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html
</textarea>
</section>

                <section data-markdown>
    <textarea data-template>
### Feature Channels
Each output of a filter operation is called a feature channel.
The deeper the channel the more abstract it is supposed to be.

https://distill.pub/2017/feature-visualization/
https://distill.pub/2018/building-blocks/
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Edges
![Edges](img/cnn/edges.png)
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Textures
![Textures](img/cnn/textures.png)
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Patterns
![Patterns](img/cnn/patterns.png)
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Parts
![Parts](img/cnn/parts.png)
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Objects
![Objects](img/cnn/objects.png)
    </textarea>
</section>

            <section>
                <h3>How do Convolutions work - Image Kernels</h3>
                <p><small>You might know from Photoshop etc., used in Convolutional Neural Networks</small></p>
                <a href="http://setosa.io/ev/image-kernels/" target="_blank">
                    <img src="img/browser/setosa_io_image-kernels.png" height="300px">
                </a>
                <p>
                    <small>
                        <a href="http://setosa.io/ev/image-kernels/" target="_blank">http://setosa.io/ev/image-kernels/</a>
                    </small>
                </p>
            </section>

                <section data-markdown>
    <textarea data-template>
### Relu Activations for CNNs

* Intuition: regions that are not matched by filter are taken out
  * perfect for blacking out everyhing beyond threshold
  * good for CNN to completely take out a feature channel
  * high values from CNN indicate high match, will be passed through
* seems to enable fast learning
* this is just what most people actually uses
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Downlsampling Layer: Reduces data sizes and risk of overfitting
![Pooling](http://cs231n.github.io/assets/cnn/pool.jpeg)
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Max Pooling
![Max Pooling](http://cs231n.github.io/assets/cnn/maxpool.jpeg)
http://cs231n.github.io/convolutional-networks/#pool
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Standard CNN Architecture

![Performance of CNN Architectures](https://cdn-images-1.medium.com/max/1600/1*kBpEOy4fzLiFxRLjpxAX6A.png)

https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba
</textarea>
</section>

        <section>
            <h3>Sample Architecture: Google Inception V3</h3>
            <img src="img/inception_v3_architecture.png" height="400px">
            <p>
                <small>
                    <a href="https://arxiv.org/abs/1409.4842" target="_blank">Going Deeper with Convolutions</a>
                </small>
            </p>
        </section>

<section data-markdown>
    <textarea data-template>
#### VGG and many basic models start with a number of convolutional blocks for feature extraction and ends with a fully connected classifier 
![VGG architecture](img/sketch/vgg.png)
The classifier more or less is what we used for our previous example
</textarea>
</section>


        <section>
            <h3>MNIST - Using a model <em>already trained</em></h3>
            <p>Exploring the different types layers together</p>
            <a href="https://transcranial.github.io/keras-js/#/mnist-cnn" target="_blank">
                <img src="img/browser/keras-browser.png" height="350px">
            </a>
            <p><small>
                <a href="https://transcranial.github.io/keras-js" target="_blank">https://transcranial.github.io/keras-js</a>
            </small></p>
        </section>

            <section>
                <h3>Training a network</h3>
                    <a target="_blank" href="https://deeplearnjs.org/demos/model-builder/">
                <img src="img/deeplearn-model-builder.png" height="500px">
                </a>
            <p>
                <small>
                    <a target="_blank" href="https://deeplearnjs.org/demos/model-builder/">
                         https://deeplearnjs.org/demos/model-builder/</a>
                </small>
            </p>
            </section>
<!-- 
                <section data-markdown  style="font-size: x-large">
                        <textarea data-template>
## Further Reading: How do Neural Networks work inside
- https://distill.pub/2018/building-blocks/
- https://distill.pub/2017/feature-visualization/
- https://research.googleblog.com/2018/03/the-building-blocks-of-interpretability.html
- https://www.nytimes.com/2018/03/06/technology/google-artificial-intelligence.html
- https://twitter.com/enjalot/status/971116427598950400?s=03
- https://github.com/tensorflow/lucid
- https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/tutorial.ipynb
                </textarea>
                </section> -->

                <section style="font-size: xx-large">
                    <h3>Shared Exercise #4</h3>
                    <p>Use tensorflow.js to experiment on the MNIST data set</p>
                    <!-- <p>
                                    <a href="js/mnist" target="_blank">
                                        https://djcordhose.github.io/ai/js/mnist</a>
                        </p>
                    <ol>
                        <li>clone this repository and locate <code>docs/js/mnist</code></li>
                        <li>run a local http server in this folder</li> -->
                        <li>make your changes to <code>model.js</code></li>
                        <li>Experiment with number of epochs (TRAIN_BATCHES), learning rate, and number of filters in convolutional layers</li>
                        <li>Monitor GPU performance using the tools of your OS (try to reach 100% utilization)</li>
                        <li>Advanced: add or remove layers</li>
                    </ol>
                    <p>
                            Reference: 
                                    <a href="https://js.tensorflow.org/api/0.8.0/" target="_blank">
                                        https://js.tensorflow.org/api/0.8.0/</a>
                        </p>
                </section>

                <section>
                        <h3>Diskussion: Auf der Suche nach Intelligenz</h3>
                        <p>Sind die Ansätze intelligent?</p>
                    </section>
    
    </div>

</div>

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>
<script src="lib/jquery-2.2.4.js"></script>

<script>
        if (window.location.hostname.indexOf('localhost') !== -1) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }
        Reveal.addEventListener( 'ready', function( event ) {
            if (window.location.hostname.indexOf('localhost') !== -1) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
            // applies to all versions
            $('code').addClass('line-numbers');
        } );
        // $('section').attr('data-background-image', "backgrounds/light-metal.jpg");
        // $('section').attr('data-background-image', "backgrounds/pink.jpg");
        $('section').attr('data-background-image', "backgrounds/white.jpg");
    //    $('section').attr('data-background-image', "backgrounds/code.jpg");
    </script>
    
<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        transition: 'fade', // none/fade/slide/convex/concave/zoom

        math: {
            mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true},
            // https://github.com/mikemiles86/reveal-line-numbers
            {src: 'lib/js/line-numbers.js'},
            { src: 'reveal.js/plugin/math/math.js', async: true }
        ]
    });

</script>

</body>
</html>
